<!DOCTYPE html><html><head><meta charset="utf-8"><title>Distributed, Parallel, and Cluster Computing  authors/titles recent submissions</title></head><body>
<h2>2020-02-18</h2>
<h3>No. 1	Concurrent Reference Counting and Resource Management in Wait-free  Constant Time</h3><h4>Guy E. Blelloch, Yuanhao Wei</h4> Abstract: A common problem when implementing concurrent programs is efficiently protecting against unsafe races between processes reading and then using a resource (e.g., memory blocks, file descriptors, or network connections) and other processes that are concurrently overwriting and then destructing the same resource. Such read-destruct races can be protected with locks, or with lock-free solutions such as hazard-pointers or read-copy-update (RCU). In this paper we describe a method for protecting read-destruct races with expected constant time overhead, $O(P^2)$ space and $O(P^2)$ delayed destructs, and with just single word atomic memory operations (reads, writes, and CAS). It is based on an interface with four primitives, an acquire-release pair to protect accesses, and a retire-eject pair to delay the destruct until it is safe. We refer to this as the acquire-retire interface. Using the acquire-retire interface, we develop simple implementations for three common use cases: (1) memory reclamation with applications to stacks and queues, (2) reference counted objects, and (3) objects manage by ownership with moves, copies, and destructs. The first two results significantly improve on previous results, and the third application is original. Importantly, all operations have expected constant time overhead. <br><a href = "http://xxx.itp.ac.cn/pdf/2002.07053">PDF</a>
<h3>No. 2	In Search for a Linear Byzantine Agreement</h3><h4>Alexander Spiegelman</h4> Abstract: The long-standing byzantine agreement problem gets more attention in recent years due to the increasing demand for scalable geo-replicated Byzantine state machine replication (SMR) systems (e.g., Blockchains). To date, the key bottleneck of such systems is the communication cost of the byzantine agreement they employ as a building block, which motivates many researchers to search for low-communication byzantine agreement protocols. The conventional approach is to design deterministic protocols in the eventually synchronous communication model that are optimized to reduce the communication cost after the global stabilization time (GST). In this paper, we challenge the conventional approach and argue it is not the best fit for scalable SMR systems since it might induce an unbounded communication cost during asynchronous periods before GST, which we prove to be inherent. Instead, we forgo eventual synchrony and propose a different approach that hopes for the best (synchrony) but prepares for the worst (asynchrony). Accordingly, we design an optimistic protocol that first tries to reach an agreement via an efficient deterministic algorithm that relies on synchrony for termination, and then, only if an agreement was not reached due to asynchrony, the protocol uses a randomized asynchronous algorithm for fallback that guarantees termination with probability $1$. Although randomized asynchronous algorithms are considered to be costly, we design our solution to pay this cost only when an equivalent cost has already been paid while unsuccessfully trying the synchronous protocol. Moreover, we formally prove that our protocol achieves optimal communication complexity under all network conditions and failure scenarios. <br><a href = "http://xxx.itp.ac.cn/pdf/2002.06993">PDF</a>
<h3>No. 3	Simulating Performance of ML Systems with Offline Profiling</h3><h4>Hongming Huang, Peng Cheng, Hong Xu, Yongqiang Xiong</h4> Abstract: We advocate that simulation based on offline profiling is a promising approach to better understand and improve the complex ML systems. Our approach uses operation-level profiling and dataflow based simulation to ensure it offers a unified and automated solution for all frameworks and ML models, and is also accurate by considering the various parallelization strategies in a real system. <br><a href = "http://xxx.itp.ac.cn/pdf/2002.06790">PDF</a>
<h3>No. 4	Byzantine Lattice Agreement in Asynchronous Systems</h3><h4>Xiong Zheng, Vijay Garg</h4> Abstract: We study the Byzantine lattice agreement (BLA) problem in asynchronous distributed message passing systems. In the BLA problem, each process proposes a value from a join semi-lattice and needs to output a value also in the lattice such that all output values of correct processes lie on a chain despite the presence of Byzantine processes. We present an algorithm for this problem with round complexity of $O(\log f)$ which tolerates $f < \frac{n}{5}$ Byzantine failures in the asynchronous setting without digital signatures, where $n$ is the number of processes. We also show how this algorithm can be modified to work in the authenticated setting (i.e., with digital signatures) to tolerate $f < \frac{n}{3}$ Byzantine failures. <br><a href = "http://xxx.itp.ac.cn/pdf/2002.06779">PDF</a>
<h3>No. 5	How fast can you update your MST? (Dynamic algorithms for cluster  computing)</h3><h4>Seth Gilbert, Lawrence Li</h4> Abstract: Imagine a large graph that is being processed by a cluster of computers, e.g., described by the $k$-machine model or the Massively Parallel Computation Model. The graph, however, is not static; instead it is receiving a constant stream of updates. How fast can the cluster process the stream of updates? The fundamental question we want to ask in this paper is whether we can update the graph fast enough to keep up with the stream. We focus specifically on the problem of maintaining a minimum spanning tree (MST), and we give an algorithm for the $k$-machine model that can process $O(k)$ graph updates per $O(1)$ rounds with high probability. (And these results carry over to the Massively Parallel Computation (MPC) model.) We also show a lower bound, i.e., it is impossible to process $k^{1+\epsilon}$ updates in $O(1)$ rounds. Thus we provide a nearly tight answer to the question of how fast a cluster can respond to a stream of graph modifications while maintaining an MST. <br><a href = "http://xxx.itp.ac.cn/pdf/2002.06762">PDF</a>
<h3>No. 6	Running a Pre-Exascale, Geographically Distributed, Multi-Cloud  Scientific Simulation</h3><h4>Igor Sfiligoi, Frank Wuerthwein, Benedikt Riedel, David Schultz</h4> Abstract: As we approach the Exascale era, it is important to verify that the existing frameworks and tools will still work at that scale. Moreover, public Cloud computing has been emerging as a viable solution for both prototyping and urgent computing. Using the elasticity of the Cloud, we have thus put in place a pre-exascale HTCondor setup for running a scientific simulation in the Cloud, with the chosen application being IceCube's photon propagation simulation. I.e. this was not a purely demonstration run, but it was also used to produce valuable and much needed scientific results for the IceCube collaboration. In order to reach the desired scale, we aggregated GPU resources across 8 GPU models from many geographic regions across Amazon Web Services, Microsoft Azure, and the Google Cloud Platform. Using this setup, we reached a peak of over 51k GPUs corresponding to almost 380 PFLOP32s, for a total integrated compute of about 100k GPU hours. In this paper we provide the description of the setup, the problems that were discovered and overcome, as well as a short description of the actual science output of the exercise. <br><a href = "http://xxx.itp.ac.cn/pdf/2002.06667">PDF</a>
<h3>No. 7	Not a COINcidence: Sub-Quadratic Asynchronous Byzantine Agreement WHP</h3><h4>Shir Cohen, Idit Keidar, Alexander Spiegelman</h4> Abstract: King and Saia were the first to break the quadratic word complexity bound for Byzantine Agreement in synchronous systems against an adaptive adversary, and Algorand broke this bound with near-optimal resilience in the eventual-synchrony model. Yet the question of asynchronous sub-quadratic Byzantine Agreement remained open. To the best of our knowledge, we are the first to answer this question in the affirmative. A key component of our solution is a novel shared coin algorithm based on a VRF, without any further trusted setup. A second essential ingredient is VRF-based committee sampling, which we formalize and utilize in the asynchronous model for the first time. Our algorithms work against a delayed-adaptive adversary, which cannot perform after-the-fact removals but has full control of Byzantine processes and full information about communication in earlier rounds. Using committee sampling and our shared coin, we solve Byzantine Agreement with high probability, with a word complexity of $\widetilde{O}(n)$ and $O(1)$ expected time, breaking the $O(n^2)$ bit barrier for asynchronous Byzantine Agreement. <br><a href = "http://xxx.itp.ac.cn/pdf/2002.06545">PDF</a>
<h3>No. 8	Distributed Sketching Methods for Privacy Preserving Regression</h3><h4>Burak Bartan, Mert Pilanci</h4> Abstract: In this work, we study distributed sketching methods for large scale regression problems. We leverage multiple randomized sketches for reducing the problem dimensions as well as preserving privacy and improving straggler resilience in asynchronous distributed systems. We derive novel approximation guarantees for classical sketching methods and analyze the accuracy of parameter averaging for distributed sketches. We consider random matrices including Gaussian, randomized Hadamard, uniform sampling and leverage score sampling in the distributed setting. Moreover, we propose a hybrid approach combining sampling and fast random projections for better computational efficiency. We illustrate the performance of distributed sketches in a serverless computing platform with large scale experiments. <br><a href = "http://xxx.itp.ac.cn/pdf/2002.06538">PDF</a>
<h3>No. 9	Demystifying the Performance of HPC Scientific Applications on NVM-based  Memory Systems</h3><h4>Ivy Peng, Kai Wu, Jie Ren, Dong Li, Maya Gokhale</h4> Abstract: The emergence of high-density byte-addressable non-volatile memory (NVM) is promising to accelerate data- and compute-intensive applications. Current NVM technologies have lower performance than DRAM and, thus, are often paired with DRAM in a heterogeneous main memory. Recently, byte-addressable NVM hardware becomes available. This work provides a timely evaluation of representative HPC applications from the "Seven Dwarfs" on NVM-based main memory. Our results quantify the effectiveness of DRAM-cached-NVM for accelerating HPC applications and enabling large problems beyond the DRAM capacity. On uncached-NVM, HPC applications exhibit three tiers of performance sensitivity, i.e., insensitive, scaled, and bottlenecked. We identify write throttling and concurrency control as the priorities in optimizing applications. We highlight that concurrency change may have a diverging effect on read and write accesses in applications. Based on these findings, we explore two optimization approaches. First, we provide a prediction model that uses datasets from a small set of configurations to estimate performance at various concurrency and data sizes to avoid exhaustive search in the configuration space. Second, we demonstrate that write-aware data placement on uncached-NVM could achieve $2$x performance improvement with a 60% reduction in DRAM usage. <br><a href = "http://xxx.itp.ac.cn/pdf/2002.06499">PDF</a>
<h3>No. 10	Big Data Staging with MPI-IO for Interactive X-ray Science</h3><h4>Justin M. Wozniak, Hemant Sharma, Timothy G. Armstrong, Michael Wilde, Jonathan D. Almer, Ian Foster</h4> Abstract: New techniques in X-ray scattering science experiments produce large data sets that can require millions of high-performance processing hours per week of computation for analysis. In such applications, data is typically moved from X-ray detectors to a large parallel file system shared by all nodes of a petascale supercomputer and then is read repeatedly as different science application tasks proceed. However, this straightforward implementation causes significant contention in the file system. We propose an alternative approach in which data is instead staged into and cached in compute node memory for extended periods, during which time various processing tasks may efficiently access it. We describe here such a big data staging framework, based on MPI-IO and the Swift parallel scripting language. We discuss a range of large-scale data management issues involved in X-ray scattering science and measure the performance benefits of the new staging framework for high-energy diffraction microscopy, an important emerging application in data-intensive X-ray scattering. We show that our framework accelerates scientific processing turnaround from three months to under 10 minutes, and that our I/O technique reduces input overheads by a factor of 5 on 8K Blue Gene/Q nodes. <br><a href = "http://xxx.itp.ac.cn/pdf/2002.06258">PDF</a>
<h3>No. 11	Bitcoin's Blockchain Data Analytics: A Graph Theoretic Perspective</h3><h4>Aman Sharma, Ashutosh Bhatia</h4> Abstract: Bitcoin is the most popular cryptocurrency used worldwide. It provides pseudonymity to its users by establishing identity using public keys as transaction end-points. These transactions are recorded on an immutable public ledger called Blockchain which is an append-only data structure. The popularity of Bitcoin has increased unreasonably. The general trend shows a positive response from the common masses indicating an increase in trust and privacy concerns which makes an interesting use case from the analysis point of view. Moreover, since the blockchain is publicly available and up-to-date, any analysis would provide a live insight into the usage patterns which ultimately would be useful for making a number of inferences by law-enforcement agencies, economists, tech-enthusiasts, etc. In this paper, we study various applications and techniques of performing data analytics over Bitcoin blockchain from a graph theoretic perspective. We also propose a framework for performing such data analytics and explored a couple of use cases using the proposed framework. <br><a href = "http://xxx.itp.ac.cn/pdf/2002.06403">PDF</a>
<h3>No. 12	Neural Architecture Search over Decentralized Data</h3><h4>Mengwei Xu, Yuxin Zhao, Kaigui Bian, Gang Huang, Qiaozhu Mei, Xuanzhe Liu</h4> Abstract: To preserve user privacy while enabling mobile intelligence, techniques have been proposed to train deep neural networks on decentralized data. However, training over decentralized data makes the design of neural architecture quite difficult as it already was. Such difficulty is further amplified when designing and deploying different neural architectures for heterogeneous mobile platforms. In this work, we propose an automatic neural architecture search into the decentralized training, as a new DNN training paradigm called Federated Neural Architecture Search, namely federated NAS. To deal with the primary challenge of limited on-client computational and communication resources, we present FedNAS, a highly optimized framework for efficient federated NAS. FedNAS fully exploits the key opportunity of insufficient model candidate re-training during the architecture search process, and incorporates three key optimizations: parallel candidates training on partial clients, early dropping candidates with inferior performance, and dynamic round numbers. Tested on large-scale datasets and typical CNN architectures, FedNAS achieves comparable model accuracy as state-of-the-art NAS algorithm that trains models with centralized data, and also reduces the client cost by up to two orders of magnitude compared to a straightforward design of federated NAS. <br><a href = "http://xxx.itp.ac.cn/pdf/2002.06352">PDF</a><h2>2020-02-18	 Total: 14</h2>
<h3>No. 1	Concurrent Reference Counting and Resource Management in Wait-free  Constant Time</h3><h4>Guy E. Blelloch, Yuanhao Wei</h4> Abstract: A common problem when implementing concurrent programs is efficiently protecting against unsafe races between processes reading and then using a resource (e.g., memory blocks, file descriptors, or network connections) and other processes that are concurrently overwriting and then destructing the same resource. Such read-destruct races can be protected with locks, or with lock-free solutions such as hazard-pointers or read-copy-update (RCU). In this paper we describe a method for protecting read-destruct races with expected constant time overhead, $O(P^2)$ space and $O(P^2)$ delayed destructs, and with just single word atomic memory operations (reads, writes, and CAS). It is based on an interface with four primitives, an acquire-release pair to protect accesses, and a retire-eject pair to delay the destruct until it is safe. We refer to this as the acquire-retire interface. Using the acquire-retire interface, we develop simple implementations for three common use cases: (1) memory reclamation with applications to stacks and queues, (2) reference counted objects, and (3) objects manage by ownership with moves, copies, and destructs. The first two results significantly improve on previous results, and the third application is original. Importantly, all operations have expected constant time overhead. <br><a href = "http://xxx.itp.ac.cn/pdf/2002.07053">PDF</a>
<h3>No. 2	In Search for a Linear Byzantine Agreement</h3><h4>Alexander Spiegelman</h4> Abstract: The long-standing byzantine agreement problem gets more attention in recent years due to the increasing demand for scalable geo-replicated Byzantine state machine replication (SMR) systems (e.g., Blockchains). To date, the key bottleneck of such systems is the communication cost of the byzantine agreement they employ as a building block, which motivates many researchers to search for low-communication byzantine agreement protocols. The conventional approach is to design deterministic protocols in the eventually synchronous communication model that are optimized to reduce the communication cost after the global stabilization time (GST). In this paper, we challenge the conventional approach and argue it is not the best fit for scalable SMR systems since it might induce an unbounded communication cost during asynchronous periods before GST, which we prove to be inherent. Instead, we forgo eventual synchrony and propose a different approach that hopes for the best (synchrony) but prepares for the worst (asynchrony). Accordingly, we design an optimistic protocol that first tries to reach an agreement via an efficient deterministic algorithm that relies on synchrony for termination, and then, only if an agreement was not reached due to asynchrony, the protocol uses a randomized asynchronous algorithm for fallback that guarantees termination with probability $1$. Although randomized asynchronous algorithms are considered to be costly, we design our solution to pay this cost only when an equivalent cost has already been paid while unsuccessfully trying the synchronous protocol. Moreover, we formally prove that our protocol achieves optimal communication complexity under all network conditions and failure scenarios. <br><a href = "http://xxx.itp.ac.cn/pdf/2002.06993">PDF</a>
<h3>No. 3	Simulating Performance of ML Systems with Offline Profiling</h3><h4>Hongming Huang, Peng Cheng, Hong Xu, Yongqiang Xiong</h4> Abstract: We advocate that simulation based on offline profiling is a promising approach to better understand and improve the complex ML systems. Our approach uses operation-level profiling and dataflow based simulation to ensure it offers a unified and automated solution for all frameworks and ML models, and is also accurate by considering the various parallelization strategies in a real system. <br><a href = "http://xxx.itp.ac.cn/pdf/2002.06790">PDF</a>
<h3>No. 4	Byzantine Lattice Agreement in Asynchronous Systems</h3><h4>Xiong Zheng, Vijay Garg</h4> Abstract: We study the Byzantine lattice agreement (BLA) problem in asynchronous distributed message passing systems. In the BLA problem, each process proposes a value from a join semi-lattice and needs to output a value also in the lattice such that all output values of correct processes lie on a chain despite the presence of Byzantine processes. We present an algorithm for this problem with round complexity of $O(\log f)$ which tolerates $f < \frac{n}{5}$ Byzantine failures in the asynchronous setting without digital signatures, where $n$ is the number of processes. We also show how this algorithm can be modified to work in the authenticated setting (i.e., with digital signatures) to tolerate $f < \frac{n}{3}$ Byzantine failures. <br><a href = "http://xxx.itp.ac.cn/pdf/2002.06779">PDF</a>
<h3>No. 5	How fast can you update your MST? (Dynamic algorithms for cluster  computing)</h3><h4>Seth Gilbert, Lawrence Li</h4> Abstract: Imagine a large graph that is being processed by a cluster of computers, e.g., described by the $k$-machine model or the Massively Parallel Computation Model. The graph, however, is not static; instead it is receiving a constant stream of updates. How fast can the cluster process the stream of updates? The fundamental question we want to ask in this paper is whether we can update the graph fast enough to keep up with the stream. We focus specifically on the problem of maintaining a minimum spanning tree (MST), and we give an algorithm for the $k$-machine model that can process $O(k)$ graph updates per $O(1)$ rounds with high probability. (And these results carry over to the Massively Parallel Computation (MPC) model.) We also show a lower bound, i.e., it is impossible to process $k^{1+\epsilon}$ updates in $O(1)$ rounds. Thus we provide a nearly tight answer to the question of how fast a cluster can respond to a stream of graph modifications while maintaining an MST. <br><a href = "http://xxx.itp.ac.cn/pdf/2002.06762">PDF</a>
<h3>No. 6	Running a Pre-Exascale, Geographically Distributed, Multi-Cloud  Scientific Simulation</h3><h4>Igor Sfiligoi, Frank Wuerthwein, Benedikt Riedel, David Schultz</h4> Abstract: As we approach the Exascale era, it is important to verify that the existing frameworks and tools will still work at that scale. Moreover, public Cloud computing has been emerging as a viable solution for both prototyping and urgent computing. Using the elasticity of the Cloud, we have thus put in place a pre-exascale HTCondor setup for running a scientific simulation in the Cloud, with the chosen application being IceCube's photon propagation simulation. I.e. this was not a purely demonstration run, but it was also used to produce valuable and much needed scientific results for the IceCube collaboration. In order to reach the desired scale, we aggregated GPU resources across 8 GPU models from many geographic regions across Amazon Web Services, Microsoft Azure, and the Google Cloud Platform. Using this setup, we reached a peak of over 51k GPUs corresponding to almost 380 PFLOP32s, for a total integrated compute of about 100k GPU hours. In this paper we provide the description of the setup, the problems that were discovered and overcome, as well as a short description of the actual science output of the exercise. <br><a href = "http://xxx.itp.ac.cn/pdf/2002.06667">PDF</a>
<h3>No. 7	Not a COINcidence: Sub-Quadratic Asynchronous Byzantine Agreement WHP</h3><h4>Shir Cohen, Idit Keidar, Alexander Spiegelman</h4> Abstract: King and Saia were the first to break the quadratic word complexity bound for Byzantine Agreement in synchronous systems against an adaptive adversary, and Algorand broke this bound with near-optimal resilience in the eventual-synchrony model. Yet the question of asynchronous sub-quadratic Byzantine Agreement remained open. To the best of our knowledge, we are the first to answer this question in the affirmative. A key component of our solution is a novel shared coin algorithm based on a VRF, without any further trusted setup. A second essential ingredient is VRF-based committee sampling, which we formalize and utilize in the asynchronous model for the first time. Our algorithms work against a delayed-adaptive adversary, which cannot perform after-the-fact removals but has full control of Byzantine processes and full information about communication in earlier rounds. Using committee sampling and our shared coin, we solve Byzantine Agreement with high probability, with a word complexity of $\widetilde{O}(n)$ and $O(1)$ expected time, breaking the $O(n^2)$ bit barrier for asynchronous Byzantine Agreement. <br><a href = "http://xxx.itp.ac.cn/pdf/2002.06545">PDF</a>
<h3>No. 8	Distributed Sketching Methods for Privacy Preserving Regression</h3><h4>Burak Bartan, Mert Pilanci</h4> Abstract: In this work, we study distributed sketching methods for large scale regression problems. We leverage multiple randomized sketches for reducing the problem dimensions as well as preserving privacy and improving straggler resilience in asynchronous distributed systems. We derive novel approximation guarantees for classical sketching methods and analyze the accuracy of parameter averaging for distributed sketches. We consider random matrices including Gaussian, randomized Hadamard, uniform sampling and leverage score sampling in the distributed setting. Moreover, we propose a hybrid approach combining sampling and fast random projections for better computational efficiency. We illustrate the performance of distributed sketches in a serverless computing platform with large scale experiments. <br><a href = "http://xxx.itp.ac.cn/pdf/2002.06538">PDF</a>
<h3>No. 9	Demystifying the Performance of HPC Scientific Applications on NVM-based  Memory Systems</h3><h4>Ivy Peng, Kai Wu, Jie Ren, Dong Li, Maya Gokhale</h4> Abstract: The emergence of high-density byte-addressable non-volatile memory (NVM) is promising to accelerate data- and compute-intensive applications. Current NVM technologies have lower performance than DRAM and, thus, are often paired with DRAM in a heterogeneous main memory. Recently, byte-addressable NVM hardware becomes available. This work provides a timely evaluation of representative HPC applications from the "Seven Dwarfs" on NVM-based main memory. Our results quantify the effectiveness of DRAM-cached-NVM for accelerating HPC applications and enabling large problems beyond the DRAM capacity. On uncached-NVM, HPC applications exhibit three tiers of performance sensitivity, i.e., insensitive, scaled, and bottlenecked. We identify write throttling and concurrency control as the priorities in optimizing applications. We highlight that concurrency change may have a diverging effect on read and write accesses in applications. Based on these findings, we explore two optimization approaches. First, we provide a prediction model that uses datasets from a small set of configurations to estimate performance at various concurrency and data sizes to avoid exhaustive search in the configuration space. Second, we demonstrate that write-aware data placement on uncached-NVM could achieve $2$x performance improvement with a 60% reduction in DRAM usage. <br><a href = "http://xxx.itp.ac.cn/pdf/2002.06499">PDF</a>
<h3>No. 10	Big Data Staging with MPI-IO for Interactive X-ray Science</h3><h4>Justin M. Wozniak, Hemant Sharma, Timothy G. Armstrong, Michael Wilde, Jonathan D. Almer, Ian Foster</h4> Abstract: New techniques in X-ray scattering science experiments produce large data sets that can require millions of high-performance processing hours per week of computation for analysis. In such applications, data is typically moved from X-ray detectors to a large parallel file system shared by all nodes of a petascale supercomputer and then is read repeatedly as different science application tasks proceed. However, this straightforward implementation causes significant contention in the file system. We propose an alternative approach in which data is instead staged into and cached in compute node memory for extended periods, during which time various processing tasks may efficiently access it. We describe here such a big data staging framework, based on MPI-IO and the Swift parallel scripting language. We discuss a range of large-scale data management issues involved in X-ray scattering science and measure the performance benefits of the new staging framework for high-energy diffraction microscopy, an important emerging application in data-intensive X-ray scattering. We show that our framework accelerates scientific processing turnaround from three months to under 10 minutes, and that our I/O technique reduces input overheads by a factor of 5 on 8K Blue Gene/Q nodes. <br><a href = "http://xxx.itp.ac.cn/pdf/2002.06258">PDF</a>
<h3>No. 11	Bitcoin's Blockchain Data Analytics: A Graph Theoretic Perspective</h3><h4>Aman Sharma, Ashutosh Bhatia</h4> Abstract: Bitcoin is the most popular cryptocurrency used worldwide. It provides pseudonymity to its users by establishing identity using public keys as transaction end-points. These transactions are recorded on an immutable public ledger called Blockchain which is an append-only data structure. The popularity of Bitcoin has increased unreasonably. The general trend shows a positive response from the common masses indicating an increase in trust and privacy concerns which makes an interesting use case from the analysis point of view. Moreover, since the blockchain is publicly available and up-to-date, any analysis would provide a live insight into the usage patterns which ultimately would be useful for making a number of inferences by law-enforcement agencies, economists, tech-enthusiasts, etc. In this paper, we study various applications and techniques of performing data analytics over Bitcoin blockchain from a graph theoretic perspective. We also propose a framework for performing such data analytics and explored a couple of use cases using the proposed framework. <br><a href = "http://xxx.itp.ac.cn/pdf/2002.06403">PDF</a>
<h3>No. 12	Neural Architecture Search over Decentralized Data</h3><h4>Mengwei Xu, Yuxin Zhao, Kaigui Bian, Gang Huang, Qiaozhu Mei, Xuanzhe Liu</h4> Abstract: To preserve user privacy while enabling mobile intelligence, techniques have been proposed to train deep neural networks on decentralized data. However, training over decentralized data makes the design of neural architecture quite difficult as it already was. Such difficulty is further amplified when designing and deploying different neural architectures for heterogeneous mobile platforms. In this work, we propose an automatic neural architecture search into the decentralized training, as a new DNN training paradigm called Federated Neural Architecture Search, namely federated NAS. To deal with the primary challenge of limited on-client computational and communication resources, we present FedNAS, a highly optimized framework for efficient federated NAS. FedNAS fully exploits the key opportunity of insufficient model candidate re-training during the architecture search process, and incorporates three key optimizations: parallel candidates training on partial clients, early dropping candidates with inferior performance, and dynamic round numbers. Tested on large-scale datasets and typical CNN architectures, FedNAS achieves comparable model accuracy as state-of-the-art NAS algorithm that trains models with centralized data, and also reduces the client cost by up to two orders of magnitude compared to a straightforward design of federated NAS. <br><a href = "http://xxx.itp.ac.cn/pdf/2002.06352">PDF</a>
</body></html>