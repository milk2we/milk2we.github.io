<!DOCTYPE html><html><head><meta charset="utf-8"><title>Distributed, Parallel, and Cluster Computing  authors/titles recent submissions</title></head><body>
<h2>2020-02-21</h2>
<h3>No. 1	Balancing Efficiency and Flexibility for DNN Acceleration via Temporal  GPU-Systolic Array Integration</h3><h4>Cong Guo, Yangjie Zhou, Jingwen Leng, Yuhao Zhu, Zidong Du, Quan Chen, Chao Li, Minyi Guo, Bin Yao</h4> Abstract: The research interest in specialized hardware accelerators for deep neural networks (DNN) spiked recently owing to their superior performance and efficiency. However, today's DNN accelerators primarily focus on accelerating specific "kernels" such as convolution and matrix multiplication, which are vital but only part of an end-to-end DNN-enabled application. Meaningful speedups over the entire application often require supporting computations that are, while massively parallel, ill-suited to DNN accelerators. Integrating a general-purpose processor such as a CPU or a GPU incurs significant data movement overhead and leads to resource under-utilization on the DNN accelerators. We propose Simultaneous Multi-mode Architecture (SMA), a novel architecture design and execution model that offers general-purpose programmability on DNN accelerators in order to accelerate end-to-end applications. The key to SMA is the temporal integration of the systolic execution model with the GPU-like SIMD execution model. The SMA exploits the common components shared between the systolic-array accelerator and the GPU, and provides lightweight reconfiguration capability to switch between the two modes in-situ. The SMA achieves up to 63% performance improvement while consuming 23% less energy than the baseline Volta architecture with TensorCore. <br><a href = "http://xxx.itp.ac.cn/pdf/2002.08326">PDF</a>
<h3>No. 2	MLModelScope: A Distributed Platform for Model Evaluation and  Benchmarking at Scale</h3><h4>Abdul Dakkak, Cheng Li, Jinjun Xiong, Wen-mei Hwu</h4> Abstract: Machine Learning (ML) and Deep Learning (DL) innovations are being introduced at such a rapid pace that researchers are hard-pressed to analyze and study them. The complicated procedures for evaluating innovations, along with the lack of standard and efficient ways of specifying and provisioning ML/DL evaluation, is a major "pain point" for the community. This paper proposes MLModelScope, an open-source, framework/hardware agnostic, extensible and customizable design that enables repeatable, fair, and scalable model evaluation and benchmarking. We implement the distributed design with support for all major frameworks and hardware, and equip it with web, command-line, and library interfaces. To demonstrate MLModelScope's capabilities we perform parallel evaluation and show how subtle changes to model evaluation pipeline affects the accuracy and HW/SW stack choices affect performance. <br><a href = "http://xxx.itp.ac.cn/pdf/2002.08295">PDF</a>
<h3>No. 3	Truly Tight-in-$Δ$ Bounds for Bipartite Maximal Matching and  Variants</h3><h4>Sebastian Brandt, Dennis Olivetti</h4> Abstract: In a recent breakthrough result, Balliu et al. [FOCS'19] proved a deterministic $\Omega(\min(\Delta,\log n /\log \log n))$-round and a randomized $\Omega(\min(\Delta,\log \log n/\log \log \log n))$-round lower bound for the complexity of the bipartite maximal matching problem on $n$-node graphs in the LOCAL model of distributed computing. Both lower bounds are asymptotically tight as a function of the maximum degree $\Delta$. We provide truly tight bounds in $\Delta$ for the complexity of bipartite maximal matching and many natural variants, up to and including the additive constant. As a by-product, our results yield a considerably simplified version of the proof by Balliu et al. We show that our results can be obtained via bounded automatic round elimination, a version of the recent automatic round elimination technique by Brandt [PODC'19] that is particularly suited for automatization from a practical perspective. In this context, our work can be seen as another step towards the automatization of lower bounds in the LOCAL model. <br><a href = "http://xxx.itp.ac.cn/pdf/2002.08216">PDF</a>
<h3>No. 4	Honing and proofing Astrophysical codes on the road to Exascale.  Experiences from code modernization on many-core systems</h3><h4>Salvatore Cielo, Luigi Iapichino, Fabio Baruffa, Matteo Bugli, Christoph Federrath</h4> Abstract: The complexity of modern and upcoming computing architectures poses severe challenges for code developers and application specialists, and forces them to expose the highest possible degree of parallelism, in order to make the best use of the available hardware. The Intel$^{(R)}$ Xeon Phi$^{(TM)}$ of second generation (code-named Knights Landing, henceforth KNL) is the latest many-core system, which implements several interesting hardware features like for example a large number of cores per node (up to 72), the 512 bits-wide vector registers and the high-bandwidth memory. The unique features of KNL make this platform a powerful testbed for modern HPC applications. The performance of codes on KNL is therefore a useful proxy of their readiness for future architectures. In this work we describe the lessons learnt during the optimisation of the widely used codes for computational astrophysics P-Gadget-3, Flash and Echo. Moreover, we present results for the visualisation and analysis tools VisIt and yt. These examples show that modern architectures benefit from code optimisation at different levels, even more than traditional multi-core systems. However, the level of modernisation of typical community codes still needs improvements, for them to fully utilise resources of novel architectures. <br><a href = "http://xxx.itp.ac.cn/pdf/2002.08161">PDF</a>
<h3>No. 5	The Sum of Its Parts: Analysis of Federated Byzantine Agreement Systems</h3><h4>Martin Florian, Sebastian Henningsen, Björn Scheuermann</h4> Abstract: Federated Byzantine Agreement Systems (FBASs) are a fascinating new paradigm in the context of consensus protocols. Originally proposed for powering the Stellar payment network, FBASs can be thought of as a middle way between typical permissionless systems (like Bitcoin) and permissioned approaches for solving consensus (like classical BFT protocols). Unlike Bitcoin and the like, validators must be explicitly chosen by peers. Unlike permissioned protocols, there is no need for the whole system to agree on the same set of validators. Instead, every node is free to decide for itself with whom it requires agreement. In this paper, we propose an intuitive yet precise methodology for determining whether the quorum systems resulting from such individual configurations can enable liveness and safety, respectively how many (byzantine) node failures they are away from losing these qualities. We apply our analysis approach and software to evaluate the effects of different node configuration policies, i.e., logics through which node configurations result from strategic considerations or an existing inter-node relationship graph. Lastly, we also investigate the reported "open-membership" property of FBASs. We observe that an often small group of nodes is exclusively relevant for determining safety and liveness "buffers", and prove that these top tiers are effectively "closed-membership" if maintaining safety is a core requirement. <br><a href = "http://xxx.itp.ac.cn/pdf/2002.08101">PDF</a>
<h3>No. 6	Holistic Slowdown Driven Scheduling and Resource Management for  Malleable Jobs</h3><h4>Marco D'Amico, Ana Jokanovic, Julita Corbalan</h4> Abstract: In job scheduling, the concept of malleability has been explored since many years ago. Research shows that malleability improves system performance, but its utilization in HPC never became widespread. The causes are the difficulty in developing malleable applications, and the lack of support and integration of the different layers of the HPC software stack. However, in the last years, malleability in job scheduling is becoming more critical because of the increasing complexity of hardware and workloads. In this context, using nodes in an exclusive mode is not always the most efficient solution as in traditional HPC jobs, where applications were highly tuned for static allocations, but offering zero flexibility to dynamic executions. This paper proposes a new holistic, dynamic job scheduling policy, Slowdown Driven (SD-Policy), which exploits the malleability of applications as the key technology to reduce the average slowdown and response time of jobs. SD-Policy is based on backfill and node sharing. It applies malleability to running jobs to make room for jobs that will run with a reduced set of resources, only when the estimated slowdown improves over the static approach. We implemented SD-Policy in SLURM and evaluated it in a real production environment, and with a simulator using workloads of up to 198K jobs. Results show better resource utilization with the reduction of makespan, response time, slowdown, and energy consumption, up to respectively 7%, 50%, 70%, and 6%, for the evaluated workloads. <br><a href = "http://xxx.itp.ac.cn/pdf/2002.08088">PDF</a>
<h3>No. 7	Supporting OpenMP 5.0 Tasks in hpxMP -- A study of an OpenMP  implementation within Task Based Runtime Systems</h3><h4>Tianyi Zhang, Shahrzad Shirzad, Bibek Wagle, Adrian S. Lemoine, Patrick Diehl, Hartmut Kaiser</h4> Abstract: OpenMP has been the de facto standard for single node parallelism for more than a decade. Recently, asynchronous many-task runtime (AMT) systems have increased in popularity as a new programming paradigm for high performance computing applications. One of the major challenges of this new paradigm is the incompatibility of the OpenMP thread model and other AMTs. Highly optimized OpenMP-based libraries do not perform well when coupled with AMTs because the threading of both libraries will compete for resources. This paper is a follow-up paper on the fundamental implementation of hpxMP, an implementation of the OpenMP standard which utilizes the C++ standard library for Parallelism and Concurrency (HPX) to schedule and manage tasks. In this paper, we present the implementation of task features, e.g. taskgroup, task depend, and task_reduction, of the OpenMP 5.0 standard and optimization of the #pragma omp parallel for pragma. We use the daxpy benchmark, the Barcelona OpenMP Tasks Suite, Parallel research kernels, and OpenBLAS benchmarks to compare the different OpenMp implementations: hpxMP, llvm-OpenMP, and GOMP. <br><a href = "http://xxx.itp.ac.cn/pdf/2002.07970">PDF</a>
<h3>No. 8	Parallel Algorithms for Small Subgraph Counting</h3><h4>Amartya Shankha Biswas, Talya Eden, Quanquan C. Liu, Slobodan Mitrović, Ronitt Rubinfeld</h4> Abstract: Subgraph counting is a fundamental problem in analyzing massive graphs, often studied in the context of social and complex networks. There is a rich literature on designing efficient, accurate, and scalable algorithms for this problem. In this work, we tackle this challenge and design several new algorithms for subgraph counting in the Massively Parallel Computation (MPC) model: Given a graph $G$ over $n$ vertices, $m$ edges and $T$ triangles, our first main result is an algorithm that, with high probability, outputs a $(1+\varepsilon)$-approximation to $T$, with optimal round and space complexity provided any $S \geq \max{(\sqrt m, n^2/m)}$ space per machine, assuming $T=\Omega(\sqrt{m/n})$. Our second main result is an $\tilde{O}_{\delta}(\log \log n)$-rounds algorithm for exactly counting the number of triangles, parametrized by the arboricity $\alpha$ of the input graph. The space per machine is $O(n^{\delta})$ for any constant $\delta$, and the total space is $O(m\alpha)$, which matches the time complexity of (combinatorial) triangle counting in the sequential model. We also prove that this result can be extended to exactly counting $k$-cliques for any constant $k$, with the same round complexity and total space $O(m\alpha^{k-2})$. Alternatively, allowing $O(\alpha^2)$ space per machine, the total space requirement reduces to $O(n\alpha^2)$. Finally, we prove that a recent result of Bera, Pashanasangi and Seshadhri (ITCS 2020) for exactly counting all subgraphs of size at most $5$, can be implemented in the MPC model in $\tilde{O}_{\delta}(\sqrt{\log n})$ rounds, $O(n^{\delta})$ space per machine and $O(m\alpha^3)$ total space. Therefore, this result also exhibits the phenomenon that a time bound in the sequential model translates to a space bound in the MPC model. <br><a href = "http://xxx.itp.ac.cn/pdf/2002.08299">PDF</a>
<h3>No. 9	BatchLayout: A Batch-Parallel Force-Directed Graph Layout Algorithm in  Shared Memory</h3><h4>Md. Khaledur Rahman, Majedul Haque Sujon, Ariful Azad</h4> Abstract: Force-directed algorithms are widely used to generate aesthetically pleasing layouts of graphs or networks arisen in many scientific disciplines. To visualize large-scale graphs, several parallel algorithms have been discussed in the literature. However, existing parallel algorithms do not utilize memory hierarchy efficiently and often offer limited parallelism. This paper addresses these limitations with BatchLayout, an algorithm that groups vertices into minibatches and processes them in parallel. BatchLayout also employs cache blocking techniques to utilize memory hierarchy efficiently. More parallelism and improved memory accesses coupled with force approximating techniques, better initialization, and optimized learning rate make BatchLayout significantly faster than other state-of-the-art algorithms such as ForceAtlas2 and OpenOrd. The visualization quality of layouts from BatchLayout is comparable or better than similar visualization tools. All of our source code, links to datasets, results and log files are available at this https URL <br><a href = "http://xxx.itp.ac.cn/pdf/2002.08233">PDF</a>
<h3>No. 10	Toward Low-Cost and Stable Blockchain Networks</h3><h4>Minghong Fang, Jia Liu</h4> Abstract: Envisioned to be the future of distributed systems, blockchain networks have received increasing attentions from both industry and academic research in recent years. However, the blockchain mining process consumes vast amounts of energy, and studies have shown that the amount of energy consumed in Bitcoin mining is almost the same as electricity used in Ireland. To address the high mining energy cost problem of blockchain networks, in this paper, we propose a blockchain mining resources allocation algorithm to reduce the mining cost in PoW-based (proof-of-work-based) blockchain networks. We first provide a systematic study on general blockchain queueing model. In our queueing model, transactions arrive randomly to the queue and served in a batch manner with unknown probability distribution and agnostic to any priority mechanism. Then, we leverage Lyapunov optimization techniques to propose a dynamic mining resources allocation algorithm (DMRA), which is parameterized by a tuning parameter $K>0$. We show that our algorithm achieves performance-delay tradeoff as $[O(1/K), O(K)]$. The simulation results also demonstrate the effectiveness of DMRA in reducing the mining cost. <br><a href = "http://xxx.itp.ac.cn/pdf/2002.08027">PDF</a>
<h3>No. 11	Repair rate lower bounds for distributed storage</h3><h4>Michael Luby</h4> Abstract: One of the primary objectives of a distributed storage system is to reliably store a large amount $dsize$ of source data for a long duration using a large number $N$ of unreliable storage nodes, each with capacity $nsize$. The storage overhead $\beta$ is the fraction of system capacity available beyond $dsize$, i.e., $\beta = 1- \frac{dsize}{N \cdot nsize}$. Storage nodes fail randomly over time and are replaced with initially empty nodes, and thus data is erased from the system at an average rate $erate = \lambda \cdot N \cdot nsize$, where $1/\lambda$ is the average lifetime of a node before failure. To maintain recoverability of the source data, a repairer continually reads data over a network from nodes at some average rate $rrate$, and generates and writes data to nodes based on the read data. The main result is that, for any repairer, if the source data is recoverable at each point in time then it must be the case that $rrate \ge \frac{erate}{2 \cdot \beta}$ asymptotically as $N$ goes to infinity and beta goes to zero. This inequality provides a fundamental lower bound on the average rate that any repairer needs to read data from the system in order to maintain recoverability of the source data. <br><a href = "http://xxx.itp.ac.cn/pdf/2002.07904">PDF</a><h2>2020-02-20</h2>
<h3>No. 1	Balancing Efficiency and Flexibility for DNN Acceleration via Temporal  GPU-Systolic Array Integration</h3><h4>Cong Guo, Yangjie Zhou, Jingwen Leng, Yuhao Zhu, Zidong Du, Quan Chen, Chao Li, Minyi Guo, Bin Yao</h4> Abstract: The research interest in specialized hardware accelerators for deep neural networks (DNN) spiked recently owing to their superior performance and efficiency. However, today's DNN accelerators primarily focus on accelerating specific "kernels" such as convolution and matrix multiplication, which are vital but only part of an end-to-end DNN-enabled application. Meaningful speedups over the entire application often require supporting computations that are, while massively parallel, ill-suited to DNN accelerators. Integrating a general-purpose processor such as a CPU or a GPU incurs significant data movement overhead and leads to resource under-utilization on the DNN accelerators. We propose Simultaneous Multi-mode Architecture (SMA), a novel architecture design and execution model that offers general-purpose programmability on DNN accelerators in order to accelerate end-to-end applications. The key to SMA is the temporal integration of the systolic execution model with the GPU-like SIMD execution model. The SMA exploits the common components shared between the systolic-array accelerator and the GPU, and provides lightweight reconfiguration capability to switch between the two modes in-situ. The SMA achieves up to 63% performance improvement while consuming 23% less energy than the baseline Volta architecture with TensorCore. <br><a href = "http://xxx.itp.ac.cn/pdf/2002.08326">PDF</a>
<h3>No. 2	MLModelScope: A Distributed Platform for Model Evaluation and  Benchmarking at Scale</h3><h4>Abdul Dakkak, Cheng Li, Jinjun Xiong, Wen-mei Hwu</h4> Abstract: Machine Learning (ML) and Deep Learning (DL) innovations are being introduced at such a rapid pace that researchers are hard-pressed to analyze and study them. The complicated procedures for evaluating innovations, along with the lack of standard and efficient ways of specifying and provisioning ML/DL evaluation, is a major "pain point" for the community. This paper proposes MLModelScope, an open-source, framework/hardware agnostic, extensible and customizable design that enables repeatable, fair, and scalable model evaluation and benchmarking. We implement the distributed design with support for all major frameworks and hardware, and equip it with web, command-line, and library interfaces. To demonstrate MLModelScope's capabilities we perform parallel evaluation and show how subtle changes to model evaluation pipeline affects the accuracy and HW/SW stack choices affect performance. <br><a href = "http://xxx.itp.ac.cn/pdf/2002.08295">PDF</a>
<h3>No. 3	Truly Tight-in-$Δ$ Bounds for Bipartite Maximal Matching and  Variants</h3><h4>Sebastian Brandt, Dennis Olivetti</h4> Abstract: In a recent breakthrough result, Balliu et al. [FOCS'19] proved a deterministic $\Omega(\min(\Delta,\log n /\log \log n))$-round and a randomized $\Omega(\min(\Delta,\log \log n/\log \log \log n))$-round lower bound for the complexity of the bipartite maximal matching problem on $n$-node graphs in the LOCAL model of distributed computing. Both lower bounds are asymptotically tight as a function of the maximum degree $\Delta$. We provide truly tight bounds in $\Delta$ for the complexity of bipartite maximal matching and many natural variants, up to and including the additive constant. As a by-product, our results yield a considerably simplified version of the proof by Balliu et al. We show that our results can be obtained via bounded automatic round elimination, a version of the recent automatic round elimination technique by Brandt [PODC'19] that is particularly suited for automatization from a practical perspective. In this context, our work can be seen as another step towards the automatization of lower bounds in the LOCAL model. <br><a href = "http://xxx.itp.ac.cn/pdf/2002.08216">PDF</a>
<h3>No. 4	Honing and proofing Astrophysical codes on the road to Exascale.  Experiences from code modernization on many-core systems</h3><h4>Salvatore Cielo, Luigi Iapichino, Fabio Baruffa, Matteo Bugli, Christoph Federrath</h4> Abstract: The complexity of modern and upcoming computing architectures poses severe challenges for code developers and application specialists, and forces them to expose the highest possible degree of parallelism, in order to make the best use of the available hardware. The Intel$^{(R)}$ Xeon Phi$^{(TM)}$ of second generation (code-named Knights Landing, henceforth KNL) is the latest many-core system, which implements several interesting hardware features like for example a large number of cores per node (up to 72), the 512 bits-wide vector registers and the high-bandwidth memory. The unique features of KNL make this platform a powerful testbed for modern HPC applications. The performance of codes on KNL is therefore a useful proxy of their readiness for future architectures. In this work we describe the lessons learnt during the optimisation of the widely used codes for computational astrophysics P-Gadget-3, Flash and Echo. Moreover, we present results for the visualisation and analysis tools VisIt and yt. These examples show that modern architectures benefit from code optimisation at different levels, even more than traditional multi-core systems. However, the level of modernisation of typical community codes still needs improvements, for them to fully utilise resources of novel architectures. <br><a href = "http://xxx.itp.ac.cn/pdf/2002.08161">PDF</a>
<h3>No. 5	The Sum of Its Parts: Analysis of Federated Byzantine Agreement Systems</h3><h4>Martin Florian, Sebastian Henningsen, Björn Scheuermann</h4> Abstract: Federated Byzantine Agreement Systems (FBASs) are a fascinating new paradigm in the context of consensus protocols. Originally proposed for powering the Stellar payment network, FBASs can be thought of as a middle way between typical permissionless systems (like Bitcoin) and permissioned approaches for solving consensus (like classical BFT protocols). Unlike Bitcoin and the like, validators must be explicitly chosen by peers. Unlike permissioned protocols, there is no need for the whole system to agree on the same set of validators. Instead, every node is free to decide for itself with whom it requires agreement. In this paper, we propose an intuitive yet precise methodology for determining whether the quorum systems resulting from such individual configurations can enable liveness and safety, respectively how many (byzantine) node failures they are away from losing these qualities. We apply our analysis approach and software to evaluate the effects of different node configuration policies, i.e., logics through which node configurations result from strategic considerations or an existing inter-node relationship graph. Lastly, we also investigate the reported "open-membership" property of FBASs. We observe that an often small group of nodes is exclusively relevant for determining safety and liveness "buffers", and prove that these top tiers are effectively "closed-membership" if maintaining safety is a core requirement. <br><a href = "http://xxx.itp.ac.cn/pdf/2002.08101">PDF</a>
<h3>No. 6	Holistic Slowdown Driven Scheduling and Resource Management for  Malleable Jobs</h3><h4>Marco D'Amico, Ana Jokanovic, Julita Corbalan</h4> Abstract: In job scheduling, the concept of malleability has been explored since many years ago. Research shows that malleability improves system performance, but its utilization in HPC never became widespread. The causes are the difficulty in developing malleable applications, and the lack of support and integration of the different layers of the HPC software stack. However, in the last years, malleability in job scheduling is becoming more critical because of the increasing complexity of hardware and workloads. In this context, using nodes in an exclusive mode is not always the most efficient solution as in traditional HPC jobs, where applications were highly tuned for static allocations, but offering zero flexibility to dynamic executions. This paper proposes a new holistic, dynamic job scheduling policy, Slowdown Driven (SD-Policy), which exploits the malleability of applications as the key technology to reduce the average slowdown and response time of jobs. SD-Policy is based on backfill and node sharing. It applies malleability to running jobs to make room for jobs that will run with a reduced set of resources, only when the estimated slowdown improves over the static approach. We implemented SD-Policy in SLURM and evaluated it in a real production environment, and with a simulator using workloads of up to 198K jobs. Results show better resource utilization with the reduction of makespan, response time, slowdown, and energy consumption, up to respectively 7%, 50%, 70%, and 6%, for the evaluated workloads. <br><a href = "http://xxx.itp.ac.cn/pdf/2002.08088">PDF</a>
<h3>No. 7	Supporting OpenMP 5.0 Tasks in hpxMP -- A study of an OpenMP  implementation within Task Based Runtime Systems</h3><h4>Tianyi Zhang, Shahrzad Shirzad, Bibek Wagle, Adrian S. Lemoine, Patrick Diehl, Hartmut Kaiser</h4> Abstract: OpenMP has been the de facto standard for single node parallelism for more than a decade. Recently, asynchronous many-task runtime (AMT) systems have increased in popularity as a new programming paradigm for high performance computing applications. One of the major challenges of this new paradigm is the incompatibility of the OpenMP thread model and other AMTs. Highly optimized OpenMP-based libraries do not perform well when coupled with AMTs because the threading of both libraries will compete for resources. This paper is a follow-up paper on the fundamental implementation of hpxMP, an implementation of the OpenMP standard which utilizes the C++ standard library for Parallelism and Concurrency (HPX) to schedule and manage tasks. In this paper, we present the implementation of task features, e.g. taskgroup, task depend, and task_reduction, of the OpenMP 5.0 standard and optimization of the #pragma omp parallel for pragma. We use the daxpy benchmark, the Barcelona OpenMP Tasks Suite, Parallel research kernels, and OpenBLAS benchmarks to compare the different OpenMp implementations: hpxMP, llvm-OpenMP, and GOMP. <br><a href = "http://xxx.itp.ac.cn/pdf/2002.07970">PDF</a>
<h3>No. 8	Parallel Algorithms for Small Subgraph Counting</h3><h4>Amartya Shankha Biswas, Talya Eden, Quanquan C. Liu, Slobodan Mitrović, Ronitt Rubinfeld</h4> Abstract: Subgraph counting is a fundamental problem in analyzing massive graphs, often studied in the context of social and complex networks. There is a rich literature on designing efficient, accurate, and scalable algorithms for this problem. In this work, we tackle this challenge and design several new algorithms for subgraph counting in the Massively Parallel Computation (MPC) model: Given a graph $G$ over $n$ vertices, $m$ edges and $T$ triangles, our first main result is an algorithm that, with high probability, outputs a $(1+\varepsilon)$-approximation to $T$, with optimal round and space complexity provided any $S \geq \max{(\sqrt m, n^2/m)}$ space per machine, assuming $T=\Omega(\sqrt{m/n})$. Our second main result is an $\tilde{O}_{\delta}(\log \log n)$-rounds algorithm for exactly counting the number of triangles, parametrized by the arboricity $\alpha$ of the input graph. The space per machine is $O(n^{\delta})$ for any constant $\delta$, and the total space is $O(m\alpha)$, which matches the time complexity of (combinatorial) triangle counting in the sequential model. We also prove that this result can be extended to exactly counting $k$-cliques for any constant $k$, with the same round complexity and total space $O(m\alpha^{k-2})$. Alternatively, allowing $O(\alpha^2)$ space per machine, the total space requirement reduces to $O(n\alpha^2)$. Finally, we prove that a recent result of Bera, Pashanasangi and Seshadhri (ITCS 2020) for exactly counting all subgraphs of size at most $5$, can be implemented in the MPC model in $\tilde{O}_{\delta}(\sqrt{\log n})$ rounds, $O(n^{\delta})$ space per machine and $O(m\alpha^3)$ total space. Therefore, this result also exhibits the phenomenon that a time bound in the sequential model translates to a space bound in the MPC model. <br><a href = "http://xxx.itp.ac.cn/pdf/2002.08299">PDF</a>
<h3>No. 9	BatchLayout: A Batch-Parallel Force-Directed Graph Layout Algorithm in  Shared Memory</h3><h4>Md. Khaledur Rahman, Majedul Haque Sujon, Ariful Azad</h4> Abstract: Force-directed algorithms are widely used to generate aesthetically pleasing layouts of graphs or networks arisen in many scientific disciplines. To visualize large-scale graphs, several parallel algorithms have been discussed in the literature. However, existing parallel algorithms do not utilize memory hierarchy efficiently and often offer limited parallelism. This paper addresses these limitations with BatchLayout, an algorithm that groups vertices into minibatches and processes them in parallel. BatchLayout also employs cache blocking techniques to utilize memory hierarchy efficiently. More parallelism and improved memory accesses coupled with force approximating techniques, better initialization, and optimized learning rate make BatchLayout significantly faster than other state-of-the-art algorithms such as ForceAtlas2 and OpenOrd. The visualization quality of layouts from BatchLayout is comparable or better than similar visualization tools. All of our source code, links to datasets, results and log files are available at this https URL <br><a href = "http://xxx.itp.ac.cn/pdf/2002.08233">PDF</a>
<h3>No. 10	Toward Low-Cost and Stable Blockchain Networks</h3><h4>Minghong Fang, Jia Liu</h4> Abstract: Envisioned to be the future of distributed systems, blockchain networks have received increasing attentions from both industry and academic research in recent years. However, the blockchain mining process consumes vast amounts of energy, and studies have shown that the amount of energy consumed in Bitcoin mining is almost the same as electricity used in Ireland. To address the high mining energy cost problem of blockchain networks, in this paper, we propose a blockchain mining resources allocation algorithm to reduce the mining cost in PoW-based (proof-of-work-based) blockchain networks. We first provide a systematic study on general blockchain queueing model. In our queueing model, transactions arrive randomly to the queue and served in a batch manner with unknown probability distribution and agnostic to any priority mechanism. Then, we leverage Lyapunov optimization techniques to propose a dynamic mining resources allocation algorithm (DMRA), which is parameterized by a tuning parameter $K>0$. We show that our algorithm achieves performance-delay tradeoff as $[O(1/K), O(K)]$. The simulation results also demonstrate the effectiveness of DMRA in reducing the mining cost. <br><a href = "http://xxx.itp.ac.cn/pdf/2002.08027">PDF</a>
<h3>No. 11	Repair rate lower bounds for distributed storage</h3><h4>Michael Luby</h4> Abstract: One of the primary objectives of a distributed storage system is to reliably store a large amount $dsize$ of source data for a long duration using a large number $N$ of unreliable storage nodes, each with capacity $nsize$. The storage overhead $\beta$ is the fraction of system capacity available beyond $dsize$, i.e., $\beta = 1- \frac{dsize}{N \cdot nsize}$. Storage nodes fail randomly over time and are replaced with initially empty nodes, and thus data is erased from the system at an average rate $erate = \lambda \cdot N \cdot nsize$, where $1/\lambda$ is the average lifetime of a node before failure. To maintain recoverability of the source data, a repairer continually reads data over a network from nodes at some average rate $rrate$, and generates and writes data to nodes based on the read data. The main result is that, for any repairer, if the source data is recoverable at each point in time then it must be the case that $rrate \ge \frac{erate}{2 \cdot \beta}$ asymptotically as $N$ goes to infinity and beta goes to zero. This inequality provides a fundamental lower bound on the average rate that any repairer needs to read data from the system in order to maintain recoverability of the source data. <br><a href = "http://xxx.itp.ac.cn/pdf/2002.07904">PDF</a><h2>2020-02-19</h2>
<h3>No. 1	Concurrent Reference Counting and Resource Management in Wait-free  Constant Time</h3><h4>Guy E. Blelloch, Yuanhao Wei</h4> Abstract: A common problem when implementing concurrent programs is efficiently protecting against unsafe races between processes reading and then using a resource (e.g., memory blocks, file descriptors, or network connections) and other processes that are concurrently overwriting and then destructing the same resource. Such read-destruct races can be protected with locks, or with lock-free solutions such as hazard-pointers or read-copy-update (RCU). In this paper we describe a method for protecting read-destruct races with expected constant time overhead, $O(P^2)$ space and $O(P^2)$ delayed destructs, and with just single word atomic memory operations (reads, writes, and CAS). It is based on an interface with four primitives, an acquire-release pair to protect accesses, and a retire-eject pair to delay the destruct until it is safe. We refer to this as the acquire-retire interface. Using the acquire-retire interface, we develop simple implementations for three common use cases: (1) memory reclamation with applications to stacks and queues, (2) reference counted objects, and (3) objects manage by ownership with moves, copies, and destructs. The first two results significantly improve on previous results, and the third application is original. Importantly, all operations have expected constant time overhead. <br><a href = "http://xxx.itp.ac.cn/pdf/2002.07053">PDF</a>
<h3>No. 2	In Search for a Linear Byzantine Agreement</h3><h4>Alexander Spiegelman</h4> Abstract: The long-standing byzantine agreement problem gets more attention in recent years due to the increasing demand for scalable geo-replicated Byzantine state machine replication (SMR) systems (e.g., Blockchains). To date, the key bottleneck of such systems is the communication cost of the byzantine agreement they employ as a building block, which motivates many researchers to search for low-communication byzantine agreement protocols. The conventional approach is to design deterministic protocols in the eventually synchronous communication model that are optimized to reduce the communication cost after the global stabilization time (GST). In this paper, we challenge the conventional approach and argue it is not the best fit for scalable SMR systems since it might induce an unbounded communication cost during asynchronous periods before GST, which we prove to be inherent. Instead, we forgo eventual synchrony and propose a different approach that hopes for the best (synchrony) but prepares for the worst (asynchrony). Accordingly, we design an optimistic protocol that first tries to reach an agreement via an efficient deterministic algorithm that relies on synchrony for termination, and then, only if an agreement was not reached due to asynchrony, the protocol uses a randomized asynchronous algorithm for fallback that guarantees termination with probability $1$. Although randomized asynchronous algorithms are considered to be costly, we design our solution to pay this cost only when an equivalent cost has already been paid while unsuccessfully trying the synchronous protocol. Moreover, we formally prove that our protocol achieves optimal communication complexity under all network conditions and failure scenarios. <br><a href = "http://xxx.itp.ac.cn/pdf/2002.06993">PDF</a>
<h3>No. 3	Simulating Performance of ML Systems with Offline Profiling</h3><h4>Hongming Huang, Peng Cheng, Hong Xu, Yongqiang Xiong</h4> Abstract: We advocate that simulation based on offline profiling is a promising approach to better understand and improve the complex ML systems. Our approach uses operation-level profiling and dataflow based simulation to ensure it offers a unified and automated solution for all frameworks and ML models, and is also accurate by considering the various parallelization strategies in a real system. <br><a href = "http://xxx.itp.ac.cn/pdf/2002.06790">PDF</a>
<h3>No. 4	Byzantine Lattice Agreement in Asynchronous Systems</h3><h4>Xiong Zheng, Vijay Garg</h4> Abstract: We study the Byzantine lattice agreement (BLA) problem in asynchronous distributed message passing systems. In the BLA problem, each process proposes a value from a join semi-lattice and needs to output a value also in the lattice such that all output values of correct processes lie on a chain despite the presence of Byzantine processes. We present an algorithm for this problem with round complexity of $O(\log f)$ which tolerates $f < \frac{n}{5}$ Byzantine failures in the asynchronous setting without digital signatures, where $n$ is the number of processes. We also show how this algorithm can be modified to work in the authenticated setting (i.e., with digital signatures) to tolerate $f < \frac{n}{3}$ Byzantine failures. <br><a href = "http://xxx.itp.ac.cn/pdf/2002.06779">PDF</a>
<h3>No. 5	How fast can you update your MST? (Dynamic algorithms for cluster  computing)</h3><h4>Seth Gilbert, Lawrence Li</h4> Abstract: Imagine a large graph that is being processed by a cluster of computers, e.g., described by the $k$-machine model or the Massively Parallel Computation Model. The graph, however, is not static; instead it is receiving a constant stream of updates. How fast can the cluster process the stream of updates? The fundamental question we want to ask in this paper is whether we can update the graph fast enough to keep up with the stream. We focus specifically on the problem of maintaining a minimum spanning tree (MST), and we give an algorithm for the $k$-machine model that can process $O(k)$ graph updates per $O(1)$ rounds with high probability. (And these results carry over to the Massively Parallel Computation (MPC) model.) We also show a lower bound, i.e., it is impossible to process $k^{1+\epsilon}$ updates in $O(1)$ rounds. Thus we provide a nearly tight answer to the question of how fast a cluster can respond to a stream of graph modifications while maintaining an MST. <br><a href = "http://xxx.itp.ac.cn/pdf/2002.06762">PDF</a>
<h3>No. 6	Running a Pre-Exascale, Geographically Distributed, Multi-Cloud  Scientific Simulation</h3><h4>Igor Sfiligoi, Frank Wuerthwein, Benedikt Riedel, David Schultz</h4> Abstract: As we approach the Exascale era, it is important to verify that the existing frameworks and tools will still work at that scale. Moreover, public Cloud computing has been emerging as a viable solution for both prototyping and urgent computing. Using the elasticity of the Cloud, we have thus put in place a pre-exascale HTCondor setup for running a scientific simulation in the Cloud, with the chosen application being IceCube's photon propagation simulation. I.e. this was not a purely demonstration run, but it was also used to produce valuable and much needed scientific results for the IceCube collaboration. In order to reach the desired scale, we aggregated GPU resources across 8 GPU models from many geographic regions across Amazon Web Services, Microsoft Azure, and the Google Cloud Platform. Using this setup, we reached a peak of over 51k GPUs corresponding to almost 380 PFLOP32s, for a total integrated compute of about 100k GPU hours. In this paper we provide the description of the setup, the problems that were discovered and overcome, as well as a short description of the actual science output of the exercise. <br><a href = "http://xxx.itp.ac.cn/pdf/2002.06667">PDF</a>
<h3>No. 7	Not a COINcidence: Sub-Quadratic Asynchronous Byzantine Agreement WHP</h3><h4>Shir Cohen, Idit Keidar, Alexander Spiegelman</h4> Abstract: King and Saia were the first to break the quadratic word complexity bound for Byzantine Agreement in synchronous systems against an adaptive adversary, and Algorand broke this bound with near-optimal resilience in the eventual-synchrony model. Yet the question of asynchronous sub-quadratic Byzantine Agreement remained open. To the best of our knowledge, we are the first to answer this question in the affirmative. A key component of our solution is a novel shared coin algorithm based on a VRF, without any further trusted setup. A second essential ingredient is VRF-based committee sampling, which we formalize and utilize in the asynchronous model for the first time. Our algorithms work against a delayed-adaptive adversary, which cannot perform after-the-fact removals but has full control of Byzantine processes and full information about communication in earlier rounds. Using committee sampling and our shared coin, we solve Byzantine Agreement with high probability, with a word complexity of $\widetilde{O}(n)$ and $O(1)$ expected time, breaking the $O(n^2)$ bit barrier for asynchronous Byzantine Agreement. <br><a href = "http://xxx.itp.ac.cn/pdf/2002.06545">PDF</a>
<h3>No. 8	Distributed Sketching Methods for Privacy Preserving Regression</h3><h4>Burak Bartan, Mert Pilanci</h4> Abstract: In this work, we study distributed sketching methods for large scale regression problems. We leverage multiple randomized sketches for reducing the problem dimensions as well as preserving privacy and improving straggler resilience in asynchronous distributed systems. We derive novel approximation guarantees for classical sketching methods and analyze the accuracy of parameter averaging for distributed sketches. We consider random matrices including Gaussian, randomized Hadamard, uniform sampling and leverage score sampling in the distributed setting. Moreover, we propose a hybrid approach combining sampling and fast random projections for better computational efficiency. We illustrate the performance of distributed sketches in a serverless computing platform with large scale experiments. <br><a href = "http://xxx.itp.ac.cn/pdf/2002.06538">PDF</a>
<h3>No. 9	Demystifying the Performance of HPC Scientific Applications on NVM-based  Memory Systems</h3><h4>Ivy Peng, Kai Wu, Jie Ren, Dong Li, Maya Gokhale</h4> Abstract: The emergence of high-density byte-addressable non-volatile memory (NVM) is promising to accelerate data- and compute-intensive applications. Current NVM technologies have lower performance than DRAM and, thus, are often paired with DRAM in a heterogeneous main memory. Recently, byte-addressable NVM hardware becomes available. This work provides a timely evaluation of representative HPC applications from the "Seven Dwarfs" on NVM-based main memory. Our results quantify the effectiveness of DRAM-cached-NVM for accelerating HPC applications and enabling large problems beyond the DRAM capacity. On uncached-NVM, HPC applications exhibit three tiers of performance sensitivity, i.e., insensitive, scaled, and bottlenecked. We identify write throttling and concurrency control as the priorities in optimizing applications. We highlight that concurrency change may have a diverging effect on read and write accesses in applications. Based on these findings, we explore two optimization approaches. First, we provide a prediction model that uses datasets from a small set of configurations to estimate performance at various concurrency and data sizes to avoid exhaustive search in the configuration space. Second, we demonstrate that write-aware data placement on uncached-NVM could achieve $2$x performance improvement with a 60% reduction in DRAM usage. <br><a href = "http://xxx.itp.ac.cn/pdf/2002.06499">PDF</a>
<h3>No. 10	Big Data Staging with MPI-IO for Interactive X-ray Science</h3><h4>Justin M. Wozniak, Hemant Sharma, Timothy G. Armstrong, Michael Wilde, Jonathan D. Almer, Ian Foster</h4> Abstract: New techniques in X-ray scattering science experiments produce large data sets that can require millions of high-performance processing hours per week of computation for analysis. In such applications, data is typically moved from X-ray detectors to a large parallel file system shared by all nodes of a petascale supercomputer and then is read repeatedly as different science application tasks proceed. However, this straightforward implementation causes significant contention in the file system. We propose an alternative approach in which data is instead staged into and cached in compute node memory for extended periods, during which time various processing tasks may efficiently access it. We describe here such a big data staging framework, based on MPI-IO and the Swift parallel scripting language. We discuss a range of large-scale data management issues involved in X-ray scattering science and measure the performance benefits of the new staging framework for high-energy diffraction microscopy, an important emerging application in data-intensive X-ray scattering. We show that our framework accelerates scientific processing turnaround from three months to under 10 minutes, and that our I/O technique reduces input overheads by a factor of 5 on 8K Blue Gene/Q nodes. <br><a href = "http://xxx.itp.ac.cn/pdf/2002.06258">PDF</a>
<h3>No. 11	Computing rank-revealing factorizations of matrices stored out-of-core</h3><h4>Nathan Heavner, Per-Gunnar Martinsson, Gregorio Quintana-Ortí</h4> Abstract: This paper describes efficient algorithms for computing rank-revealing factorizations of matrices that are too large to fit in RAM, and must instead be stored on slow external memory devices such as solid-state or spinning disk hard drives (out-of-core or out-of-memory). Traditional algorithms for computing rank revealing factorizations, such as the column pivoted QR factorization, or techniques for computing a full singular value decomposition of a matrix, are very communication intensive. They are naturally expressed as a sequence of matrix-vector operations, which become prohibitively expensive when data is not available in main memory. Randomization allows these methods to be reformulated so that large contiguous blocks of the matrix can be processed in bulk. The paper describes two distinct methods. The first is a blocked version of column pivoted Householder QR, organized as a ``left-looking'' method to minimize the number of write operations (which are more expensive than read operations on a spinning disk drive). The second method results in a so called UTV factorization which expresses a matrix $A$ as $A = U T V^*$ where $U$ and $V$ are unitary, and $T$ is triangular. This method is organized as an algorithm-by-blocks, in which floating point operations overlap read and write operations. The second method incorporates power iterations, and is exceptionally good at revealing the numerical rank; it can often be used as a substitute for a full singular value decomposition. Numerical experiments demonstrate that the new algorithms are almost as fast when processing data stored on a hard drive as traditional algorithms are for data stored in main memory. To be precise, the computational time for fully factorizing an $n\times n$ matrix scales as $cn^{3}$, with a scaling constant $c$ that is only marginally larger when the matrix is stored out of core. <br><a href = "http://xxx.itp.ac.cn/pdf/2002.06960">PDF</a>
<h3>No. 12	Distributed Averaging Methods for Randomized Second Order Optimization</h3><h4>Burak Bartan, Mert Pilanci</h4> Abstract: We consider distributed optimization problems where forming the Hessian is computationally challenging and communication is a significant bottleneck. We develop unbiased parameter averaging methods for randomized second order optimization that employ sampling and sketching of the Hessian. Existing works do not take the bias of the estimators into consideration, which limits their application to massively parallel computation. We provide closed-form formulas for regularization parameters and step sizes that provably minimize the bias for sketched Newton directions. We also extend the framework of second order averaging methods to introduce an unbiased distributed optimization framework for heterogeneous computing systems with varying worker resources. Additionally, we demonstrate the implications of our theoretical findings via large scale experiments performed on a serverless computing platform. <br><a href = "http://xxx.itp.ac.cn/pdf/2002.06540">PDF</a>
<h3>No. 13	Bitcoin's Blockchain Data Analytics: A Graph Theoretic Perspective</h3><h4>Aman Sharma, Ashutosh Bhatia</h4> Abstract: Bitcoin is the most popular cryptocurrency used worldwide. It provides pseudonymity to its users by establishing identity using public keys as transaction end-points. These transactions are recorded on an immutable public ledger called Blockchain which is an append-only data structure. The popularity of Bitcoin has increased unreasonably. The general trend shows a positive response from the common masses indicating an increase in trust and privacy concerns which makes an interesting use case from the analysis point of view. Moreover, since the blockchain is publicly available and up-to-date, any analysis would provide a live insight into the usage patterns which ultimately would be useful for making a number of inferences by law-enforcement agencies, economists, tech-enthusiasts, etc. In this paper, we study various applications and techniques of performing data analytics over Bitcoin blockchain from a graph theoretic perspective. We also propose a framework for performing such data analytics and explored a couple of use cases using the proposed framework. <br><a href = "http://xxx.itp.ac.cn/pdf/2002.06403">PDF</a>
<h3>No. 14	Neural Architecture Search over Decentralized Data</h3><h4>Mengwei Xu, Yuxin Zhao, Kaigui Bian, Gang Huang, Qiaozhu Mei, Xuanzhe Liu</h4> Abstract: To preserve user privacy while enabling mobile intelligence, techniques have been proposed to train deep neural networks on decentralized data. However, training over decentralized data makes the design of neural architecture quite difficult as it already was. Such difficulty is further amplified when designing and deploying different neural architectures for heterogeneous mobile platforms. In this work, we propose an automatic neural architecture search into the decentralized training, as a new DNN training paradigm called Federated Neural Architecture Search, namely federated NAS. To deal with the primary challenge of limited on-client computational and communication resources, we present FedNAS, a highly optimized framework for efficient federated NAS. FedNAS fully exploits the key opportunity of insufficient model candidate re-training during the architecture search process, and incorporates three key optimizations: parallel candidates training on partial clients, early dropping candidates with inferior performance, and dynamic round numbers. Tested on large-scale datasets and typical CNN architectures, FedNAS achieves comparable model accuracy as state-of-the-art NAS algorithm that trains models with centralized data, and also reduces the client cost by up to two orders of magnitude compared to a straightforward design of federated NAS. <br><a href = "http://xxx.itp.ac.cn/pdf/2002.06352">PDF</a><h2>2020-02-18</h2>
<h3>No. 1	Concurrent Reference Counting and Resource Management in Wait-free  Constant Time</h3><h4>Guy E. Blelloch, Yuanhao Wei</h4> Abstract: A common problem when implementing concurrent programs is efficiently protecting against unsafe races between processes reading and then using a resource (e.g., memory blocks, file descriptors, or network connections) and other processes that are concurrently overwriting and then destructing the same resource. Such read-destruct races can be protected with locks, or with lock-free solutions such as hazard-pointers or read-copy-update (RCU). In this paper we describe a method for protecting read-destruct races with expected constant time overhead, $O(P^2)$ space and $O(P^2)$ delayed destructs, and with just single word atomic memory operations (reads, writes, and CAS). It is based on an interface with four primitives, an acquire-release pair to protect accesses, and a retire-eject pair to delay the destruct until it is safe. We refer to this as the acquire-retire interface. Using the acquire-retire interface, we develop simple implementations for three common use cases: (1) memory reclamation with applications to stacks and queues, (2) reference counted objects, and (3) objects manage by ownership with moves, copies, and destructs. The first two results significantly improve on previous results, and the third application is original. Importantly, all operations have expected constant time overhead. <br><a href = "http://xxx.itp.ac.cn/pdf/2002.07053">PDF</a>
<h3>No. 2	In Search for a Linear Byzantine Agreement</h3><h4>Alexander Spiegelman</h4> Abstract: The long-standing byzantine agreement problem gets more attention in recent years due to the increasing demand for scalable geo-replicated Byzantine state machine replication (SMR) systems (e.g., Blockchains). To date, the key bottleneck of such systems is the communication cost of the byzantine agreement they employ as a building block, which motivates many researchers to search for low-communication byzantine agreement protocols. The conventional approach is to design deterministic protocols in the eventually synchronous communication model that are optimized to reduce the communication cost after the global stabilization time (GST). In this paper, we challenge the conventional approach and argue it is not the best fit for scalable SMR systems since it might induce an unbounded communication cost during asynchronous periods before GST, which we prove to be inherent. Instead, we forgo eventual synchrony and propose a different approach that hopes for the best (synchrony) but prepares for the worst (asynchrony). Accordingly, we design an optimistic protocol that first tries to reach an agreement via an efficient deterministic algorithm that relies on synchrony for termination, and then, only if an agreement was not reached due to asynchrony, the protocol uses a randomized asynchronous algorithm for fallback that guarantees termination with probability $1$. Although randomized asynchronous algorithms are considered to be costly, we design our solution to pay this cost only when an equivalent cost has already been paid while unsuccessfully trying the synchronous protocol. Moreover, we formally prove that our protocol achieves optimal communication complexity under all network conditions and failure scenarios. <br><a href = "http://xxx.itp.ac.cn/pdf/2002.06993">PDF</a>
<h3>No. 3	Simulating Performance of ML Systems with Offline Profiling</h3><h4>Hongming Huang, Peng Cheng, Hong Xu, Yongqiang Xiong</h4> Abstract: We advocate that simulation based on offline profiling is a promising approach to better understand and improve the complex ML systems. Our approach uses operation-level profiling and dataflow based simulation to ensure it offers a unified and automated solution for all frameworks and ML models, and is also accurate by considering the various parallelization strategies in a real system. <br><a href = "http://xxx.itp.ac.cn/pdf/2002.06790">PDF</a>
<h3>No. 4	Byzantine Lattice Agreement in Asynchronous Systems</h3><h4>Xiong Zheng, Vijay Garg</h4> Abstract: We study the Byzantine lattice agreement (BLA) problem in asynchronous distributed message passing systems. In the BLA problem, each process proposes a value from a join semi-lattice and needs to output a value also in the lattice such that all output values of correct processes lie on a chain despite the presence of Byzantine processes. We present an algorithm for this problem with round complexity of $O(\log f)$ which tolerates $f < \frac{n}{5}$ Byzantine failures in the asynchronous setting without digital signatures, where $n$ is the number of processes. We also show how this algorithm can be modified to work in the authenticated setting (i.e., with digital signatures) to tolerate $f < \frac{n}{3}$ Byzantine failures. <br><a href = "http://xxx.itp.ac.cn/pdf/2002.06779">PDF</a>
<h3>No. 5	How fast can you update your MST? (Dynamic algorithms for cluster  computing)</h3><h4>Seth Gilbert, Lawrence Li</h4> Abstract: Imagine a large graph that is being processed by a cluster of computers, e.g., described by the $k$-machine model or the Massively Parallel Computation Model. The graph, however, is not static; instead it is receiving a constant stream of updates. How fast can the cluster process the stream of updates? The fundamental question we want to ask in this paper is whether we can update the graph fast enough to keep up with the stream. We focus specifically on the problem of maintaining a minimum spanning tree (MST), and we give an algorithm for the $k$-machine model that can process $O(k)$ graph updates per $O(1)$ rounds with high probability. (And these results carry over to the Massively Parallel Computation (MPC) model.) We also show a lower bound, i.e., it is impossible to process $k^{1+\epsilon}$ updates in $O(1)$ rounds. Thus we provide a nearly tight answer to the question of how fast a cluster can respond to a stream of graph modifications while maintaining an MST. <br><a href = "http://xxx.itp.ac.cn/pdf/2002.06762">PDF</a>
<h3>No. 6	Running a Pre-Exascale, Geographically Distributed, Multi-Cloud  Scientific Simulation</h3><h4>Igor Sfiligoi, Frank Wuerthwein, Benedikt Riedel, David Schultz</h4> Abstract: As we approach the Exascale era, it is important to verify that the existing frameworks and tools will still work at that scale. Moreover, public Cloud computing has been emerging as a viable solution for both prototyping and urgent computing. Using the elasticity of the Cloud, we have thus put in place a pre-exascale HTCondor setup for running a scientific simulation in the Cloud, with the chosen application being IceCube's photon propagation simulation. I.e. this was not a purely demonstration run, but it was also used to produce valuable and much needed scientific results for the IceCube collaboration. In order to reach the desired scale, we aggregated GPU resources across 8 GPU models from many geographic regions across Amazon Web Services, Microsoft Azure, and the Google Cloud Platform. Using this setup, we reached a peak of over 51k GPUs corresponding to almost 380 PFLOP32s, for a total integrated compute of about 100k GPU hours. In this paper we provide the description of the setup, the problems that were discovered and overcome, as well as a short description of the actual science output of the exercise. <br><a href = "http://xxx.itp.ac.cn/pdf/2002.06667">PDF</a>
<h3>No. 7	Not a COINcidence: Sub-Quadratic Asynchronous Byzantine Agreement WHP</h3><h4>Shir Cohen, Idit Keidar, Alexander Spiegelman</h4> Abstract: King and Saia were the first to break the quadratic word complexity bound for Byzantine Agreement in synchronous systems against an adaptive adversary, and Algorand broke this bound with near-optimal resilience in the eventual-synchrony model. Yet the question of asynchronous sub-quadratic Byzantine Agreement remained open. To the best of our knowledge, we are the first to answer this question in the affirmative. A key component of our solution is a novel shared coin algorithm based on a VRF, without any further trusted setup. A second essential ingredient is VRF-based committee sampling, which we formalize and utilize in the asynchronous model for the first time. Our algorithms work against a delayed-adaptive adversary, which cannot perform after-the-fact removals but has full control of Byzantine processes and full information about communication in earlier rounds. Using committee sampling and our shared coin, we solve Byzantine Agreement with high probability, with a word complexity of $\widetilde{O}(n)$ and $O(1)$ expected time, breaking the $O(n^2)$ bit barrier for asynchronous Byzantine Agreement. <br><a href = "http://xxx.itp.ac.cn/pdf/2002.06545">PDF</a>
<h3>No. 8	Distributed Sketching Methods for Privacy Preserving Regression</h3><h4>Burak Bartan, Mert Pilanci</h4> Abstract: In this work, we study distributed sketching methods for large scale regression problems. We leverage multiple randomized sketches for reducing the problem dimensions as well as preserving privacy and improving straggler resilience in asynchronous distributed systems. We derive novel approximation guarantees for classical sketching methods and analyze the accuracy of parameter averaging for distributed sketches. We consider random matrices including Gaussian, randomized Hadamard, uniform sampling and leverage score sampling in the distributed setting. Moreover, we propose a hybrid approach combining sampling and fast random projections for better computational efficiency. We illustrate the performance of distributed sketches in a serverless computing platform with large scale experiments. <br><a href = "http://xxx.itp.ac.cn/pdf/2002.06538">PDF</a>
<h3>No. 9	Demystifying the Performance of HPC Scientific Applications on NVM-based  Memory Systems</h3><h4>Ivy Peng, Kai Wu, Jie Ren, Dong Li, Maya Gokhale</h4> Abstract: The emergence of high-density byte-addressable non-volatile memory (NVM) is promising to accelerate data- and compute-intensive applications. Current NVM technologies have lower performance than DRAM and, thus, are often paired with DRAM in a heterogeneous main memory. Recently, byte-addressable NVM hardware becomes available. This work provides a timely evaluation of representative HPC applications from the "Seven Dwarfs" on NVM-based main memory. Our results quantify the effectiveness of DRAM-cached-NVM for accelerating HPC applications and enabling large problems beyond the DRAM capacity. On uncached-NVM, HPC applications exhibit three tiers of performance sensitivity, i.e., insensitive, scaled, and bottlenecked. We identify write throttling and concurrency control as the priorities in optimizing applications. We highlight that concurrency change may have a diverging effect on read and write accesses in applications. Based on these findings, we explore two optimization approaches. First, we provide a prediction model that uses datasets from a small set of configurations to estimate performance at various concurrency and data sizes to avoid exhaustive search in the configuration space. Second, we demonstrate that write-aware data placement on uncached-NVM could achieve $2$x performance improvement with a 60% reduction in DRAM usage. <br><a href = "http://xxx.itp.ac.cn/pdf/2002.06499">PDF</a>
<h3>No. 10	Big Data Staging with MPI-IO for Interactive X-ray Science</h3><h4>Justin M. Wozniak, Hemant Sharma, Timothy G. Armstrong, Michael Wilde, Jonathan D. Almer, Ian Foster</h4> Abstract: New techniques in X-ray scattering science experiments produce large data sets that can require millions of high-performance processing hours per week of computation for analysis. In such applications, data is typically moved from X-ray detectors to a large parallel file system shared by all nodes of a petascale supercomputer and then is read repeatedly as different science application tasks proceed. However, this straightforward implementation causes significant contention in the file system. We propose an alternative approach in which data is instead staged into and cached in compute node memory for extended periods, during which time various processing tasks may efficiently access it. We describe here such a big data staging framework, based on MPI-IO and the Swift parallel scripting language. We discuss a range of large-scale data management issues involved in X-ray scattering science and measure the performance benefits of the new staging framework for high-energy diffraction microscopy, an important emerging application in data-intensive X-ray scattering. We show that our framework accelerates scientific processing turnaround from three months to under 10 minutes, and that our I/O technique reduces input overheads by a factor of 5 on 8K Blue Gene/Q nodes. <br><a href = "http://xxx.itp.ac.cn/pdf/2002.06258">PDF</a>
<h3>No. 11	Bitcoin's Blockchain Data Analytics: A Graph Theoretic Perspective</h3><h4>Aman Sharma, Ashutosh Bhatia</h4> Abstract: Bitcoin is the most popular cryptocurrency used worldwide. It provides pseudonymity to its users by establishing identity using public keys as transaction end-points. These transactions are recorded on an immutable public ledger called Blockchain which is an append-only data structure. The popularity of Bitcoin has increased unreasonably. The general trend shows a positive response from the common masses indicating an increase in trust and privacy concerns which makes an interesting use case from the analysis point of view. Moreover, since the blockchain is publicly available and up-to-date, any analysis would provide a live insight into the usage patterns which ultimately would be useful for making a number of inferences by law-enforcement agencies, economists, tech-enthusiasts, etc. In this paper, we study various applications and techniques of performing data analytics over Bitcoin blockchain from a graph theoretic perspective. We also propose a framework for performing such data analytics and explored a couple of use cases using the proposed framework. <br><a href = "http://xxx.itp.ac.cn/pdf/2002.06403">PDF</a>
<h3>No. 12	Neural Architecture Search over Decentralized Data</h3><h4>Mengwei Xu, Yuxin Zhao, Kaigui Bian, Gang Huang, Qiaozhu Mei, Xuanzhe Liu</h4> Abstract: To preserve user privacy while enabling mobile intelligence, techniques have been proposed to train deep neural networks on decentralized data. However, training over decentralized data makes the design of neural architecture quite difficult as it already was. Such difficulty is further amplified when designing and deploying different neural architectures for heterogeneous mobile platforms. In this work, we propose an automatic neural architecture search into the decentralized training, as a new DNN training paradigm called Federated Neural Architecture Search, namely federated NAS. To deal with the primary challenge of limited on-client computational and communication resources, we present FedNAS, a highly optimized framework for efficient federated NAS. FedNAS fully exploits the key opportunity of insufficient model candidate re-training during the architecture search process, and incorporates three key optimizations: parallel candidates training on partial clients, early dropping candidates with inferior performance, and dynamic round numbers. Tested on large-scale datasets and typical CNN architectures, FedNAS achieves comparable model accuracy as state-of-the-art NAS algorithm that trains models with centralized data, and also reduces the client cost by up to two orders of magnitude compared to a straightforward design of federated NAS. <br><a href = "http://xxx.itp.ac.cn/pdf/2002.06352">PDF</a>
</body></html>