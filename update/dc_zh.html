<!DOCTYPE html><html><head><meta charset="utf-8"><title>Distributed, Parallel, and Cluster Computing  authors/titles recent submissions</title></head><body>
<h2>2020-03-01</h2>
<h3>No. 1	基于ARM-NEON扩展的形态滤波快速实现</h3><h4>Elena Limonova, Arseny Terekhin, Dmitry Nikolaev, Vladimir Arlazarov</h4>文摘：本文研究了ARM处理器上形态学图像滤波的加速潜力。形态学操作在图像分析和识别中有着广泛的应用，在某些情况下，形态学操作的加速可以显著缩短识别的总体执行时间。更具体地说，我们建议使用ARM SIMD extension NEON快速实现腐蚀和膨胀。使用矩形结构元素的这些操作是可分离的。它们是利用可分离性作为连续水平和垂直通道的优点来实现的。每一步都是用van-Herk/Gil-Werman算法实现的，对于大窗口和小窗口分别采用低常线性复杂度算法。最后用SIMD进行了改进，并将这些方法结合起来使用。我们还考虑了使用ARM-NEON实现8x8和16x16矩阵的快速转置，以获得形态学操作的额外计算增益。实验表明，与没有SIMD的van-Herk/Gil-Werman算法相比，最终实现侵蚀和扩张的效率提高了3倍，8x8矩阵转置的速度提高了5.7倍，16x16矩阵转置的速度提高了12倍。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.09474">PDF</a>
<h3>No. 2	Faasm：实现高效有状态无服务器计算的轻量级隔离</h3><h4>Simon Shillaker, Peter Pietzuch</h4>摘要：无服务器计算可以快速、廉价地扩展到数千个并行函数，非常适合大数据处理。然而，现有的无服务器平台将功能隔离在短暂的、无状态的容器中。这意味着函数不能有效地共享内存，迫使用户在编写函数时重复序列化数据。我们发现基于容器的隔离不适合于无服务器的大数据处理。相反，它需要一种轻量级的隔离方法，允许高效的状态共享。我们介绍了faaslet，一种新的用于无服务器大数据计算的隔离抽象。faaslet使用WebAssembly提供的软件故障隔离（SFI）隔离已执行函数的内存，同时允许在同一地址空间中的函数之间共享内存区域。因此，当函数位于同一台机器上时，faaslet可以避免昂贵的数据移动。我们的faaslet、Faasm运行时使用标准的Linux cgroup隔离了其他资源，例如CPU和网络，并为网络、文件系统访问和动态加载提供了一个低级POSIX主机接口。为了减少初始化时间，Faasm从已经初始化的快照中恢复faaslet。我们将Faasm与标准的基于容器的平台进行了比较，结果表明，在训练机器学习模型时，它的速度提高了2倍，内存减少了10倍；对于服务于机器学习推理，Faasm的吞吐量增加了一倍，尾部延迟减少了90%。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.09344">PDF</a>
<h3>No. 3	为数据密集型科学应用开发摘要的方法和经验</h3><h4>Andre Luckow, Shantenu Jha</h4>摘要：为科学应用开发软件，需要集成各种类型的计算、仪器和数据，由于规模、异构性以及将各种编程和计算模型与不断发展和异构的基础设施集成的需要，这些挑战不同于商业软件。因此，普遍有效的抽象是至关重要的。为科学应用和基础设施开发摘要的过程还没有被很好地理解。虽然基于理论的方法适用于定义良好的封闭环境，但它们在为复杂的现实系统设计抽象方面有着严重的局限性。设计科学研究（DSR）方法为设计能够处理现实世界复杂性的有效系统提供了基础。DSR包括两个互补的阶段：设计和评估。本文将DSR方法应用于科学应用文摘的开发。具体来说，我们解决了异构基础设施上的分布式资源管理这一关键问题，这一挑战目前限制了许多科学应用。我们使用pilot抽象，这是一个广泛用于高性能、高吞吐量、大数据和流应用程序的资源管理抽象，作为一个案例研究。我们评估流程的活动，并使用不同的方法广泛地评估工件，包括概念建模、性能描述和建模。我们展示了DSR方法在整体处理并行和分布式计算环境复杂性方面的适用性，解决了科学应用中的重要应用、系统和基础设施挑战。最后，我们总结经验，总结经验教训。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.09009">PDF</a>
<h3>No. 4	具有最优误差界的分布平均估计</h3><h4>Dan Alistarh, Saleh Ashkboos, Peter Davies</h4>文摘：在分布式优化和机器学习应用的推动下，我们考虑了一个分布式平均估计问题，其中$n$节点被分配一个多维输入向量，并且必须合作估计输入向量的平均值，同时最小化通信量。本文根据节点间通信量与节点估计值相对于均值真值的方差之间的权衡关系，给出了该问题的第一个紧界。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.09268">PDF</a>
<h3>No. 5	子模最大化自适应复杂度的多项式下界</h3><h4>Wenzheng Li, Paul Liu, Jan Vondrak</h4>摘要：在大数据应用中，需要设计高度并行化的算法。在子模块优化的背景下，自适应复杂度已经成为衡量算法“顺序性”的一个广泛使用的指标。自适应模型中的算法是一轮一轮地进行的，每轮可以对一个函数$f$发出多项式形式的多个查询。每轮中的查询必须是独立的，由仅依赖于前几轮中获得的查询结果的计算生成。本文研究了自适应复杂度模型中子模最大化的两个基本变量：基数约束单调最大化和无约束非单调最大化。我们的主要结果是，$r$-基数约束单调最大化的圆算法对于任何$r<n^c$（其中$c>0$是某个常数）都不能获得一个优于$1-1/e-\Omega（\min{\frac{1}{r}、\frac{log^2 n}{r^3}）的因子。这是第一个结果，当我们接近最优因子$1-1/e$时，轮数必须多项式放大。对于无约束非单调最大化问题，我们给出了一个正的结果：对于每一个例子，并且每$\delta>0$，我们要么在$1$轮中得到$（1/2-\delta）$-近似值，要么在$O（1/\delta ^2）$轮中得到$（1/2+\Omega（\delta ^2））$-近似值。特别是（与基数约束的情况相反），不可能存在这样的情况：（i）无论轮数多少，都不可能获得优于$1/2$的因子，并且（ii）需要$r$轮才能获得$1/2-O（1/r）$的因子。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.09130">PDF</a>
<h3>No. 6	异步并行自适应随机梯度法</h3><h4>Yangyang Xu, Colin Sutcher-Shepard, Yibo Xu, Jie Chen</h4>文摘：随机梯度法是训练深度学习模型的主要方法。自适应版本（如Adam和AMSGrad）在实践中得到了广泛的应用，部分原因是它们比非自适应版本实现了更快的收敛，同时开销也很小。另一方面，异步（async）并行计算比同步（sync）并行计算显示出更好的速度。然而，异步并行实现只在非自适应SGMs中得到了验证。自适应SGMs的困难源于二阶矩项，这使得收敛分析在异步更新时具有挑战性。本文提出了一种基于AMSGrad的异步并行自适应SGM。我们证明，如果异步引起的陈旧性（也称为延迟）是有界的，该方法继承了AMSGrad对凸和非凸问题的收敛保证。我们的收敛速度结果表明，如果$\tau=o（K^{\frac{1}{4}）$，则近似线性的并行化速度加快，其中$\tau$是陈旧性，$K$是迭代次数。该方法在凸和非凸机器学习问题上都得到了验证，数值结果表明其明显优于同步方法。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.09095">PDF</a>
<h3>No. 7	分布式联合学习中通信压缩的不确定性原理及最优压缩器的搜索</h3><h4>Mher Safaryan, Egor Shulgin, Peter Richtárik</h4>摘要：为了降低分布式和联邦学习中的高通信成本，各种矢量压缩方案，如量化、稀疏化和抖动等，已成为当前的研究热点。在设计压缩方法时，一个目的是尽可能少地通信比特，这使得每一通信回合的成本最小化，同时试图将尽可能小的失真（方差）传递给所通信的消息，从而最大限度地减少了压缩对通信轮次总数的不利影响。然而，直观地说，这两个目标在根本上是冲突的：我们允许的压缩越多，消息就越失真。我们将这种直觉形式化，并证明了随机压缩算子的{em不确定性原理}，从而从数学上量化了这种限制，并且{em有效地提供了通信压缩可能实现的下限}。基于这些发展，我们要求寻找最优压缩算子。为了向这个方向迈出第一步，我们构造了一种新的无偏压缩方法，该方法受向量的Kashin表示的启发，我们称之为{em Kashin compression（KC）}。与之前提出的所有压缩机制相比，我们证明了即使在每个向量条目只需要通信几个位的情况下，KC也具有{em维数无关}的方差边界，并且有一个显式公式。我们展示了如何将KC与现有的几种优化算法有效地结合起来，从而在所有情况下提高通信复杂度。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08958">PDF</a><h2>2020-02-29</h2>
<h3>No. 1	基于ARM-NEON扩展的形态滤波快速实现</h3><h4>Elena Limonova, Arseny Terekhin, Dmitry Nikolaev, Vladimir Arlazarov</h4>文摘：本文研究了ARM处理器上形态学图像滤波的加速潜力。形态学操作在图像分析和识别中有着广泛的应用，在某些情况下，形态学操作的加速可以显著缩短识别的总体执行时间。更具体地说，我们建议使用ARM SIMD extension NEON快速实现腐蚀和膨胀。使用矩形结构元素的这些操作是可分离的。它们是利用可分离性作为连续水平和垂直通道的优点来实现的。每一步都是用van-Herk/Gil-Werman算法实现的，对于大窗口和小窗口分别采用低常线性复杂度算法。最后用SIMD进行了改进，并将这些方法结合起来使用。我们还考虑了使用ARM-NEON实现8x8和16x16矩阵的快速转置，以获得形态学操作的额外计算增益。实验表明，与没有SIMD的van-Herk/Gil-Werman算法相比，最终实现侵蚀和扩张的效率提高了3倍，8x8矩阵转置的速度提高了5.7倍，16x16矩阵转置的速度提高了12倍。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.09474">PDF</a>
<h3>No. 2	Faasm：实现高效有状态无服务器计算的轻量级隔离</h3><h4>Simon Shillaker, Peter Pietzuch</h4>摘要：无服务器计算可以快速、廉价地扩展到数千个并行函数，非常适合大数据处理。然而，现有的无服务器平台将功能隔离在短暂的、无状态的容器中。这意味着函数不能有效地共享内存，迫使用户在编写函数时重复序列化数据。我们发现基于容器的隔离不适合于无服务器的大数据处理。相反，它需要一种轻量级的隔离方法，允许高效的状态共享。我们介绍了faaslet，一种新的用于无服务器大数据计算的隔离抽象。faaslet使用WebAssembly提供的软件故障隔离（SFI）隔离已执行函数的内存，同时允许在同一地址空间中的函数之间共享内存区域。因此，当函数位于同一台机器上时，faaslet可以避免昂贵的数据移动。我们的faaslet、Faasm运行时使用标准的Linux cgroup隔离了其他资源，例如CPU和网络，并为网络、文件系统访问和动态加载提供了一个低级POSIX主机接口。为了减少初始化时间，Faasm从已经初始化的快照中恢复faaslet。我们将Faasm与标准的基于容器的平台进行了比较，结果表明，在训练机器学习模型时，它的速度提高了2倍，内存减少了10倍；对于服务于机器学习推理，Faasm的吞吐量增加了一倍，尾部延迟减少了90%。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.09344">PDF</a>
<h3>No. 3	为数据密集型科学应用开发摘要的方法和经验</h3><h4>Andre Luckow, Shantenu Jha</h4>摘要：为科学应用开发软件，需要集成各种类型的计算、仪器和数据，由于规模、异构性以及将各种编程和计算模型与不断发展和异构的基础设施集成的需要，这些挑战与商业软件不同。因此，普遍有效的抽象是至关重要的。为科学应用和基础设施开发摘要的过程还没有被很好地理解。虽然基于理论的方法适用于定义良好的封闭环境，但它们在为复杂的现实系统设计抽象方面有着严重的局限性。设计科学研究（DSR）方法为设计能够处理现实世界复杂性的有效系统提供了基础。DSR包括两个互补的阶段：设计和评估。本文将DSR方法应用于科学应用文摘的开发。具体来说，我们解决了异构基础设施上的分布式资源管理这一关键问题，这一挑战目前限制了许多科学应用。我们使用pilot抽象，这是一个广泛用于高性能、高吞吐量、大数据和流应用程序的资源管理抽象，作为一个案例研究。我们评估流程的活动，并使用不同的方法广泛地评估工件，包括概念建模、性能描述和建模。我们展示了DSR方法在整体处理并行和分布式计算环境复杂性方面的适用性，解决了科学应用中的重要应用、系统和基础设施挑战。最后，我们总结经验，总结经验教训。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.09009">PDF</a>
<h3>No. 4	具有最优误差界的分布平均估计</h3><h4>Dan Alistarh, Saleh Ashkboos, Peter Davies</h4>文摘：在分布式优化和机器学习应用的推动下，我们考虑了一个分布式平均估计问题，其中$n$节点被分配一个多维输入向量，并且必须合作估计输入向量的平均值，同时最小化通信量。本文根据节点间通信量与节点估计值相对于均值真值的方差之间的权衡关系，给出了该问题的第一个紧界。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.09268">PDF</a>
<h3>No. 5	子模最大化自适应复杂度的多项式下界</h3><h4>Wenzheng Li, Paul Liu, Jan Vondrak</h4>摘要：在大数据应用中，需要设计高度并行化的算法。在子模块优化的背景下，自适应复杂度已经成为衡量算法“顺序性”的一个广泛使用的指标。自适应模型中的算法是一轮一轮地进行的，每轮可以对一个函数$f$发出多项式形式的多个查询。每轮中的查询必须是独立的，由仅依赖于前几轮中获得的查询结果的计算生成。本文研究了自适应复杂度模型中子模最大化的两个基本变量：基数约束单调最大化和无约束非单调最大化。我们的主要结果是，$r$-基数约束单调最大化的圆算法对于任何$r<n^c$（其中$c>0$是某个常数）都不能获得一个优于$1-1/e-\Omega（\min{\frac{1}{r}、\frac{log^2 n}{r^3}）的因子。这是第一个结果，当我们接近最优因子$1-1/e$时，轮数必须多项式放大。对于无约束非单调最大化问题，我们给出了一个正的结果：对于每一个例子，并且每$\delta>0$，我们要么在$1$轮中得到$（1/2-\delta）$-近似值，要么在$O（1/\delta ^2）$轮中得到$（1/2+\Omega（\delta ^2））$-近似值。特别是（与基数约束的情况相反），不可能存在这样的情况：（i）无论轮数多少，都不可能获得优于$1/2$的因子，并且（ii）需要$r$轮才能获得$1/2-O（1/r）$的因子。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.09130">PDF</a>
<h3>No. 6	异步并行自适应随机梯度法</h3><h4>Yangyang Xu, Colin Sutcher-Shepard, Yibo Xu, Jie Chen</h4>文摘：随机梯度法是训练深度学习模型的主要方法。自适应版本（如Adam和AMSGrad）在实践中得到了广泛的应用，部分原因是它们比非自适应版本实现了更快的收敛，同时开销也很小。另一方面，异步（async）并行计算比同步（sync）并行计算显示出更好的速度。然而，异步并行实现只在非自适应SGMs中得到了验证。自适应SGMs的困难源于二阶矩项，这使得收敛分析在异步更新时具有挑战性。本文提出了一种基于AMSGrad的异步并行自适应SGM。我们证明，如果异步引起的陈旧性（也称为延迟）是有界的，该方法继承了AMSGrad对凸和非凸问题的收敛保证。我们的收敛速度结果表明，如果$\tau=o（K^{\frac{1}{4}）$，则近似线性的并行化速度加快，其中$\tau$是陈旧性，$K$是迭代次数。该方法在凸和非凸机器学习问题上都得到了验证，数值结果表明其明显优于同步方法。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.09095">PDF</a>
<h3>No. 7	分布式联合学习中通信压缩的不确定性原理及最优压缩器的搜索</h3><h4>Mher Safaryan, Egor Shulgin, Peter Richtárik</h4>摘要：为了降低分布式和联邦学习中的高通信成本，各种矢量压缩方案，如量化、稀疏化和抖动等，已成为当前的研究热点。在设计压缩方法时，一个目的是尽可能少地通信比特，这使得每一通信回合的成本最小化，同时试图将尽可能小的失真（方差）传递给所通信的消息，从而最大限度地减少了压缩对通信轮次总数的不利影响。然而，直观地说，这两个目标在根本上是冲突的：我们允许的压缩越多，消息就越失真。我们将这种直觉形式化，并证明了随机压缩算子的{em不确定性原理}，从而从数学上量化了这种限制，并且{em有效地提供了通信压缩可能实现的下限}。基于这些发展，我们要求寻找最优压缩算子。为了向这个方向迈出第一步，我们构造了一种新的无偏压缩方法，该方法受向量的Kashin表示的启发，我们称之为{em Kashin compression（KC）}。与之前提出的所有压缩机制相比，我们证明了即使在每个向量条目只需要通信几个位的情况下，KC也具有{em维数无关}的方差边界，并且有一个显式公式。我们展示了如何将KC与现有的几种优化算法有效地结合起来，从而在所有情况下提高通信复杂度。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08958">PDF</a><h2>2020-02-29</h2>
<h3>No. 1	基于ARM-NEON扩展的形态滤波快速实现</h3><h4>Elena Limonova, Arseny Terekhin, Dmitry Nikolaev, Vladimir Arlazarov</h4>文摘：本文研究了ARM处理器上形态学图像滤波的加速潜力。形态学操作在图像分析和识别中有着广泛的应用，在某些情况下，形态学操作的加速可以显著缩短识别的总体执行时间。更具体地说，我们建议使用ARM SIMD extension NEON快速实现腐蚀和膨胀。使用矩形结构元素的这些操作是可分离的。它们是利用可分离性作为连续水平和垂直通道的优点来实现的。每一步都是用van-Herk/Gil-Werman算法实现的，对于大窗口和小窗口分别采用低常线性复杂度算法。最后用SIMD进行了改进，并将这些方法结合起来使用。我们还考虑了使用ARM-NEON实现8x8和16x16矩阵的快速转置，以获得形态学操作的额外计算增益。实验表明，与没有SIMD的van-Herk/Gil-Werman算法相比，最终实现侵蚀和扩张的效率提高了3倍，8x8矩阵转置的速度提高了5.7倍，16x16矩阵转置的速度提高了12倍。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.09474">PDF</a>
<h3>No. 2	Faasm：实现高效有状态无服务器计算的轻量级隔离</h3><h4>Simon Shillaker, Peter Pietzuch</h4>摘要：无服务器计算可以快速、廉价地扩展到数千个并行函数，非常适合大数据处理。然而，现有的无服务器平台将功能隔离在短暂的、无状态的容器中。这意味着函数不能有效地共享内存，迫使用户在编写函数时重复序列化数据。我们发现基于容器的隔离不适合于无服务器的大数据处理。相反，它需要一种轻量级的隔离方法，允许高效的状态共享。我们介绍了faaslet，一种新的用于无服务器大数据计算的隔离抽象。faaslet使用WebAssembly提供的软件故障隔离（SFI）隔离已执行函数的内存，同时允许在同一地址空间中的函数之间共享内存区域。因此，当函数位于同一台机器上时，faaslet可以避免昂贵的数据移动。我们的faaslet、Faasm运行时使用标准的Linux cgroup隔离了其他资源，例如CPU和网络，并为网络、文件系统访问和动态加载提供了一个低级POSIX主机接口。为了减少初始化时间，Faasm从已经初始化的快照中恢复faaslet。我们将Faasm与标准的基于容器的平台进行了比较，结果表明，在训练机器学习模型时，它的速度提高了2倍，内存减少了10倍；对于服务于机器学习推理，Faasm的吞吐量增加了一倍，尾部延迟减少了90%。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.09344">PDF</a>
<h3>No. 3	为数据密集型科学应用开发摘要的方法和经验</h3><h4>Andre Luckow, Shantenu Jha</h4>摘要：为科学应用开发软件，需要集成各种类型的计算、仪器和数据，由于规模、异构性以及将各种编程和计算模型与不断发展和异构的基础设施集成的需要，这些挑战与商业软件不同。因此，普遍有效的抽象是至关重要的。为科学应用和基础设施开发摘要的过程还没有被很好地理解。虽然基于理论的方法适用于定义良好的封闭环境，但它们在为复杂的现实系统设计抽象方面有着严重的局限性。设计科学研究（DSR）方法为设计能够处理现实世界复杂性的有效系统提供了基础。DSR包括两个互补的阶段：设计和评估。本文将DSR方法应用于科学应用文摘的开发。具体来说，我们解决了异构基础设施上的分布式资源管理这一关键问题，这一挑战目前限制了许多科学应用。我们使用pilot抽象，这是一个广泛用于高性能、高吞吐量、大数据和流应用程序的资源管理抽象，作为一个案例研究。我们评估流程的活动，并使用不同的方法广泛地评估工件，包括概念建模、性能描述和建模。我们展示了DSR方法在整体处理并行和分布式计算环境复杂性方面的适用性，解决了科学应用中的重要应用、系统和基础设施挑战。最后，我们总结经验，总结经验教训。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.09009">PDF</a>
<h3>No. 4	具有最优误差界的分布平均估计</h3><h4>Dan Alistarh, Saleh Ashkboos, Peter Davies</h4>文摘：在分布式优化和机器学习应用的推动下，我们考虑了一个分布式平均估计问题，其中$n$节点被分配一个多维输入向量，并且必须合作估计输入向量的平均值，同时最小化通信量。本文根据节点间通信量与节点估计值相对于均值真值的方差之间的权衡关系，给出了该问题的第一个紧界。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.09268">PDF</a>
<h3>No. 5	子模最大化自适应复杂度的多项式下界</h3><h4>Wenzheng Li, Paul Liu, Jan Vondrak</h4>摘要：在大数据应用中，需要设计高度并行化的算法。在子模块优化的背景下，自适应复杂度已经成为衡量算法“顺序性”的一个广泛使用的指标。自适应模型中的算法是一轮一轮地进行的，每轮可以对一个函数$f$发出多项式形式的多个查询。每轮中的查询必须是独立的，由仅依赖于前几轮中获得的查询结果的计算生成。本文研究了自适应复杂度模型中子模最大化的两个基本变量：基数约束单调最大化和无约束非单调最大化。我们的主要结果是，$r$-基数约束单调最大化的圆算法对于任何$r<n^c$（其中$c>0$是某个常数）都不能获得一个优于$1-1/e-\Omega（\min{\frac{1}{r}、\frac{log^2 n}{r^3}）的因子。这是第一个结果，当我们接近最优因子$1-1/e$时，轮数必须多项式放大。对于无约束非单调最大化问题，我们给出了一个正的结果：对于每一个例子，并且每$\delta>0$，我们要么在$1$轮中得到$（1/2-\delta）$-近似值，要么在$O（1/\delta ^2）$轮中得到$（1/2+\Omega（\delta ^2））$-近似值。特别是（与基数约束的情况相反），不可能存在这样的情况：（i）无论轮数多少，都不可能获得优于$1/2$的因子，并且（ii）需要$r$轮才能获得$1/2-O（1/r）$的因子。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.09130">PDF</a>
<h3>No. 6	异步并行自适应随机梯度法</h3><h4>Yangyang Xu, Colin Sutcher-Shepard, Yibo Xu, Jie Chen</h4>文摘：随机梯度法是训练深度学习模型的主要方法。自适应版本（如Adam和AMSGrad）在实践中得到了广泛的应用，部分原因是它们比非自适应版本实现了更快的收敛，同时开销也很小。另一方面，异步（async）并行计算比同步（sync）并行计算显示出更好的速度。然而，异步并行实现只在非自适应SGMs中得到了验证。自适应SGMs的困难源于二阶矩项，这使得收敛分析在异步更新时具有挑战性。本文提出了一种基于AMSGrad的异步并行自适应SGM。我们证明，如果异步引起的陈旧性（也称为延迟）是有界的，该方法继承了AMSGrad对凸和非凸问题的收敛保证。我们的收敛速度结果表明，如果$\tau=o（K^{\frac{1}{4}）$，则近似线性的并行化速度加快，其中$\tau$是陈旧性，$K$是迭代次数。该方法在凸和非凸机器学习问题上都得到了验证，数值结果表明其明显优于同步方法。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.09095">PDF</a>
<h3>No. 7	分布式联合学习中通信压缩的不确定性原理及最优压缩器的搜索</h3><h4>Mher Safaryan, Egor Shulgin, Peter Richtárik</h4>摘要：为了降低分布式和联邦学习中的高通信成本，各种矢量压缩方案，如量化、稀疏化和抖动等，已成为当前的研究热点。在设计压缩方法时，一个目的是尽可能少地通信比特，这使得每一通信回合的成本最小化，同时试图将尽可能小的失真（方差）传递给所通信的消息，从而最大限度地减少了压缩对通信轮次总数的不利影响。然而，直观地说，这两个目标在根本上是冲突的：我们允许的压缩越多，消息就越失真。我们将这种直觉形式化，并证明了随机压缩算子的{em不确定性原理}，从而从数学上量化了这种限制，并且{em有效地提供了通信压缩可能实现的下限}。基于这些发展，我们要求寻找最优压缩算子。为了向这个方向迈出第一步，我们构造了一种新的无偏压缩方法，该方法受向量的Kashin表示的启发，我们称之为{em Kashin compression（KC）}。与之前提出的所有压缩机制相比，我们证明了即使在每个向量条目只需要通信几位的情况下，KC也具有{em维数无关}的方差边界，并且有一个显式公式。我们展示了如何将KC与现有的几种优化算法有效地结合起来，从而在所有情况下提高通信复杂度。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08958">PDF</a><h2>2020-02-28</h2>
<h3>No. 1	基于ARM-NEON扩展的形态滤波快速实现</h3><h4>Elena Limonova, Arseny Terekhin, Dmitry Nikolaev, Vladimir Arlazarov</h4>文摘：本文研究了ARM处理器上形态学图像滤波的加速潜力。形态学操作在图像分析和识别中有着广泛的应用，在某些情况下，形态学操作的加速可以显著缩短识别的总体执行时间。更具体地说，我们建议使用ARM SIMD extension NEON快速实现腐蚀和膨胀。使用矩形结构元素的这些操作是可分离的。它们是利用可分离性作为连续水平和垂直通道的优点来实现的。每一步都是用van-Herk/Gil-Werman算法实现的，对于大窗口和小窗口分别采用低常线性复杂度算法。最后用SIMD进行了改进，并将这些方法结合起来使用。我们还考虑了使用ARM-NEON实现8x8和16x16矩阵的快速转置，以获得形态学操作的额外计算增益。实验表明，与没有SIMD的van-Herk/Gil-Werman算法相比，最终实现侵蚀和扩张的效率提高了3倍，8x8矩阵转置的速度提高了5.7倍，16x16矩阵转置的速度提高了12倍。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.09474">PDF</a>
<h3>No. 2	Faasm：实现高效有状态无服务器计算的轻量级隔离</h3><h4>Simon Shillaker, Peter Pietzuch</h4>摘要：无服务器计算可以快速、廉价地扩展到数千个并行函数，非常适合大数据处理。然而，现有的无服务器平台将功能隔离在短暂的、无状态的容器中。这意味着函数不能有效地共享内存，迫使用户在编写函数时重复序列化数据。我们发现基于容器的隔离不适合于无服务器的大数据处理。相反，它需要一种轻量级的隔离方法，允许高效的状态共享。我们介绍了faaslet，一种新的用于无服务器大数据计算的隔离抽象。faaslet使用WebAssembly提供的软件故障隔离（SFI）隔离已执行函数的内存，同时允许在同一地址空间中的函数之间共享内存区域。因此，当函数位于同一台机器上时，faaslet可以避免昂贵的数据移动。我们的faaslet、Faasm运行时使用标准的Linux cgroup隔离了其他资源，例如CPU和网络，并为网络、文件系统访问和动态加载提供了一个低级POSIX主机接口。为了减少初始化时间，Faasm从已经初始化的快照中恢复faaslet。我们将Faasm与标准的基于容器的平台进行了比较，结果表明，在训练机器学习模型时，它的速度提高了2倍，内存减少了10倍；对于服务于机器学习推理，Faasm的吞吐量增加了一倍，尾部延迟减少了90%。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.09344">PDF</a>
<h3>No. 3	为数据密集型科学应用开发摘要的方法和经验</h3><h4>Andre Luckow, Shantenu Jha</h4>摘要：为科学应用开发软件，需要集成各种类型的计算、仪器和数据，由于规模、异构性以及将各种编程和计算模型与不断发展和异构的基础设施集成的需要，这些挑战不同于商业软件。因此，普遍有效的抽象是至关重要的。为科学应用和基础设施开发摘要的过程还没有被很好地理解。虽然基于理论的方法适用于定义良好的封闭环境，但它们在为复杂的现实系统设计抽象方面有着严重的局限性。设计科学研究（DSR）方法为设计能够处理现实世界复杂性的有效系统提供了基础。DSR包括两个互补的阶段：设计和评估。本文将DSR方法应用于科学应用文摘的开发。具体来说，我们解决了异构基础设施上的分布式资源管理这一关键问题，这一挑战目前限制了许多科学应用。我们使用pilot抽象，这是一个广泛用于高性能、高吞吐量、大数据和流应用程序的资源管理抽象，作为一个案例研究。我们评估流程的活动，并使用不同的方法广泛地评估工件，包括概念建模、性能描述和建模。我们展示了DSR方法在整体处理并行和分布式计算环境复杂性方面的适用性，解决了科学应用中的重要应用、系统和基础设施挑战。最后，我们总结经验，总结经验教训。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.09009">PDF</a>
<h3>No. 4	具有最优误差界的分布平均估计</h3><h4>Dan Alistarh, Saleh Ashkboos, Peter Davies</h4>文摘：在分布式优化和机器学习应用的推动下，我们考虑了一个分布式平均估计问题，其中$n$节点被分配一个多维输入向量，并且必须合作估计输入向量的平均值，同时最小化通信量。本文根据节点间通信量与节点估计值相对于均值真值的方差之间的权衡关系，给出了该问题的第一个紧界。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.09268">PDF</a>
<h3>No. 5	子模最大化自适应复杂度的多项式下界</h3><h4>Wenzheng Li, Paul Liu, Jan Vondrak</h4>摘要：在大数据应用中，需要设计高度并行化的算法。在子模块优化的背景下，自适应复杂度已经成为衡量算法“顺序性”的一个广泛使用的指标。自适应模型中的算法是一轮一轮地进行的，每轮可以对一个函数$f$发出多项式形式的多个查询。每轮中的查询必须是独立的，由仅依赖于前几轮中获得的查询结果的计算生成。本文研究了自适应复杂度模型中子模最大化的两个基本变量：基数约束单调最大化和无约束非单调最大化。我们的主要结果是，$r$-基数约束单调最大化的圆算法对于任何$r<n^c$（其中$c>0$是某个常数）都不能获得一个优于$1-1/e-\Omega（\min{\frac{1}{r}、\frac{log^2 n}{r^3}）的因子。这是第一个结果，当我们接近最优因子$1-1/e$时，轮数必须多项式放大。对于无约束非单调最大化问题，我们给出了一个正的结果：对于每一个例子，并且每$\delta>0$，我们要么在$1$轮中得到$（1/2-\delta）$-近似值，要么在$O（1/\delta ^2）$轮中得到$（1/2+\Omega（\delta ^2））$-近似值。特别是（与基数约束的情况相反），不可能存在这样的情况：（i）无论轮数多少，都不可能获得优于$1/2$的因子，并且（ii）需要$r$轮才能获得$1/2-O（1/r）$的因子。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.09130">PDF</a>
<h3>No. 6	异步并行自适应随机梯度法</h3><h4>Yangyang Xu, Colin Sutcher-Shepard, Yibo Xu, Jie Chen</h4>文摘：随机梯度法是训练深度学习模型的主要方法。自适应版本（如Adam和AMSGrad）在实践中得到了广泛的应用，部分原因是它们比非自适应版本实现了更快的收敛，同时开销也很小。另一方面，异步（async）并行计算比同步（sync）并行计算显示出更好的速度。然而，异步并行实现只在非自适应SGMs中得到了验证。自适应SGMs的困难源于二阶矩项，这使得收敛分析在异步更新时具有挑战性。本文提出了一种基于AMSGrad的异步并行自适应SGM。我们证明，如果异步引起的陈旧性（也称为延迟）是有界的，该方法继承了AMSGrad对凸和非凸问题的收敛保证。我们的收敛速度结果表明，如果$\tau=o（K^{\frac{1}{4}）$，则近似线性的并行化速度加快，其中$\tau$是陈旧性，$K$是迭代次数。该方法在凸和非凸机器学习问题上都得到了验证，数值结果表明其明显优于同步方法。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.09095">PDF</a>
<h3>No. 7	分布式联合学习中通信压缩的不确定性原理及最优压缩器的搜索</h3><h4>Mher Safaryan, Egor Shulgin, Peter Richtárik</h4>摘要：为了降低分布式和联邦学习中的高通信成本，各种矢量压缩方案，如量化、稀疏化和抖动等，已成为当前的研究热点。在设计压缩方法时，一个目的是尽可能少地通信比特，这使得每一通信回合的成本最小化，同时试图将尽可能小的失真（方差）传递给所通信的消息，从而最大限度地减少了压缩对通信轮次总数的不利影响。然而，直观地说，这两个目标在根本上是冲突的：我们允许的压缩越多，消息就越失真。我们将这种直觉形式化，并证明了随机压缩算子的{em不确定性原理}，从而从数学上量化了这种限制，并且{em有效地提供了通信压缩可能实现的下限}。基于这些发展，我们要求寻找最优压缩算子。为了向这个方向迈出第一步，我们构造了一种新的无偏压缩方法，该方法受向量的Kashin表示的启发，我们称之为{em Kashin compression（KC）}。与之前提出的所有压缩机制相比，我们证明了即使在每个向量条目只需要通信几位的情况下，KC也具有{em维数无关}的方差边界，并且有一个显式公式。我们展示了如何将KC与现有的几种优化算法有效地结合起来，从而在所有情况下提高通信复杂度。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08958">PDF</a><h2>2020-02-27</h2>
<h3>No. 1	基于ARM-NEON扩展的形态滤波快速实现</h3><h4>Elena Limonova, Arseny Terekhin, Dmitry Nikolaev, Vladimir Arlazarov</h4>文摘：本文研究了ARM处理器上形态学图像滤波的加速潜力。形态学操作在图像分析和识别中有着广泛的应用，在某些情况下，形态学操作的加速可以显著缩短识别的总体执行时间。更具体地说，我们建议使用ARM SIMD extension NEON快速实现腐蚀和膨胀。使用矩形结构元素的这些操作是可分离的。它们是利用可分离性作为连续水平和垂直通道的优点来实现的。每一步都是用van-Herk/Gil-Werman算法实现的，对于大窗口和小窗口分别采用低常线性复杂度算法。最后用SIMD进行了改进，并将这些方法结合起来使用。我们还考虑了使用ARM-NEON实现8x8和16x16矩阵的快速转置，以获得形态学操作的额外计算增益。实验表明，与没有SIMD的van-Herk/Gil-Werman算法相比，最终实现侵蚀和扩张的效率提高了3倍，8x8矩阵转置的速度提高了5.7倍，16x16矩阵转置的速度提高了12倍。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.09474">PDF</a>
<h3>No. 2	Faasm：实现高效有状态无服务器计算的轻量级隔离</h3><h4>Simon Shillaker, Peter Pietzuch</h4>摘要：无服务器计算可以快速、廉价地扩展到数千个并行函数，非常适合大数据处理。然而，现有的无服务器平台将功能隔离在短暂的、无状态的容器中。这意味着函数不能有效地共享内存，迫使用户在编写函数时重复序列化数据。我们发现基于容器的隔离不适合于无服务器的大数据处理。相反，它需要一种轻量级的隔离方法，允许高效的状态共享。我们介绍了faaslet，一种新的用于无服务器大数据计算的隔离抽象。faaslet使用WebAssembly提供的软件故障隔离（SFI）隔离已执行函数的内存，同时允许在同一地址空间中的函数之间共享内存区域。因此，当函数位于同一台机器上时，faaslet可以避免昂贵的数据移动。我们的faaslet、Faasm运行时使用标准的Linux cgroup隔离了其他资源，例如CPU和网络，并为网络、文件系统访问和动态加载提供了一个低级POSIX主机接口。为了减少初始化时间，Faasm从已经初始化的快照中恢复faaslet。我们将Faasm与标准的基于容器的平台进行了比较，结果表明，在训练机器学习模型时，它的速度提高了2倍，内存减少了10倍；对于服务于机器学习推理，Faasm的吞吐量增加了一倍，尾部延迟减少了90%。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.09344">PDF</a>
<h3>No. 3	为数据密集型科学应用开发摘要的方法和经验</h3><h4>Andre Luckow, Shantenu Jha</h4>摘要：为科学应用开发软件，需要集成各种类型的计算、仪器和数据，由于规模、异构性以及将各种编程和计算模型与不断发展和异构的基础设施集成的需要，这些挑战与商业软件不同。因此，普遍有效的抽象是至关重要的。为科学应用和基础设施开发摘要的过程还没有被很好地理解。虽然基于理论的方法适用于定义良好的封闭环境，但它们在为复杂的现实系统设计抽象方面有着严重的局限性。设计科学研究（DSR）方法为设计能够处理现实世界复杂性的有效系统提供了基础。DSR包括两个互补的阶段：设计和评估。本文将DSR方法应用于科学应用文摘的开发。具体来说，我们解决了异构基础设施上的分布式资源管理这一关键问题，这一挑战目前限制了许多科学应用。我们使用pilot抽象，这是一个广泛用于高性能、高吞吐量、大数据和流应用程序的资源管理抽象，作为一个案例研究。我们评估流程的活动，并使用不同的方法广泛地评估工件，包括概念建模、性能描述和建模。我们展示了DSR方法在整体处理并行和分布式计算环境复杂性方面的适用性，解决了科学应用中的重要应用、系统和基础设施挑战。最后，我们总结经验，总结经验教训。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.09009">PDF</a>
<h3>No. 4	具有最优误差界的分布平均估计</h3><h4>Dan Alistarh, Saleh Ashkboos, Peter Davies</h4>文摘：在分布式优化和机器学习应用的推动下，我们考虑了一个分布式平均估计问题，其中$n$节点被分配一个多维输入向量，并且必须合作估计输入向量的平均值，同时最小化通信量。本文根据节点间通信量与节点估计值相对于均值真值的方差之间的权衡关系，给出了该问题的第一个紧界。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.09268">PDF</a>
<h3>No. 5	子模最大化自适应复杂度的多项式下界</h3><h4>Wenzheng Li, Paul Liu, Jan Vondrak</h4>摘要：在大数据应用中，需要设计高度并行化的算法。在子模块优化的背景下，自适应复杂度已经成为衡量算法“顺序性”的一个广泛使用的指标。自适应模型中的算法是一轮一轮地进行的，每轮可以对一个函数$f$发出多项式形式的多个查询。每轮中的查询必须是独立的，由仅依赖于前几轮中获得的查询结果的计算生成。本文研究了自适应复杂度模型中子模最大化的两个基本变量：基数约束单调最大化和无约束非单调最大化。我们的主要结果是，$r$-基数约束单调最大化的圆算法对于任何$r<n^c$（其中$c>0$是某个常数）都不能获得一个优于$1-1/e-\Omega（\min{\frac{1}{r}、\frac{log^2 n}{r^3}）的因子。这是第一个结果，当我们接近最优因子$1-1/e$时，轮数必须多项式放大。对于无约束非单调最大化问题，我们给出了一个正的结果：对于每一个例子，并且每$\delta>0$，我们要么在$1$轮中得到$（1/2-\delta）$-近似值，要么在$O（1/\delta ^2）$轮中得到$（1/2+\Omega（\delta ^2））$-近似值。特别是（与基数约束的情况相反），不可能存在这样的情况：（i）无论轮数多少，都不可能获得优于$1/2$的因子，并且（ii）需要$r$轮才能获得$1/2-O（1/r）$的因子。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.09130">PDF</a>
<h3>No. 6	异步并行自适应随机梯度法</h3><h4>Yangyang Xu, Colin Sutcher-Shepard, Yibo Xu, Jie Chen</h4>文摘：随机梯度法是训练深度学习模型的主要方法。自适应版本（如Adam和AMSGrad）在实践中得到了广泛的应用，部分原因是它们比非自适应版本实现了更快的收敛，同时开销也很小。另一方面，异步（async）并行计算比同步（sync）并行计算显示出更好的速度。然而，异步并行实现只在非自适应SGMs中得到了验证。自适应SGMs的困难源于二阶矩项，这使得收敛分析在异步更新时具有挑战性。本文提出了一种基于AMSGrad的异步并行自适应SGM。我们证明，如果异步引起的陈旧性（也称为延迟）是有界的，该方法继承了AMSGrad对凸和非凸问题的收敛保证。我们的收敛速度结果表明，如果$\tau=o（K^{\frac{1}{4}）$，则近似线性的并行化速度加快，其中$\tau$是陈旧性，$K$是迭代次数。该方法在凸和非凸机器学习问题上都得到了验证，数值结果表明其明显优于同步方法。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.09095">PDF</a>
<h3>No. 7	分布式联合学习中通信压缩的不确定性原理及最优压缩器的搜索</h3><h4>Mher Safaryan, Egor Shulgin, Peter Richtárik</h4>摘要：为了降低分布式和联邦学习中的高通信成本，各种矢量压缩方案，如量化、稀疏化和抖动等，已成为当前的研究热点。在设计压缩方法时，一个目的是尽可能少地通信比特，这使得每一通信回合的成本最小化，同时试图将尽可能小的失真（方差）传递给所通信的消息，从而最大限度地减少了压缩对通信轮次总数的不利影响。然而，直观地说，这两个目标在根本上是冲突的：我们允许的压缩越多，消息就越失真。我们将这种直觉形式化，并证明了随机压缩算子的{em不确定性原理}，从而从数学上量化了这种限制，并且{em有效地提供了通信压缩可能实现的下限}。基于这些发展，我们要求寻找最优压缩算子。为了向这个方向迈出第一步，我们构造了一种新的无偏压缩方法，该方法受向量的Kashin表示的启发，我们称之为{em Kashin compression（KC）}。与之前提出的所有压缩机制相比，我们证明了即使在每个向量条目只需要通信几位的情况下，KC也具有{em维数无关}的方差边界，并且有一个显式公式。我们展示了如何将KC与现有的几种优化算法有效地结合起来，从而在所有情况下提高通信复杂度。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08958">PDF</a><h2>2020-02-26</h2>
<h3>No. 1	基于ARM-NEON扩展的形态滤波快速实现</h3><h4>Elena Limonova, Arseny Terekhin, Dmitry Nikolaev, Vladimir Arlazarov</h4>文摘：本文研究了ARM处理器上形态学图像滤波的加速潜力。形态学操作在图像分析和识别中有着广泛的应用，在某些情况下，形态学操作的加速可以显著缩短识别的总体执行时间。更具体地说，我们建议使用ARM SIMD extension NEON快速实现腐蚀和膨胀。使用矩形结构元素的这些操作是可分离的。它们是利用可分离性作为连续水平和垂直通道的优点来实现的。每一步都是用van-Herk/Gil-Werman算法实现的，对于大窗口和小窗口分别采用低常线性复杂度算法。最后用SIMD进行了改进，并将这些方法结合起来使用。我们还考虑了使用ARM-NEON实现8x8和16x16矩阵的快速转置，以获得形态学操作的额外计算增益。实验表明，与没有SIMD的van-Herk/Gil-Werman算法相比，最终实现侵蚀和扩张的效率提高了3倍，8x8矩阵转置的速度提高了5.7倍，16x16矩阵转置的速度提高了12倍。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.09474">PDF</a>
<h3>No. 2	Faasm：实现高效有状态无服务器计算的轻量级隔离</h3><h4>Simon Shillaker, Peter Pietzuch</h4>摘要：无服务器计算可以快速、廉价地扩展到数千个并行函数，非常适合大数据处理。然而，现有的无服务器平台将功能隔离在短暂的、无状态的容器中。这意味着函数不能有效地共享内存，迫使用户在编写函数时重复序列化数据。我们发现基于容器的隔离不适合于无服务器的大数据处理。相反，它需要一种轻量级的隔离方法，允许高效的状态共享。我们介绍了faaslet，一种新的用于无服务器大数据计算的隔离抽象。faaslet使用WebAssembly提供的软件故障隔离（SFI）隔离已执行函数的内存，同时允许在同一地址空间中的函数之间共享内存区域。因此，当函数位于同一台机器上时，faaslet可以避免昂贵的数据移动。我们的faaslet、Faasm运行时使用标准的Linux cgroup隔离了其他资源，例如CPU和网络，并为网络、文件系统访问和动态加载提供了一个低级别的POSIX主机接口。为了减少初始化时间，Faasm从已经初始化的快照中恢复faaslet。我们将Faasm与标准的基于容器的平台进行了比较，结果表明，在训练机器学习模型时，它的速度提高了2倍，内存减少了10倍；对于服务于机器学习推理，Faasm的吞吐量增加了一倍，尾部延迟减少了90%。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.09344">PDF</a>
<h3>No. 3	为数据密集型科学应用开发摘要的方法和经验</h3><h4>Andre Luckow, Shantenu Jha</h4>摘要：为科学应用开发软件，需要集成各种类型的计算、仪器和数据，由于规模、异构性以及将各种编程和计算模型与不断发展和异构的基础设施集成的需要，这些挑战不同于商业软件。因此，普遍有效的抽象是至关重要的。为科学应用和基础设施开发摘要的过程还没有被很好地理解。虽然基于理论的方法适用于定义良好的封闭环境，但它们在为复杂的现实系统设计抽象方面有着严重的局限性。设计科学研究（DSR）方法为设计能够处理现实世界复杂性的有效系统提供了基础。DSR包括两个互补的阶段：设计和评估。本文将DSR方法应用于科学应用文摘的开发。具体来说，我们解决了异构基础设施上的分布式资源管理这一关键问题，这一挑战目前限制了许多科学应用。我们使用pilot抽象，这是一个广泛用于高性能、高吞吐量、大数据和流应用程序的资源管理抽象，作为一个案例研究。我们评估流程的活动，并使用不同的方法广泛地评估工件，包括概念建模、性能描述和建模。我们展示了DSR方法在整体处理并行和分布式计算环境复杂性方面的适用性，解决了科学应用中的重要应用、系统和基础设施挑战。最后，我们总结经验，总结经验教训。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.09009">PDF</a>
<h3>No. 4	具有最优误差界的分布平均估计</h3><h4>Dan Alistarh, Saleh Ashkboos, Peter Davies</h4>文摘：在分布式优化和机器学习应用的推动下，我们考虑了一个分布式平均估计问题，其中$n$节点被分配一个多维输入向量，并且必须合作估计输入向量的平均值，同时最小化通信量。本文根据节点间通信量与节点估计值相对于均值真值的方差之间的权衡关系，给出了该问题的第一个紧界。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.09268">PDF</a>
<h3>No. 5	子模最大化自适应复杂度的多项式下界</h3><h4>Wenzheng Li, Paul Liu, Jan Vondrak</h4>摘要：在大数据应用中，需要设计高度并行化的算法。在子模块优化的背景下，自适应复杂度已经成为衡量算法“顺序性”的一个广泛使用的指标。自适应模型中的算法是一轮一轮地进行的，每轮可以对一个函数$f$发出多项式形式的多个查询。每轮中的查询必须是独立的，由仅依赖于前几轮中获得的查询结果的计算生成。本文研究了自适应复杂度模型中子模最大化的两个基本变量：基数约束单调最大化和无约束非单调最大化。我们的主要结果是，$r$-基数约束单调最大化的圆算法对于任何$r<n^c$（其中$c>0$是某个常数）都不能获得一个优于$1-1/e-\Omega（\min{\frac{1}{r}、\frac{log^2 n}{r^3}）的因子。这是第一个结果，当我们接近最优因子$1-1/e$时，轮数必须多项式放大。对于无约束非单调最大化问题，我们给出了一个正的结果：对于每一个例子，并且每$\delta>0$，我们要么在$1$轮中得到$（1/2-\delta）$-近似值，要么在$O（1/\delta ^2）$轮中得到$（1/2+\Omega（\delta ^2））$-近似值。特别是（与基数约束的情况相反），不可能存在这样的情况：（i）无论轮数多少，都不可能获得优于$1/2$的因子，并且（ii）需要$r$轮才能获得$1/2-O（1/r）$的因子。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.09130">PDF</a>
<h3>No. 6	异步并行自适应随机梯度法</h3><h4>Yangyang Xu, Colin Sutcher-Shepard, Yibo Xu, Jie Chen</h4>文摘：随机梯度法是训练深度学习模型的主要方法。自适应版本（如Adam和AMSGrad）在实践中得到了广泛的应用，部分原因是它们比非自适应版本实现了更快的收敛，同时开销也很小。另一方面，异步（async）并行计算比同步（sync）并行计算显示出更好的速度。然而，异步并行实现只在非自适应SGMs中得到了验证。自适应SGMs的困难源于二阶矩项，这使得收敛分析在异步更新时具有挑战性。本文提出了一种基于AMSGrad的异步并行自适应SGM。我们证明，如果异步引起的陈旧性（也称为延迟）是有界的，该方法继承了AMSGrad对凸和非凸问题的收敛保证。我们的收敛速度结果表明，如果$\tau=o（K^{\frac{1}{4}）$，则近似线性的并行化速度加快，其中$\tau$是陈旧性，$K$是迭代次数。该方法在凸和非凸机器学习问题上都得到了验证，数值结果表明其明显优于同步方法。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.09095">PDF</a>
<h3>No. 7	分布式联合学习中通信压缩的不确定性原理及最优压缩器的搜索</h3><h4>Mher Safaryan, Egor Shulgin, Peter Richtárik</h4>摘要：为了降低分布式和联邦学习中的高通信成本，各种矢量压缩方案，如量化、稀疏化和抖动等，已成为当前的研究热点。在设计压缩方法时，一个目的是尽可能少地通信比特，这使得每一通信回合的成本最小化，同时试图将尽可能小的失真（方差）传递给所通信的消息，从而最大限度地减少了压缩对通信轮次总数的不利影响。然而，直观地说，这两个目标在根本上是冲突的：我们允许的压缩越多，消息就越失真。我们将这种直觉形式化，并证明了随机压缩算子的{em不确定性原理}，从而从数学上量化了这种限制，并且{em有效地提供了通信压缩可能实现的下限}。基于这些发展，我们要求寻找最优压缩算子。为了向这个方向迈出第一步，我们构造了一种新的无偏压缩方法，该方法受向量的Kashin表示的启发，我们称之为{em Kashin compression（KC）}。与之前提出的所有压缩机制相比，我们证明了即使在每个向量条目只需要通信几个位的情况下，KC也具有{em维数无关}的方差边界，并且有一个显式公式。我们展示了如何将KC与现有的几种优化算法有效地结合起来，从而在所有情况下提高通信复杂度。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08958">PDF</a><h2>2020-02-25</h2>
<h3>No. 1	基于ARM-NEON扩展的形态滤波快速实现</h3><h4>Elena Limonova, Arseny Terekhin, Dmitry Nikolaev, Vladimir Arlazarov</h4>文摘：本文研究了ARM处理器上形态学图像滤波的加速潜力。形态学操作在图像分析和识别中有着广泛的应用，在某些情况下，形态学操作的加速可以显著缩短识别的总体执行时间。更具体地说，我们建议使用ARM SIMD extension NEON快速实现腐蚀和膨胀。使用矩形结构元素的这些操作是可分离的。它们是利用可分离性作为连续水平和垂直通道的优点来实现的。每一步都是用van-Herk/Gil-Werman算法实现的，对于大窗口和小窗口分别采用低常线性复杂度算法。最后用SIMD进行了改进，并将这些方法结合起来使用。我们还考虑了使用ARM-NEON实现8x8和16x16矩阵的快速转置，以获得形态学操作的额外计算增益。实验表明，与没有SIMD的van-Herk/Gil-Werman算法相比，最终实现侵蚀和扩张的效率提高了3倍，8x8矩阵转置的速度提高了5.7倍，16x16矩阵转置的速度提高了12倍。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.09474">PDF</a>
<h3>No. 2	Faasm：实现高效有状态无服务器计算的轻量级隔离</h3><h4>Simon Shillaker, Peter Pietzuch</h4>摘要：无服务器计算可以快速、廉价地扩展到数千个并行函数，非常适合大数据处理。然而，现有的无服务器平台将功能隔离在短暂的、无状态的容器中。这意味着函数不能有效地共享内存，迫使用户在编写函数时重复序列化数据。我们发现基于容器的隔离不适合于无服务器的大数据处理。相反，它需要一种轻量级的隔离方法，允许高效的状态共享。我们介绍了faaslet，一种新的用于无服务器大数据计算的隔离抽象。faaslet使用WebAssembly提供的软件故障隔离（SFI）隔离已执行函数的内存，同时允许在同一地址空间中的函数之间共享内存区域。因此，当函数位于同一台机器上时，faaslet可以避免昂贵的数据移动。我们的faaslet、Faasm运行时使用标准的Linux cgroup隔离了其他资源，例如CPU和网络，并为网络、文件系统访问和动态加载提供了一个低级POSIX主机接口。为了减少初始化时间，Faasm从已经初始化的快照中恢复faaslet。我们将Faasm与标准的基于容器的平台进行了比较，结果表明，在训练机器学习模型时，它的速度提高了2倍，内存减少了10倍；对于服务于机器学习推理，Faasm的吞吐量增加了一倍，尾部延迟减少了90%。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.09344">PDF</a>
<h3>No. 3	为数据密集型科学应用开发摘要的方法和经验</h3><h4>Andre Luckow, Shantenu Jha</h4>摘要：为科学应用开发软件，需要集成各种类型的计算、仪器和数据，由于规模、异构性以及将各种编程和计算模型与不断发展和异构的基础设施集成的需要，这些挑战不同于商业软件。因此，普遍有效的抽象是至关重要的。为科学应用和基础设施开发摘要的过程还没有被很好地理解。虽然基于理论的方法适用于定义良好的封闭环境，但它们在为复杂的现实系统设计抽象方面有着严重的局限性。设计科学研究（DSR）方法为设计能够处理现实世界复杂性的有效系统提供了基础。DSR包括两个互补的阶段：设计和评估。本文将DSR方法应用于科学应用文摘的开发。具体来说，我们解决了异构基础设施上的分布式资源管理这一关键问题，这一挑战目前限制了许多科学应用。我们使用pilot抽象，这是一个广泛用于高性能、高吞吐量、大数据和流应用程序的资源管理抽象，作为一个案例研究。我们评估流程的活动，并使用不同的方法广泛地评估工件，包括概念建模、性能描述和建模。我们展示了DSR方法在整体处理并行和分布式计算环境复杂性方面的适用性，解决了科学应用中的重要应用、系统和基础设施挑战。最后，我们总结经验，总结经验教训。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.09009">PDF</a>
<h3>No. 4	具有最优误差界的分布平均估计</h3><h4>Dan Alistarh, Saleh Ashkboos, Peter Davies</h4>文摘：在分布式优化和机器学习应用的推动下，我们考虑了一个分布式平均估计问题，其中$n$节点被分配一个多维输入向量，并且必须合作估计输入向量的平均值，同时最小化通信量。本文根据节点间通信量与节点估计值相对于均值真值的方差之间的权衡关系，给出了该问题的第一个紧界。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.09268">PDF</a>
<h3>No. 5	子模最大化自适应复杂度的多项式下界</h3><h4>Wenzheng Li, Paul Liu, Jan Vondrak</h4>摘要：在大数据应用中，需要设计高度并行化的算法。在子模块优化的背景下，自适应复杂度已经成为衡量算法“顺序性”的一个广泛使用的指标。自适应模型中的算法是一轮一轮地进行的，每轮可以对一个函数$f$发出多项式形式的多个查询。每轮中的查询必须是独立的，由仅依赖于前几轮中获得的查询结果的计算生成。本文研究了自适应复杂度模型中子模最大化的两个基本变量：基数约束单调最大化和无约束非单调最大化。我们的主要结果是，$r$-基数约束单调最大化的圆算法对于任何$r<n^c$（其中$c>0$是某个常数）都不能获得一个优于$1-1/e-\Omega（\min{\frac{1}{r}、\frac{log^2 n}{r^3}）的因子。这是第一个结果，当我们接近最优因子$1-1/e$时，轮数必须多项式放大。对于无约束非单调最大化问题，我们给出了一个正的结果：对于每一个例子，并且每$\delta>0$，我们要么在$1$轮中得到$（1/2-\delta）$-近似值，要么在$O（1/\delta ^2）$轮中得到$（1/2+\Omega（\delta ^2））$-近似值。特别是（与基数约束的情况相反），不可能存在这样的情况：（i）无论轮数多少，都不可能获得优于$1/2$的因子，并且（ii）需要$r$轮才能获得$1/2-O（1/r）$的因子。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.09130">PDF</a>
<h3>No. 6	异步并行自适应随机梯度法</h3><h4>Yangyang Xu, Colin Sutcher-Shepard, Yibo Xu, Jie Chen</h4>文摘：随机梯度法是训练深度学习模型的主要方法。自适应版本（如Adam和AMSGrad）在实践中得到了广泛的应用，部分原因是它们比非自适应版本实现了更快的收敛，同时开销也很小。另一方面，异步（async）并行计算比同步（sync）并行计算显示出更好的速度。然而，异步并行实现只在非自适应SGMs中得到了验证。自适应SGMs的困难源于二阶矩项，这使得收敛分析在异步更新时具有挑战性。本文提出了一种基于AMSGrad的异步并行自适应SGM。我们证明，如果异步引起的陈旧性（也称为延迟）是有界的，该方法继承了AMSGrad对凸和非凸问题的收敛保证。我们的收敛速度结果表明，如果$\tau=o（K^{\frac{1}{4}）$，则近似线性的并行化速度加快，其中$\tau$是陈旧性，$K$是迭代次数。该方法在凸和非凸机器学习问题上都得到了验证，数值结果表明该方法明显优于同步学习方法。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.09095">PDF</a>
<h3>No. 7	分布式联合学习中通信压缩的不确定性原理及最优压缩器的搜索</h3><h4>Mher Safaryan, Egor Shulgin, Peter Richtárik</h4>摘要：为了降低分布式和联邦学习中的高通信成本，各种矢量压缩方案，如量化、稀疏化和抖动等，已成为当前的研究热点。在设计压缩方法时，一个目的是尽可能少地通信比特，这使得每一通信回合的成本最小化，同时试图将尽可能小的失真（方差）传递给所通信的消息，从而最大限度地减少了压缩对通信轮次总数的不利影响。然而，直观地说，这两个目标在根本上是冲突的：我们允许的压缩越多，消息就越失真。我们将这种直觉形式化，并证明了随机压缩算子的{em不确定性原理}，从而从数学上量化了这种限制，并且{em有效地提供了通信压缩可能实现的下限}。基于这些发展，我们要求寻找最优压缩算子。为了向这个方向迈出第一步，我们构造了一种新的无偏压缩方法，该方法受向量的Kashin表示的启发，我们称之为{em Kashin compression（KC）}。与之前提出的所有压缩机制相比，我们证明了即使在每个向量条目只需要通信几位的情况下，KC也具有{em维数无关}的方差边界，并且有一个显式公式。我们展示了如何将KC与现有的几种优化算法有效地结合起来，从而在所有情况下提高通信复杂度。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08958">PDF</a><h2>2020-02-24</h2>
<h3>No. 1	基于ARM-NEON扩展的形态滤波快速实现</h3><h4>Elena Limonova, Arseny Terekhin, Dmitry Nikolaev, Vladimir Arlazarov</h4>文摘：本文研究了ARM处理器上形态学图像滤波的加速潜力。形态学操作在图像分析和识别中有着广泛的应用，在某些情况下，形态学操作的加速可以显著缩短识别的总体执行时间。更具体地说，我们建议使用ARM SIMD extension NEON快速实现腐蚀和膨胀。使用矩形结构元素的这些操作是可分离的。它们是利用可分离性作为连续水平和垂直通道的优点来实现的。每一步都是用van-Herk/Gil-Werman算法实现的，对于大窗口和小窗口分别采用低常线性复杂度算法。最后用SIMD进行了改进，并将这些方法结合起来使用。我们还考虑了使用ARM-NEON实现8x8和16x16矩阵的快速转置，以获得形态学操作的额外计算增益。实验表明，与没有SIMD的van-Herk/Gil-Werman算法相比，最终实现侵蚀和扩张的效率提高了3倍，8x8矩阵转置的速度提高了5.7倍，16x16矩阵转置的速度提高了12倍。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.09474">PDF</a>
<h3>No. 2	Faasm：实现高效有状态无服务器计算的轻量级隔离</h3><h4>Simon Shillaker, Peter Pietzuch</h4>摘要：无服务器计算可以快速、廉价地扩展到数千个并行函数，非常适合大数据处理。然而，现有的无服务器平台将功能隔离在短暂的、无状态的容器中。这意味着函数不能有效地共享内存，迫使用户在编写函数时重复序列化数据。我们发现基于容器的隔离不适合于无服务器的大数据处理。相反，它需要一种轻量级的隔离方法，允许高效的状态共享。我们介绍了faaslet，一种新的用于无服务器大数据计算的隔离抽象。faaslet使用WebAssembly提供的软件故障隔离（SFI）隔离已执行函数的内存，同时允许在同一地址空间中的函数之间共享内存区域。因此，当函数位于同一台机器上时，faaslet可以避免昂贵的数据移动。我们的faaslet、Faasm运行时使用标准的Linux cgroup隔离了其他资源，例如CPU和网络，并为网络、文件系统访问和动态加载提供了一个低级POSIX主机接口。为了减少初始化时间，Faasm从已经初始化的快照中恢复faaslet。我们将Faasm与标准的基于容器的平台进行了比较，结果表明，在训练机器学习模型时，它的速度提高了2倍，内存减少了10倍；对于服务于机器学习推理，Faasm的吞吐量增加了一倍，尾部延迟减少了90%。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.09344">PDF</a>
<h3>No. 3	为数据密集型科学应用开发摘要的方法和经验</h3><h4>Andre Luckow, Shantenu Jha</h4>摘要：为科学应用开发软件，需要集成各种类型的计算、仪器和数据，由于规模、异构性以及将各种编程和计算模型与不断发展和异构的基础设施集成的需要，这些挑战不同于商业软件。因此，普遍有效的抽象是至关重要的。为科学应用和基础设施开发摘要的过程还没有被很好地理解。虽然基于理论的方法适用于定义良好的封闭环境，但它们在为复杂的现实系统设计抽象方面有着严重的局限性。设计科学研究（DSR）方法为设计能够处理现实世界复杂性的有效系统提供了基础。DSR包括两个互补的阶段：设计和评估。本文将DSR方法应用于科学应用文摘的开发。具体来说，我们解决了异构基础设施上的分布式资源管理这一关键问题，这一挑战目前限制了许多科学应用。我们使用pilot抽象，这是一个广泛用于高性能、高吞吐量、大数据和流应用程序的资源管理抽象，作为一个案例研究。我们评估流程的活动，并使用不同的方法广泛地评估工件，包括概念建模、性能描述和建模。我们展示了DSR方法在整体处理并行和分布式计算环境复杂性方面的适用性，解决了科学应用中的重要应用、系统和基础设施挑战。最后，我们总结经验，总结经验教训。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.09009">PDF</a>
<h3>No. 4	具有最优误差界的分布平均估计</h3><h4>Dan Alistarh, Saleh Ashkboos, Peter Davies</h4>文摘：在分布式优化和机器学习应用的推动下，我们考虑了一个分布式平均估计问题，其中$n$节点被分配一个多维输入向量，并且必须合作估计输入向量的平均值，同时最小化通信量。本文根据节点间通信量与节点估计值相对于均值真值的方差之间的权衡关系，给出了该问题的第一个紧界。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.09268">PDF</a>
<h3>No. 5	子模最大化自适应复杂度的多项式下界</h3><h4>Wenzheng Li, Paul Liu, Jan Vondrak</h4>摘要：在大数据应用中，需要设计高度并行化的算法。在子模块优化的背景下，自适应复杂度已经成为衡量算法“顺序性”的一个广泛使用的指标。自适应模型中的算法是一轮一轮地进行的，每轮可以对一个函数$f$发出多项式形式的多个查询。每轮中的查询必须是独立的，由仅依赖于前几轮中获得的查询结果的计算生成。本文研究了自适应复杂度模型中子模最大化的两个基本变量：基数约束单调最大化和无约束非单调最大化。我们的主要结果是，$r$-基数约束单调最大化的圆算法对于任何$r<n^c$（其中$c>0$是某个常数）都不能获得一个优于$1-1/e-\Omega（\min{\frac{1}{r}、\frac{log^2 n}{r^3}）的因子。这是第一个结果，当我们接近最优因子$1-1/e$时，轮数必须多项式放大。对于无约束非单调最大化问题，我们给出了一个正的结果：对于每一个例子，并且每$\delta>0$，我们要么在$1$轮中得到$（1/2-\delta）$-近似值，要么在$O（1/\delta ^2）$轮中得到$（1/2+\Omega（\delta ^2））$-近似值。特别是（与基数约束的情况相反），不可能存在这样的情况：（i）无论轮数多少，都不可能获得优于$1/2$的因子，并且（ii）需要$r$轮才能获得$1/2-O（1/r）$的因子。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.09130">PDF</a>
<h3>No. 6	异步并行自适应随机梯度法</h3><h4>Yangyang Xu, Colin Sutcher-Shepard, Yibo Xu, Jie Chen</h4>文摘：随机梯度法是训练深度学习模型的主要方法。自适应版本（如Adam和AMSGrad）在实践中得到了广泛的应用，部分原因是它们比非自适应版本实现了更快的收敛，同时开销也很小。另一方面，异步（async）并行计算比同步（sync）并行计算显示出更好的速度。然而，异步并行实现只在非自适应SGMs中得到了验证。自适应SGMs的困难源于二阶矩项，这使得收敛分析在异步更新时具有挑战性。本文提出了一种基于AMSGrad的异步并行自适应SGM。我们证明，如果异步引起的陈旧性（也称为延迟）是有界的，该方法继承了AMSGrad对凸和非凸问题的收敛保证。我们的收敛速度结果表明，如果$\tau=o（K^{\frac{1}{4}）$，则近似线性的并行化速度加快，其中$\tau$是陈旧性，$K$是迭代次数。该方法在凸和非凸机器学习问题上都得到了验证，数值结果表明其明显优于同步方法。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.09095">PDF</a>
<h3>No. 7	分布式联合学习中通信压缩的不确定性原理及最优压缩器的搜索</h3><h4>Mher Safaryan, Egor Shulgin, Peter Richtárik</h4>摘要：为了降低分布式和联邦学习中的高通信成本，各种矢量压缩方案，如量化、稀疏化和抖动等，已成为当前的研究热点。在设计压缩方法时，一个目的是尽可能少地通信比特，这使得每一通信回合的成本最小化，同时试图将尽可能小的失真（方差）传递给所通信的消息，从而最大限度地减少了压缩对通信轮次总数的不利影响。然而，直观地说，这两个目标在根本上是冲突的：我们允许的压缩越多，消息就越失真。我们将这种直觉形式化，并证明了随机压缩算子的{em不确定性原理}，从而从数学上量化了这种限制，并且{em有效地提供了通信压缩可能实现的下限}。基于这些发展，我们要求寻找最优压缩算子。为了向这个方向迈出第一步，我们构造了一种新的无偏压缩方法，该方法受向量的Kashin表示的启发，我们称之为{em Kashin compression（KC）}。与之前提出的所有压缩机制相比，我们证明了即使在每个向量条目只需要通信几位的情况下，KC也具有{em维数无关}的方差边界，并且有一个显式公式。我们展示了如何将KC与现有的几种优化算法有效地结合起来，从而在所有情况下提高通信复杂度。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08958">PDF</a><h2>2020-02-24</h2>
<h3>No. 1	具有冗余数据分配的可靠分布式集群</h3><h4>Venkata Gandikota, Arya Mazumdar, Ankit Singh Rawat</h4>文摘：本文提出了一种分布式广义聚类算法，该算法能在多台机器之间处理大规模数据，而不必考虑机器的分散性和不可靠性。我们提出了一种新的数据分配方案，使我们能够获得关于整个数据的全局信息，即使在某些机器无法对分配的本地计算结果作出响应的情况下。这种分配方案使得分布式算法能够很好地逼近各种聚类和降维问题。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08892">PDF</a>
<h3>No. 2	知识与简单情结</h3><h4>Hans van Ditmarsch, Eric Goubault, Jeremy Ledent, Sergio Rajsbaum</h4>文摘：简单复合结构是一种通用的、方便的范式，它在假定初始认知模型可以用分布的方式描述的前提下，构建知识逻辑的所有工具和技术。因此，我们可以定义：知识、信念、相互模拟、相互的、分布的和共同的知识的群体概念，以及以简单行为模型的形式存在的动力学。我们就如何解释所有这样的概念关于单纯复合体，建立在Goubault和其他人先前工作奠定的基础上进行了调查。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08863">PDF</a>
<h3>No. 3	另外两个随机无签名异步二进制拜占庭共识算法，$t<n/3$和$O（n^2）$消息和$O（1）$圆预期终止</h3><h4>Tyler Crain</h4>文摘：本文在文献[25]和[26]的基础上，提出了两种随机、异步、基于圆的二进制拜占庭容错一致性算法。与[25]和[26]的算法一样，它们不使用签名，每轮使用$O（n^2）$条消息（其中每条消息由一个轮数和一个恒定的位数组成），最多可容忍三分之一的失败，并在恒定的轮数中预期终止。第一种方法和[26]一样，使用弱公共硬币（即在不同进程中以恒定概率返回不同值的硬币）来确保终止。该算法由每轮5美元到7美元的消息广播组成。描述了一种优化，对于第一轮之后的轮次，每轮的广播费用降低到4美元到5美元。相比之下，[26]包含每轮8美元到12美元的消息广播。第二种算法，如[25]，使用一个完美的公共硬币（即，在所有非错误进程中返回相同值的硬币），用于终止和正确性。与[25]不同，它不需要公平的调度程序来确保终止。此外，该算法包括第一轮的$2$到$3$消息广播和下一轮的$1$到$2$广播，而[29]包括每轮的$2$到$3$广播。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08765">PDF</a>
<h3>No. 4	SpArch：稀疏矩阵乘法的有效结构</h3><h4>Zhekai Zhang, Hanrui Wang, Song Han, William J. Dally</h4>摘要：广义稀疏矩阵乘法（SpGEMM）是一项广泛存在于各种工程和科学应用中的任务。然而，基于内积的SpGENN为不匹配的非零操作数引入了冗余的输入获取，而基于外积的SpGENN由于存在大量的部分积矩阵而导致输出局部性差。输入或输出数据重用的低效率导致了广泛而昂贵的DRAM访问。为了解决这一问题，本文提出了一种有效的稀疏矩阵乘法加速结构SpArch，它可以联合优化输入矩阵和输出矩阵的数据局部性。我们首先设计了一个高度并行的基于流的合并，将部分矩阵的乘法和合并阶段流水线化，使得部分矩阵在产生后立即在芯片上合并。然后，我们提出了一个压缩矩阵表示法，它将部分矩阵的数量减少了三个数量级，从而将DRAM访问减少了5.4倍。我们进一步开发了一个Huffman树调度程序，以提高更大稀疏矩阵合并的可伸缩性，这将使DRAM访问量再减少1.8倍。我们还使用行预取器和近乎最优的缓冲区替换策略解决了新表示导致的输入矩阵读取增加的问题，进一步将DRAM访问量减少了1.5倍。通过20个基准测试，SpArch将DRAM访问总量减少了2.8倍。平均而言，SPARCH分别实现4x、19x、18x、17x、1285 x加速和6x、164x、435x、307x、62x能量节省，分别在外层空间、MKL、CuSpSeSE、尖点和ARM犰狳上。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08947">PDF</a>
<h3>No. 5	具有多个调度器的大型异构系统的渐近最优负载平衡</h3><h4>Xingyu Zhou, Ness Shroff, Adam Wierman</h4>文摘：研究了具有多个调度器的大型异构系统的负载平衡问题。我们介绍了一个称为局部估计驱动（LED）的通用框架。在这个框架下，每个分派器保持对所有服务器的队列长度的本地（可能过时）估计，而分派决策完全基于这些本地估计。本地估计值通过调度员和服务器之间的不频繁通信进行更新。我们分别推导了在大流量情况下LED策略达到吞吐量最优和时延最优的充分条件。这些条件直接意味着在大流量情况下，许多以前基于本地内存的策略具有延迟最优性。此外，研究结果还为多调度员异构系统设计了新的时延优化策略。最后，LED框架的重流量延迟优化直接解决了如何利用延迟信息设计最优负载平衡方案的一个新问题。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08908">PDF</a>
<h3>No. 6	基于效用感知的移动代理选择的感知驱动时空覆盖增强</h3><h4>Navid Hashemi Tonekaboni, Lakshmish Ramaswamy, Deepak Mishra, Sorush Omidvar</h4>摘要：近年来，传感驱动模式在城市区域监测中的应用越来越广泛。驱动感应是一种众感知，其中配备传感器的车辆（又名移动代理）是主要的数据收集代理。提高传感驱动的效率带来了许多挑战，其中一个重要挑战是选择非专用的移动代理，在这些代理上安装数量有限的传感器。这个问题，我们称之为移动代理选择问题，对感测平台的时空覆盖以及由此产生的数据集有重大影响。这里的挑战是在考虑地理区域相对重要性的同时，实现最大的时空覆盖。本文以城市热岛现象为研究对象，以城市热岛现象为研究对象，对城市热岛现象进行精确的地图绘制和分析。我们的工作作出了几项重大的技术贡献。首先，我们描述了一个表示移动代理选择问题的模型。该模型考虑了车辆（在我们的例子中是公共交通巴士）的行驶轨迹和城市区域的相对重要性，并将其作为一个优化问题来描述。其次，我们提供了两种基于移动代理的效用（覆盖）值的算法，即基于热点的算法，该算法将搜索空间限制在重要的子区域内，以及基于效用的遗传算法，该算法使后者能够进行无偏选择。第三，设计了一种高效的覆盖冗余最小化算法，在每一步中选择移动代理，最大限度地提高了时空覆盖率。本文在美国佐治亚州雅典市的一个真实数据集上进行了一系列实验，以证明所提方法的有效性。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08886">PDF</a>
<h3>No. 7	PrivacyFL：一个用于隐私保护和安全联邦学习的模拟器</h3><h4>Vaikkunth Mugunthan, Anton Peraire-Bueno, Lalana Kagal</h4>摘要：联合学习是一种使分布式客户机能够在保持训练数据本地化的同时协同学习共享机器学习模型的技术。这降低了数据隐私风险，但是，隐私问题仍然存在，因为有可能从训练模型的权重或参数泄漏有关训练数据集的信息。建立一个联邦学习环境，特别是有安全和隐私保证的环境，是一个耗时的过程，有许多配置和参数可以操作。为了帮助客户确保协作是可行的，并检查协作是否提高了模型的准确性，需要一个用于隐私保护和安全联邦学习的真实世界模拟器。本文介绍了PrivacyFL，它是一个可扩展、易配置、可扩展的联邦学习环境模拟器。其关键特性包括延迟模拟、对客户端离开的鲁棒性、对集中和分散学习的支持，以及基于差异隐私和安全多方计算的可配置隐私和安全机制。在本文中，我们激发了我们的研究，描述了模拟器和相关协议的体系结构，并讨论了它在许多场景中的评估，突出了它的广泛功能和优势。我们的论文解决了一个重要的现实问题：在各种情况下检查参与联合学习环境的可行性。它还具有很强的实际影响，因为医院、银行和研究机构等拥有大量敏感数据并愿意合作的组织，将从拥有一个能够以保护隐私和安全的方式这样做的系统中受益匪浅。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08423">PDF</a><h2>2020-02-23</h2>
<h3>No. 1	具有冗余数据分配的可靠分布式集群</h3><h4>Venkata Gandikota, Arya Mazumdar, Ankit Singh Rawat</h4>文摘：本文提出了一种分布式广义聚类算法，该算法能在多台机器之间处理大规模数据，而不必考虑机器的分散性和不可靠性。我们提出了一种新的数据分配方案，使我们能够获得关于整个数据的全局信息，即使在某些机器无法对分配的本地计算结果作出响应的情况下。这种分配方案使得分布式算法能够很好地逼近各种聚类和降维问题。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08892">PDF</a>
<h3>No. 2	知识与简单情结</h3><h4>Hans van Ditmarsch, Eric Goubault, Jeremy Ledent, Sergio Rajsbaum</h4>文摘：简单复合结构是一种通用的、方便的范式，它在假定初始认知模型可以用分布的方式描述的前提下，构建知识逻辑的所有工具和技术。因此，我们可以定义：知识、信念、相互模拟、相互的、分布的和共同的知识的群体概念，以及以简单行为模型的形式存在的动力学。我们就如何解释所有这样的概念关于单纯复合体，建立在Goubault和其他人先前工作奠定的基础上进行了调查。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08863">PDF</a>
<h3>No. 3	另外两个随机无签名异步二进制拜占庭共识算法，$t<n/3$和$O（n^2）$消息和$O（1）$圆预期终止</h3><h4>Tyler Crain</h4>文摘：本文在文献[25]和[26]的基础上，提出了两种随机、异步、基于圆的二进制拜占庭容错一致性算法。与[25]和[26]的算法一样，它们不使用签名，每轮使用$O（n^2）$条消息（其中每条消息由一个轮数和一个恒定的位数组成），最多可容忍三分之一的失败，并在恒定的轮数中预期终止。第一种方法和[26]一样，使用弱公共硬币（即在不同进程中以恒定概率返回不同值的硬币）来确保终止。该算法由每轮5美元到7美元的消息广播组成。描述了一种优化，对于第一轮之后的轮次，每轮的广播费用降低到4美元到5美元。相比之下，[26]包含每轮8美元到12美元的消息广播。第二种算法，如[25]，使用一个完美的公共硬币（即，在所有非错误进程中返回相同值的硬币），用于终止和正确性。与[25]不同，它不需要公平的调度程序来确保终止。此外，该算法包括第一轮的$2$到$3$消息广播和下一轮的$1$到$2$广播，而[29]包括每轮的$2$到$3$广播。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08765">PDF</a>
<h3>No. 4	SpArch：稀疏矩阵乘法的有效结构</h3><h4>Zhekai Zhang, Hanrui Wang, Song Han, William J. Dally</h4>摘要：广义稀疏矩阵乘法（SpGEMM）是一项广泛存在于各种工程和科学应用中的任务。然而，基于内积的SpGENN为不匹配的非零操作数引入了冗余的输入获取，而基于外积的SpGENN由于存在大量的部分积矩阵而导致输出局部性差。输入或输出数据重用的低效率导致了广泛而昂贵的DRAM访问。为了解决这一问题，本文提出了一种有效的稀疏矩阵乘法加速结构SpArch，它可以联合优化输入矩阵和输出矩阵的数据局部性。我们首先设计了一个高度并行的基于流的合并，将部分矩阵的乘法和合并阶段流水线化，使得部分矩阵在产生后立即在芯片上合并。然后，我们提出了一个压缩矩阵表示法，它将部分矩阵的数量减少了三个数量级，从而将DRAM访问减少了5.4倍。我们进一步开发了一个Huffman树调度程序，以提高更大稀疏矩阵合并的可伸缩性，这将使DRAM访问量再减少1.8倍。我们还使用行预取器和近乎最优的缓冲区替换策略解决了新表示导致的输入矩阵读取增加的问题，进一步将DRAM访问量减少了1.5倍。通过20个基准测试，SpArch将DRAM访问总量减少了2.8倍。平均而言，SPARCH分别实现4x、19x、18x、17x、1285 x加速和6x、164x、435x、307x、62x能量节省，分别在外层空间、MKL、CuSpSeSE、尖点和ARM犰狳上。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08947">PDF</a>
<h3>No. 5	具有多个调度器的大型异构系统的渐近最优负载平衡</h3><h4>Xingyu Zhou, Ness Shroff, Adam Wierman</h4>文摘：研究了具有多个调度器的大型异构系统的负载平衡问题。我们介绍了一个称为局部估计驱动（LED）的通用框架。在这个框架下，每个分派器保持对所有服务器的队列长度的本地（可能过时）估计，而分派决策完全基于这些本地估计。本地估计值通过调度员和服务器之间的不频繁通信进行更新。我们分别推导了在大流量情况下LED策略达到吞吐量最优和时延最优的充分条件。这些条件直接意味着在大流量情况下，许多以前基于本地内存的策略具有延迟最优性。此外，研究结果还为多调度员异构系统设计了新的时延优化策略。最后，LED框架的重流量延迟优化直接解决了如何利用延迟信息设计最优负载平衡方案的一个新问题。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08908">PDF</a>
<h3>No. 6	基于效用感知的移动代理选择的感知驱动时空覆盖增强</h3><h4>Navid Hashemi Tonekaboni, Lakshmish Ramaswamy, Deepak Mishra, Sorush Omidvar</h4>摘要：近年来，传感驱动模式在城市区域监测中的应用越来越广泛。驱动感应是一种众感知，其中配备传感器的车辆（又名移动代理）是主要的数据收集代理。提高传感驱动的效率带来了许多挑战，其中一个重要挑战是选择非专用的移动代理，在这些代理上安装数量有限的传感器。这个问题，我们称之为移动代理选择问题，对感测平台的时空覆盖以及由此产生的数据集有重大影响。这里的挑战是在考虑地理区域相对重要性的同时，实现最大的时空覆盖。本文以城市热岛现象为研究对象，以城市热岛现象为研究对象，对城市热岛现象进行精确的地图绘制和分析。我们的工作作出了几项重大的技术贡献。首先，我们描述了一个表示移动代理选择问题的模型。该模型考虑了车辆（在我们的例子中是公共交通巴士）的行驶轨迹和城市区域的相对重要性，并将其作为一个优化问题来描述。其次，我们提供了两种基于移动代理的效用（覆盖）值的算法，即基于热点的算法，该算法将搜索空间限制在重要的子区域内，以及基于效用的遗传算法，该算法使后者能够进行无偏选择。第三，设计了一种高效的覆盖冗余最小化算法，在每一步中选择移动代理，最大限度地提高了时空覆盖率。本文在美国佐治亚州雅典市的一个真实数据集上进行了一系列实验，以证明所提方法的有效性。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08886">PDF</a>
<h3>No. 7	PrivacyFL：一个用于隐私保护和安全联邦学习的模拟器</h3><h4>Vaikkunth Mugunthan, Anton Peraire-Bueno, Lalana Kagal</h4>摘要：联合学习是一种使分布式客户机能够在保持训练数据本地化的同时协同学习共享机器学习模型的技术。这降低了数据隐私风险，然而，由于可能从训练模型的权重或参数中泄漏有关训练数据集的信息，隐私问题仍然存在。建立一个联邦学习环境，特别是有安全和隐私保证的环境，是一个耗时的过程，有许多配置和参数可以操作。为了帮助客户确保协作是可行的，并检查协作是否提高了模型的准确性，需要一个用于隐私保护和安全联邦学习的真实世界模拟器。本文介绍了PrivacyFL，它是一个可扩展、易配置、可扩展的联邦学习环境模拟器。其关键特性包括延迟模拟、对客户端离开的鲁棒性、对集中和分散学习的支持，以及基于差异隐私和安全多方计算的可配置隐私和安全机制。在本文中，我们激发了我们的研究，描述了模拟器和相关协议的体系结构，并讨论了它在许多场景中的评估，突出了它的广泛功能和优势。我们的论文解决了一个重要的现实问题：在各种情况下检查参与联合学习环境的可行性。它还具有很强的实际影响，因为医院、银行和研究机构等拥有大量敏感数据并愿意合作的组织，将从拥有一个能够以保护隐私和安全的方式这样做的系统中受益匪浅。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08423">PDF</a><h2>2020-02-22</h2>
<h3>No. 1	具有冗余数据分配的可靠分布式集群</h3><h4>Venkata Gandikota, Arya Mazumdar, Ankit Singh Rawat</h4>文摘：本文提出了一种分布式广义聚类算法，该算法能在多台机器之间处理大规模数据，而不必考虑机器的分散性和不可靠性。我们提出了一种新的数据分配方案，使我们能够获得关于整个数据的全局信息，即使在某些机器无法对分配的本地计算结果作出响应的情况下。这种分配方案使得分布式算法能够很好地逼近各种聚类和降维问题。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08892">PDF</a>
<h3>No. 2	知识与简单情结</h3><h4>Hans van Ditmarsch, Eric Goubault, Jeremy Ledent, Sergio Rajsbaum</h4>文摘：简单复合结构是一种通用的、方便的范式，它在假定初始认知模型可以用分布的方式描述的前提下，构建知识逻辑的所有工具和技术。因此，我们可以定义：知识、信念、相互模拟、相互的、分布的和共同的知识的群体概念，以及以简单行为模型的形式存在的动力学。我们就如何解释所有这样的概念关于单纯复合体，建立在Goubault和其他人先前工作奠定的基础上进行了调查。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08863">PDF</a>
<h3>No. 3	另外两个随机无签名异步二进制拜占庭共识算法，$t<n/3$和$O（n^2）$消息和$O（1）$圆预期终止</h3><h4>Tyler Crain</h4>文摘：本文在文献[25]和[26]的基础上，提出了两种随机、异步、基于圆的二进制拜占庭容错一致性算法。与[25]和[26]的算法一样，它们不使用签名，每轮使用$O（n^2）$条消息（其中每条消息由一个轮数和一个恒定的位数组成），最多可容忍三分之一的失败，并在恒定的轮数中预期终止。第一种方法和[26]一样，使用弱公共硬币（即在不同进程中以恒定概率返回不同值的硬币）来确保终止。该算法由每轮5美元到7美元的消息广播组成。描述了一种优化，对于第一轮之后的轮次，每轮的广播费用降低到4美元到5美元。相比之下，[26]包含每轮8美元到12美元的消息广播。第二种算法，如[25]，使用一个完美的公共硬币（即，在所有非错误进程中返回相同值的硬币），用于终止和正确性。与[25]不同，它不需要公平的调度程序来确保终止。此外，该算法包括第一轮2美元至3美元的消息广播和下一轮1美元至2美元的广播，而[29]则包括每轮2美元至3美元的广播。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08765">PDF</a>
<h3>No. 4	SpArch：稀疏矩阵乘法的有效结构</h3><h4>Zhekai Zhang, Hanrui Wang, Song Han, William J. Dally</h4>摘要：广义稀疏矩阵乘法（SpGEMM）是一项广泛存在于各种工程和科学应用中的任务。然而，基于内积的SpGENN为不匹配的非零操作数引入了冗余的输入获取，而基于外积的SpGENN由于存在大量的部分积矩阵而导致输出局部性差。输入或输出数据重用的低效率导致了广泛而昂贵的DRAM访问。为了解决这一问题，本文提出了一种有效的稀疏矩阵乘法加速结构SpArch，它可以联合优化输入矩阵和输出矩阵的数据局部性。我们首先设计了一个高度并行的基于流的合并，将部分矩阵的乘法和合并阶段流水线化，使得部分矩阵在产生后立即在芯片上合并。然后，我们提出了一个压缩矩阵表示法，它将部分矩阵的数量减少了三个数量级，从而将DRAM访问减少了5.4倍。我们进一步开发了一个Huffman树调度程序，以提高更大稀疏矩阵合并的可伸缩性，这将使DRAM访问量再减少1.8倍。我们还使用行预取器和近乎最优的缓冲区替换策略解决了新表示导致的输入矩阵读取增加的问题，进一步将DRAM访问量减少了1.5倍。通过20个基准测试，SpArch将DRAM访问总量减少了2.8倍。平均而言，SPARCH分别实现4x、19x、18x、17x、1285 x加速和6x、164x、435x、307x、62x能量节省，分别在外层空间、MKL、CuSpSeSE、尖点和ARM犰狳上。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08947">PDF</a>
<h3>No. 5	具有多个调度器的大型异构系统的渐近最优负载平衡</h3><h4>Xingyu Zhou, Ness Shroff, Adam Wierman</h4>文摘：研究了具有多个调度器的大型异构系统的负载平衡问题。我们介绍了一个称为局部估计驱动（LED）的通用框架。在这个框架下，每个分派器保持对所有服务器的队列长度的本地（可能过时）估计，而分派决策完全基于这些本地估计。本地估计值通过调度员和服务器之间的不频繁通信进行更新。我们分别推导了在大流量情况下LED策略达到吞吐量最优和时延最优的充分条件。这些条件直接意味着在大流量情况下，许多以前基于本地内存的策略具有延迟最优性。此外，研究结果还为多调度员异构系统设计了新的时延优化策略。最后，LED框架的重流量延迟优化直接解决了如何利用延迟信息设计最优负载平衡方案的一个新问题。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08908">PDF</a>
<h3>No. 6	基于效用感知的移动代理选择的感知驱动时空覆盖增强</h3><h4>Navid Hashemi Tonekaboni, Lakshmish Ramaswamy, Deepak Mishra, Sorush Omidvar</h4>摘要：近年来，传感驱动模式在城市区域监测中的应用越来越广泛。驱动感应是一种众感知，其中配备传感器的车辆（又名移动代理）是主要的数据收集代理。提高传感驱动的效率带来了许多挑战，其中一个重要挑战是选择非专用的移动代理，在这些代理上安装数量有限的传感器。这个问题，我们称之为移动代理选择问题，对感测平台的时空覆盖以及由此产生的数据集有重大影响。这里的挑战是在考虑地理区域相对重要性的同时，实现最大的时空覆盖。本文以城市热岛现象为研究对象，以城市热岛现象为研究对象，对城市热岛现象进行精确的地图绘制和分析。我们的工作作出了几项重大的技术贡献。首先，我们描述了一个表示移动代理选择问题的模型。该模型考虑了车辆（在我们的例子中是公共交通巴士）的行驶轨迹和城市区域的相对重要性，并将其作为一个优化问题来描述。其次，我们提供了两种基于移动代理的效用（覆盖）值的算法，即基于热点的算法，该算法将搜索空间限制在重要的子区域内，以及基于效用的遗传算法，该算法使后者能够进行无偏选择。第三，设计了一种高效的覆盖冗余最小化算法，在每一步中选择移动代理，最大限度地提高了时空覆盖率。本文在美国佐治亚州雅典市的一个真实数据集上进行了一系列实验，以证明所提方法的有效性。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08886">PDF</a>
<h3>No. 7	PrivacyFL：一个用于隐私保护和安全联邦学习的模拟器</h3><h4>Vaikkunth Mugunthan, Anton Peraire-Bueno, Lalana Kagal</h4>摘要：联合学习是一种使分布式客户机能够在保持训练数据本地化的同时协同学习共享机器学习模型的技术。这降低了数据隐私风险，然而，由于可能从训练模型的权重或参数中泄漏有关训练数据集的信息，隐私问题仍然存在。建立一个联邦学习环境，特别是有安全和隐私保证的环境，是一个耗时的过程，有许多配置和参数可以操作。为了帮助客户确保协作是可行的，并检查协作是否提高了模型的准确性，需要一个用于隐私保护和安全联邦学习的真实世界模拟器。本文介绍了PrivacyFL，它是一个可扩展、易配置、可扩展的联邦学习环境模拟器。其关键特性包括延迟模拟、对客户端离开的鲁棒性、对集中和分散学习的支持，以及基于差异隐私和安全多方计算的可配置隐私和安全机制。在本文中，我们激发了我们的研究，描述了模拟器和相关协议的体系结构，并讨论了它在许多场景中的评估，突出了它的广泛功能和优势。我们的论文解决了一个重要的现实问题：在各种情况下检查参与联合学习环境的可行性。它还具有很强的实际影响，因为医院、银行和研究机构等拥有大量敏感数据并愿意合作的组织，将从拥有一个能够以保护隐私和安全的方式这样做的系统中受益匪浅。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08423">PDF</a><h2>2020-02-21</h2>
<h3>No. 1	基于时态GPU脉动阵列积分的DNN加速度平衡效率与灵活性</h3><h4>Cong Guo, Yangjie Zhou, Jingwen Leng, Yuhao Zhu, Zidong Du, Quan Chen, Chao Li, Minyi Guo, Bin Yao</h4>文摘：深神经网络专用硬件加速器由于其优越的性能和效率，近年来引起了人们的研究兴趣。然而，今天的DNN加速器主要关注于加速特定的“核”，如卷积和矩阵乘法，它们是端到端DNN应用程序的关键但只是一部分。在整个应用程序中有意义的加速通常需要支持计算，这些计算虽然大量并行，但不适合DNN加速器。集成通用处理器（如CPU或GPU）会产生大量的数据移动开销，并导致DNN加速器上的资源利用率不足。我们提出了同步多模式架构（SMA），这是一种新的架构设计和执行模型，它在DNN加速器上提供通用的可编程性，以加速端到端的应用。SMA的关键是收缩执行模型和类GPU的SIMD执行模型的时间集成。SMA利用了脉动阵列加速器和GPU之间共享的公共组件，并提供了在两种模式之间就地切换的轻量级重新配置能力。SMA的性能提高高达63%，同时比采用TensorCore的基本Volta架构能耗低23%。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08326">PDF</a>
<h3>No. 2	MLModelScope：一个大规模的模型评估和基准测试的分布式平台</h3><h4>Abdul Dakkak, Cheng Li, Jinjun Xiong, Wen-mei Hwu</h4>摘要：机器学习（ML）和深度学习（DL）的创新正以如此之快的速度被引入，以至于研究人员很难对它们进行分析和研究。评估创新的复杂过程，以及缺乏标准和有效的方法来指定和提供ML/DL评估，是社区的一个主要“痛点”。本文提出了MLModelScope，这是一个开源的、框架/硬件无关的、可扩展的和可定制的设计，它支持可重复的、公平的和可伸缩的模型评估和基准测试。我们实现了支持所有主要框架和硬件的分布式设计，并为其配备了web、命令行和库接口。为了演示MLModelScope的功能，我们执行并行评估，并展示对模型评估管道的细微更改如何影响准确性，以及软硬件堆栈选择如何影响性能。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08295">PDF</a>
<h3>No. 3	二分最大匹配和变量的真紧in-$Δ$界</h3><h4>Sebastian Brandt, Dennis Olivetti</h4>摘要：在最近的一项突破性成果中，Balliu等人。[FOCS'19]证明了在分布式计算的局部模型中，$n$节点图的二部最大匹配问题的复杂性的一个确定的$\Omega（\min（\Delta，\log n/\log\log n））$-圆和一个随机的$\Omega（\min（\Delta，\log n/\log\log\n））$-圆下界。这两个下界作为最大度$\Delta$的函数是渐近紧的。我们在$\Delta$中为二分最大匹配和许多自然变量的复杂性提供了真正严格的界限，直到并包括加法常数。作为副产品，我们的结果得到了Balliu等人的证明的相当简化的版本。我们证明，我们的结果可以通过有界自动圆消去获得，这是Brandt[PODC'19]最新的自动圆消去技术的一个版本，特别适合从实际角度进行自动化。在这种情况下，我们的工作可视为实现本地模型下界自动化的又一步。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08216">PDF</a>
<h3>No. 4	在去Exascale的路上磨练和校对天体物理代码。多核心系统代码现代化的经验</h3><h4>Salvatore Cielo, Luigi Iapichino, Fabio Baruffa, Matteo Bugli, Christoph Federrath</h4>摘要：现代和即将到来的计算体系结构的复杂性给代码开发人员和应用程序专家带来了严峻的挑战，迫使他们暴露出尽可能高的并行度，以便充分利用可用的硬件。第二代Intel$^{（R）}$Xeon Phi$^{（TM）}$（代号Knights Landing，以下简称KNL）是最新的多核系统，它实现了一些有趣的硬件功能，例如每个节点有大量的核（最多72个）、512位宽矢量寄存器和高带宽内存。KNL的独特功能使该平台成为现代HPC应用的强大测试平台。因此，KNL上代码的性能是它们对未来架构准备就绪的一个有用的代理。在这项工作中，我们描述了在优化计算天体物理学P-Gadget-3、Flash和Echo的广泛使用的代码过程中吸取的经验教训。此外，我们还提供了可视化和分析工具VisIt和yt的结果。这些例子表明，现代架构从不同级别的代码优化中获益，甚至超过了传统的多核系统。然而，典型社区规范的现代化水平仍有待提高，以充分利用新建筑的资源。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08161">PDF</a>
<h3>No. 5	部分之和：拜占庭联邦协议体系分析</h3><h4>Martin Florian, Sebastian Henningsen, Björn Scheuermann</h4>摘要：联邦拜占庭协议系统（FBASs）是共识协议背景下的一个有趣的新范例。FBASs最初是为明星支付网络供电而提出的，它可以被认为是典型的无许可系统（如比特币）和解决共识的许可方法（如经典的BFT协议）之间的一种中间方式。与比特币等不同，验证程序必须由对等方明确选择。与许可协议不同，整个系统不需要就同一组验证器达成一致。相反，每个节点都可以自行决定它需要与谁达成协议。在本文中，我们提出了一种直观而精确的方法，用以确定由这种个别配置产生的仲裁系统是否能够实现活跃性和安全性，以及它们离失去这些质量还有多少（拜占庭式）节点故障。我们使用我们的分析方法和软件来评估不同节点配置策略的效果，即，通过逻辑，节点配置是由战略考虑或现有的节点间关系图产生的。最后，我们还研究了FBASs的公开会员属性。我们观察到，通常很小的一组节点只与确定安全性和活跃度“缓冲区”相关，并且证明如果维护安全是核心要求，那么这些顶层是有效的“封闭成员”。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08101">PDF</a>
<h3>No. 6	可延展性工作的整体减速驱动调度和资源管理</h3><h4>Marco D'Amico, Ana Jokanovic, Julita Corbalan</h4>摘要：在作业调度中，可延展性的概念在多年前就已被探索出来。研究表明，可锻性改善了系统性能，但其在高性能混凝土中的应用从未得到广泛应用。其原因是开发可扩展应用程序的困难，以及HPC软件堆栈的不同层缺乏支持和集成。然而，在过去的几年中，由于硬件和工作负载的日益复杂，工作调度的可塑性变得越来越重要。在这种情况下，以独占模式使用节点并不像传统的HPC作业那样总是最有效的解决方案，在HPC作业中，应用程序针对静态分配进行了高度优化，但对动态执行提供了零灵活性。本文提出了一种新的全局动态作业调度策略，即减速驱动（SD）策略，该策略利用应用程序的可塑性作为降低作业平均减速和响应时间的关键技术。SD策略基于回填和节点共享。它将可延展性应用于运行作业，以便为将在减少资源集的情况下运行的作业腾出空间，前提是估计的减速比静态方法有所改善。我们在SLURM中实现了SD策略，并在实际的生产环境中对其进行了评估，并且使用了一个模拟器，使用的工作负载高达198K个作业。结果表明，对于评估的工作负载，随着制造时间、响应时间、减速和能耗的减少，资源利用率提高，分别达到7%、50%、70%和6%。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08088">PDF</a>
<h3>No. 7	在hpxMP中支持OpenMP 5.0任务——基于任务的运行时系统中OpenMP实现的研究</h3><h4>Tianyi Zhang, Shahrzad Shirzad, Bibek Wagle, Adrian S. Lemoine, Patrick Diehl, Hartmut Kaiser</h4>摘要：OpenMP已经成为单节点并行的事实标准十多年了。近年来，异步多任务运行时（AMT）系统作为高性能计算应用的一种新的编程模式越来越受到人们的欢迎。这种新范例的主要挑战之一是OpenMP线程模型与其他amt的不兼容。高度优化的基于OpenMP的库在与amt结合时性能不佳，因为两个库的线程都将争夺资源。本文是一篇关于HPXMP基本实现的后续论文，它是利用C++标准库并行和并发（HPX）来调度和管理任务的OpenMP标准的实现。本文介绍了OpenMP 5.0标准中任务组、任务依赖、任务缩减等任务特性的实现，并对pragma的pragma omp parallel进行了优化。我们使用daxpy基准、巴塞罗那OpenMP任务套件、并行研究内核和OpenBLAS基准来比较不同的OpenMP实现：hpxMP、llvm OpenMP和GOMP。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07970">PDF</a>
<h3>No. 8	小子图计数的并行算法</h3><h4>Amartya Shankha Biswas, Talya Eden, Quanquan C. Liu, Slobodan Mitrović, Ronitt Rubinfeld</h4>摘要：子图计数是分析海量图的一个基本问题，通常是在复杂的社会网络环境下研究的。关于如何设计高效、准确和可伸缩的算法，有大量的文献。在这项工作中，我们解决了这个难题，并设计了几个新的算法来计算大规模并行计算（MPC）模型中的子图：给定一个图$G$超过$n$顶点，$m$边和$T$三角形，我们的第一个主要结果是一个算法，它以高概率输出$（1+\varepsilon）$-近似于$T$，以最佳的圆形和空间复杂度提供每台计算机任何$S\geq\max{（\sqrt m，n^2/m）}$space，假设$T=\Omega（\sqrt{m/n}）$。我们的第二个主要结果是$\tilde{O}{\delta}（\log\log n）$-rounds算法，用于精确计算三角形的数量，由输入图的树形$\alpha$参数化。对于任何常量$\delta$，每台计算机的空间为$O（n^{\delta}），总空间为$O（m\alpha）$，这与序列模型中（组合）三角形计数的时间复杂性相匹配。我们还证明了这个结果可以推广到精确计算任意常数$k$的$k$-团，并且具有相同的轮复杂度和总空间$O（m\alpha^{k-2}）$。或者，允许每台机器有$O（\alpha^2）$空间，总空间需求减少到$O（n\alpha^2）$。最后，我们证明了Bera、Pashanasangi和Seshadhri（ITCS 2020）最近的一个结果，即精确计算所有大小不超过$5$的子图，可以在MPC模型中以$\tilde{O}{\delta}（\sqrt{\log n}）$轮、$O（n^{\delta}）$每台计算机空间和$O（m\alpha^3）$总空间实现。因此，这一结果也揭示了序列模型中的时间界转化为MPC模型中的空间界的现象。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08299">PDF</a>
<h3>No. 9	Batch Layout：一种共享内存中的批并行Force-Directed图布局算法</h3><h4>Md. Khaledur Rahman, Majedul Haque Sujon, Ariful Azad</h4>摘要：力定向算法广泛应用于许多科学领域中产生的图形或网络的美观布局。为了实现大规模图形的可视化，文献中讨论了几种并行算法。然而，现有的并行算法并没有有效地利用内存层次结构，并且通常提供有限的并行性。本文使用BatchLayout来解决这些限制，BatchLayout是一种将顶点分组成小批量并并行处理它们的算法。BatchLayout还采用缓存阻塞技术来有效地利用内存层次结构。更多的并行性和改进的内存访问，再加上强制近似技术、更好的初始化和优化的学习速度，使得BatchLayout明显快于其他最新算法，如ForceAtlas2和OpenOrd。BatchLayout中布局的可视化质量与类似的可视化工具相当或更好。我们所有的源代码、数据集链接、结果和日志文件都可以在这个https URL上找到<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08233">PDF</a>
<h3>No. 10	走向低成本、稳定的区块链网络</h3><h4>Minghong Fang, Jia Liu</h4>摘要：区块链网络被认为是分布式系统的未来，近年来受到了业界和学术界越来越多的关注。然而，区块链开采过程消耗大量能源，研究表明，比特币开采消耗的能源量几乎与爱尔兰使用的电力量相同。针对区块链网络的高挖掘能耗问题，提出了一种区块链挖掘资源分配算法，以降低基于PoW（工作证明）的区块链网络的挖掘成本。我们首先对一般的区块链排队模型进行了系统的研究。在我们的排队模型中，事务随机到达队列，并以批处理的方式提供服务，其概率分布未知，对任何优先级机制都不可知。然后，利用Lyapunov优化技术，提出了一种动态挖掘资源分配算法（DMRA），该算法由一个参数$K>0$来参数化。结果表明，该算法在性能延迟上达到了$[O（1/K），O（K）]$的折衷。仿真结果也证明了DMRA在降低采矿成本方面的有效性。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08027">PDF</a>
<h3>No. 11	分布式存储的修复率下限</h3><h4>Michael Luby</h4>摘要：分布式存储系统的主要目标之一是使用大量不可靠的存储节点（每个节点的容量为$nsize$）长期可靠地存储大量$dsize$的源数据。存储开销$\beta$是超过$dsize$的可用系统容量的一部分，即$\beta=1-\frac{dsize}{N\cdot nsize}$。随着时间的推移，存储节点随机发生故障，并被最初为空的节点替换，因此数据将以平均速率$rate=\lambda\cdot N\cdot nsize$从系统中擦除，其中$1/\lambda$是故障前节点的平均生存期。为了保持源数据的可恢复性，修复程序以一定的平均速率$rrate$从节点通过网络连续读取数据，并根据读取的数据生成数据并将数据写入节点。主要结果是，对于任何修复程序，如果源数据在每个时间点都是可恢复的，那么$rrate\ge\frac{rate}{2\cdot\beta}$必须是渐进的，因为$N$变为无穷大，beta变为零。这个不等式提供了一个基本的下限，即任何修理工需要从系统中读取数据以保持源数据的可恢复性的平均速率。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07904">PDF</a><h2>2020-02-20</h2>
<h3>No. 1	基于时态GPU脉动阵列积分的DNN加速度平衡效率与灵活性</h3><h4>Cong Guo, Yangjie Zhou, Jingwen Leng, Yuhao Zhu, Zidong Du, Quan Chen, Chao Li, Minyi Guo, Bin Yao</h4>文摘：深神经网络专用硬件加速器由于其优越的性能和效率，近年来引起了人们的研究兴趣。然而，今天的DNN加速器主要关注于加速特定的“核”，如卷积和矩阵乘法，它们是端到端DNN应用程序的关键但只是一部分。在整个应用程序中有意义的加速通常需要支持计算，这些计算虽然大量并行，但不适合DNN加速器。集成通用处理器（如CPU或GPU）会产生大量的数据移动开销，并导致DNN加速器上的资源利用率不足。我们提出了同步多模式架构（SMA），这是一种新的架构设计和执行模型，它在DNN加速器上提供通用的可编程性，以加速端到端的应用。SMA的关键是收缩执行模型和类GPU的SIMD执行模型的时间集成。SMA利用了脉动阵列加速器和GPU之间共享的公共组件，并提供了在两种模式之间就地切换的轻量级重新配置能力。SMA的性能提高高达63%，同时比采用TensorCore的基本Volta架构能耗低23%。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08326">PDF</a>
<h3>No. 2	MLModelScope：一个大规模的模型评估和基准测试的分布式平台</h3><h4>Abdul Dakkak, Cheng Li, Jinjun Xiong, Wen-mei Hwu</h4>摘要：机器学习（ML）和深度学习（DL）的创新正以如此之快的速度被引入，以至于研究人员很难对它们进行分析和研究。评估创新的复杂过程，以及缺乏标准和有效的方法来指定和提供ML/DL评估，是社区的一个主要“痛点”。本文提出了MLModelScope，这是一个开源的、框架/硬件无关的、可扩展的和可定制的设计，它支持可重复的、公平的和可伸缩的模型评估和基准测试。我们实现了支持所有主要框架和硬件的分布式设计，并为其配备了web、命令行和库接口。为了演示MLModelScope的功能，我们执行并行评估，并展示对模型评估管道的细微更改如何影响准确性，以及软硬件堆栈选择如何影响性能。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08295">PDF</a>
<h3>No. 3	二分最大匹配和变量的真紧in-$Δ$界</h3><h4>Sebastian Brandt, Dennis Olivetti</h4>摘要：在最近的一项突破性成果中，Balliu等人。[FOCS'19]证明了在分布式计算的局部模型中，$n$节点图的二部最大匹配问题的复杂性的一个确定的$\Omega（\min（\Delta，\log n/\log\log n））$-圆和一个随机的$\Omega（\min（\Delta，\log n/\log\log\n））$-圆下界。这两个下界作为最大度$\Delta$的函数是渐近紧的。我们在$\Delta$中为二分最大匹配和许多自然变量的复杂性提供了真正严格的界限，直到并包括加法常数。作为副产品，我们的结果得到了Balliu等人的证明的相当简化的版本。我们证明，我们的结果可以通过有界自动圆消去获得，这是Brandt[PODC'19]最新的自动圆消去技术的一个版本，特别适合从实际角度进行自动化。在这种情况下，我们的工作可视为实现本地模型下界自动化的又一步。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08216">PDF</a>
<h3>No. 4	在去Exascale的路上磨练和校对天体物理代码。多个核心系统代码现代化的经验</h3><h4>Salvatore Cielo, Luigi Iapichino, Fabio Baruffa, Matteo Bugli, Christoph Federrath</h4>摘要：现代和即将到来的计算体系结构的复杂性给代码开发人员和应用程序专家带来了严峻的挑战，迫使他们暴露出尽可能高的并行度，以便充分利用可用的硬件。第二代Intel$^{（R）}$Xeon Phi$^{（TM）}$（代号Knights Landing，以下简称KNL）是最新的多核系统，它实现了一些有趣的硬件功能，例如每个节点有大量的核（最多72个）、512位宽矢量寄存器和高带宽内存。KNL的独特功能使该平台成为现代HPC应用的强大测试平台。因此，KNL上代码的性能是它们对未来架构准备就绪的一个有用的代理。在这项工作中，我们描述了在优化计算天体物理学P-Gadget-3、Flash和Echo的广泛使用的代码过程中吸取的经验教训。此外，我们还提供了可视化和分析工具VisIt和yt的结果。这些例子表明，现代架构从不同级别的代码优化中获益，甚至超过了传统的多核系统。然而，典型社区规范的现代化水平仍有待提高，以充分利用新建筑的资源。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08161">PDF</a>
<h3>No. 5	部分之和：拜占庭联邦协议体系分析</h3><h4>Martin Florian, Sebastian Henningsen, Björn Scheuermann</h4>摘要：联邦拜占庭协议系统（FBASs）是共识协议背景下的一个有趣的新范例。FBASs最初是为明星支付网络供电而提出的，它可以被认为是典型的无许可系统（如比特币）和解决共识的许可方法（如经典的BFT协议）之间的一种中间方式。与比特币等不同，验证程序必须由对等方明确选择。与许可协议不同，整个系统不需要就同一组验证器达成一致。相反，每个节点都可以自行决定它需要与谁达成协议。在本文中，我们提出了一种直观而精确的方法，用以确定由这种个别配置产生的仲裁系统是否能够实现活跃性和安全性，以及它们离失去这些质量还有多少（拜占庭式）节点故障。我们使用我们的分析方法和软件来评估不同节点配置策略的效果，即，通过逻辑，节点配置是由战略考虑或现有的节点间关系图产生的。最后，我们还研究了FBASs的公开会员属性。我们观察到，通常很小的一组节点只与确定安全性和活跃度“缓冲区”相关，并且证明如果维护安全是核心要求，那么这些顶层是有效的“封闭成员”。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08101">PDF</a>
<h3>No. 6	可延展性工作的整体减速驱动调度和资源管理</h3><h4>Marco D'Amico, Ana Jokanovic, Julita Corbalan</h4>摘要：在作业调度中，可延展性的概念在多年前就已被探索出来。研究表明，可锻性改善了系统性能，但其在高性能混凝土中的应用从未得到广泛应用。其原因是开发可扩展应用程序的困难，以及HPC软件堆栈的不同层缺乏支持和集成。然而，在过去的几年中，由于硬件和工作负载的日益复杂，工作调度的可塑性变得越来越重要。在这种情况下，以独占模式使用节点并不像传统的HPC作业那样总是最有效的解决方案，在HPC作业中，应用程序针对静态分配进行了高度优化，但对动态执行提供了零灵活性。本文提出了一种新的全局动态作业调度策略&减速驱动策略（SD policy），它利用应用程序的可扩展性作为降低作业平均减速和响应时间的关键技术。SD策略基于回填和节点共享。它将可延展性应用于运行作业，以便为将在减少资源集的情况下运行的作业腾出空间，前提是估计的减速比静态方法有所改善。我们在SLURM中实现了SD策略，并在实际的生产环境中对其进行了评估，并且使用了一个模拟器，使用的工作负载高达198K个作业。结果表明，对于评估的工作负载，随着制造时间、响应时间、减速和能耗的减少，资源利用率提高，分别达到7%、50%、70%和6%。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08088">PDF</a>
<h3>No. 7	在hpxMP中支持OpenMP 5.0任务——基于任务的运行时系统中OpenMP实现的研究</h3><h4>Tianyi Zhang, Shahrzad Shirzad, Bibek Wagle, Adrian S. Lemoine, Patrick Diehl, Hartmut Kaiser</h4>摘要：OpenMP已经成为单节点并行的事实标准十多年了。近年来，异步多任务运行时（AMT）系统作为高性能计算应用的一种新的编程模式越来越受到人们的欢迎。这种新范例的主要挑战之一是OpenMP线程模型与其他amt的不兼容。高度优化的基于OpenMP的库在与amt结合时性能不佳，因为两个库的线程都将争夺资源。本文是一篇关于HPXMP基本实现的后续论文，它是利用C++标准库并行和并发（HPX）来调度和管理任务的OpenMP标准的实现。本文介绍了OpenMP 5.0标准中任务组、任务依赖、任务缩减等任务特性的实现，并对pragma的pragma omp parallel进行了优化。我们使用daxpy基准、巴塞罗那OpenMP任务套件、并行研究内核和OpenBLAS基准来比较不同的OpenMP实现：hpxMP、llvm OpenMP和GOMP。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07970">PDF</a>
<h3>No. 8	小子图计数的并行算法</h3><h4>Amartya Shankha Biswas, Talya Eden, Quanquan C. Liu, Slobodan Mitrović, Ronitt Rubinfeld</h4>摘要：子图计数是分析海量图的一个基本问题，通常是在复杂的社会网络环境下研究的。关于如何设计高效、准确和可伸缩的算法，有大量的文献。在这项工作中，我们解决了这个难题，并设计了几个新的算法来计算大规模并行计算（MPC）模型中的子图：给定一个图$G$超过$n$顶点，$m$边和$T$三角形，我们的第一个主要结果是一个算法，它以高概率输出$（1+\varepsilon）$-近似于$T$，以最佳的圆形和空间复杂度提供每台计算机任何$S\geq\max{（\sqrt m，n^2/m）}$space，假设$T=\Omega（\sqrt{m/n}）$。我们的第二个主要结果是$\tilde{O}{\delta}（\log\log n）$-rounds算法，用于精确计算三角形的数量，由输入图的树形$\alpha$参数化。对于任何常量$\delta$，每台计算机的空间为$O（n^{\delta}），总空间为$O（m\alpha）$，这与序列模型中（组合）三角形计数的时间复杂性相匹配。我们还证明了这个结果可以推广到精确计算任意常数$k$的$k$-团，并且具有相同的轮复杂度和总空间$O（m\alpha^{k-2}）$。或者，允许每台机器有$O（\alpha^2）$空间，总空间需求减少到$O（n\alpha^2）$。最后，我们证明了Bera、Pashanasangi和Seshadhri（ITCS 2020）最近的一个结果，即精确计算所有大小不超过$5$的子图，可以在MPC模型中以$\tilde{O}{\delta}（\sqrt{\log n}）$轮、$O（n^{\delta}）$每台计算机空间和$O（m\alpha^3）$总空间实现。因此，这一结果也揭示了序列模型中的时间界转化为MPC模型中的空间界的现象。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08299">PDF</a>
<h3>No. 9	Batch Layout：一种共享内存中的批并行Force-Directed图布局算法</h3><h4>Md. Khaledur Rahman, Majedul Haque Sujon, Ariful Azad</h4>摘要：力定向算法广泛应用于许多科学领域中产生的图形或网络的美观布局。为了实现大规模图形的可视化，文献中讨论了几种并行算法。然而，现有的并行算法并没有有效地利用内存层次结构，并且通常提供有限的并行性。本文使用BatchLayout来解决这些限制，BatchLayout是一种将顶点分组成小批量并并行处理它们的算法。BatchLayout还采用缓存阻塞技术来有效地利用内存层次结构。更多的并行性和改进的内存访问，再加上强制近似技术、更好的初始化和优化的学习速度，使得BatchLayout明显快于其他最新算法，如ForceAtlas2和OpenOrd。BatchLayout中布局的可视化质量与类似的可视化工具相当或更好。我们所有的源代码、数据集链接、结果和日志文件都可以在这个https URL上找到<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08233">PDF</a>
<h3>No. 10	走向低成本、稳定的区块链网络</h3><h4>Minghong Fang, Jia Liu</h4>摘要：区块链网络被认为是分布式系统的未来，近年来受到了业界和学术界越来越多的关注。然而，区块链开采过程消耗大量能源，研究表明，比特币开采消耗的能源量几乎与爱尔兰使用的电力量相同。针对区块链网络的高挖掘能耗问题，提出了一种区块链挖掘资源分配算法，以降低基于PoW（工作证明）的区块链网络的挖掘成本。我们首先对一般的区块链排队模型进行了系统的研究。在我们的排队模型中，事务随机到达队列，并以批处理的方式提供服务，其概率分布未知，对任何优先级机制都不可知。然后，利用Lyapunov优化技术，提出了一种动态挖掘资源分配算法（DMRA），该算法由一个参数$K>0$来参数化。结果表明，该算法在性能延迟上达到了$[O（1/K），O（K）]$的折衷。仿真结果也证明了DMRA在降低采矿成本方面的有效性。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08027">PDF</a>
<h3>No. 11	分布式存储的修复率下限</h3><h4>Michael Luby</h4>摘要：分布式存储系统的主要目标之一是使用大量不可靠的存储节点（每个节点的容量为$nsize$）长期可靠地存储大量$dsize$的源数据。存储开销$\beta$是超过$dsize$的可用系统容量的一部分，即$\beta=1-\frac{dsize}{N\cdot nsize}$。随着时间的推移，存储节点随机发生故障，并被最初为空的节点替换，因此数据将以平均速率$rate=\lambda\cdot N\cdot nsize$从系统中擦除，其中$1/\lambda$是故障前节点的平均生存期。为了保持源数据的可恢复性，修复程序以一定的平均速率$rrate$从节点通过网络连续读取数据，并根据读取的数据生成数据并将数据写入节点。主要结果是，对于任何修复程序，如果源数据在每个时间点都是可恢复的，那么$rrate\ge\frac{rate}{2\cdot\beta}$必须是渐进的，因为$N$变为无穷大，beta变为零。这个不等式提供了一个基本的下限，即任何修理工需要从系统中读取数据以保持源数据的可恢复性的平均速率。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07904">PDF</a><h2>2020-02-19</h2>
<h3>No. 1	无等待常数时间下的并发引用计数与资源管理</h3><h4>Guy E. Blelloch, Yuanhao Wei</h4>文摘：在实现并发程序时，一个常见的问题是有效地防止进程之间的不安全竞争，即读取和使用资源（例如，内存块、文件描述符或网络连接）和其他进程同时覆盖和销毁同一资源。这样的read-destruct竞争可以用锁来保护，或者用无锁的解决方案来保护，比如危险指针或read-copy-update（RCU）。在这篇文章中，我们描述了一种保护读-析构函数竞赛的方法，这种竞赛具有预期的恒定时间开销，$O（P^2）$空间和$O（P^2）$延迟析构函数，并且仅具有单字原子内存操作（读、写和CAS）。它基于一个具有四个原语的接口、一个用于保护访问的获取释放对和一个用于延迟销毁直至安全的退出弹出对。我们将其称为acquire-retire接口。使用acquire-retire接口，我们为三种常见的用例开发了简单的实现：（1）使用应用程序对堆栈和队列进行内存回收，（2）引用计数对象，以及（3）使用移动、复制和销毁按所有权管理对象。前两个结果比之前的结果有了显著的改进，第三个应用程序是原始的。重要的是，所有的操作都期望有恒定的时间开销。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07053">PDF</a>
<h3>No. 2	寻找一个线性拜占庭协议</h3><h4>Alexander Spiegelman</h4>摘要：近年来，随着对可扩展的地理复制拜占庭国家机器复制（SMR）系统（如区块链）需求的增加，长期存在的拜占庭协议问题越来越受到关注。迄今为止，这些系统的关键瓶颈是它们作为构建块使用的拜占庭协议的通信成本，这促使许多研究人员寻找低通信拜占庭协议。传统的方法是在最终同步通信模型中设计确定性的协议，在全局稳定时间（GST）之后优化这些协议以降低通信成本。在本文中，我们对传统的方法提出了挑战，认为它不适合于可扩展的SMR系统，因为它可能会在GST之前的异步期间导致无限的通信成本，我们证明这是固有的。相反，我们放弃了最终的同步，并提出了一种不同的方法，希望最好的（同步），但准备最坏的（异步）。因此，我们设计了一个乐观的协议，该协议首先通过一个依赖于同步终止的高效确定性算法来达成协议，然后，只有在由于异步而未能达成协议的情况下，该协议使用一个随机异步回退算法，保证以1$的概率终止。虽然随机异步算法被认为是昂贵的，但我们设计的解决方案只有在已经支付了同等费用，而同步协议尝试失败时才支付该费用。此外，我们正式证明，我们的协议在所有网络条件和故障场景下实现最佳通信复杂度。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06993">PDF</a>
<h3>No. 3	利用离线分析模拟ML系统的性能</h3><h4>Hongming Huang, Peng Cheng, Hong Xu, Yongqiang Xiong</h4>文摘：我们认为基于离线评测的仿真是一种有希望的方法，可以更好地理解和改进复杂的ML系统。我们的方法使用操作级分析和基于数据流的模拟，以确保为所有框架和ML模型提供一个统一和自动化的解决方案，并且通过考虑实际系统中的各种并行化策略也很精确。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06790">PDF</a>
<h3>No. 4	异步系统中的拜占庭格一致性</h3><h4>Xiong Zheng, Vijay Garg</h4>文摘：研究了异步分布式消息传递系统中的拜占庭格协议问题。在BLA问题中，每个进程从连接半格中提出一个值，并且需要在格中输出一个值，使得正确进程的所有输出值都位于链上，尽管存在拜占庭进程。我们提出了一个具有圆形复杂度的O（\log f）$的算法，该算法在没有数字签名的异步设置中容忍$F\Frace{n}{ 5 } $拜占庭失败，其中$N$是进程的数目。我们还展示了如何修改此算法，使其在经过身份验证的设置（即，使用数字签名）中工作，以容忍$f<\frac{n}{3}$Byzantine失败。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06779">PDF</a>
<h3>No. 5	你能多快更新你的MST？（集群计算的动态算法）</h3><h4>Seth Gilbert, Lawrence Li</h4>文摘：想象一个由计算机集群处理的大型图，例如由$k$机器模型或大规模并行计算模型描述的图。然而，图不是静态的；相反，它接收到的是一个不断的更新流。集群处理更新流的速度有多快？在本文中，我们要问的基本问题是，我们是否能够足够快地更新图以跟上流。针对最小生成树（MST）的维护问题，给出了一个$k$-机器模型的算法，该模型能够处理$O（k）$图的每$O（1）$轮高概率更新。（这些结果将被带入大规模并行计算（MPC）模型）我们还显示了一个下限，即不可能在$O（1）$轮中处理$k^{1+\epsilon}$更新。因此，对于集群在维护MST的同时如何快速地响应图形修改流的问题，我们提供了一个近乎严密的答案。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06762">PDF</a>
<h3>No. 6	运行一个预先的、地理分布的、多云的科学模拟</h3><h4>Igor Sfiligoi, Frank Wuerthwein, Benedikt Riedel, David Schultz</h4>翻译后摘要：当我们接近ExasCale时代，重要的是要验证现有的框架和工具仍将工作在这样的规模。此外，公共云计算已经成为原型和紧急计算的可行解决方案。因此，我们利用云的弹性，为在云中运行科学模拟，建立了一个预先测量的HTCondor装置，选择的应用是IceCube的光子传播模拟。一、 e.这不是一次纯粹的演示运行，但它也被用于为冰立方合作产生有价值和急需的科学结果。为了达到所需的规模，我们在Amazon Web服务、Microsoft Azure和Google云平台的许多地理区域的8个GPU模型中聚合了GPU资源。使用此设置，我们达到了51k GPU以上的峰值，相当于将近380 PFLOP32s，总的集成计算时间约为100k GPU小时。本文介绍了实验装置，发现和克服的问题，以及实验的实际科学产出。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06667">PDF</a>
<h3>No. 7	不是巧合：亚二次异步拜占庭协议</h3><h4>Shir Cohen, Idit Keidar, Alexander Spiegelman</h4>翻译后摘要：国王和Saia是第一个打破二次字复杂度界限的同步系统对自适应对手拜占庭协议，AlgRoand打破这个界限与接近最佳弹性的最终同步模型。然而，异步次二次拜占庭协议的问题仍然悬而未决。据我们所知，我们是第一个肯定地回答这个问题的人。我们的解决方案的一个关键组成部分是一个新的基于VRF的共享硬币算法，不需要任何进一步的信任设置。第二个基本要素是基于VRF的委员会抽样，我们首次将其形式化并应用到异步模型中。我们的算法针对的是一个延迟的自适应对手，它不能在实际删除后执行，但可以完全控制拜占庭进程和前几轮通信的全部信息。使用委员会抽样和我们的共享硬币，我们解决拜占庭协议的概率很高，字复杂度$ \广角{o}（n）$和$ O（1）$预期时间，打破$ O（n ^ 2）$位屏障为异步拜占庭协议。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06545">PDF</a>
<h3>No. 8	隐私保护回归的分布式绘制方法</h3><h4>Burak Bartan, Mert Pilanci</h4>文摘：本文研究了大规模回归问题的分布式绘制方法。在异步分布式系统中，我们利用多个随机草图来减少问题的维数，同时保护隐私和提高散乱者的弹性。我们推导出新的近似保证经典草图方法，并分析参数的平均分布草图的准确性。在分布式环境下，我们考虑了随机矩阵，包括高斯、随机Hadamard、均匀采样和杠杆分数采样。此外，为了提高计算效率，我们提出了一种结合抽样和快速随机投影的混合方法。在无服务器计算平台上，通过大规模的实验验证了分布式草图的性能。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06538">PDF</a>
<h3>No. 9	在基于NVM的存储系统上揭开HPC科学应用程序性能的神秘面纱</h3><h4>Ivy Peng, Kai Wu, Jie Ren, Dong Li, Maya Gokhale</h4>摘要：高密度字节可寻址非易失性存储器（NVM）的出现有望加速数据和计算密集型应用。目前的NVM技术的性能比DRAM低，因此常常与异构主存中的DRAM配对。最近，字节可寻址的NVM硬件变得可用。这项工作为基于NVM的主存上的“七个小矮星”中具有代表性的HPC应用提供了一个及时的评估。我们的结果量化了DRAM缓存的NVM对于加速HPC应用程序和实现超出DRAM容量的大问题的有效性。在未缓存的NVM上，HPC应用程序表现出三层性能敏感性，即不敏感、可伸缩和瓶颈。我们将写限制和并发控制确定为优化应用程序的优先级。我们强调并发性更改可能会对应用程序中的读写访问产生不同的影响。基于这些发现，我们探索了两种优化方法。首先，我们提供一个预测模型，该模型使用来自一小组配置的数据集来估计不同并发性和数据大小下的性能，以避免在配置空间中进行穷举搜索。其次，我们演示了在未缓存的NVM上放置感知写的数据可以在DRAM使用减少60%的情况下实现2$x的性能改进。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06499">PDF</a>
<h3>No. 10	基于MPI-IO的交互式X射线科学大数据分期</h3><h4>Justin M. Wozniak, Hemant Sharma, Timothy G. Armstrong, Michael Wilde, Jonathan D. Almer, Ian Foster</h4>文摘：X射线散射科学实验中的新技术产生了大量数据集，每周需要数百万个高性能处理小时进行分析计算。在此类应用中，数据通常从X射线探测器移动到petascale超级计算机的所有节点共享的大型并行文件系统中，然后随着不同的科学应用任务的进行而重复读取。但是，这种简单的实现会在文件系统中引起严重的争用。我们提出了另一种方法，在这种方法中，数据被转移到计算节点内存中并被长时间缓存，在此期间，各种处理任务可以有效地访问它。本文描述了一个基于MPI-IO和Swift并行脚本语言的大数据转移框架。我们讨论了X射线散射科学中涉及的一系列大规模数据管理问题，并测量了高能衍射显微镜（一种在数据密集型X射线散射中新兴的重要应用）的新分级框架的性能优势。我们的框架加速了科学处理从3个月到10分钟的转变，并且我们的I/O技术将8K蓝色基因/Q节点的输入开销减少了5倍。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06258">PDF</a>
<h3>No. 11	计算核外存储矩阵的秩揭示因子分解</h3><h4>Nathan Heavner, Per-Gunnar Martinsson, Gregorio Quintana-Ortí</h4>文摘：本文描述了一种计算矩阵的秩揭示因子分解的有效算法，这些矩阵太大，无法装入RAM，而必须存储在诸如固态或旋转磁盘硬盘驱动器（内核不足或内存不足）等速度较慢的外部存储设备上。传统的计算秩揭示因子分解的算法，如列透视QR因子分解，或计算矩阵的完全奇异值分解的技术，都是非常需要通信的。它们自然地被表示为一系列矩阵向量操作，当数据在主存中不可用时，这些操作变得非常昂贵。随机化允许这些方法被重新格式化，以便可以批量处理矩阵的大块相邻块。本文描述了两种不同的方法。第一种是列透视Householder QR的阻塞版本，它被组织为“左看”方法，以最小化写入操作的数量（这比旋转磁盘驱动器上的读取操作更昂贵）。第二种方法产生了所谓的U T V分解，它将矩阵$a$表示为$a=U T V^*$，其中$U$和$V$是酉的，而$T$是三角形的。这种方法是按块组织的算法，其中浮点操作与读写操作重叠。第二种方法包含幂次迭代，并且特别擅长揭示数值秩；它通常可以用作完全奇异值分解的替代。数值实验表明，新算法对硬盘数据的处理速度与传统算法对主存数据的处理速度相当。准确地说，将一个$n乘以n$矩阵完全分解的计算时间可扩展为$cn^{3}$，而当矩阵存储在核心之外时，缩放常数$c$仅略大一些。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06960">PDF</a>
<h3>No. 12	随机二阶优化的分布平均法</h3><h4>Burak Bartan, Mert Pilanci</h4>文摘：我们考虑了分布优化问题，其中Hessian的形成在计算上具有挑战性，而通信是一个重要的瓶颈。我们发展了随机二阶优化的无偏参数平均方法，采用海森抽样和草图。现有的工作不考虑估计的偏倚，这限制了它们在大规模并行计算中的应用。我们提供了正则化参数和步长的闭式公式，这些公式可证明最小化了牛顿方向草图的偏差。本文还扩展了二阶平均法的框架，提出了一种适用于具有不同工作资源的异构计算系统的无偏分布式优化框架。此外，我们通过在无服务器计算平台上进行的大规模实验，证明了我们的理论发现的含义。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06540">PDF</a>
<h3>No. 13	比特币区块链数据分析：图论视角</h3><h4>Aman Sharma, Ashutosh Bhatia</h4>摘要：比特币是世界上最流行的加密货币。它通过使用公钥作为事务端点建立身份来为用户提供假名。这些交易记录在称为区块链的不可变公共分类账上，区块链是一种仅附加的数据结构。比特币的受欢迎程度增加得不合理。总体趋势显示，来自普通大众的积极响应表明信任和隐私关注的增加，从分析的角度来看，这是一个有趣的用例。此外，由于区块链是公开的和最新的，任何分析都将提供对使用模式的实时洞察，这最终将有助于执法机构、经济学家、技术爱好者等在本文中做出一些推论，我们从图论的角度研究在比特币区块链上执行数据分析的各种应用和技术。我们还提出了一个执行此类数据分析的框架，并使用该框架探索了几个用例。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06403">PDF</a>
<h3>No. 14	分散数据的神经结构搜索</h3><h4>Mengwei Xu, Yuxin Zhao, Kaigui Bian, Gang Huang, Qiaozhu Mei, Xuanzhe Liu</h4>摘要：为了保护用户隐私，同时实现移动智能，人们提出了在分散数据上训练深层神经网络的技术。然而，对分散数据的训练使得神经结构的设计变得相当困难。在为异构移动平台设计和部署不同的神经体系结构时，这种困难进一步扩大。在这项工作中，我们提出了一个自动神经架构搜索到分散训练，作为一个新的DNN训练范例称为联邦神经架构搜索，即联邦NAS。为了解决客户端计算和通信资源有限的主要挑战，我们提出了一个高效联邦NAS的高度优化框架FedNAS。FedNAS充分利用了体系结构搜索过程中模型候选重新训练不足的关键机会，并结合了三个关键优化：部分客户端上的并行候选训练、性能较差的候选提前丢弃和动态轮数。FedNAS在大规模数据集和典型CNN体系结构上进行了测试，它达到了与最先进的NAS算法相当的模型精度，该算法使用集中数据训练模型，并且与联邦NAS的直接设计相比，它还将客户机成本降低了两个数量级。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06352">PDF</a><h2>2020-02-18</h2>
<h3>No. 1	无等待常数时间下的并发引用计数与资源管理</h3><h4>Guy E. Blelloch, Yuanhao Wei</h4>文摘：在实现并发程序时，一个常见的问题是有效地防止进程之间的不安全竞争，即读取和使用资源（例如，内存块、文件描述符或网络连接）和其他进程同时覆盖和销毁同一资源。这样的read-destruct竞争可以用锁来保护，或者用无锁的解决方案来保护，比如危险指针或read-copy-update（RCU）。在这篇文章中，我们描述了一种保护读-析构函数竞赛的方法，这种竞赛具有预期的恒定时间开销，$O（P^2）$空间和$O（P^2）$延迟析构函数，并且仅具有单字原子内存操作（读、写和CAS）。它基于一个具有四个原语的接口、一个用于保护访问的获取释放对和一个用于延迟销毁直至安全的退出弹出对。我们将其称为acquire-retire接口。使用acquire-retire接口，我们为三种常见的用例开发了简单的实现：（1）使用应用程序对堆栈和队列进行内存回收，（2）引用计数对象，以及（3）使用移动、复制和销毁按所有权管理对象。前两个结果比之前的结果有了显著的改进，第三个应用程序是原始的。重要的是，所有的操作都期望有恒定的时间开销。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07053">PDF</a>
<h3>No. 2	寻找一个线性拜占庭协议</h3><h4>Alexander Spiegelman</h4>摘要：近年来，随着对可扩展的地理复制拜占庭国家机器复制（SMR）系统（如区块链）需求的增加，长期存在的拜占庭协议问题越来越受到关注。迄今为止，这些系统的关键瓶颈是它们作为构建块使用的拜占庭协议的通信成本，这促使许多研究人员寻找低通信拜占庭协议。传统的方法是在最终同步通信模型中设计确定性的协议，在全局稳定时间（GST）之后优化这些协议以降低通信成本。在本文中，我们对传统的方法提出了挑战，认为它不适合于可扩展的SMR系统，因为它可能会在GST之前的异步期间导致无限的通信成本，我们证明这是固有的。相反，我们放弃了最终的同步，并提出了一种不同的方法，希望最好的（同步），但准备最坏的（异步）。因此，我们设计了一个乐观的协议，该协议首先通过一个依赖于同步终止的高效确定性算法来达成协议，然后，只有在由于异步而未能达成协议的情况下，该协议使用一个随机异步回退算法，保证以1$的概率终止。虽然随机异步算法被认为是昂贵的，但我们设计的解决方案只有在已经支付了同等费用，而同步协议尝试失败时才支付该费用。此外，我们正式证明，我们的协议在所有网络条件和故障场景下实现最佳通信复杂度。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06993">PDF</a>
<h3>No. 3	利用离线分析模拟ML系统的性能</h3><h4>Hongming Huang, Peng Cheng, Hong Xu, Yongqiang Xiong</h4>文摘：我们认为基于离线评测的仿真是一种有希望的方法，可以更好地理解和改进复杂的ML系统。我们的方法使用操作级分析和基于数据流的模拟，以确保为所有框架和ML模型提供一个统一和自动化的解决方案，并且通过考虑实际系统中的各种并行化策略也很精确。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06790">PDF</a>
<h3>No. 4	异步系统中的拜占庭格一致性</h3><h4>Xiong Zheng, Vijay Garg</h4>文摘：研究了异步分布式消息传递系统中的拜占庭格协议问题。在BLA问题中，每个进程从连接半格中提出一个值，并且需要在格中输出一个值，使得正确进程的所有输出值都位于链上，尽管存在拜占庭进程。我们提出了一个具有圆形复杂度的O（\log f）$的算法，该算法在没有数字签名的异步设置中容忍$F\Frace{n}{ 5 } $拜占庭失败，其中$N$是进程的数目。我们还展示了如何修改此算法，使其在经过身份验证的设置（即，使用数字签名）中工作，以容忍$f<\frac{n}{3}$Byzantine失败。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06779">PDF</a>
<h3>No. 5	你能多快更新你的MST？（集群计算的动态算法）</h3><h4>Seth Gilbert, Lawrence Li</h4>文摘：想象一个由计算机集群处理的大型图，例如由$k$机器模型或大规模并行计算模型描述的图。然而，图不是静态的；相反，它接收到的是一个不断的更新流。集群处理更新流的速度有多快？在本文中，我们要问的基本问题是，我们是否能够足够快地更新图以跟上流。针对最小生成树（MST）的维护问题，给出了一个$k$-机器模型的算法，该模型能够处理$O（k）$图的每$O（1）$轮高概率更新。（这些结果将被带入大规模并行计算（MPC）模型）我们还显示了一个下限，即不可能在$O（1）$轮中处理$k^{1+\epsilon}$更新。因此，对于集群在维护MST的同时如何快速地响应图形修改流的问题，我们提供了一个近乎严密的答案。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06762">PDF</a>
<h3>No. 6	运行一个预先的、地理分布的、多云的科学模拟</h3><h4>Igor Sfiligoi, Frank Wuerthwein, Benedikt Riedel, David Schultz</h4>翻译后摘要：当我们接近ExasCale时代，重要的是要验证现有的框架和工具仍将工作在这样的规模。此外，公共云计算已经成为原型和紧急计算的可行解决方案。因此，我们利用云的弹性，为在云中运行科学模拟，建立了一个预先测量的HTCondor装置，选择的应用是IceCube的光子传播模拟。一、 e.这不是一次纯粹的演示运行，但它也被用于为冰立方合作产生有价值和急需的科学结果。为了达到所需的规模，我们在Amazon Web服务、Microsoft Azure和Google云平台的许多地理区域的8个GPU模型中聚合了GPU资源。使用这个设置，我们达到了超过51k GPU的峰值，相当于将近380个pflop32，总的集成计算大约100k GPU小时。本文介绍了实验装置，发现和克服的问题，以及实验的实际科学产出。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06667">PDF</a>
<h3>No. 7	不是巧合：亚二次异步拜占庭协议</h3><h4>Shir Cohen, Idit Keidar, Alexander Spiegelman</h4>翻译后摘要：国王和Saia是第一个打破二次字复杂度界限的同步系统对自适应对手拜占庭协议，AlgRoand打破这个界限与接近最佳弹性的最终同步模型。然而，异步次二次拜占庭协议的问题仍然悬而未决。据我们所知，我们是第一个肯定地回答这个问题的人。我们的解决方案的一个关键组成部分是一个新的基于VRF的共享硬币算法，不需要任何进一步的信任设置。第二个基本要素是基于VRF的委员会抽样，我们首次将其形式化并应用到异步模型中。我们的算法针对的是一个延迟的自适应对手，它不能在实际删除后执行，但可以完全控制拜占庭进程和前几轮通信的全部信息。使用委员会抽样和我们的共享硬币，我们解决拜占庭协议的概率很高，字复杂度$ \广角{o}（n）$和$ O（1）$预期时间，打破$ O（n ^ 2）$位屏障为异步拜占庭协议。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06545">PDF</a>
<h3>No. 8	隐私保护回归的分布式绘制方法</h3><h4>Burak Bartan, Mert Pilanci</h4>文摘：本文研究了大规模回归问题的分布式绘制方法。在异步分布式系统中，我们利用多个随机草图来减少问题的维数，同时保护隐私和提高散乱者的弹性。我们推导出新的近似保证经典草图方法，并分析参数的平均分布草图的准确性。在分布式环境下，我们考虑了随机矩阵，包括高斯、随机Hadamard、均匀采样和杠杆分数采样。此外，为了提高计算效率，我们提出了一种结合抽样和快速随机投影的混合方法。在无服务器计算平台上，通过大规模的实验验证了分布式草图的性能。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06538">PDF</a>
<h3>No. 9	在基于NVM的存储系统上揭开HPC科学应用程序性能的神秘面纱</h3><h4>Ivy Peng, Kai Wu, Jie Ren, Dong Li, Maya Gokhale</h4>摘要：高密度字节可寻址非易失性存储器（NVM）的出现有望加速数据和计算密集型应用。目前的NVM技术的性能比DRAM低，因此常常与异构主存中的DRAM配对。最近，字节可寻址的NVM硬件变得可用。这项工作为基于NVM的主存上的“七个小矮星”中具有代表性的HPC应用提供了一个及时的评估。我们的结果量化了DRAM缓存的NVM对于加速HPC应用程序和实现超出DRAM容量的大问题的有效性。在未缓存的NVM上，HPC应用程序表现出三层性能敏感性，即不敏感、可伸缩和瓶颈。我们将写限制和并发控制确定为优化应用程序的优先级。我们强调并发性更改可能会对应用程序中的读写访问产生不同的影响。基于这些发现，我们探索了两种优化方法。首先，我们提供一个预测模型，该模型使用来自一小组配置的数据集来估计不同并发性和数据大小下的性能，以避免在配置空间中进行穷举搜索。其次，我们演示了在未缓存的NVM上放置感知写的数据可以在DRAM使用减少60%的情况下实现2$x的性能改进。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06499">PDF</a>
<h3>No. 10	基于MPI-IO的交互式X射线科学大数据分期</h3><h4>Justin M. Wozniak, Hemant Sharma, Timothy G. Armstrong, Michael Wilde, Jonathan D. Almer, Ian Foster</h4>文摘：X射线散射科学实验中的新技术产生了大量数据集，每周需要数百万个高性能处理小时进行分析计算。在此类应用中，数据通常从X射线探测器移动到petascale超级计算机的所有节点共享的大型并行文件系统中，然后随着不同的科学应用任务的进行而重复读取。但是，这种简单的实现会在文件系统中引起严重的争用。我们提出了另一种方法，在这种方法中，数据被转移到计算节点内存中并被长时间缓存，在此期间，各种处理任务可以有效地访问它。本文描述了一个基于MPI-IO和Swift并行脚本语言的大数据转移框架。我们讨论了X射线散射科学中涉及的一系列大规模数据管理问题，并测量了高能衍射显微镜（一种在数据密集型X射线散射中新兴的重要应用）的新分级框架的性能优势。我们的框架加速了科学处理从3个月到10分钟的转变，并且我们的I/O技术将8K蓝色基因/Q节点的输入开销减少了5倍。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06258">PDF</a>
<h3>No. 11	比特币区块链数据分析：图论视角</h3><h4>Aman Sharma, Ashutosh Bhatia</h4>摘要：比特币是世界上最流行的加密货币。它通过使用公钥作为事务端点建立身份来为用户提供假名。这些交易记录在称为区块链的不可变公共分类账上，区块链是一种仅附加的数据结构。比特币的受欢迎程度增加得不合理。总体趋势显示，来自普通大众的积极响应表明信任和隐私关注的增加，从分析的角度来看，这是一个有趣的用例。此外，由于区块链是公开的和最新的，任何分析都将提供对使用模式的实时洞察，这最终将有助于执法机构、经济学家、技术爱好者等在本文中做出一些推论，我们从图论的角度研究在比特币区块链上执行数据分析的各种应用和技术。我们还提出了一个执行此类数据分析的框架，并使用该框架探索了几个用例。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06403">PDF</a>
<h3>No. 12	分散数据的神经结构搜索</h3><h4>Mengwei Xu, Yuxin Zhao, Kaigui Bian, Gang Huang, Qiaozhu Mei, Xuanzhe Liu</h4>摘要：为了保护用户隐私，同时实现移动智能，人们提出了在分散数据上训练深层神经网络的技术。然而，对分散数据的训练使得神经结构的设计变得相当困难。在为异构移动平台设计和部署不同的神经体系结构时，这种困难进一步扩大。在这项工作中，我们提出了一个自动神经架构搜索到分散训练，作为一个新的DNN训练范例称为联邦神经架构搜索，即联邦NAS。为了解决客户端计算和通信资源有限的主要挑战，我们提出了一个高效联邦NAS的高度优化框架FedNAS。FedNAS充分利用了体系结构搜索过程中模型候选重新训练不足的关键机会，并结合了三个关键优化：部分客户端上的并行候选训练、性能较差的候选提前丢弃和动态轮数。FedNAS在大规模数据集和典型CNN体系结构上进行了测试，它达到了与最先进的NAS算法相当的模型精度，该算法使用集中数据训练模型，并且与联邦NAS的直接设计相比，它还将客户机成本降低了两个数量级。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06352">PDF</a>
</body></html>