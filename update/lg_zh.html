<!DOCTYPE html><html><head><meta charset="utf-8"><title>CS.LG</title></head><body>
<h2>2020-02-20</h2>
<h3>No. 1	论对抗性范例防御的自适应攻击</h3><h4>Florian Tramer, Nicholas Carlini, Wieland Brendel, Aleksander Madry</h4>摘要：适应性攻击已经（理所当然地）成为评估对抗性例子防御的事实标准。然而，我们发现，典型的适应性评估是不完整的。我们证明，最近在ICLR、ICML和NeurIPS上发表的13种防御措施——为了说明和教学目的而选择的——尽管尝试使用自适应攻击进行评估，但可以被规避。先前的评估论文主要关注的是最终结果——表明防御是无效的——而本文则侧重于阐述执行自适应攻击所需的方法和途径。我们希望这些分析能为如何正确地针对对抗性的例子进行适应性攻击提供指导，从而使社区在建立更健壮的模型方面取得进一步进展。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08347">PDF</a>
<h3>No. 2	Schoenberg-Rao距离：基于熵和几何感知的统计Hilbert距离</h3><h4>Gaëtan Hadjeres, Frank Nielsen</h4>文摘：在机器学习中，考虑样本空间几何结构的概率分布之间的距离，如Wasserstein距离或最大平均差（MMD）距离，受到了广泛的关注，因为它们可以用来比较不相交支持下的概率分布。本文研究了一类统计Hilbert距离，我们称之为Schoenberg-Rao距离，这是MMD的一个推广，它允许我们考虑一类更广泛的核，即条件负半定核。特别地，我们引入了一种构造此类核的原则性方法，并推导了高斯分布混合物之间的新的闭合形式距离。这些距离由凹Rao的二次熵导出，具有很好的理论性质，并具有可解释的超参数，可根据具体应用进行调整。我们的方法是Wasserstein距离的一种实用替代方法，并且我们在许多机器学习任务上证明了它的有效性，如密度估计、生成建模和混合简化。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08345">PDF</a>
<h3>No. 3	神经结构：识别用于训练先验稀疏网络的理想拓扑</h3><h4>Mihailo Isakov, Michel A. Kinsy</h4>摘要：深层神经网络训练时间长是机器学习研究的瓶颈。快速训练的主要障碍是密集层和卷积层的存储和计算需求相对于其信息带宽的二次增长。最近，训练“先验”稀疏网络被提出作为一种允许层保持高信息带宽，同时保持低内存和低计算的方法。然而，在这些网络中应该使用哪种稀疏拓扑结构还不清楚。本工作为层间拓扑结构的选择提供了理论基础。首先，我们推导了一个新的稀疏神经网络初始化方案，它允许我们探索非常深的稀疏网络的空间。接下来，我们评估了几个拓扑，并表明看似相似的拓扑通常在可达到的精度上有很大的差异。为了解释这些差异，我们开发了一种无数据启发式算法，它可以独立于网络将要训练的数据集来评估拓扑。然后，我们得到一组要求，这些要求构成一个好的拓扑，并得到一个满足所有这些要求的单一拓扑。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08339">PDF</a>
<h3>No. 4	基于变形真值和插补反馈的去噪自编码多重插补</h3><h4>Haw-minn Lu (1), Giancarlo Perrone (1), José Unpingco (1) ((1) Gary and Mary West Health Institute)</h4>摘要：虽然数据可能很丰富，但由于缺少列或行，完整的数据就不那么丰富了。这种缺失会破坏下游数据产品的性能，这些产品要么忽略不完整的情况，要么创建派生的完整数据以供后续处理。为了充分利用和正确使用数据，需要适当地管理丢失的数据。我们提出了一个多重插补模型，利用去噪自编码器来学习数据的内部表示。此外，我们还利用变形真值和插补反馈的新机制来保持属性的统计完整性并消除学习过程中的偏差。我们的方法探索了插补对各种缺失机制和缺失数据模式的影响，在许多标准测试案例中优于其他方法。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08338">PDF</a>
<h3>No. 5	价值驱动的事后模型</h3><h4>Arthur Guez, Fabio Viola, Théophane Weber, Lars Buesing, Steven Kapturowski, Doina Precup, David Silver, Nicolas Heess</h4>摘要：价值评估是强化学习范式的重要组成部分。如何有效地从数据中学习价值预测是RL界研究的主要问题之一，不同的方法以不同的方式利用问题域的结构。模型学习可以利用观测序列中丰富的过渡结构，但这种方法通常对报酬函数不敏感。相比之下，无模型方法直接利用未来的兴趣量，但必须与潜在的弱标量信号（回报的估计）组合。本文提出了一种介于这两个极端之间的RL表示学习方法：我们提出用一种能直接帮助价值预测的方法来学习建模。为此，我们确定未来轨迹的哪些特征为预测相关收益提供了有用的信息。这为我们提供了与任务直接相关的可处理的预测目标，从而可以加速价值函数的学习。这个想法可以理解为事后诸葛亮的推理，关于未来观察的哪些方面可以帮助过去的价值预测。我们展示了即使在简单的策略评估设置中，这也能极大地帮助您。然后我们在具有挑战性的领域中测试我们的方法，包括57个Atari2600游戏。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08329">PDF</a>
<h3>No. 6	基于变分编码器的可靠分类</h3><h4>Chitresh Bhushan, Zhaoyuan Yang, Nurali Virani, Naresh Iyer</h4>摘要：机器学习模型提供了统计上令人印象深刻的结果，这些结果可能是个别不可靠的。为了提供可靠性，我们提出了一个认知分类器（EC），该分类器可以利用训练数据集的支持和重建质量来证明其信念。我们的方法是基于改进的变分自动编码器，它可以识别语义上有意义的低维空间，其中感知上相似的实例在$ell_2$-距离内也很接近。结果表明，与基于softmax阈值的基线方法相比，该方法提高了对抗性攻击样本预测和鲁棒识别的可靠性。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08289">PDF</a>
<h3>No. 7	图神经网络回归的结果相关性</h3><h4>Junteng Jia, Austin Benson</h4>文摘：在训练过程中，图形神经网络利用对标记顶点的监督，在顶点邻域中聚集特征，学习所有顶点的矢量表示。然后，预测器是向量表示的函数，并且在未标记的节点上独立地进行预测。这种被广泛采用的方法隐含地假设顶点标签在对其邻域进行条件化之后是独立的。我们证明，这种强假设在许多真实的图形数据集上是不正确的，并且严重限制了对一些回归任务的预测能力。鉴于传统的基于图的半监督学习方法通过显式地建模预测结果中的相关性而以相反的方式操作，这种限制可能并不令人惊讶。在这里，我们用一个简单且可解释的框架来解决这个问题，该框架可以通过在回归结果残差中建模相关结构来改进任何图神经网络结构。具体地说，我们使用参数化的多元高斯模型来模拟顶点上的结果残差的联合分布，其中参数是通过最大化观测标签的边缘似然来估计的。我们的模型极大地提高了图神经网络的性能，并且学习到的参数也可以解释为连接顶点之间的关联强度。为了使我们能够扩展到大型网络，我们设计了基于随机跟踪估计的低方差无偏模型参数估计的线性时间算法。我们还提供了我们的方法的一个简化版本，它对相关结构做出了更有力的假设，但是非常容易实现，并且在一些情况下提供了很好的实际性能。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08274">PDF</a>
<h3>No. 8	分子注意变压器</h3><h4>Łukasz Maziarka, Tomasz Danel, Sławomir Mucha, Krzysztof Rataj, Jacek Tabor, Stanisław Jastrzębski</h4>文摘：设计一种单一的神经网络结构，在一系列分子性质预测任务中具有竞争力，这在很大程度上仍是一个开放的挑战，其解决方案可能会在药物研发行业中开启深度学习的广泛应用。为了实现这一目标，我们提出了分子注意力变压器（MAT）。我们的主要创新是利用原子间距离和分子图结构来增强变压器的注意机制。实验表明，MAT在一系列不同的分子预测任务上具有竞争力。最重要的是，通过简单的自我监督预训练，MAT只需要调整几个超参数值，就可以在下游任务上获得最先进的性能。最后，我们证明了MAT学习到的注意权重可以从化学的角度来解释。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08264">PDF</a>
<h3>No. 9	背包内蒸馏修剪</h3><h4>Yonathan Aflalo, Asaf Noy, Ming Lin, Itamar Friedman, Lihi Zelnik</h4>文摘：神经网络剪枝减少了过参数化网络的计算量，提高了网络的效率。常用的方法有$\ell 1$-范数稀疏化和神经结构搜索（NAS）。在这项工作中，我们提出了一种新的剪枝方法，优化了剪枝网络的最终精度，并从过度参数化的父网络的内层提取知识。为了实现这种方法，我们将网络剪枝作为一个背包问题，优化神经元重要性与其相关计算成本之间的权衡。然后在保持网络高层结构的同时对网络信道进行剪枝。修剪后的网络在父网络的监督下利用其内部网络知识进行微调，我们称之为内部知识蒸馏技术。我们的方法可以在ImageNet、CIFAR-10和CIFAR-100上使用ResNet主干得到最新的修剪结果。为了剪除复杂的网络结构，如具有跳跃链接的卷积和深度卷积，我们提出了一种块分组方法来处理这些结构。通过这一点，我们产生了与EfficientNet-B0和MobileNetV3相同的触发器的紧凑架构，但精确度更高，在ImageNet上分别为$1\%$和$0.3\%$，在GPU上运行更快。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08258">PDF</a>
<h3>No. 10	从局部对比解释中学习全局透明模型</h3><h4>Tejaswini Pedapati, Avinash Balakrishnan, Karthikeyan Shanmugam, Amit Dhurandhar</h4>文摘：关于复杂模型的局部点对点对比/反事实解释的文献越来越多。这些方法强调了证明分类正确和/或产生改变最终分类的对比点的重要性。其他的工作试图通过使用数据进行有效的模型搜索，或者通过使用类似于蒸馏的方法从复杂模型传输信息，直接构建决策树和规则列表等全局可解释的模型。尽管这些可解释的全局模型可能有用，但它们可能与所选择的特定复杂模型的局部解释不一致。在这项工作中，我们探讨了这样一个问题：我们能否产生一个透明的、与局部解释一致/可由局部解释导出的全局模型？基于一个关键的见解，我们提出了一种新的方法，使得每一个局部对比/反事实解释都可以转化为布尔特征。这些布尔特征是二值化特征的稀疏连接。这样构造的数据集与设计的局部解释是一致的，可以在其上训练决策树这样的可解释模型。我们注意到，这种方法由于只依赖于稀疏的局部解释而严格地丢失了信息，然而，我们从经验上证明，在许多情况下，它仍然可以在复杂模型的性能和直接从原始数据集学习的其他方法方面具有竞争力。我们的方法还提供了一种以量化方式对本地解释方法进行基准测试的途径。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08247">PDF</a>
<h3>No. 11	带Bandit反馈的乐观策略优化</h3><h4>Yonathan Efroni, Lior Shani, Aviv Rosenberg, Shie Mannor</h4>摘要：策略优化方法是应用最广泛的一类强化学习算法。然而，到目前为止，这些方法大多是从优化的角度进行分析的，没有解决探索的问题，也没有对与环境的相互作用作出强有力的假设。本文考虑了具有未知跃迁和bandit反馈的表格式有限层位MDP设置中基于模型的RL。对于这种情况，我们提出了一个乐观信任域策略优化（TRPO）算法，我们为随机报酬建立了$tilde O（\sqrt{S^2a H^4k}）$遗憾。此外，我们还证明了$tilde O（\sqrt{S^2 A H^4}K^{2/3}）$对于对抗性奖励的后悔。有趣的是，这个结果与先前为bandit反馈情况导出的边界相匹配，但具有已知的转换。就我们所知，这两个结果是第一次得到的子线性后悔界，对于未知的转移和bandit反馈的策略优化算法。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08243">PDF</a>
<h3>No. 12	工业4.0预测维修综述</h3><h4>Christian Krupitzer (1), Tim Wagenhals (2), Marwin Züfle (1), Veronika Lesch (1), Dominik Schäfer (3), Amin Mozaffarin (4), Janick Edinger (2), Christian Becker (2), Samuel Kounev (1) ((1) University of Würzburg, Würzburg, Germany, (2) University of Mannheim, Mannheim, Germany, (3) Syntax Systems GmbH, Weinheim, Germany, (4) MOZYS Engineering GmbH, Würzburg)</h4>摘要：2016年，大众汽车的生产问题导致每周高达4亿欧元的销售大幅亏损。这个例子显示了一个工作生产设施对公司的巨大财务影响。尤其是在工业4.0和工业物联网（带智能连接机器）的数据驱动领域，传统的静态维护计划似乎过时了。本文综述了工业4.0预测维修技术的发展现状。在结构化文献调查的基础上，我们提出了工业4.0背景下预测性维修的分类，并讨论了这一领域的最新发展。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08224">PDF</a>
<h3>No. 13	SYMOG：学习对称混合高斯模以改进不动点量化</h3><h4>Lukas Enderich, Fabian Timm, Wolfram Burgard</h4>摘要：深度神经网络（DNNs）已被证明在几种机器学习基准上优于经典方法。然而，它们的计算复杂度很高，需要强大的处理单元。尤其是在嵌入式系统上部署时，模型的大小和推理时间必须大大减少。我们提出对称高斯模混合（symo），通过低比特定点量化显著降低DNNs的复杂度。SYMOG是一种新的软量化方法，它能同时解决学习任务和量化问题。在训练过程中，权值分布由单峰高斯分布变为对称的高斯混合分布，其中每个平均值属于一个特定的不动点模式。我们在公共基准数据集（MNIST、CIFAR-10、CIFAR-100）上用不同的架构（LeNet5、VGG7、VGG11、DenseNet）评估我们的方法，并与最新的量化方法进行比较。我们在CIFAR-10和CIFAR-100上分别获得了5.71%和27.65%的错误率，取得了优异的结果并优于2位最新性能。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08204">PDF</a>
<h3>No. 14	空中联合学习：无人机群联合功率分配与调度</h3><h4>Tengchan Zeng, Omid Semiari, Mohammad Mozaffari, Mingzhe Chen, Walid Saad, Mehdi Bennis</h4>摘要：无人机群体必须利用机器学习技术来完成从协调航迹规划到协同目标识别等多种任务。然而，由于无人机群和地面基站（BSs）之间缺乏连续的连接，使用集中式ML将是一项挑战，特别是在处理大量数据时。本文提出了一种新的无人机群结构来实现分布式联邦学习算法。随后的每一架无人机根据其收集的数据训练一个本地飞行模型，然后将该训练的本地模型发送给领先的无人机，后者将汇总接收的模型，生成一个全局飞行模型，并通过群内网络将其发送给跟随者。为了确定由风和机械振动引起的衰落、传输延迟和无人机天线角度偏差等无线因素如何影响FL的性能，对FL进行了严格的收敛性分析。在此基础上，提出了一种联合功率分配与调度的设计方案，以优化FL的收敛速度，同时考虑到收敛过程中的能量消耗和群控制系统的延迟要求。仿真结果验证了FL收敛性分析的有效性，表明联合设计策略与基线设计相比，可以减少收敛所需的通信轮数35%。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08196">PDF</a>
<h3>No. 15	利用后见之明在持续学习中巩固过去的知识</h3><h4>Arslan Chaudhry, Albert Gordo, Puneet K. Dokania, Philip Torr, David Lopez-Paz</h4>摘要：在持续学习中，学习者面对的是一个数据流，其分布随时间而变化。众所周知，现代神经网络在这种情况下会受到影响，因为它们很快就会忘记以前获得的知识。为了解决这种灾难性遗忘，许多连续学习方法实现了不同类型的经验重放，即对存储在称为情景记忆的小缓冲区中的过去数据进行再学习。在这项工作中，我们用一个新的目标来补充经验回放，我们称之为锚定，学习者使用双层优化来更新当前任务的知识，同时保持对过去任务的某些锚定点的预测不变。这些锚定点是通过基于梯度的优化来学习的，以最大化遗忘，这是通过微调当前训练的模型对过去任务的情节记忆来近似的。对几种有监督的连续学习学习基准的实验表明，我们的方法在准确度和遗忘度以及不同大小的情景记忆方面都提高了标准经验重放。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08165">PDF</a>
<h3>No. 16	卷积语音识别模型综合内省的梯度调整神经元激活谱</h3><h4>Andreas Krug, Sebastian Stober</h4>摘要：基于深度学习的自动语音识别（ASR）模型非常成功，但难以解释。为了更好地理解人工神经网络（ann）是如何完成其任务的，人们提出了内省方法。将这种技术从计算机视觉应用到语音识别并非一帆风顺，因为语音数据比图像数据更复杂，解释性也更低。在这项工作中，我们引入梯度调整的神经元激活轮廓（GradNAPs）来解释深部神经网络的特征和表示。梯度是神经网络对特定输入组的特征性反应，它包含了神经元对预测的相关性。我们将展示如何利用渐变来了解如何在ann中处理数据。这包括可视化特征的不同方式和梯度的聚类，以比较给定网络的任何层中不同输入组的嵌入。我们使用一个完全卷积的ASR模型来演示我们提出的技术。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08125">PDF</a>
<h3>No. 17	所有形状和大小的随机平滑</h3><h4>Greg Yang, Tony Duan, Edward Hu, Hadi Salman, Ilya Razenshteyn, Jerry Li</h4>摘要：随机平滑是最近提出的一种对抗攻击的防御方法，它对$ell_2$扰动具有最先进的可证明鲁棒性。不久之后，许多工作为其他度量设计了新的随机平滑方案，例如$\ell 1$或$\ell infty$；但是，对于每个几何体，都需要大量的工作来获得新的稳健性保证。这就引出了一个问题：我们能找到随机平滑的一般理论吗？本文提出了一种新的随机平滑方案设计与分析框架，并在实际应用中验证了其有效性。我们的理论贡献如下：（1）证明了对于一个适当的“最优”概念，任何“nice”范数的最优平滑分布都具有由该范数的*Wulff晶体*给出的水平集。（2） 我们提出了两种新的互补方法来推导任意光滑分布的可证明鲁棒半径。最后，利用Banach空间同型态理论，给出了当前随机平滑技术的基本极限。通过结合（1）和（2），我们显著提高了标准数据集上$ell_1$的最新认证精度。另一方面，利用（3），我们表明，在随机输入扰动下，如果没有比标签统计更多的信息，当输入维数$d$较大时，随机平滑无法获得针对$\ell\infty$-norm$\Omega（1/\sqrt d）$扰动的非平凡认证精度。我们在github.com/tonyduan/rs4a中提供代码。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08118">PDF</a>
<h3>No. 18	分层量化自动编码器</h3><h4>Will Williams, Sam Ringer, Tom Ash, John Hughes, David MacLeod, Jamie Dougherty</h4>摘要：尽管神经网络在有损图像压缩方面的训练取得了进展，但目前的方法不能在很低的比特率下保持感知质量和高层次特征。由于最近在矢量量化变分自编码（VQ-VAEs）中学习离散表示的成功，我们鼓励使用VQ-VAEs的层次来获得高压缩因子。我们证明了量化和层次潜在结构的结合有助于基于似然的图像压缩。这使得我们引入了一个更具概率性的VQ-VAE框架，而之前的工作是一个极限情况。我们的层次结构产生了一系列马尔可夫的潜在变量，这些变量可以重建保留语义意义特征的高质量图像。这些延迟可以进一步用于生成真实的样本。我们对CelebA和MNIST数据集的重建和样本进行定性和定量评估。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08111">PDF</a>
<h3>No. 19	随机图上的神经网络</h3><h4>Romuald A. Janik, Aleksandra Nowak</h4>文摘：我们对神经网络进行了大规模的评估，其结构对应于各种类型的随机图。除了经典的随机图族（包括随机图、无标度图和小世界图）外，我们提出了一种新的、灵活的直接生成随机有向无环图（DAG）的算法，并研究了一类由函数静息状态fMRI网络导出的图。大多数表现最好的网络确实是在这些新家庭中。我们还提出了一个将图转化为前馈神经网络所必需的DAG的一般过程。我们研究了图的各种结构和数值特性与神经网络测试精度的关系。由于经典的数值图不变量本身似乎不允许挑选出最佳网络，我们引入了新的数值特征，选择了一组准一维图，这些图是性能最好的网络中的大多数。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08104">PDF</a>
<h3>No. 20	学习线性二次调节器的对数遗憾</h3><h4>Asaf Cassel (1), Alon Cohen (2), Tomer Koren (1) ((1) School of Computer Science, Tel Aviv University, (2) Google Research, Tel Aviv)</h4>文摘：研究了过渡参数初始未知的线性二次型控制系统的学习问题。最近在这方面的研究结果已经证明了有效的学习算法，并且遗憾地随着决策步骤数的平方根的增长而增长。我们提出了新的有效算法，在两种情况下，当只有状态转移矩阵$A$未知，当只有状态作用转移矩阵$B$未知，且最优策略满足一定的非简并条件时，可能令人惊讶地实现了仅随步数对数缩放（poly）。另一方面，我们给出了一个下界，它表明当违反后一个条件时，平方根遗憾是不可避免的。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08095">PDF</a>
<h3>No. 21	解剖神经节律</h3><h4>Stefano Massaroli, Michael Poli, Jinkyoo Park, Atsushi Yamashita, Hajime Asama</h4>摘要：连续的深度学习结构最近重新出现作为神经常微分方程（Neural ods）的变体。这些模型提供的无限深度方法在理论上弥合了深度学习和动态系统之间的鸿沟；然而，破译它们的内部工作仍然是一个开放的挑战，它们的大多数应用目前仅限于作为通用黑盒模块的包含。在这项工作中，我们“开箱”并提供了一个系统理论的观点，包括状态增强策略和鲁棒性，目的是澄清几个设计选择对底层动力学的影响。我们还介绍了新的体系结构：其中，Galerkin启发的深度变化参数模型和具有数据控制向量场的神经网络节点。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08071">PDF</a>
<h3>No. 22	符号梯度下降几何</h3><h4>Lukas Balles, Fabian Pedregosa, Nicolas Le Roux</h4>文摘：基于符号的优化方法由于其在分布式优化中具有良好的通信代价和在神经网络训练中令人惊讶的良好性能，在机器学习中得到了广泛的应用。此外，它们与Adam等所谓的自适应梯度方法密切相关。最近关于signSGD的工作使用了一个非标准的“可分离平滑度”假设，而一些较老的工作研究符号梯度下降作为相对于$\ell\infty$-范数的最陡下降。在这项工作中，我们通过显示可分离光滑性和$\ell\infty$-光滑性之间的密切联系来统一这些现有的结果，并认为后者是较弱且更自然的假设。然后，我们继续研究相对于$\ell\infty$-范数的平滑常数，从而分离出影响基于符号的方法性能的目标函数的几何性质。简而言之，如果（i）Hessian在某种程度上集中在其对角线上，并且（ii）其最大特征值远大于平均特征值，则基于符号的方法优于梯度下降法。这两种特性在深层网络中都很常见。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08056">PDF</a>
<h3>No. 23	部分标签学习中真标签的渐进识别</h3><h4>Jiaqi Lv, Miao Xu, Lei Feng, Gang Niu, Xin Geng, Masashi Sugiyama</h4>摘要：部分标签学习是一个重要的弱监督学习问题，每个训练实例都有一组包含真实标签的候选标签。现有的大多数方法都将学习目标精心设计为必须以特定方式解决的约束优化，这使得它们的计算复杂性成为扩展到大数据的瓶颈。本文的目的是提出一种新的无隐式模型假设或优化算法的局部标号学习框架。更具体地说，我们提出了分类风险的一般估计，从理论上分析了分类一致性，并建立了估计误差界。然后，我们探索了一种渐进辨识方法来近似最小化所提出的风险估计器，其中模型的更新和真实标签的辨识是以无缝的方式进行的。所得算法与模型无关，与损失无关，且与随机优化相容。深入的实验证明它开创了新的艺术境界。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08053">PDF</a>
<h3>No. 24	通过在无监督域自适应中增加一个额外的类来扩大区分能力</h3><h4>Hai H. Tran, Sumyeong Ahn, Taeyoung Lee, Yung Yi</h4>文摘：本文研究了无监督域自适应问题，目的是利用源域的有标记数据和目标域的无标记数据建立目标域的预测模型。基于特征提取的思想，近年来出现了一系列的研究，这些特征不仅对两个领域都具有不变性，而且对目标领域也具有很高的识别能力。本文提出了一种增强区分能力的思想：加入一个新的人工类，并结合新类的GAN生成样本对数据进行模型训练。基于新类样本的训练模型能够通过在目标域中重新定位当前类的数据，从而更有效地提取出判别性更强的特征，从而绘制出决策边界。我们的思想是高度通用的，因此与许多现有的方法如DANN、VADA和DIRT-T兼容。我们对用于评估无监督域自适应的标准数据进行了各种实验，并证明我们的算法在许多情况下都达到了SOTA性能。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08041">PDF</a>
<h3>No. 25	通过政策转移实现有效的深度强化学习</h3><h4>Tianpei Yang, Jianye Hao, Zhaopeng Meng, Zongzhang Zhang, Weixun Wang, Yujing Hu, Yingfeng Cheng, Changjie Fan, Zhaodong Wang, Jiajie Peng</h4>摘要：迁移学习（TL）利用以往学习到的相关任务策略中的先验知识，在促进强化学习（RL）方面显示出巨大的潜力。现有的传输方法要么显式计算任务之间的相似性，要么选择适当的源策略为目标任务提供指导性的探索。然而，如何通过交替地利用来自适当源策略的知识而不显式地度量相似度来直接优化目标策略，目前还缺少。本文利用这一思想，提出了一种新的策略转移框架（PTF）来加速RL。我们的框架通过将多策略转移建模为选项学习问题，来学习何时和哪一个源策略是对目标策略最好的重用，以及何时终止它。PTF可以很容易地与现有的深RL方法相结合。实验结果表明，无论是在离散的还是连续的行为空间中，它都显著地加快了学习过程，并且在学习效率和最终性能方面都超过了最新的策略转移方法。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08037">PDF</a>
<h3>No. 26	一个固定的观点：基于模型的聚类框架</h3><h4>Jianhao Ding, Lansheng Han</h4>摘要：随着数据的膨胀，聚类分析作为无监督学习的一个分支，对其数学规律缺乏统一的认识和应用。本文从不动点的观点出发，重新阐述了基于模型的聚类方法，提出了一个统一的聚类框架。为了寻找不动点作为聚类中心，该框架迭代地构造了压缩映射，有力地揭示了算法的收敛机制和算法之间的相互联系。通过指定一个压缩映射，高斯混合模型（GMM）可以作为一个应用映射到框架。我们希望这个不动点框架能帮助我们设计未来的聚类算法。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08032">PDF</a>
<h3>No. 27	图卷积网络中通过毒害邻域的间接对抗攻击</h3><h4>Tsubasa Takahashi</h4>摘要：图卷积神经网络是一种在相邻节点上学习聚集的神经网络，在节点分类任务中取得了良好的性能。然而，最近的研究表明，这种图卷积节点分类器会被图上的对抗性扰动所欺骗。滥用图卷积，一个节点的分类结果可能会受到毒害其邻居的影响。给定一个属性图和一个节点分类器，我们如何评估这种间接对抗攻击的鲁棒性？我们能否产生强大的对抗性扰动，这种扰动不仅对一跳邻居有效，而且对离目标更远的邻居有效？在本文中，我们证明了节点分类器可以通过毒害距离目标较远的一个节点甚至两个跳或更远的节点而被高置信度欺骗。为了实现攻击，我们提出了一种新的方法，它只在远离目标的单个节点上搜索较小的扰动。在我们的实验中，我们提出的方法在两个数据集中，在距离目标两个跳的范围内，攻击成功率达到99%。我们还证明了m层图卷积神经网络有机会被我们在m跳邻居中的间接攻击所欺骗。所提出的攻击可作为未来防御尝试的基准，以开发具有对手鲁棒性的图形卷积神经网络。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08012">PDF</a>
<h3>No. 28	对随机盗贼的操作攻击：攻击与防御</h3><h4>Guanlin Liu, Lifeng lai</h4>文摘：由于随机多臂bandit模型的广泛应用，了解敌方攻击的影响，设计对攻击具有鲁棒性的bandit算法是该模型安全应用的关键。本文介绍了一种新的攻击类型，即操作攻击。在此攻击中，对手可以更改用户选择的动作信号。结果表明，在不知道武器平均回报的情况下，我们提出的攻击只需花费对数代价，就可以操纵广泛使用的bandit算法UCB（Upper Confidence Bound）。为了防御这类攻击，我们提出了一种新的算法，在给定攻击总代价的上界时，该算法对操作操作攻击具有鲁棒性。我们证明了我们的算法有一个伪后悔上界$\mathcal{O}（\max{\log T，a}）$，其中$T$是总轮数，$a$是总攻击代价的上界。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08000">PDF</a>
<h3>No. 29	具有子集选择的随机效用模型的最优项学习</h3><h4>Aadirupa Saha, Aditya Gopalan</h4>文摘：我们考虑了PAC从n$个项目池中学习最有价值的项目的问题，使用k$个项目子集的顺序、自适应选择的播放，当播放子集时，学习者接收根据一般随机效用模型（RUM）采样的相对反馈，该模型对潜在项目效用具有独立的噪声扰动。我们确定了这种RUM的一个新性质，称为最小优势，它有助于根据项目对的相对盈亏经验计数来描述项目对分离的复杂性，并且可以仅作为噪声分布的函数来限定。我们给出了一个基于项目的成对相对计数和层次消去的通用RUMs学习算法，以及一个新的PAC样本复杂度保证$O（\frac{n}{c^2\epsilon^2}\log\frac{k}{delta}）$轮来识别一个$\epsilon$-具有置信度$1-\delta$的最优项目，当RUM中的最坏情况成对优势对项目的参数间隙具有至少$c$的敏感度时。PAC样本复杂度的基本下界表明，就其对$n、k$和$c$的依赖性而言，这是接近最优的。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07994">PDF</a>
<h3>No. 30	梯度增强神经网络：GrowNet</h3><h4>Sarkhan Badirli, Xuanqing Liu, Zhengming Xing, Avradeep Bhowmik, Sathiya S. Keerthi</h4>文摘：提出了一种新的梯度增强框架，该框架采用浅层神经网络作为弱学习者。在此统一框架下考虑了一般损失函数，并给出了分类、回归和学习排序的具体实例。为了弥补经典梯度提升决策树贪心函数逼近的缺陷，引入了一个完全修正步骤。该模型在多个数据集上完成了所有这三个任务。进行了消融研究，揭示了各模型成分和模型超参数的影响。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07971">PDF</a>
<h3>No. 31	关于范畴概率的贝叶斯</h3><h4>Taejong Joo, Uijung Chung, Min-Gwan Seo</h4>文摘：神经网络在分类任务中以软极大值为基础，存在过度自信问题，缺乏不确定性表示能力。作为softmax的贝叶斯替代，我们考虑了类标签上的一个分类概率随机变量。在这个框架中，先验分布显式地对观察到的标签中固有的假定噪声进行建模，从而在多个具有挑战性的任务中提供一致的泛化性能增益。该方法继承了贝叶斯方法的优点，可以获得更好的不确定性估计和模型校正。与带交叉熵损失函数的softmax相比，我们的方法可以实现为一个即插即用损失函数，计算开销可以忽略不计。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07965">PDF</a>
<h3>No. 32	时序图的归纳表示学习</h3><h4>Da Xu, Chuanwei Ruan, Evren Korpeoglu, Sushant Kumar, Kannan Achan</h4>摘要：时间图归纳表示学习是面向现实动态网络的可销售机器学习的重要一步。时态动态图的演化本质要求处理新的节点以及捕获时态模式。节点嵌入现在是时间的函数，它应该同时表示静态节点特征和演化的拓扑结构。此外，节点和拓扑特征也可以是时态的，节点嵌入还应该捕获其模式。我们提出时间图注意（TGAT）层来有效地聚集时间拓扑邻域特征以及学习时间特征之间的相互作用。对于TGAT，我们以自关注机制为基础，在经典Bochner谐波分析定理的基础上，提出了一种新的函数时间编码技术。通过叠加TGAT层，该网络将节点嵌入识别为时间函数，并能随着图的演化归纳出新节点和观测节点的嵌入。该方法同时处理节点分类和链路预测任务，并且可以自然地扩展到包含时间边缘特征。在两个基准和一个工业数据集的时间背景下，我们对我们的方法进行了评估。我们的TGAT模型与目前最先进的基线以及之前的时间图嵌入方法相比具有优势。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07962">PDF</a>
<h3>No. 33	梯度元强化学习课程</h3><h4>Bhairav Mehta, Tristan Deleu, Sharath Chandra Raparthy, Chris J. Pal, Liam Paull</h4>摘要：基于梯度的元学习者，如模型不可知元学习（MAML）在有监督和强化学习环境中表现出了很强的少镜头学习性能。然而，特别是在元强化学习（meta-RL）的情况下，我们可以证明基于梯度的元学习者对任务分布非常敏感。在错误的课程设置下，代理人会受到元过度适应、浅适应和适应不稳定的影响。在这项工作中，我们首先强调基于梯度的元RL的有趣的失败案例，并表明任务分布可以广泛地影响算法的输出、稳定性和性能。为了解决这个问题，我们利用最近关于领域随机化的文献中的见解，提出了元主动领域随机化（meta-ADR），它学习基于梯度的meta-RL的任务课程，类似于ADR学习sim2real转移。结果表明，该方法在各种模拟的移动和导航任务上能产生更稳定的策略。我们对分布内和分布外的泛化进行了评估，发现即使在非结构化任务空间中，学习到的任务分布也大大提高了MAML的自适应性能。最后，我们激发了meta-RL中更好的基准测试的需求，该基准测试优先于单个任务的适应性能。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07956">PDF</a>
<h3>No. 34	个性化联合学习：一种元学习方法</h3><h4>Alireza Fallah, Aryan Mokhtari, Asuman Ozdaglar</h4>摘要：联邦学习的目标是设计多个代理以隐私保护的方式与一个中心节点通信的算法，以最小化它们的平均损失函数。在这种方法中，每个节点不仅共享所需的计算预算，而且可以访问更大的数据集，从而提高了生成模型的质量。然而，这种方法只为所有代理开发一个公共输出，因此不能使模型适应每个用户的数据。这是一个重要的缺失特性，特别是考虑到不同代理的底层数据分布的异构性。在本文中，我们研究了一种个性化的联邦学习变体，我们的目标是以分布式的方式找到一个共享的初始模型，该模型可以由当前用户或新用户通过对其自身的损失函数执行一步或几步梯度下降来稍微更新。这种方法保留了联邦学习体系结构的所有优点，同时为每个用户带来了更个性化的模型。我们证明这个问题可以在模型不可知元学习（MAML）框架下进行研究。受此启发，我们提出了一个著名的联邦平均算法的个性化变体，并用非凸损失函数的梯度范数来评估其性能。此外，我们还描述了用户数据的基本分布的紧密性如何影响这种性能，这些分布是根据分布距离（如总变差和1-Wasserstein度量）来测量的。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07948">PDF</a>
<h3>No. 35	具有深生成先验的源分离</h3><h4>Vivek Jayaram, John Thickstun</h4>摘要：尽管在信号源分离方面取得了实质性进展，但对于结构丰富的数据，其结果仍然包含可感知的伪影。相比之下，最近的深度生成模型可以在不同的域中生成真实的样本，这些域与数据分布的样本无法区分。本文介绍了一种基于贝叶斯方法的信源分离方法，该方法以生成模型作为信源混合物成分的先验，并利用Langevin动态系统对给定混合物的信源后验分布进行采样。这将源分离问题与生成模型分离开来，使我们能够直接使用最新的生成模型作为优先级。该方法实现了MNIST数字分离的最新性能。介绍了在较丰富数据集上评价分离质量的新方法，给出了在CIFAR-10上对分离结果的定量评价。我们还提供了关于LSUN的定性结果。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07942">PDF</a>
<h3>No. 36	用神经网络权值控制标签噪声信息提高泛化能力</h3><h4>Hrayr Harutyunyan, Kyle Reing, Greg Ver Steeg, Aram Galstyan</h4>摘要：在有噪声或错误标签的情况下，神经网络具有记忆噪声信息的不良倾向。标准的正则化技术，如辍学、体重衰减或数据增加，有时会有帮助，但不能阻止这种行为。如果将神经网络权值视为依赖于训练数据和随机性的随机变量，则可以用权值与给定输入的所有训练标签向量之间的Shannon互信息来量化记忆信息量，$I（w:\ mathbf{y}\mid\mathbf{x}）。我们证明，对于任何训练算法，这个项的低值对应于标签噪声记忆的减少和更好的泛化界。为了获得这些低值，我们提出了训练算法，该算法使用一个辅助网络，在不访问标签的情况下预测分类器最后一层的梯度。我们在MNIST、CIFAR-10和CIFAR-100的不同版本上以及在一个有噪声标签的大数据集Clothing1M上说明了我们的方法的有效性。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07933">PDF</a>
<h3>No. 37	基于变分LSTM网络的短期交通流预测</h3><h4>Mehrdad Farahani, Marzieh Farahani, Mohammad Manthouri, Okyay Kaynak</h4>摘要：交通流特性是一个地区最重要的决策和交通警务因素之一。对交通流预测状态的认识在交通管理和交通信息部门具有重要意义。本研究的目的是提出一个基于历史资料的深度学习交通流量预测模型。2019年从Caltrans绩效测量系统（PeMS）收集的6个月历史数据。所提出的预测模型是一个变分的长短期存储器编码器，与其它常规方法相比，VLSTM-E试图准确估计流量。VLSTM-E可以考虑分布和缺失值，提供更可靠的短期交通流。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07922">PDF</a>
<h3>No. 38	块交换：一种用于深度学习安全的随机方法</h3><h4>Xiao Wang, Siyue Wang, Pin-Yu Chen, Xue Lin, Peter Chin</h4>摘要：近年来对抗性攻击的研究揭示了现代深度学习模型的脆弱性。也就是说，精心设计的输入扰动可以使经过训练的高精度网络产生任意的错误预测，同时保持对人类视觉系统的不可察觉性。本文介绍了一种基于随机性的对抗攻击防御策略——块交换（BS）。BS用多个并行信道替换一个模型层块，而活动信道在运行时被随机分配，因此不可预测。实验结果表明，与随机激活剪枝（SAP）等随机防御方法相比，BS具有更分散的输入梯度分布和更好的防御效果。与其他防御相比，BS还具有以下特点：（i）BS导致较少的测试精度下降；（ii）BS独立于攻击，并且（iii）BS与其他防御兼容，可以与其他防御联合使用。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07920">PDF</a>
<h3>No. 39	信息浓缩主动学习</h3><h4>Siddhartha Jain, Ge Liu, David Gifford</h4>文摘：介绍了一种针对深度贝叶斯主动学习的批处理模式不可知主动学习方法，即信息凝聚主动学习法，该方法着重于获取尽可能多的关于未知点的信息。ICAL使用Hilbert-Schmidt独立性准则（HSIC）来度量候选批点与未标记集之间的依赖强度。我们开发了关键优化，使我们能够将我们的方法扩展到大型未标记集。我们在模型精度和负对数似然（NLL）方面与目前最先进的深度学习批处理模式AL方法相比有了显著的改进。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07916">PDF</a>
<h3>No. 40	自监督主动域随机化自动生成课程</h3><h4>Sharath Chandra Raparthy, Bhairav Mehta, Florian Golemo, Liam Paull</h4>文摘：目标定向强化学习（RL）传统上是考虑一个与环境交互的agent，给一个agent规定一个与某个目标的完成成比例的实值奖励。目标导向的RL由于易于重用或通过提出目标生成新体验，在样本效率方面有了很大的提高。在这项工作中，我们建立在自我游戏的框架上，允许一个代理与自己交互，以便在一些未知的任务上取得进展。我们使用主动领域随机化和自我游戏来创建一个新颖的、耦合的环境目标课程，在该课程中，代理通过逐步增加的困难任务和环境变化来学习。我们的方法，自我监督的主动领域随机化（SS-ADR），产生了一个不断增长的课程，鼓励代理人尝试超出其当前能力的任务，同时建立一个领域随机化课程，使最先进的结果对各种简单的转移任务。我们的研究结果显示，一个环境困难与在每个环境中设定的目标的困难共同演变的课程，在测试目标导向的任务中提供了实际的好处。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07911">PDF</a>
<h3>No. 41	原因：使用归因方法从事件序列中学习Granger因果关系</h3><h4>Wei Zhang, Thomas Kobber Panum, Somesh Jha, Prasad Chalasani, David Page</h4>文摘：研究了从异步、相互依存、多类型的事件序列中学习事件类型之间格兰杰因果关系的问题。现有的研究要么是模型的灵活性有限，要么是模型的可解释性差，因此无法揭示具有不同事件相关性的各种事件序列之间的Granger因果关系。为了解决这些缺点，我们提出了一个新的研究任务框架CAUSE（事件序列归因的因果关系）。因果关系的核心思想是先通过拟合神经点过程隐式地捕捉潜在的事件相关性，然后用公理化的归因方法从过程中提取Granger因果关系统计。在充满不同事件相关性的多个数据集中，我们证明CAUSE在一系列最新方法上正确推断类型间Granger因果关系方面取得了优异的性能。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07906">PDF</a>
<h3>No. 42	基于超图的实证政策评估</h3><h4>Daniel Vial, Vijay Subramanian</h4>文摘：设计并分析了强化学习中的经验策略评价问题的算法。我们的算法从高成本状态向后探索以找到高价值状态，而不是从所有状态向前探索。虽然有几篇论文已经从经验上证明了反向探索的实用性，但是我们进行了严格的分析，结果表明我们的算法可以将平均案例样本复杂度从$O（S\logs）$降低到$O（\logs）$。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07905">PDF</a>
<h3>No. 43	深度变换与度量学习网络：深度字典学习与神经网络的结合</h3><h4>Wen Tang, Emilie Chouzenoux, Jean-Christophe Pesquet, Hamid Krim</h4>文摘：字典学习及其相关的稀疏优化问题由于在推理任务和去噪应用方面取得了许多成功，引起了广泛的研究兴趣。虽然大多数解决方案都集中在单层字典上，但最近提出的改进的Deep DL（DDL）方法在一些问题上也有不足。在此，我们提出了一种新的DDL方法，其中每个DL层可以表示为一个线性层和一个递归神经网络（RNN）的组合。RNN灵活地解释了相关层和学习度量。我们提出的工作揭示了对神经网络和DDL的新见解，并提供了一种新的、有效的和有竞争力的方法来共同学习深度转换和推理应用的度量。通过大量的实验证明，该方法不仅可以优于现有的DDL算法，而且可以获得最新的通用CNNs。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07898">PDF</a>
<h3>No. 44	一种具有零阶自然梯度下降的高效黑盒敌手查询方法</h3><h4>Pu Zhao, Pin-Yu Chen, Siyue Wang, Xue Lin</h4>文摘：尽管现代深神经网络（DNNs）取得了巨大的成就，但目前最先进的DNNs的脆弱性和鲁棒性在许多需要高可靠性的应用领域引起了人们的安全关注。为了破坏DNN模型的学习性能，提出了各种对抗性攻击。其中，黑盒对抗攻击方法以其实用性和简单性受到了特别的关注。黑盒攻击通常倾向于较少的查询，以保持隐蔽性和低成本。然而，目前的黑盒攻击方法大多采用一阶梯度下降法，可能存在收敛速度慢、对超参数设置敏感度高等缺点。本文提出了一种零阶自然梯度下降（ZO-NGD）方法来设计对抗性攻击，该方法结合了针对黑箱攻击场景的零阶梯度估计技术和二阶自然梯度下降技术，以获得更高的查询效率。对图像分类数据集的实证评估表明，ZO-NGD与目前最先进的攻击方法相比，能够获得显著降低的模型查询复杂度。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07891">PDF</a>
<h3>No. 45	一个宽层金字塔拓扑深网络的全局收敛性</h3><h4>Quynh Nguyen, Marco Mondelli</h4>文摘：最近的一系列研究为梯度下降算法在过度参数化的情况下提供了收敛保证，在这种情况下，所有隐层的宽度都要求在训练样本数中多项式地大。然而，实际的深度网络的宽度往往只在第一层较大，然后开始向输出层减小。这就提出了一个有趣的开放性问题：在这种经验相关的背景下，类似的结果是否也成立。现有的理论观点表明，这类网络的损耗面表现良好，但这些结果通常不能为优化提供直接的算法保证。在本文中，我们通过证明一个宽层后接一个金字塔深网络拓扑足以使梯度下降找到一个具有几何速率的全局最小值来缩小这一差距。我们的证明基于Polyak-Lojasiewicz不等式的一个弱形式，它适用于全秩权矩阵流形中的深金字塔网络。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07867">PDF</a>
<h3>No. 46	数值模拟中的学习相似度量</h3><h4>Georg Kohl, Kiwon Um, Nils Thuerey</h4>文摘：提出了一种基于神经网络的方法来计算稳定的广义度量（LSiM），以比较各种数值模拟源的现场数据。我们的方法采用了暹罗网络结构，该结构是由度量的数学特性驱动的。我们利用带有偏微分方程（PDE）解算器的可控数据生成设置，从受控环境中的参考仿真创建越来越不同的输出。我们学习的度量的一个核心部分是一个专门的损失函数，它将有关单个数据样本之间相关性的知识引入到训练过程中。为了证明所提出的方法在向量空间和其他基于图像的学习度量方面优于现有的简单度量，我们在大量测试数据上评估了不同的方法。此外，我们还分析了泛化的好处以及可调训练数据难度的影响。通过对三个真实数据集的评估，证明了LSiM的鲁棒性。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07863">PDF</a>
<h3>No. 47	本地SGD比小批量SGD好吗？</h3><h4>Blake Woodworth, Kumar Kshitij Patel, Sebastian U. Stich, Zhen Dai, Brian Bullins, H. Brendan McMahan, Ohad Shamir, Nathan Srebro</h4>文摘：研究了一种自然的、常用的随机分布优化方法局部SGD（又称并行SGD和联邦平均）。它的理论基础目前缺乏，我们强调如何在现有的错误保证在凸设置主要由一个简单的基线，小批量SGD。（1） 对于二次型目标，我们证明了局部SGD严格控制小批量SGD，并且加速局部SGD对于二次型是最小极大最优的；（2）对于一般凸目标，我们提供了至少有时比小批量SGD改进的第一个保证；（3）我们证明了局部SGD确实不控制小批量SGD低于小批量SGD保证的本地SGD性能下限。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07839">PDF</a>
<h3>No. 48	多步模型不可知元学习：收敛性与改进算法</h3><h4>Kaiyi Ji, Junjie Yang, Yingbin Liang</h4>摘要：模型不可知元学习（MAML）算法作为一种流行的元学习方法，因其简单有效而得到了广泛的应用。然而，一般多步MAML的收敛性仍有待进一步研究。本文提出了一个新的理论框架，在此框架下，我们描述了多步MAML的收敛速度和计算复杂度。结果表明，虽然随机元梯度的估计偏差和方差包含指数因子$N$（内阶梯度更新次数），但在适当选择内阶步长的情况下，当复杂度仅随$N$线性增加时，MAML仍能达到收敛。然后，我们采取进一步的步骤，以开发一个更有效的无黑森MAML。我们首先证明了现有的零阶Hessian估计包含一个恒定的水平估计误差，因此MAML算法可以执行不稳定。针对这一问题，我们提出了一种新的基于梯度的高斯平滑的Hessian估计方法，并证明了该方法具有更小的估计偏差和方差，并且在温和的条件下得到了与原始MAML相同的性能保证。我们的实验验证了我们的理论，并证明了所提出的Hessian估计的有效性。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07836">PDF</a>
<h3>No. 49	核流神经网络内层的深度正则化和直接训练</h3><h4>Gene Ryan Yoo, Houman Owhadi</h4>文摘：提出了一种基于核流的人工神经网络正则化方法。在回归/克里格算法中，KFs是一种基于将随机批数据中的插值点数减半而导致的精度损失最小化的核选择方法。正在为ANN的组成结构的函数表示编写$f{（n）}{\theta{n}\circ f{（n-1）}{\theta{n-1}\circ f{（1）}\circ f{\theta{1}\big）（x）$，h^{（i）}（x）-h^{（i）}（x'）\|u 2^2）$。当与一批数据集相结合时，这些内核产生KF损失$e^2^{（i）}$（使用该批的任意一半预测另一半而产生的$L^2$回归误差），这取决于内层的参数$\theta 1、\ldots、\theta i$（和$\gamma i$）。所提出的方法只是将这些KF损失的一个子集与一个经典的输出损失相加。在不改变结构和输出分类器的情况下，我们在CNNs和WRNs上测试了所提出的方法，并报告了在不显著增加计算复杂度的情况下，减少了测试误差、减小了泛化间隙和增强了对分布移位的鲁棒性。我们怀疑，这些结果可能是由以下事实解释的：虽然传统训练只使用数据集定义的经验分布的线性函数（广义矩），并且容易陷入神经切线核区域（在过度参数化的情况下），所提出的损失函数（定义为经验分布的非线性函数）有效地训练CNN定义的底层核，而不是用该核对数据进行回归。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08335">PDF</a>
<h3>No. 50	基于强化学习的个性化产品智能选配装配</h3><h4>Caterina Neef, Dario Luipers, Jan Bollenbacher, Christian Gebel, Anja Richert</h4>摘要：个性化制造作为满足消费者日益多样化、个性化的需求和期望的一种手段，正成为一种重要的途径。虽然制造过程的实施有多种解决方案，例如添加剂制造，但随后的自动化装配仍然是一项具有挑战性的任务。作为解决这一问题的一种方法，我们旨在通过实施强化学习，教一个协作机器人成功地执行拣选和放置任务。对于在不断变化的制造环境中装配个性化产品，模拟的几何参数和动力学参数会发生变化。利用元学习的强化学习算法，首先对任务进行模拟训练。然后，它们将在真实环境中执行，其中引入了新的因素，这些因素在训练中没有模拟，以确认算法的稳健性。机器人将从触觉传感器、区域扫描摄像机和用于生成环境和物体高度图的三维摄像机获取输入数据。本文的工作包括机器学习算法和硬件组件的选择，以及实现上述生产场景的进一步研究问题。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08333">PDF</a>
<h3>No. 51	福克斯：保护个人隐私，防止未经授权的深度学习模式</h3><h4>Shawn Shan, Emily Wenger, Jiayun Zhang, Huiying Li, Haitao Zheng, Ben Y. Zhao</h4>摘要：如今，功能强大的面部识别模型层出不穷，对个人隐私构成了真正的威胁。正如Clearview.ai所展示的，任何人都可以在互联网上寻找数据，并在不知情的情况下训练我们高度精确的面部识别模型。我们需要一些工具来保护自己免受未经授权的面部识别系统及其无数潜在误用的侵害。不幸的是，相关领域的工作在实用性和有效性方面受到限制。在这篇文章中，我们提出福克斯，一个系统，允许个人接种自己的未经授权的面部识别模型。福克斯通过帮助用户在在线发布照片之前，在自己的照片中添加不可察觉的像素级变化（我们称之为“斗篷”）来实现这一点。当被第三方“追踪器”收集并用于训练面部识别模型时，这些“隐形”图像生成的功能模型会持续错误地识别用户。实验证明，无论追踪器如何训练模型，福克斯都能提供95%以上的用户识别保护。即使当干净的、未被屏蔽的图像被“泄露”到跟踪器并用于训练时，福克斯仍然可以保持80%以上的保护成功率。事实上，我们对当今最先进的面部识别服务进行了真正的实验，并取得了100%的成功。最后，我们展示了福克斯对各种试图探测或破坏斗篷的反制措施的鲁棒性。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08327">PDF</a>
<h3>No. 52	基于时态GPU脉动阵列积分的DNN加速度平衡效率与灵活性</h3><h4>Cong Guo, Yangjie Zhou, Jingwen Leng, Yuhao Zhu, Zidong Du, Quan Chen, Chao Li, Minyi Guo, Bin Yao</h4>文摘：深神经网络专用硬件加速器由于其优越的性能和效率，近年来引起了人们的研究兴趣。然而，今天的DNN加速器主要关注于加速特定的“核”，如卷积和矩阵乘法，它们是端到端DNN应用程序的关键但只是一部分。在整个应用程序中有意义的加速通常需要支持计算，这些计算虽然大量并行，但不适合DNN加速器。集成通用处理器（如CPU或GPU）会产生大量的数据移动开销，并导致DNN加速器上的资源利用率不足。我们提出了同步多模式架构（SMA），这是一种新的架构设计和执行模型，它在DNN加速器上提供通用的可编程性，以加速端到端的应用。SMA的关键是收缩执行模型和类GPU的SIMD执行模型的时间集成。SMA利用了脉动阵列加速器和GPU之间共享的公共组件，并提供了在两种模式之间就地切换的轻量级重新配置能力。SMA的性能提高高达63%，同时比采用TensorCore的基本Volta架构能耗低23%。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08326">PDF</a>
<h3>No. 53	2020年网络安全人工智能研讨会论文集</h3><h4>Dennis Ross, Arunesh Sinha, Diane Staheli, Bill Streilein</h4>摘要：本次研讨会将集中讨论人工智能在网络安全问题上的应用。AICS 2020的重点将放在网络安全问题背景下的人机合作上，并将特别探索人类操作员与人工智能技术之间的合作。研讨会将讨论人工智能的应用领域，如机器学习、博弈论、自然语言处理、知识表示、自动和辅助推理以及人机交互。此外，网络安全应用领域，特别强调人机协作的特征和部署将是重点。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08320">PDF</a>
<h3>No. 54	基于度量嵌入和最优传输的不一致分布距离</h3><h4>Mokhtar Z. Alaya, Maxime Bérar, Gilles Gasso, Alain Rakotomamonjy</h4>文摘：我们提出了一种新的方法来比较支持度不一定在同一度量空间上的分布。与Gromov-Wasserstein（GW）距离不同，我们考虑了一种将度量度量空间嵌入公共欧氏空间并计算嵌入分布上的最优传输（OT）的方法。这就产生了我们所说的子嵌入健壮Wasserstein（SERW）。在某些条件下，SERW是一个距离，它考虑了使用公共度量的（低失真）嵌入分布的OT距离。除了这一概括了最近几项OT工作的新建议外，我们的贡献还基于几个理论分析：i）我们刻画了嵌入空间来定义用于分布对齐的SERW距离；ii）我们证明了SERW模拟了几乎相同的GW距离的性质，并且我们给出了GW和SERW之间的成本关系。本文还提供了一些数值实验来说明SERW在实际匹配问题中的行为。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08314">PDF</a>
<h3>No. 55	后门DNNs的广谱靶向治疗</h3><h4>Akshaj Kumar Veldanda, Kang Liu, Benjamin Tan, Prashanth Krishnamurthy, Farshad Khorrami, Ramesh Karri, Brendan Dolan-Gavitt, Siddharth Garg</h4>文摘：提出了一种新的针对后门神经网络（BadNet s）的两级防御（NNoculation），它不同于现有防御，对后门触发器的形状、大小和位置以及BadNet的功能作了最小的假设。在预部署阶段，NNoculation使用从干净的验证集提取的输入的“广谱”随机扰动来重新训练网络，以部分减少后门的对抗性影响。在部署后阶段，NNoculation通过记录原始和部署前修补网络之间的分歧来检测和隔离后门测试输入。然后训练CycleGAN学习干净验证输入和隔离输入之间的转换；也就是说，它学习向干净验证图像添加触发器。这组经过转换的后门验证图像及其正确的标签被用于进一步重新训练BadNet，从而产生我们的最终防御。当攻击者绕过限制性假设时，NNoculation的性能优于我们所展示的最先进的神经清洁和人工大脑模拟（ABS）。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08313">PDF</a>
<h3>No. 56	多小波残差密集卷积神经网络图像去噪</h3><h4>Shuo-Fei Wang, Wen-Kai Yu, Ya-Xin Li</h4>摘要：近年来，具有大接收场（RF）的网络显示出了更高的拟合能力。在这项工作中，我们利用短期残差学习方法来改善网路对于影像去噪工作的效能与稳健性。在这里，我们选择了一个多小波卷积神经网络（MWCNN）作为骨干网络，它是一个具有大RF的最新网络之一，并在其每一层中插入剩余密集块（rdb）。我们称之为多小波残差密集卷积神经网络（MWRDCNN）。与其他基于RDB的网络相比，它可以从相邻层中提取更多的目标特征，保留较大的RF，提高计算效率。同时，这种方法也提供了在一个网络中吸收多个体系结构的优点而不发生冲突的可能性。该方法的性能已在大量实验中得到验证，并与现有技术进行了比较。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08301">PDF</a>
<h3>No. 57	MLModelScope：一个大规模的模型评估和基准测试的分布式平台</h3><h4>Abdul Dakkak, Cheng Li, Jinjun Xiong, Wen-mei Hwu</h4>摘要：机器学习（ML）和深度学习（DL）的创新正以如此之快的速度被引入，以至于研究人员很难对它们进行分析和研究。评估创新的复杂过程，以及缺乏标准和有效的方法来指定和提供ML/DL评估，是社区的一个主要“痛点”。本文提出了MLModelScope，这是一个开源的、框架/硬件无关的、可扩展的和可定制的设计，它支持可重复的、公平的和可伸缩的模型评估和基准测试。我们实现了支持所有主要框架和硬件的分布式设计，并为其配备了web、命令行和库接口。为了演示MLModelScope的功能，我们执行并行评估，并展示对模型评估管道的细微更改如何影响准确性，以及软硬件堆栈选择如何影响性能。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08295">PDF</a>
<h3>No. 58	当放射科报告生成遇到知识图时</h3><h4>Yixiao Zhang, Xiaosong Wang, Ziyue Xu, Qihang Yu, Alan Yuille, Daguang Xu</h4>文摘：近年来，为了减轻医生的工作量，放射科报告的自动生成一直是计算机辅助诊断领域的研究热点。自然图像字幕的深度学习技术已成功地应用于生成放射学报告。然而，放射学图像报告与自然图像字幕任务在两个方面有所不同：1）与自然图像字幕中每个单词的同等重要性相比，在放射学图像报告中，阳性疾病关键词提及的准确性至关重要；2）报告质量的评估应更侧重于匹配疾病关键字及其相关属性，而不是计算N-gram的发生率。基于这些考虑，我们建议在多个疾病发现上使用预先构建的图嵌入模块（用图卷积神经网络建模）来辅助报告的生成。知识图的合并允许对每个疾病发现和它们之间的关系建模进行专门的特征学习。此外，我们还提出了一个新的评估指标，以帮助放射影像报告的同一组成图。实验结果表明，与传统的图像字幕评价方法和我们提出的方法相比，在可公开访问的胸片数据集（IU-RR）上集成图形嵌入模块的方法具有更好的性能。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08277">PDF</a>
<h3>No. 59	部分Gromov-Wasserstein及其在正无标记学习中的应用</h3><h4>Laetitia Chapel, Mokhtar Z. Alaya, Gilles Gasso</h4>摘要：最优传输（OT）框架允许定义概率分布之间的相似性，并提供诸如Wasserstein和Gromov-Wasserstein差异等度量。经典OT问题寻求一个保持总质量的运输图，要求源和目标分布的质量相同。在某些应用中，例如颜色或形状匹配中，这可能限制太多，因为分布可能具有任意质量，或者只需要运输总质量的一小部分。已经设计了一些算法来计算非平衡Wasserstein度量，但是当涉及Gromov-Wasserstein问题时，还没有部分公式可用。这就排除了使用不在同一度量空间中的分布或需要对旋转或平移保持不变性的情况。本文针对部分Gromov-Wasserstein问题，提出了一种求解该问题的算法。我们在一个积极的无标签（PU）学习应用程序中展示了新的公式。据我们所知，这是本文中最优传输的第一个应用，我们首先强调基于Wasserstein的部分度量在通常的PU学习环境中证明是有效的。然后我们证明了部分Gromov-Wasserstein度量在点云来自不同领域或具有不同特征的情况下是有效的。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08276">PDF</a>
<h3>No. 60	多logue网：一种用于会话中多模态情感检测和情感分析的上下文感知RNN</h3><h4>Aman Shenoy, Ashish Sardana</h4>摘要：会话中的情感分析和情感检测是许多实际应用中的关键，不同的应用利用不同的数据来实现合理准确的预测。多模态情感检测和情感分析特别有用，因为应用程序将能够根据可用数据使用可用模式的特定子集，以生成相关预测。当前处理多模态功能的系统无法通过所有模式、对话中的当前说话者和听众以及通过适当的融合机制可用模式之间的相关性和关系来利用和捕获对话的上下文。在本文中，我们提出了一个递归神经网络架构，它试图考虑到上述所有的缺点，并跟踪对话的上下文、对话者的状态以及对话者在对话中所表达的情绪。我们提出的模型在两个基准数据集上对各种精度和回归度量进行了最新的测试。我们的模型实现是公开的，可以在github.com/amanshenoy/multilogue-net上找到<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08267">PDF</a>
<h3>No. 61	基于矩域自适应的学习界</h3><h4>Werner Zellinger, Bernhard A Moser, Susanne Saminger-Platz</h4>文摘：针对训练数据较少的目标领域，设计了一种领域自适应算法，通过对训练数据较多的源领域的模型进行自适应，最大限度地降低了判别模型的误分类风险。标准方法基于源域和目标域中经验概率分布之间的距离度量来度量适应差异。在这一背景下，我们讨论了在面向实践的一般条件下，关于潜在概率分布的学习界的推导问题。结果，我们得到了基于有限多个矩和光滑条件的域自适应学习界。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08260">PDF</a>
<h3>No. 62	用于微调的深网络基于距离的正则化</h3><h4>Henry Gouk, Timothy M. Hospedales, Massimiliano Pontil</h4>文摘：我们研究了深度神经网络微调过程中的正则化方法。首先，我们提供一个基于Rademacher复杂度的神经网络泛化界，它使用权重从初始值移动的距离。当应用于卷积网络时，这个界不直接依赖于权值的数目，并且与其他界相比是有利的。我们的界限与微调高度相关，因为提供基于转移学习的良好初始化的网络意味着学习可以较少地修改权重，从而实现更严格的泛化。受此启发，我们开发了一个简单而有效的微调算法，将假设类约束在一个以初始预训练权重为中心的小球体上，从而获得比传统转移学习更好的泛化性能。实验结果表明，我们的算法运行良好，验证了我们的理论结果。它不仅优于最先进的微调竞争对手，而且我们展示的基于惩罚的替代方案也不直接限制搜索空间的半径。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08253">PDF</a>
<h3>No. 63	研讨会报告：深入学习海洋生物声学的检测和分类</h3><h4>Fabio Frazao, Bruno Padovese, Oliver S. Kirsebom</h4>摘要：2019年11月21日至22日，约30名研究人员齐聚加拿大不列颠哥伦比亚省维多利亚市，参加由MERIDIAN组织、加拿大海洋网络主办的“海洋生物声学深度学习中的检测和分类”研讨会。来自加拿大海岸和美国的海洋生物学家、数据科学家和计算机科学家出席了研讨会，他们代表了包括大学、政府（加拿大渔业和海洋局、国家海洋和大气管理局）、工业（JASCO应用科学公司、谷歌，Axiom数据科学）和非营利组织（Orcasound，OrcaLab）。包括口头陈述、公开讨论和实践指导，研讨会项目为来自不同领域的专家提供了一个难得的机会，他们可以就深度学习及其在水声探测和分类算法发展方面的潜力进行交流。在本研讨会报告中，我们总结了演讲和讨论会的要点。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08249">PDF</a>
<h3>No. 64	洗牌型梯度法的统一收敛性分析</h3><h4>Lam M. Nguyen, Quoc Tran-Dinh, Dzung T. Phan, Phuong Ha Nguyen, Marten van Dijk</h4>文摘：针对机器学习中常用的有限和极小化问题，给出了一类洗牌型梯度法的统一收敛性分析。该算法包括各种变体，如随机重新洗牌、单洗牌和循环/增量梯度方案。我们考虑两种不同的情形：强凸和非凸问题。我们的主要贡献包括一类求解非凸和强凸问题的一般洗牌型梯度方法的新的非渐近和渐近收敛速度。虽然我们在非凸问题中的速率是新的（即在标准假设下还不知道），但是在强凸情况下的速率（直到常数）匹配最著名的结果。然而，与此方向的现有工作不同，我们仅使用平滑性和强凸性等标准假设。最后，我们通过一个非凸logistic回归和神经网络实例来实证说明学习率的影响。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08246">PDF</a>
<h3>No. 65	量子统计查询学习</h3><h4>Srinivasan Arunachalam, Alex B. Grilo, Henry Yuen</h4>文摘：我们提出了一种量子统计学习QSQ模型，它将Kearns引入的SQ学习模型推广到量子环境中。我们的模型也可以看作是量子PAC学习模型的一个限制：在这里，学习者不能直接访问量子示例，只能获得它们的测量统计估计。理论上，这个模型提供了一个简单而富有表现力的环境来探索量子例子在机器学习中的威力。从实际的角度来看，由于需要更简单的操作，QSQ模型中的学习算法更适合在近期量子器件上实现。我们证明了QSQ学习模型的一些结果。我们首先证明了奇偶函数（log n）-juntas和多项式大小的DNF公式在QSQ模型中是有效可学习的，与经典的难以证明的情形相比。这意味着量子PAC学习的许多优点甚至可以在更受限的量子SQ学习模型中实现。众所周知，用WSQDIM（C）表示的弱统计查询维数表征了经典SQ模型中C类概念学习的复杂性。我们证明了log（WSQDIM（C））是QSQ学习复杂性的一个下界，而且对于某些概念类C是紧的。此外，我们还证明了这个量为积分布下的小偏差量子通信模型提供了强下界。最后，我们引入了私有量子PAC学习的概念，其中量子PAC学习者必须是差异私有的。我们证明了QSQ模型中的可学习性意味着量子私有PAC模型中的可学习性。此外，我们还证明在私有PAC学习环境中，经典和量子样本的复杂度是相等的，直到常数因子。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08240">PDF</a>
<h3>No. 66	求解非线性扩散系数和Biot方程的物理信息神经网络</h3><h4>Teeratorn Kadeethum, Thomas M Jorgensen, Hamidreza M Nick</h4>文摘：介绍了应用物理信息神经网络解决生物医学工程、地震预报、地下能量采集等领域所必需的非线性多物理问题的潜力。具体地说，我们研究如何扩展物理信息神经网络的方法来求解非线性扩散系数和Biot方程的正问题和反问题。研究了不同训练样本大小和超参数选择下的物理信息神经网络的精度。研究了不同训练实现方式之间随机变化的影响。在相反的情况下，我们还研究了噪声测量的影响。此外，我们还讨论了选择逆模型超参数的挑战，并说明了如何将此挑战与为正向模型选择超参数联系起来。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08235">PDF</a>
<h3>No. 67	学习公平评分函数：公平定义、算法和二部排序的推广界</h3><h4>Robin Vogel, Aurélien Bellet, Stéphan Clémençon</h4>摘要：人工智能的许多应用，从信用贷款到通过累犯预测设计医疗诊断支持工具，都涉及到使用其属性的学习函数对个体进行评分。这些预测风险得分用于对一组人进行排序，和/或根据得分是否超过某个阈值（可能取决于所做决策的上下文）对他们进行个人决策。授予这种制度的授权程度将在很大程度上取决于如何回答公平问题。虽然这种关注在分类设置中得到了很多关注，但是针对学习评分函数的公平约束设计问题却没有得到太多的研究。本文针对二元标记数据的评分问题，提出了一种灵活的群体公平性方法，这是一种称为二元排序的标准学习任务。我们认为，ROC曲线的功能性质，即衡量排名绩效的金标准，导致了制定公平约束的几种可能方法。在二部排序中引入了一般的公平条件类，并建立了在这种约束下学习的评分规则的推广界。在理论公式和结果的基础上，我们设计了实用的学习算法，并通过数值实验说明了我们的方法。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08159">PDF</a>
<h3>No. 68	基于贝叶斯算术编码的可变比特率神经压缩</h3><h4>Yibo Yang, Robert Bamler, Stephan Mandt</h4>摘要：深度贝叶斯潜在变量模型为模型和数据压缩提供了新的途径。在这里，我们提出了一种新的算法来压缩后处理中的深层概率模型中的潜在表示，例如变分自编码。因此，该方法将模型设计和训练从压缩任务中分离出来。我们的算法将算术编码推广到连续域，使用自适应离散化精度，利用后验不确定性估计。我们方法的“即插即用”性质的一个结果是，可以通过一个单一的训练模型来实现各种速率失真的权衡，从而消除了为不同比特率训练多个模型的需要。我们的实验结果证明了考虑后验不确定性的重要性，并且表明，在仅使用一个机器学习模型的情况下，使用该算法的图像压缩在很大的比特率范围内优于JPEG。进一步的贝叶斯神经单词嵌入实验证明了该方法的通用性。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08158">PDF</a>
<h3>No. 69	基于互信息神经估计的隐式模型贝叶斯实验设计</h3><h4>Steven Kleinegesse, Michael U. Gutmann</h4>摘要：隐式随机模型是自然科学中普遍存在的一种模型，它的数据生成分布是不易处理的，但抽样是可能的。这些模型通常有自由参数，需要从科学实验收集的数据中推断出来。一个基本的问题是如何设计实验，使收集到的数据最有用。贝叶斯实验设计领域主张，理想情况下，我们应该选择最大化数据和参数之间相互信息（MI）的设计。然而，对于隐式模型，这种方法受到计算后验和最大化MI的高计算成本的严重阻碍，特别是当我们有多个设计变量需要优化时。本文提出了一种新的隐式模型贝叶斯实验设计方法，利用神经MI估计的最新进展来解决这些问题。我们证明，训练一个神经网络以使MI的下界最大化，可以让我们共同决定最优设计和后验。仿真研究表明，该方法将隐式模型的贝叶斯实验设计扩展到更高的设计维度。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08129">PDF</a>
<h3>No. 70	带语言偏差的Rnn变换器在汉英语码转换语音识别中的应用</h3><h4>Shuai Zhang, Jiangyan Yi, Zhengkun Tian, Jianhua Tao, Ye Bai</h4>文摘：近年来，人们利用语言身份信息来提高端到端码转换（CS）语音识别的性能。然而，以往的研究多采用附加的语言识别（LID）模型作为辅助模块，导致系统复杂。在这项工作中，我们提出了一个改进的带有语言偏差的递归神经网络转换器（RNN-T）模型来缓解这个问题。利用语言恒等式对模型进行偏误预测。这促进了该模型直接从转录中学习语言身份信息，不需要额外的LID模型。我们对一个汉英CS语料库seam进行了评价。与我们的RNN-T基线相比，该方法在两个测试集上的相对误差分别降低了16.2%和12.9%。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08126">PDF</a>
<h3>No. 71	BB U疏散：基于快速位置敏感行为的建筑物疏散</h3><h4>Subhra Mazumdar, Arindam Pal, Francesco Parisi, V.S. Subrahmanian</h4>摘要：过去关于疏散计划的工作假设疏散人员会遵守指示——然而，有充分的证据表明情况并非如此。有些人会按照指示行事，有些人则会按照自己的意愿行事。本文给出了一个基于行为的疏散问题（BBEP）的形式化定义，其中在规划疏散时考虑了人的行为模型。我们证明了一种特定形式的约束可以用来表达这种行为。我们证明，bbep可以通过一个称为BB_-IP的整数程序精确求解，而通过一个称为BB_-Evac的更快的算法则可以精确求解。我们对两种应用于建筑物的算法进行了详细的实验评估（尽管原则上算法可以应用于任何图形），并表明后者比BB_IP快一个数量级，同时在一个真实的建筑物图形和几个综合的建筑物图形上产生的结果几乎一样好生成的图表。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08114">PDF</a>
<h3>No. 72	走向低成本、稳定的区块链网络</h3><h4>Minghong Fang, Jia Liu</h4>摘要：区块链网络被认为是分布式系统的未来，近年来受到了业界和学术界越来越多的关注。然而，区块链开采过程消耗大量能源，研究表明，比特币开采消耗的能源量几乎与爱尔兰使用的电力量相同。针对区块链网络的高挖掘能耗问题，提出了一种区块链挖掘资源分配算法，以降低基于PoW（工作证明）的区块链网络的挖掘成本。我们首先对一般的区块链排队模型进行了系统的研究。在我们的排队模型中，事务随机到达队列，并以批处理的方式提供服务，其概率分布未知，对任何优先级机制都不可知。然后，利用Lyapunov优化技术，提出了一种动态挖掘资源分配算法（DMRA），该算法由一个参数$K>0$来参数化。结果表明，该算法在性能延迟上达到了$[O（1/K），O（K）]$的折衷。仿真结果也证明了DMRA在降低采矿成本方面的有效性。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08027">PDF</a>
<h3>No. 73	基于影响函数的数据中毒攻击对Top-N推荐系统的影响</h3><h4>Minghong Fang, Neil Zhenqiang Gong, Jia Liu</h4>文摘：推荐系统是web服务吸引用户的重要组成部分。流行的推荐系统使用大量的众包用户-项目交互数据（如评分）对用户偏好和项目属性进行建模；然后向用户推荐与用户偏好最匹配的顶级-N$项目。在这项工作中，我们证明攻击者可以通过向伪用户注入精心编制的用户项交互数据，向推荐系统发起数据中毒攻击，以根据攻击者的需要提出建议。具体来说，攻击者可以欺骗推荐系统，向尽可能多的普通用户推荐目标项。基于矩阵分解的推荐系统在工业上得到了广泛的应用。考虑到攻击者可以注入的假用户的数量，我们将假用户的评分作为一个优化问题来制定。然而，该优化问题是一个非凸整数规划问题，求解难度很大。为了应对这一挑战，我们开发了几种近似求解优化问题的技术。例如，我们利用影响函数来选择对推荐有影响的正常用户的子集，并基于这些有影响的用户来解决我们提出的优化问题。结果表明，我们的攻击是有效的，并优于现有的方法。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08025">PDF</a>
<h3>No. 74	非自回归对话状态跟踪</h3><h4>Hung Le, Richard Socher, Steven C.H. Hoi</h4>摘要：面向任务对话的对话状态跟踪（DST）研究已经向开放词汇或基于生成的方法发展，在这种方法中，模型可以从对话历史本身生成候选时隙值。这些方法显示了良好的性能增益，特别是在具有动态时隙值的复杂对话域中。然而，它们在两个方面存在不足：（1）它们不允许模型显式地跨域和时隙学习信号，以检测（域、时隙）对之间的潜在依赖性；（2）现有模型遵循自回归方法，当对话在多域和多圈上演化时，会产生较高的时间代价。本文提出了一种新的非自回归对话状态跟踪（NADST）框架，该框架可以考虑域和时隙之间潜在的依赖关系，以优化模型，从而更好地将对话状态预测为一个完整的集，而不是单独的时隙。特别是，我们的方法的非自回归特性不仅使得并行解码能够显著地减少DST的延迟，以便实时生成对话响应，而且还可以检测令牌级别的时隙之间以及时隙和域级别的依赖关系。我们的实验结果表明，我们的模型在MultiWOZ 2.1语料库上实现了跨领域的最新联合精度，并且随着对话历史的延长，我们的模型的延迟比以前的水平低一个数量级。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08024">PDF</a>
<h3>No. 75	基于自适应多尺度集成学习的游客季节趋势预测</h3><h4>Shaolong Suna, Dan Bi, Ju-e Guo, Shouyang Wang</h4>摘要：准确预测旅游者的季节和趋势是一项极具挑战性的任务。鉴于季节性和趋势性预测在旅游客源预测中的重要性，以往的研究工作对其重视不够。在本研究中，我们提出一种新的自适应多尺度集合（AME）学习方法，将变分模式分解（VMD）与最小二乘支援向量回归（LSSVR）相结合，来预测短期、中期及长期的季节及趋势。在我们开发的AME学习方法的公式中，首先将原始的游客到达序列分解为趋势、季节和剩余波动分量。然后利用ARIMA对趋势分量进行预测，SARIMA对12个月周期的季节性分量进行预测，LSSVR对剩余波动分量进行预测。最后，利用基于LSSVR的非线性集合方法，将三个分量的预测结果进行聚合，生成游客到达量的集合预测。此外，采用直接策略进行多步预测。通过两种精度测度和Diebold-Mariano检验，实证结果表明，本文提出的AME学习方法与本研究中使用的其他基准相比，能够获得更高的水平和方向预测精度，这表明我们的方法是一个很有前途的模型，预测游客人数具有很高的季节性和波动性。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08021">PDF</a>
<h3>No. 76	基于局部功率迭代的分布式SVD通信效率</h3><h4>Xiang Li, Shusen Wang, Kun Chen, Zhihua Zhang</h4>文摘：研究了截断奇异值分解（SVD）的分布计算。为了提高通信效率，我们开发了一个称为\texttt{LocalPower}的算法。具体地说，我们在$m$节点之间统一地划分数据集，并在多个（准确地说$p$）局部幂迭代和一个全局聚合之间交替。我们从理论上证明，在某些假设下，texttt{LocalPower}会将所需的通信次数降低$p$一个因子，以达到一定的精度。我们还展示了周期性衰减$p$的策略有助于提高\texttt{LocalPower}的性能。我们进行了实验，以证明\texttt{LocalPower}的有效性。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08014">PDF</a>
<h3>No. 77	基于游客注意力的旅游需求预测：一种集成的深度学习方法</h3><h4>Shaolong Sun, Yanzhao Li, Shouyang Wang, Ju-e Guo</h4>摘要：大量的旅游相关数据对旅游需求预测提出了一系列挑战，包括数据不足、多重共线性、计算时间长等。为了解决这一问题，提出了一种基于Bagging的多元集成深度学习模型。采用来京游客历史数据、经济指标和游客在线行为变量对四国来京游客进行预测。四个来源国的实证结果表明，我们提出的B-SAKE模型无论在水平精度、方向精度还是统计显著性上都优于基准模型。套袋和叠层自动编码都能提高模型的预测性能。并利用多步超前预报方案对模型的预报性能进行了评价，结果一致。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07964">PDF</a>
<h3>No. 78	基于渐进生长GANs的21cm断层扫描样本生成与参数推断的统一框架</h3><h4>Florian List, Geraint F. Lewis</h4>文摘：考虑到所涉及的天体物理过程的范围和可能要探测的高维参数空间，为一系列再电离历史建立一个21厘米亮度-温度信号的数据库是一项复杂和计算成本高昂的任务。我们使用一种特定类型的神经网络，一种逐步增长的生成对抗网络（PGGAN），在提高采收率期间生成21cm亮度温度的真实层析图像，覆盖一个连续的三维参数空间，该空间模拟不同的X射线发射率、Lyman波段发射率以及硬与软之间的比率X光片。GPU训练的网络以每秒$\sim 3'$的分辨率（在笔记本电脑CPU上）生成新样本，得到的全局21cm信号、功率谱和像素分布函数与21SSD目录{Semelin2017}中的训练数据非常一致。最后，我们展示了如何利用经过训练的PGGAN通过近似贝叶斯计算从21cm断层样本中推断参数。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07940">PDF</a>
<h3>No. 79	局部卷积GAN</h3><h4>Łukasz Struski, Szymon Knop, Jacek Tabor, Wiktor Daniec, Przemysław Spurek</h4>文摘：本文构造了一个完全卷积的GAN模型：LocoGAN，它的潜在空间是由可能不同分辨率的噪声图像给出的。学习是局部的，即我们处理的不是整个噪声图像，而是固定大小的子图像。因此，LocoGAN可以生成任意尺寸的图像，例如LSUN卧室数据集。我们方法的另一个优点来自于我们使用的位置通道，它允许生成完全周期的（例如圆柱全景图像）或几乎周期的、无限长的“图像”（例如墙纸）。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07897">PDF</a>
<h3>No. 80	观测不可辨识性、广义似然与自由能</h3><h4>A.E. Allahverdyan</h4>文摘：研究了具有观测不可辨识性的混合模型的参数估计问题：完全模型（也包含隐变量）是可辨识的，而边际模型（观测）不是可辨识的。因此，边际似然的全局极大值是（无限）退化的，边际似然的预测不是唯一的。我们通过引入一个有效温度，使其与自由能相似，来说明如何推广边际似然。这种推广解决了观测的不可识别性，因为它的最大化导致的唯一结果比边缘似然的一个退化极大值的随机选择或在许多这样的极大值上的平均更好。广义似然方法继承了一般似然方法的许多特点，如它具有条件性原理，通过适当的改进期望最大化方法可以寻找其局部极大值。广义似然最大化与熵优化有关。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07884">PDF</a>
<h3>No. 81	基于深度学习特征的CBIR</h3><h4>Subhadip Maji, Smarajit Bose</h4>摘要：在基于内容的图像检索系统中，任务是从给定查询图像的大型数据库中检索相似图像。通常的步骤是从查询图像中提取一些有用的特征，并检索具有相似特征集的图像。为此，选择一个合适的相似度度量方法，对相似度较高的图像进行检索。当然，这些特征的选择对系统的成功起着非常重要的作用，需要高层次的特征来减少语义鸿沟。在本文中，我们建议使用从为一个大型图像分类问题训练的深度学习卷积网络的预先训练的网络模型中得到的特征。这种方法似乎为各种数据库产生了非常优越的结果，并且它优于许多当代的CBIR系统。我们分析了该方法的检索时间，并提出了一种基于上述特征的数据库预聚类方法，在大多数情况下，在更短的时间内得到了可比的结果。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07877">PDF</a>
<h3>No. 82	自闭症和其他任务中大型、混合位点fMRI数据集的集成深度学习</h3><h4>Matthew Leming, Juan Manuel Górriz, John Suckling</h4>摘要：用于磁共振分类的深度学习模型面临着两个反复出现的问题：它们通常受样本量的限制，并且被自身的复杂性所抽象（“黑箱问题”）。在本文中，我们训练了一个卷积神经网络（CNN），它包含有史以来最大的多源功能磁共振（fMRI）连接组数据集，由43858个数据点组成。我们将此模型应用于自闭症（ASD）与典型发育期（TD）对照的横断面比较，这些对照被证明难以用推论统计来描述。为了将这些发现具体化，我们还对性别和任务与休息进行了分类。利用类平衡建立训练集，我们在一个集成模型中训练了3$乘以300美元的修正CNN，对ASD与TD、性别和任务与休息的总体AUROC分别为0.6774、0.7680和0.9222的功能磁共振连接性矩阵进行分类。此外，我们的目标是解决这个背景下的黑箱问题，使用两种可视化方法。首先，类激活图显示了我们的模型在进行分类时关注的大脑功能连接。其次，通过分析隐藏层的最大激活，我们还能够探索该模型如何组织一个大型的混合中心数据集，发现它将隐藏层的特定区域用于处理不同的数据协变量（取决于所分析的自变量），以及其他混合不同来源数据的领域。我们的研究发现，区分ASD和TD对照的深度学习模型主要集中在颞叶和小脑连接，尤其是右尾状核和中央旁沟。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07874">PDF</a>
<h3>No. 83	统计学习技术在儿童阻塞性睡眠呼吸暂停中的应用</h3><h4>Emily T. Winn, Marilyn Vazquez, Prachi Loliencar, Kaisa Taipale, Xu Wang, Giseon Heo</h4>摘要：儿童阻塞性睡眠呼吸暂停症约影响1-5%的小学生，并可能导致其他有害的健康问题。快速的诊断和治疗对孩子的成长和发展至关重要，但症状的多样性和现有数据的复杂性使这成为一个挑战。我们通过关注调查问卷和颅面测量的廉价数据，在简化这一过程中迈出了第一步。在探索性数据分析过程中，我们应用了相关网络、拓扑数据分析中的映射算法和奇异值分解。然后，我们应用各种有监督和无监督的学习技术，从统计、机器学习和拓扑，从支持向量机到贝叶斯分类器和流形学习。最后，我们分析了每种方法的结果，并讨论了向前移动的多数据源算法的含义。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07873">PDF</a>
<h3>No. 84	基于高斯过程的安全临界系统参数在线估计</h3><h4>Mouhyemen Khan, Abhijit Chatterjee</h4>文摘：参数估计是复杂动态系统建模、跟踪和控制的关键。然而，在依赖于标称参数值的控制器下，参数不确定性会影响系统性能。通常情况下，参数是用数值回归方法作为反问题来估计的。然而，由于存在多个局部最优解、对梯度的依赖、大量的实验数据或稳定性问题，它们具有非唯一性。针对这些缺点，我们提出了一个基于高斯过程（GPs）的贝叶斯优化框架，用于在线参数估计。它在参数空间中对响应曲面使用一种有效的搜索策略来寻找具有最小函数估计的全局最优解。利用GPs在噪声数据上建立响应面相关代理模型。利用GP后验预测方差进行智能自适应采样。这平衡了勘探与开发之间的权衡，这是在有限的预算下达到全球最优的关键。我们在一个驱动的平面摆上演示了我们的技术，并在改变参数的模拟中演示了安全临界四旋翼。我们还使用内点法和序列二次规划将结果与求解器进行了比较。通过迭代地用新的优化参数重新配置控制器，我们大大改善了系统相对于标称情况和其他解算器的轨迹跟踪。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07870">PDF</a><h2>2020-02-19</h2>
<h3>No. 1	递进神经网络学习的子集抽样</h3><h4>Dat Thanh Tran, Moncef Gabbouj, Alexandros Iosifidis</h4>文摘：递进神经网络学习是一类基于训练数据逐步构造网络拓扑结构并优化网络参数的算法。虽然这种方法免除了用户设计和验证多个网络拓扑的手动任务，但它通常需要大量的计算。在本文中，我们建议通过在每个增量训练步骤中利用训练数据子集来加速这一过程。提出并评价了三种根据不同准则选择训练样本的抽样策略。我们还建议在网络进行过程中进行在线超参数选择，从而进一步减少整体训练时间。在目标、场景和人脸识别问题上的实验结果表明，该方法在训练过程中充分利用了整个训练集，在与基线方法相同的条件下，大大加快了优化过程。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07141">PDF</a>
<h3>No. 2	确定性系统中函数逼近的不可知Q学习：逼近误差和样本复杂度的严格界限</h3><h4>Simon S. Du, Jason D. Lee, Gaurav Mahajan, Ruosong Wang</h4>文摘：本文研究了确定性系统中不相关Q $ $学习的函数逼近问题，其中最佳$q $函数可由类$ \ MathCAL{f}$中的函数逼近，逼近误差$Δ\ GE 0 $。我们提出了一种新的基于递归的算法，并证明了如果$\delta=O\left（\rho/\sqrt{\dim_E}\right）$，则可以使用$O\left（\dim_E}\right）$轨迹找到最优策略，其中，$\rho$是最佳操作的最优$Q$值与次佳操作的最优$Q$值之间的差距，$\dim_E$是$\mathcal{F}$的洗脱器维度。我们的结果有两个含义：1）结合[DU等人，ICLR 2020 ]中的下界，我们的上界表明条件$\ delta \广角{\θ}左（\Roo/\qrt{{Mathm {Dim}} }）对于多项式样本复杂度的算法是必要的和充分的。2）结合[Win和Van Roy，NIPS 2013 ]中的下界，我们的上界表明样本复杂性$\广角{ \θ}左（\ Mathm {Dime} \右）$是紧的，即使在不可知的设置中。因此，我们解决了[Wen and Van Roy，NIPS 2013]中提出的不可知论$Q$-学习的开放问题。我们进一步将我们的算法推广到随机报酬设置中，得到了类似的结果。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07125">PDF</a>
<h3>No. 3	监督学习数据中缺失标注的处理</h3><h4>Alaa E. Abdel-Hakim, Wael Deabes</h4>摘要：数据标注是监督学习的一个重要阶段。然而，注释过程是详尽和耗时的，特别是对于大型数据集。日常生活活动（ADL）识别是利用非常大的原始传感器数据读数的系统的一个例子。在这种系统中，传感器读数是以24/7的方式从活动监测传感器收集的。生成的数据集太大，以至于人工注释器几乎不可能为数据集中的每个实例都赋予特定的标签。这导致采用监督学习系统的输入数据中存在注释间隙。这些差距对识别系统的性能产生了负面影响。在这项工作中，我们提出并研究了三种不同的模式来处理这些差距。在第一种范式中，通过删除所有未标记的读数来消除间隙。一个“未知”或“不做任何事”的标签被给予在第二个范例的操作中的未标记的读数。最后一个范型通过给它们中的每一个提供一个唯一的标签来识别封装的确定性标签来处理这些间隙。此外，我们还提出了一种注释间隙的语义预处理方法，通过构造这些范例的混合组合来进一步提高性能。使用ADL基准数据集（包含超过2.5美元乘以超过9个月收集的10^6美元传感器读数）评估所提出的三种范式及其混合组合的性能。评估结果强调了每种范式运作下的绩效对比，并支持特定的差距处理方法以获得更好的绩效。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07113">PDF</a>
<h3>No. 4	神经序列模型的计算与质量控制</h3><h4>Ankur Bapna, Naveen Arivazhagan, Orhan Firat</h4>翻译后摘要：大多数神经网络利用相同数量的计算为每个例子独立于固有的复杂性的输入。此外，使计算量适应示例的方法侧重于为每个示例查找固定的推理时间计算图，而忽略任何外部计算预算或变化的推理时间限制。在这项工作中，我们利用条件计算使神经序列模型（Transformer）在推理过程中更有效率和计算意识。我们首先修改Transformer架构，使每一组操作根据学习到的控制网络的输出有条件地执行。然后，我们在多任务设置中训练该模型，其中每个任务对应于特定的计算预算。这允许我们训练一个单一的模型，该模型可以控制在计算质量权衡曲线的不同点上运行，具体取决于推断时可用的计算预算。我们在两个任务上评估了我们的方法：（i）WMT英法翻译和（ii）无监督表示学习（BERT）。我们的实验表明，当允许使用条件计算转换器（CCT）的全部计算预算时，该转换器与普通变压器相比具有竞争力，而当在较小的计算预算下操作时，其性能显著优于计算等效基线。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07106">PDF</a>
<h3>No. 5	增强规范化流：弥合生成流和潜在变量模型之间的鸿沟</h3><h4>Chin-Wei Huang, Laurent Dinh, Aaron Courville</h4>文摘：在这项工作中，我们提出了一个在扩充数据空间上的新的生成流族，目的是在不显著增加抽样和估计似然下界的计算成本的情况下提高表示性。理论上，我们证明了所提出的流可以逼近哈密顿量作为一个普适映射。在经验上，我们在基于流的生成建模的标准基准上展示了最先进的性能。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07101">PDF</a>
<h3>No. 6	图反褶积生成</h3><h4>Daniel Flam-Shepherd, Tony Wu, Alan Aspuru-Guzik</h4>摘要：图形生成是一项极其重要的工作，因为图形贯穿于科学和工程的各个领域。本文研究了鄂尔多斯人一随机图模型的现代等价：图变分自编码（GVAE）。该模型假设边缘和节点是独立的，以便使用多层感知器解码器一次生成完整的图形。由于这些假设，GVAE难以匹配训练分布，并且依赖于昂贵的图匹配过程。我们通过在GVAE的编解码器中建立一个消息传递神经网络来改进这类模型。我们展示了我们关于生成小有机分子的模型<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07087">PDF</a>
<h3>No. 7	三大问题：通过回答公司关心的问题来提高数据科学投资回报率的方法</h3><h4>Daniel K. Griffin</h4>摘要：在工业应用中，企业从数据科学中获得的价值可能只有三分之一。在这篇文章中，我们提出了一种使用数据科学对“三大”问题进行分类和回答的方法（发生了什么，是什么原因造成的，我可以采取什么行动来优化我关心的问题）。数据科学的应用在当今的现代环境中似乎是无穷无尽的，每家公司都在争夺新的数据和洞察力经济的地位。然而，数据科学家似乎只专注于使用分类、回归和聚类方法来回答“发生了什么”的问题。在工业数据科学分析中，关于为什么会发生这种情况或如何采取最佳行动来改进度量的问题，通常被归入利基研究领域而被忽视。我们调查技术方法以回答这些其他重要问题，描述其中一些方法正在应用的领域，并提供如何将我们的方法和所选方法应用于实际业务用例的实际示例。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07069">PDF</a>
<h3>No. 8	用函数逼近和相关均衡学习零和同时移动马尔可夫博弈</h3><h4>Qiaomin Xie, Yudong Chen, Zhaoran Wang, Zhuoran Yang</h4>文摘：针对两人零和马尔可夫对策，提出了两人同时采取行动的可证明有效的强化学习算法。为了结合函数逼近，我们考虑了一类马尔可夫游戏，其中奖赏函数和转移核具有线性结构。同时考虑问题的脱机和联机设置。在离线环境下，我们同时控制两个参与者，目标是通过最小化最坏情况下的二元差距来有效地找到纳什均衡。在联机设置中，我们控制单个玩家与任意对手比赛，目标是最小化遗憾。对于这两种情况，我们提出了一种乐观的最小二乘最小极大值迭代算法。我们证明了我们的算法是计算有效的，并且在不需要对抽样模型进行额外假设的情况下，在对偶间隙和遗憾上可证明达到$\tilde O（\sqrt{d^3h^3t}）$上界。我们强调，我们的设置需要克服马尔可夫决策过程或基于转向的马尔可夫博弈中缺少的几个新挑战。特别地，为了在同时移动Marko博弈中实现乐观，我们构造了价值函数的上下置信界，然后通过求解一个以这些置信界为收益矩阵的一般和矩阵博弈来计算乐观策略。由于求解一般和博弈的纳什均衡是一个计算困难的问题，我们的算法求解的是一个粗相关均衡（CCE），它可以通过线性规划得到。据我们所知，这样一个基于央企的乐观主义实施方案并没有出现在文献中，它本身可能会引起人们的兴趣。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07066">PDF</a>
<h3>No. 9	再培训还是不培训？--深CNN网络的有效剪枝方法</h3><h4>Marcin Pietron, Maciej Wielgosz</h4>摘要：卷积神经网络（CNN）在图像分类、目标检测、语义分割等图像处理任务中发挥着重要作用。CNN网络通常有几百个堆叠的层和几兆字节的权重。减少复杂性和内存占用的一种可能方法是修剪。剪枝是一个去除网络中连接两个相邻层神经元的权值的过程。当DL模型具有较高的卷积层数时，寻找具有指定精度下降的近似最优解的过程会更加复杂。本文对基于再培训和非再培训的几种方法进行了描述和比较。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07051">PDF</a>
<h3>No. 10	多任务协同智能的位分配</h3><h4>Saeed Ranjbar Alvar, Ivan V. Bajić</h4>文摘：近年来的研究表明，协作智能（CI）是一种很有前途的在移动设备上部署基于人工智能（AI）的服务的框架。在CI中，在移动设备和云之间分割出一个深层神经网络。在移动设备上获得的深层特征被压缩并传输到云端以完成推理。到目前为止，文献中的方法主要集中在将单个深度特征张量从移动设备转移到云上。这种方法不适用于一些具有多分支和跳跃连接的高性能网络。本文提出了多流、多任务CI的第一位分配方法。我们首先建立了一个多个任务的联合失真模型，作为分配给不同深度特征张量的比特率的函数。然后，利用该模型求解了总速率约束下的速率失真优化问题，得到了待传输张量之间的最优速率分配。实验结果表明，与几种不同的比特分配方法相比，该方案是有效的。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07048">PDF</a>
<h3>No. 11	基于图像结构的对象变形测试</h3><h4>Adrian Wildandyawan, Yasuharu Nishi</h4>摘要：由于需要大量生成测试用例并为其提供测试oracle，测试软件往往成本高昂。这通常被称为oracle问题。为了缓解oracle问题，人们提出了一种方法：变形测试。变质测试通过改变现有的测试用例来产生新的测试用例，并利用被测试系统（SUT）的输入和输出之间的变质关系来预测所产生的测试用例的预期输出。变形测试通常用于图像处理软件，其中对图像的属性应用更改以创建带有与原始图像相同的注释的新测试用例。我们将现有的方法称为基于图像的变形测试。在本研究中，我们提出一个基于物件的变质主义测试和一个复合变质主义测试，结合不同的变质主义测试方法，以相对增加测试覆盖率。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07046">PDF</a>
<h3>No. 12	深部张量压缩的前后预测</h3><h4>Hyomin Choi, Robert A. Cohen, Ivan V. Bajic</h4>摘要：近年来人工智能的应用，如协同智能和神经网络，涉及到在不同的计算设备之间传递深层特征张量。这就需要张量压缩来优化设备之间带宽受限信道的使用。本文提出了一种针对深特征张量的预测方案，称为前后（BaF）预测，它能显著减小张量的大小，提高张量的压缩性。我们使用最先进的目标检测器进行的实验表明，所提出的方法可以显著减少压缩从模型内部深层提取的特征张量所需的比特数，而检测性能的退化可以忽略不计，并且不需要重新训练网络权值。在保证网络精度损失分别小于1%和2%的情况下，张量减小了62%和75%。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07036">PDF</a>
<h3>No. 13	为知识跟踪提供适当的查询、键和值计算</h3><h4>Youngduck Choi, Youngnam Lee, Junghyun Cho, Jineon Baek, Byungsoo Kim, Yeongmin Cha, Dongmin Shin, Chan Bae, Jaewe Heo</h4>摘要：知识追踪是计算机辅助教育领域中一个广泛研究的问题，是通过学习活动来模拟学生知识的行为。尽管带有注意机制的模型比传统的方法（如贝叶斯知识跟踪和协作过滤）有更好的性能，但它们有两个共同的局限性。首先，这些模型依赖于浅层的注意力，无法捕捉到随着时间推移练习和反应之间的复杂关系。其次，没有广泛探讨用于知识追踪的自我注意层的查询、键和值的不同组合。通常将练习和交互（练习-响应对）分别用作查询和键/值的做法缺乏经验支持。本文提出了一种新的基于变压器的知识跟踪模型SAINT：分离自关注神经知识跟踪。SAINT具有编译码结构，其中运动和响应嵌入序列分别进入编码器和解码器，允许多次堆叠注意层。据我们所知，这是第一个提出一个用于知识跟踪的编码器-解码器模型的工作，该模型将深层的自我关注层分别应用于练习和响应。对一个大规模知识跟踪数据集的实证评估表明，SAINT在知识跟踪方面取得了最新的性能，与现有的最新模型相比，AUC提高了1.8%。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07033">PDF</a>
<h3>No. 14	基于多元时间序列分类的结构健康监测全卷积网络</h3><h4>Luca Rosafalco, Andrea Manzoni, Stefano Mariani, Alberto Corigliano</h4>文摘：提出了一种新的结构健康监测方法，旨在从普适传感器系统获取的数据中自动识别损伤敏感特征。将损伤检测和定位问题描述为分类问题，并通过完全卷积网络（FCNs）进行处理。基于物理模型（扮演被监控结构的数字孪生兄弟角色）的数值模拟数据，针对不同的损伤场景，对所提出的网络体系结构进行监督训练。基于这种简化的结构模型，在FCN的训练阶段考虑了多种载荷条件，设计了FCN的结构来处理不同长度的时间序列。神经网络的训练是在监测系统开始工作之前完成的，因此能够进行实时损伤分类。以八层剪力楼为算例，在两种荷载作用下，对该方法的数值性能进行了评估，其中一种荷载作用是模拟低能地震引起的随机振动。在结构响应中加入测量噪声，以模拟实际监测系统的输出。显示了非常好的分类能力：在九种可能的备选方案中（以健康状态和任何楼层的损伤为代表），损伤在高达95%的情况下被正确分类，从而显示了所提出的方法在实际应用中的强大潜力。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07032">PDF</a>
<h3>No. 15	具有流形光滑损失的半监督图卷积网络正则化</h3><h4>Qilin Li, Wanquan Liu, Ling Li</h4>摘要：现有的图卷积网络侧重于邻域聚集方案。在应用于半监督学习时，由于网络是在少量标记数据上进行交叉熵损失训练的，常常会出现过拟合问题。本文提出了一种与图结构相关的无监督流形光滑度损失，它可以作为正则化加入到损失函数中。我们将所提出的损失与迭代扩散过程联系起来，并证明了最小化损失等价于无限层的聚合邻居预测。我们在多层感知器和现有的图形网络上进行实验，并证明添加所提出的损失可以一致地改善性能。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07031">PDF</a>
<h3>No. 16	多头注意模型中的低阶瓶颈</h3><h4>Srinadh Bhojanapalli, Chulhee Yun, Ankit Singh Rawat, Sashank J. Reddi, Sanjiv Kumar</h4>摘要：基于注意的转换结构在自然语言处理领域取得了重大进展。除了新的预训练技术外，最近的改进主要依赖于使用相对较大的令牌嵌入维度。不幸的是，这会导致在下游任务中使用的模型过大。在本文中，我们确定了一个重要因素，导致了大嵌入尺寸的要求。特别是，我们的分析强调了当前架构中头部数量和每个头部大小之间的缩放导致了注意力头部的低级别瓶颈，从而导致了这种限制。我们在实验中进一步验证了这一点。作为一种解决方案，我们建议将注意单元的头部大小设置为输入序列长度，并且与头部数量无关，从而产生具有可证明的更高表达能力的多个头部注意层。我们的经验表明，这使得我们能够训练嵌入维数相对较小且具有更好性能伸缩性的模型。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07028">PDF</a>
<h3>No. 17	基于策略修正的因果特征发现</h3><h4>Yahav Bechavod, Katrina Ligett, Zhiwei Steven Wu, Juba Ziani</h4>文摘：我们考虑了一个在线回归环境，在这个环境中，个体可以适应回归模型：到达的个体可以在整个过程中访问该模型，并战略性地投资于修改自己的特征，从而提高分配的分数。我们发现，这种策略性操作可能有助于学习者恢复因果变量，在这种情况下，代理人可以投资于改善影响性特征，也可以改善他的真实标签。我们表明，即使是学习者的简单行为（即，通过最小二乘回归，根据迄今为止观察到的数据定期更新她的模型）也能让她同时i）准确地恢复哪些特征对代理的真实标签有影响，前提是这些特征已经被大量投资，以及ii）鼓励代理商投资于这些有影响力的功能，而不是对其真实标签没有影响的功能。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07024">PDF</a>
<h3>No. 18	基于多视图信息瓶颈的鲁棒表示学习</h3><h4>Marco Federici, Anjan Dutta, Patrick Forré, Nate Kushman, Zeynep Akata</h4>文摘：信息瓶颈原理为表示学习提供了一种信息论方法，它通过训练编码器保留与预测标签相关的所有信息，同时最小化表示中的其他多余信息量。然而，原始的公式需要标记的数据来识别多余的信息。在这项工作中，我们将此功能扩展到多视图无监督设置，其中提供了同一基础实体的两个视图，但标签未知。这使我们能够将多余的信息识别为两个视图都不共享的信息。通过理论分析，定义了一个新的多视图模型，该模型可以在粗略的数据集上生成最新的结果，并为MIR Flickr数据集的有限版本添加标签。我们还利用标准的数据增强技术将理论扩展到单视图设置，在经验上显示出比一般的无监督表示学习方法更好的泛化能力。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07017">PDF</a>
<h3>No. 19	动态环境的学习群结构与解构表示</h3><h4>Robin Quessard, Thomas D. Barrett, William R. Clements</h4>摘要：发现一个动态环境的基本结构需要学习可解释和可分离的表征，这是一项具有挑战性的任务。在物理学中，对我们的宇宙及其基本动力学的可解释的表示是用对称变换群的表示来表示的。我们提出了一种受物理学启发的方法，它建立在群表示理论的基础上，学习一个环境的表示，该环境是围绕生成其演化的变换而构建的。实验上，我们学习了无监督的显式对称环境的结构，同时保证了表示的可解释性。我们表明，所学习的表示允许精确的长视界预测，并进一步证明了预测质量与潜在空间解纠缠之间的相关性。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06991">PDF</a>
<h3>No. 20	一种用于有效CTR预测的稀疏深度因子分解机</h3><h4>Wei Deng, Junwei Pan, Tian Zhou, Aaron Flores, Guang Lin</h4>摘要：点击率（CTR）预测是在线展示广告中的一项关键任务，关键是学习重要的特征交互。主流的模型是基于嵌入的神经网络，它通过融合混合组件来对低阶和高阶特征交互进行建模，从而提供端到端的训练。然而，由于深度神经网络（DNN）的存在，这些模型将预测推理速度降低了至少数百倍。考虑到在网络广告中采用嵌入式神经网络的挑战，我们首次提出对冗余参数进行剪枝，以加速推理，减少运行时的内存使用。最值得注意的是，在Criteo数据集和Avazu数据集上，我们可以在不损失预测精度的情况下，分别加速46X和27X的推理。此外，深度模型加速使得低延迟和显著性能提高的高效模型集成成为可能。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06987">PDF</a>
<h3>No. 21	深度无监督对映学习中端到端训练的收敛性</h3><h4>Zixin Wen</h4>摘要：无监督对比学习在最近的研究中得到了越来越多的关注，并被证明是一种从无标记数据中学习表示的有效方法。然而，对这一框架的理论分析却鲜为人知。本文研究了深度无监督对比学习的优化问题。我们证明了对于过参数化神经网络，通过应用端到端训练同时更新两个深度神经网络，可以找到非凸对比损失的近似平稳解。这一结果与现有的在监督设置中的过度参数化分析本质上是不同的，因为与学习特定的目标函数相反，无监督对比学习试图将未标记的数据分布编码到神经网络中，神经网络通常没有最优解。我们的分析为这些无监督预训练方法的实际成功提供了理论上的见解。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06979">PDF</a>
<h3>No. 22	深层神经网络的组成结构研究</h3><h4>Francesco Craighero, Fabrizio Angaroni, Alex Graudenzi, Fabio Stella, Marco Antoniotti</h4>文摘：目前对深部神经网络的理解只能部分地解释输入结构、网络参数和优化算法如何共同作用于实现在许多实际应用中通常观察到的强泛化能力。为了提高对深层神经网络的理解和解释能力，提出了一种基于分段线性激活函数组合结构的深层神经网络理论框架。通过定义表示通过网络层的激活模式的组成的直接无环图，可以针对预测标签和用于执行预测的特定（线性）变换来表征输入数据的实例。MNIST数据集的初步测试表明，我们的方法可以将输入实例与它们在神经网络的内部表示中的相似性分组，提供输入复杂性的直观度量。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06967">PDF</a>
<h3>No. 23	具有调整平均秩的链路预测或实体对齐方法的可解释性和公平性比较</h3><h4>Max Berrendorf, Evgeniy Faerman, Laurent Vermue, Volker Tresp</h4>文摘：在这项工作中，我们仔细研究了两类从知识图中丰富信息的方法：链接预测和实体对齐。在当前的实验环境中，多个不同的分数被用来评估模型性能的不同方面。我们分析了这些评价方法的信息价值，并指出了一些不足之处。特别是，我们表明，所有现有的分数难以用于比较不同数据集的结果。此外，当比较同一数据集的不同列车/测试分段时，也可能出现此问题。我们发现，这会导致在解释结果时出现各种各样的问题，这可能支持误导性的结论。因此，我们提出了一种不同的评估方法，并通过实证证明这有助于对模型绩效进行公平、可比和可解释的评估。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06914">PDF</a>
<h3>No. 24	t-viSNE：t-SNE投影的交互评价与解释</h3><h4>Angelos Chatzimparmpas, Rafael Messias Martins, Andreas Kerren</h4>文摘：基于t-分布随机邻域嵌入（t-SNE）的多维数据可视化方法已被证明是一种流行的方法，在许多领域都有成功的应用。尽管t-SNE预测有用，但它可能很难解释，甚至误导人，这损害了结果的可信度。了解t-SNE本身的细节及其输出中特定模式背后的原因可能是一项艰巨的任务，特别是对于非维度归约专家来说。在这项工作中，我们提出了t-viSNE，一个用于t-SNE投影可视化探索的交互式工具，它使分析人员能够检查其准确性和含义的不同方面，例如超参数的影响、距离和邻域保护、特定邻域的密度和成本，以及维度和视觉模式之间的相互关系。我们提出了一个连贯的，可访问的，并且很好地集成了不同视图的集合，用于t-SNE投影的可视化。通过实际数据集的假设使用场景，验证了t-viSNE的适用性和可用性。最后，我们给出了一个用户研究的结果，其中评估了工具的有效性。通过揭示运行t-SNE后通常会丢失的信息，我们希望支持分析师使用t-SNE，并使其结果更易于理解。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06910">PDF</a>
<h3>No. 25	$π$VAE:用变分自编码器编码随机过程先验</h3><h4>Swapnil Mishra, Seth Flaxman, Samir Bhatt</h4>摘要：随机过程为复杂数据建模提供了一种数学上优雅的方法。理论上，它们在函数类上提供灵活的先验，可以对广泛的有趣假设进行编码。然而，在实践中，通过优化或边缘化进行有效的推理是困难的，大数据和高维输入空间进一步加剧了这一问题。我们提出了一种新的变分自动编码器（VAE），称为先验编码变分自动编码器（VAE）。$\pi$VAE是有限可交换且Kolmogorov一致的，因而是一个连续的随机过程。我们使用$\pi$VAE来学习函数类的低维嵌入。我们证明我们的框架可以准确地学习表示函数类，如高斯过程，还可以学习函数的性质，以便进行统计推断（如对数高斯过程的积分）。对于流行的任务，如空间插值，$\pi$VAE在精度和计算效率方面都达到了最先进的性能。也许最有用的是，我们证明了所学习的低维独立分布的潜在空间表示提供了一种优雅和可伸缩的方法，可以在概率编程语言（如Stan）中对随机过程执行贝叶斯推理。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06873">PDF</a>
<h3>No. 26	深度神经网络的可扩展性定量验证</h3><h4>Teodora Baluta, Zheng Leong Chua, Kuldeep S. Meel, Prateek Saxena</h4>文摘：验证深度神经网络（DNNs）的安全性越来越重要。本文介绍了一种新的DNN定量验证框架，该框架可以在用户指定的置信度下，确定给定DNN输入空间上定义的给定逻辑属性{\psi}是否保持在用户指定的阈值{\theta}以下。我们提出了新的算法，可扩展到大型现实世界模型，并证明是健全的。我们的方法只需要黑盒访问模型。进一步证明了确定性DNNs和非确定性DNNs的性质。我们在一个叫做PROVERO的工具中实现了我们的方法。我们将PROVERO应用于证明对抗稳健性的问题。在这种情况下，PROVERO为给定DNN和测试输入提供了一种与攻击无关的健壮性度量。首先，我们发现这个度量与目前最显著的两种白盒攻击策略所报告的扰动界具有很强的统计相关性。其次，我们证明了PROVERO可以在最新的定性验证工具（ERAN）不能产生结论性结果的情况下，以高度的置信度对稳健性进行定量验证。因此，定量验证容易扩展到大dnn。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06864">PDF</a>
<h3>No. 27	隶属度推理攻击的数据和模型依赖性</h3><h4>Shakila Mahjabin Tonni, Farhad Farokhi, Dinusha Vatsalan, Dali Kaafar</h4>摘要：机器学习（ML）技术被大多数数据驱动的组织用来提取洞察力。机器学习即服务（MLaaS）正在成为现实，在MLaaS中，模型被训练成潜在的敏感用户数据，然后被外部方查询。然而，最近的研究表明，这些系统易受成员推断攻击（MIA）的攻击，在MIA中，可以推断目标的数据是否属于训练数据。虽然MIMA成功的关键因素还没有完全了解，现有的防御机制只考虑模型特有的性质。我们研究了数据和ML模型属性对ML技术对MIA的脆弱性的影响。我们的分析表明MIA的成功与使用中的数据的属性（如数据大小和类之间的平衡）以及模型属性（包括预测的公平性和记录与模型参数之间的相互信息）之间有着密切的关系。然后，我们提出了一种新的方法来保护ML模型不受MIA的攻击，该方法利用了模型的公平性和记录与模型参数之间的互信息作为正则化，使得攻击精度降低了25%，同时得到了一个更公平、性能更好的ML模型。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06856">PDF</a>
<h3>No. 28	间歇强化学习中基于动作持久性的控制频率自适应</h3><h4>Alberto Maria Metelli, Flavio Mazzolini, Lorenzo Bisi, Luca Sabbioni, Marcello Restelli</h4>摘要：系统控制频率的选择对强化学习算法学习高性能策略的能力有着相关的影响。在本文中，我们引入了动作持续性的概念，即在固定的决策步骤数下重复一个动作，从而改变控制频率。我们首先分析了行为持久性对最优策略性能的影响，然后提出了一种新的算法，持久拟合Q迭代（PFQI），它扩展了FQI，目的是在给定的持久性下学习最优值函数。在对PFQI进行了理论研究和启发式方法识别最优持久性之后，我们提出了一个在基准域上的实验活动，展示了行动持久性的优点，并证明了我们的持久性选择方法的有效性。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06836">PDF</a>
<h3>No. 29	班级非均衡半监督学习</h3><h4>Minsung Hyun, Jisoo Jeong, Nojun Kwak</h4>摘要：半监督学习在克服标注困难和充分利用未标注数据方面取得了巨大的成功。然而，SSL有一个有限的假设，即不同类中的样本数是平衡的，并且许多SSL算法对于类分布不平衡的数据集表现出较低的性能。本文介绍了一个类不平衡半监督学习（CISSL）的任务，即利用类不平衡数据进行半监督学习。在这个过程中，我们考虑了有标签集和无标签集的类不平衡。首先，我们分析现有的SSL方法在不平衡的环境中，并检查类不平衡如何影响SSL方法。然后，我们提出了抑制一致性损失（SCL），一种对类不平衡鲁棒的正则化方法。在CISSL环境下，我们的方法比传统方法显示出更好的性能。特别是，类不平衡越严重，标记数据的大小越小，我们的方法的性能就越好。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06815">PDF</a>
<h3>No. 30	眼跟踪数据处理中的强化学习</h3><h4>Wolfgang Fuhl</h4>文摘：提出了一种基于强化学习的眼动跟踪数据处理方法。它基于两个相反的代理，其中一个代理试图正确分类数据，另一个代理在数据中寻找模式，这些模式被操纵以隐藏特定信息。我们证明我们的方法是成功地适用于保护一个主题的隐私。此外，我们的方法可以评估眼睛跟踪数据的时间和空间信息对于特定分类目标的重要性。一般来说，这种方法也可用于刺激操作，使其对注视引导感兴趣。为此，本文提供了理论依据，这也是为什么我们还整合了一节如何应用这种方法进行凝视引导。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06806">PDF</a>
<h3>No. 31	基于图序列神经模型重写规则的数据流图等价性</h3><h4>Steve Kommrusch, Théo Barollet, Louis-Noël Pouchet</h4>文摘：本文的研究目标是可证明地计算以数据流图表示的两个程序之间的等价性。为此，我们将两个程序之间的等价问题形式化为找到一组语义保持重写规则，从而在重写之后，两个程序在结构上是相同的，因此是微不足道的等价。然后，我们开发了第一个用于程序等价的图到序列神经网络系统，通过精心设计的自动示例生成算法训练生成这样的重写序列。我们利用丰富的多类型线性代数表达式语言，利用100 +图重写公理的任意组合，对系统进行了广泛的评价。我们的系统通过推理输出一个正确的重写序列，用于测试的10000个程序对中的96%，使用30个术语的程序。而且在所有情况下，产生的序列的有效性以及由此可证明的程序等价性断言是可计算的，在可忽略的时间内。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06799">PDF</a>
<h3>No. 32	CAT：定制对抗训练，提高健壮性</h3><h4>Minhao Cheng, Qi Lei, Pin-Yu Chen, Inderjit Dhillon, Cho-Jui Hsieh</h4>摘要：对抗训练已成为提高神经网络鲁棒性的最有效方法之一。然而，无论是在干净的数据上还是在扰动的数据上，它通常都会受到不好的泛化。本文提出了一种新的算法，称为自定义对抗训练（CAT），它自适应地为对抗训练中的每个训练样本定制扰动水平和相应的标签。通过大量实验证明，该算法比以往的对抗性训练方法具有更好的干净性和鲁棒性。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06789">PDF</a>
<h3>No. 33	剩余持续学习</h3><h4>Janghyeon Lee, Donggyu Joo, Hyeong Gwon Hong, Junmo Kim</h4>文摘：提出了一种新的连续学习方法：剩余连续学习（ResCL）。该方法可以避免多任务序列学习中的灾难性遗忘现象，除了原始网络外，不需要任何源任务信息。ResCL通过线性组合原始网络和微调网络的每一层来重新参数化网络参数；因此，网络的大小根本没有增加。为了将该方法应用于一般的卷积神经网络，还考虑了批量归一化层的影响。通过利用剩余学习（如重新参数化）和特殊的权重衰减，有效地控制了源性能和目标性能之间的权衡。所提出的方法在不同的持续学习情境中表现出最先进的性能。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06774">PDF</a>
<h3>No. 34	可微盗贼探测</h3><h4>Craig Boutilier, Chih-Wei Hsu, Branislav Kveton, Martin Mladenov, Csaba Szepesvari, Manzil Zaheer</h4>翻译后摘要：我们学习ButdID政策，最大限度地获得平均回报的匪徒实例从一个未知的分布$ \ MathCAL{P}$，从一个样本$ \ MathCAL{P}$。我们的方法是元学习的一个实例，它的吸引力在于可以不受限制地利用$\mathcal{P}$的属性。我们以可微的方式参数化我们的策略，并通过策略梯度来优化它们——这是一种易于实现且令人愉快的通用方法。接下来的挑战是设计有效的梯度估计和良好的策略类。为了使政策梯度实用化，我们引入了新的方差减少技术。我们实验了各种强盗策略类，包括神经网络和一种新的软消除策略。后者有遗憾的保证，是我们优化的自然起点。我们的实验突出了我们方法的多功能性。我们还观察到，神经网络策略可以学习隐式偏见，这些偏见只在训练期间通过样本bandit实例来表达。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06772">PDF</a>
<h3>No. 35	无悔学习中的最后迭代收敛：凸凹景观的约束最小最大优化</h3><h4>Qi Lei, Sai Ganesh Nagarajan, Ioannis Panageas, Xiao Wang</h4>文摘：在最近的一系列文献中，我们已经证明了在凸凹零和对策中梯度下降/上升和镜像下降的变量具有最后迭代收敛性。具体来说，{DISZ17，LiangS18}显示了所谓的“乐观梯度下降/上升”的最后一次迭代收敛，适用于{textit{unconstrained}min-max优化。此外，在{Metal}一文中，作者指出，对于凸凹问题（约束和非约束问题），具有额外梯度步长的镜像下降显示出最后一次迭代收敛，尽管他们的算法不遵循在线学习框架；它使用额外的信息而不是历史来计算下一次迭代。在这项工作中，我们证明了遵循无遗憾在线学习框架的“乐观乘性权值更新（OMWU）”在局部凸凹博弈中表现出最后一次迭代收敛，推广了{DP19}的结果，其中OMWU的最后一次迭代收敛仅在{textit{bilinar case}中表现出来。实验结果表明，该方法收敛速度快。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06768">PDF</a>
<h3>No. 36	基于w-LPPD-SVM集成的嵌入式稀疏自编码器</h3><h4>Yongming Li, Yan Lei, Pin Wang, Yuchuan Liu</h4>文摘：深度学习是一种具有强非线性特征变换的特征学习方法，在人工智能的许多领域中越来越重要。深度自动编码器是深度学习方法的代表方法之一，能够有效地提取数据集的抽象信息。但是，在深度特征变换过程中没有考虑深度特征与原始特征之间的互补性。此外，它还存在小样本问题。为了解决这些问题，本文提出了一种新的深度自动编码器-混合特征嵌入式叠置稀疏自动编码器（HESSAE）。在训练过程中，HFESAE能够通过嵌入原始特征来过滤弱隐层输出，从而学习鉴别深层特征。针对小样本问题限制了抽象信息的类表示能力的问题，设计了一种将HFESAE学习到的抽象信息与原始特征相结合，获得混合特征进行特征约简的特征融合策略。该策略是基于L1正则化的混合特征选择策略，其次是支持向量机（SVM）集成模型，在每个基分类器上设计并使用加权局部判别保持投影（w_-LPPD）。最后，利用几个具有代表性的公共数据集验证了算法的有效性。实验结果表明，所提出的特征学习方法与现有和最先进的特征学习算法（包括一些有代表性的深度自编码方法）相比，具有更好的性能。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06761">PDF</a>
<h3>No. 37	知识图完成的实体上下文和关系路径</h3><h4>Hongwei Wang, Hongyu Ren, Jure Leskovec</h4>摘要：知识图补全是为了预测知识图中实体间的缺失关系。虽然提出了许多不同的方法，但缺乏一个统一的框架，这将导致最先进的结果。在这里，我们开发PathCon，知识图完成方法，利用四个新的见解优于现有的方法。PathCon通过以下方法预测一对实体之间的关系：（1）通过捕获与实体相邻的关系类型并通过一种新的基于边缘的消息传递方案建模来考虑每个实体的关系上下文；（2）考虑捕获两个实体之间所有路径的关系路径；（3）自适应地集成通过可学习注意机制的关系语境和关系路径。重要的是，（4）与传统的基于节点的表示不同，PathCon只使用关系类型表示上下文和路径，这使得它适用于归纳设置。在知识图基准测试和我们新提出的数据集上的实验结果表明，PathCon在很大程度上优于最新的知识图完成方法。最后，PathCon能够通过识别为给定的预测关系提供重要上下文和路径的关系来提供可解释的解释。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06757">PDF</a>
<h3>No. 38	统一图卷积神经网络与标记传播</h3><h4>Hongwei Wang, Jure Leskovec</h4>摘要：标签传播（LPA）和图卷积神经网络（GCN）都是图上的消息传递算法。两者都解决了节点分类的任务，但LPA将节点标签信息传播到图的边缘，而GCN则传播和转换节点特征信息。然而，虽然在概念上相似，但LPA和GCN之间的理论关系尚未得到研究。这里我们从两个方面研究LPA和GCN之间的关系：（1）特征/标签平滑，我们分析一个节点的特征/标签是如何分布到其邻居的；（2）特征/标签对一个节点的初始特征/标签对另一个节点的最终特征/标签的影响程度。在理论分析的基础上，提出了一种将GCN和LPA相结合的端到端节点分类模型。在我们的统一模型中，边缘权值是可学习的，LPA作为正则化来帮助GCN学习适当的边缘权值，从而提高分类性能。我们的模型也可以被看作是学习基于节点标签的注意力权重，它比现有的基于特征的注意力模型更面向任务。在实际图形上的大量实验中，我们的模型在节点分类精度方面显示出优于最新的基于GCN的方法。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06755">PDF</a>
<h3>No. 39	解构元学习：理解少量射击任务的特征表示</h3><h4>Micah Goldblum, Steven Reich, Liam Fowl, Renkun Ni, Valeriia Cherepanova, Tom Goldstein</h4>摘要：元学习算法产生的特征抽取器在少量镜头分类上达到了最新的性能。虽然文献中有大量的元学习方法，但是对于为什么得到的特征抽取器表现得如此出色却知之甚少。我们对元学习的基本机制以及元学习模型和经典模型的区别有了更好的理解。在这样做的过程中，我们为元学习模型为什么表现得更好提出了几个假设。除了可视化之外，我们还设计了一些受我们的假设启发的正则化器，这些正则化器可以提高很少镜头分类的性能。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06753">PDF</a>
<h3>No. 40	因果约束下个体公平分类器的学习</h3><h4>Yoichi Chikahara, Shinsaku Sakaue, Akinori Fujino</h4>摘要：机器学习越来越多地应用于为个人做出决策的各种应用中。对于这样的应用，我们需要在实现良好的预测准确性和对敏感特征（例如种族或性别）做出公平决策之间取得平衡，这在复杂的现实场景中是很难做到的。现有的方法测量不公平性在这样的场景{它不公平的因果效应}，并将其均值约束为零。不幸的是，使用这些方法，决定不一定对所有个人都公平，因为即使平均不公平影响为零，不公平影响也可能对某些个人有利，对其他人不利，这对他们是歧视性的。为了学习一个对所有个体都公平的分类器，我们将不公平定义为个体不公平的it概率（PIU），并提出了一个约束PIU上界的优化问题。我们从理论上解释了为什么我们的方法能够实现个人公平。实验结果表明，该方法在保证预测精度的前提下，学习了一个独立的公平分类器。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06746">PDF</a>
<h3>No. 41	跨流形聚类的多平面投影</h3><h4>Lan Bai, Yuan-Hai Shao, Wei-Jie Chen, Zhen Wang, Nai-Yang Deng</h4>摘要：交叉流形聚类是一个很难解决的问题，传统的聚类方法由于存在交叉流形结构而失败。针对交叉流形聚类问题，提出了一种多平面投影聚类算法。在我们的MFPC中，将给定的样本投影到多个子空间以发现隐式流形的全局结构。因此，交叉流形簇区别于各种投影。进一步，我们的MFPC通过核技巧扩展到非线性流形聚类，以处理更复杂的交叉流形聚类。采用递归算法求解了MFPC中的一系列非凸矩阵优化问题。综合测试表明，我们的MFPC在交叉流形结构上工作良好。此外，在基准数据集上的实验结果表明，与一些最新的聚类方法相比，我们的MFPC具有优异的性能。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06739">PDF</a>
<h3>No. 42	基于多智能体强化学习的驾驶员重新定位奖励设计</h3><h4>Zhenyu Shou, Xuan Di</h4>摘要：据报道，大部分乘客的请求都是无效的，部分原因是空乘司机在乘客寻找过程中的巡航行为。本文旨在利用平均场多智能体强化学习（MARL）方法对多驾驶员重新定位任务进行建模。注意到在给定的报酬机制下，直接将MARL应用于多驱动系统很可能会由于驱动者的自私性而产生次优均衡，因此本研究提出了一个报酬设计方案，用以达到更期望的均衡。为了有效地解决以上层为奖赏设计，下层为多智能体系统（MAS）的双层优化问题，采用贝叶斯优化算法加快学习速度。然后，我们使用一个合成数据集来测试所提出的模型。结果表明，与无奖励设计相比，使用简单的平台服务收费，订单响应率和总服务收费的加权平均值可提高4%。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06723">PDF</a>
<h3>No. 43	在没有训练或测试数据的情况下预测最先进的神经网络的质量趋势</h3><h4>Charles H. Martin, Tongsu (Serena)Peng, Michael W. Mahoney</h4>文摘：在许多应用中，人们使用由他人训练的深度神经网络（DNN）模型。对于这种预先训练的模型，通常无法获得训练/测试数据。此外，人们对模型的许多细节并不了解，例如训练数据的细节、损失函数、超参数值等。给定一个或多个预先训练的模型，人们能对模型的预期性能或质量说些什么吗？在这里，我们提出并评估了预训练DNN模型的经验质量度量。使用开源的WeightWatcher工具，我们分析了数百个公开可用的预训练模型，包括CV和NLP中的旧模型和当前的最新模型。从最近发展起来的重尾自正则化理论出发，我们研究了基于范数的容量控制度量以及新的基于幂律（PL）的度量（包括拟合PL指数和加权α度量）。基于规范的度量与几乎所有CV体系结构系列中训练有素模型的测试精度报告有很好的相关性。另一方面，基于规范的度量不能区分“好的和坏的”模型——这可以说是需要质量度量的关键。事实上，他们可能会给出虚假的结果。基于损益的指标做得更好——在数量上更好地区分一系列“好的更好的最好”模型，在质量上更好地区分“好的和坏的”模型。基于PL的度量也可以用来描述模型的精细尺度特性，我们引入了分层相关流作为新的质量评估。我们展示了训练不好（和/或微调不好）的模型可能同时表现出尺度塌陷和异常大的PL指数，特别是对于最近的NLP模型。我们的技术可用于识别预先训练的DNN何时存在仅通过检查训练/测试精度无法检测到的问题。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06716">PDF</a>
<h3>No. 44	批集成：一种有效集成和终身学习的替代方法</h3><h4>Yeming Wen, Dustin Tran, Jimmy Ba</h4>文摘：多个神经网络单独训练并对其预测进行平均的集合在提高单个神经网络的精度和预测不确定性方面取得了广泛的成功。然而，一个集成的训练和测试成本都随着网络数量的增加而线性增加，这很快就变得难以维持。在本文中，我们提出了BatchEnsemble，这是一种计算和存储成本显著低于典型集成的集成方法。BatchEnsemble通过将每个权重矩阵定义为所有集成成员共享权重和每个成员一个秩一矩阵的Hadamard乘积来实现这一点。与集成不同，batch ensemble不仅可以跨设备并行化，其中一个设备训练一个成员，而且可以在一个设备内并行化，其中多个集成成员在给定的小批量中同时更新。通过CIFAR-10、CIFAR-100、WMT14 EN-DE/EN-FR转换和分发外任务，BatchEnsemble作为典型的集成产生了竞争性的准确性和不确定性；在测试时的加速是3倍，在大小为4的集成中的内存减少是3倍。我们还将BatchEnsemble应用于终身学习，在Split-CIFAR-100上，BatchEnsemble可以获得与渐进式神经网络相当的性能，同时具有更低的计算和内存成本。我们进一步证明，在包含100个顺序学习任务的分割图像网络上，BatchEnsemble可以很容易地扩展到终身学习。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06715">PDF</a>
<h3>No. 45	无模型深层强化学习中简单对象表示的研究</h3><h4>Guy Davidson, Brenden M. Lake</h4>文摘：我们探讨了使用简单的对象表示来增强最新的无模型深度增强算法的好处。根据Lake等人提出的冻伤挑战。（2017），我们将对象表征确定为当前强化学习代理缺乏的关键认知能力。我们发现，为彩虹模型（Hessel等人，2018年）提供简单、功能工程化的对象表示大大提高了它在Atari 2600的冻伤游戏中的性能。然后，我们分析不同类型对象的表示的相对贡献，确定这些表示最具影响力的环境状态，并检查这些表示如何有助于将其归纳为新的情况。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06703">PDF</a>
<h3>No. 46	行为预测</h3><h4>Juan C. Perdomo, Tijana Zrnic, Celestine Mendler-Dünner, Moritz Hardt</h4>摘要：当预测支持决策时，他们可能会影响他们想要预测的结果。我们把这种预测称为行为预测；预测影响目标。绩效是决策中一个被广泛研究的现象，但在监督学习中却一直被忽视。当忽略时，表现力表现为不希望的分布变化，通常通过再训练来解决。我们将统计学、博弈论和因果关系的概念结合起来，开发了一个绩效预测的风险最小化框架。概念新颖性是一种平衡概念，我们称之为行为稳定性。行为稳定性意味着预测不是针对过去的结果进行校准，而是针对未来的结果进行校准，这些结果是通过对预测的作用而显现出来的。我们的主要结果是再训练收敛到几乎最小损失的性能稳定点的充分必要条件。总体而言，绩效预测严格地包含了战略分类。因此，我们也给出了第一个充分的条件，使再培训能够克服战略反馈效应。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06673">PDF</a>
<h3>No. 47	过度参数化对抗训练：克服维度诅咒的分析</h3><h4>Yi Zhang, Orestis Plevrakis, Simon S. Du, Xingguo Li, Zhao Song, Sanjeev Arora</h4>摘要：对抗性训练是一种常用的神经网络抗对抗性扰动的方法。在实践中，对抗性训练导致低强度训练损失。然而，对于为什么在自然条件下会发生这种情况，仍然缺少一个严格的解释。最近，针对{em超参数化}网络，不同的研究小组提出了一种标准（非对抗性）监督训练的收敛理论。目前尚不清楚如何将这些结果推广到对抗性训练中，因为这是最小-最大目标。最近，Gao等人朝着这个方向迈出了第一步。使用来自在线学习的工具，但它们要求网络的宽度在输入维度$d$中为{指数}，并且具有非自然的激活函数。我们的工作证明了在自然假设和ReLU激活下，对于多项式宽度而不是指数宽度，收敛到低鲁棒训练损失。我们的证明的关键元素表明，Relu网络接近初始化可以近似的阶跃函数，这可能是独立的利益。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06668">PDF</a>
<h3>No. 48	TempLe：样本有效多任务RL转换学习模板</h3><h4>Yanchao Sun, Xiangyu Yin, Furong Huang</h4>摘要：知识在不同环境中的传递对于有效地在线学习多个任务具有重要意义。大多数现有的方法直接使用先前学习的模型或先前学习的最优策略来学习新任务。然而，当底层模型或最优策略在不同任务之间存在显著差异时，这些方法可能效率低下。本文提出了模板学习（Template Learning，简称TempLe）方法，这是第一种用于多任务强化学习的PAC-MDP方法，适用于状态/动作空间变化的任务。TempLe生成转换动力学模板，即跨任务的转换动力学的抽象，以便通过提取任务之间的相似性来获得样本效率，即使它们的底层模型或最优策略具有有限的共性。我们提出了两个算法分别为“在线”和“有限模型”设置。我们证明了我们所提出的PANK算法比单任务学习者或最先进的多任务方法实现的样本复杂度要低得多。我们通过系统设计的实验表明，我们的TempLe方法在不同的环境和条件下都比目前最先进的多任务方法（PAC-MDP或not）有更好的性能。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06659">PDF</a>
<h3>No. 49	变压器的稳健性验证</h3><h4>Zhouxing Shi, Huan Zhang, Kai-Wei Chang, Minlie Huang, Cho-Jui Hsieh</h4>文摘：以形式化验证神经网络预测行为为目的的鲁棒性验证已成为理解模型行为、获取安全保证的重要工具。然而，以往的方法通常只能处理结构相对简单的神经网络。本文研究变压器的鲁棒性验证问题。变压器具有复杂的自关注层，这对验证提出了许多挑战，包括交叉非线性和交叉位置相关性，这在以前的工作中还没有讨论过。我们解决了这些挑战，并开发了第一个变压器稳健性验证算法。该方法计算出的鲁棒性界比单纯区间界传播法计算出的鲁棒性界要严格得多。这些界限也有助于解释变形金刚，因为它们一贯反映了不同的词在情感分析中的重要性。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06622">PDF</a>
<h3>No. 50	基于GANs的汽车软件在环测试控制时序生成</h3><h4>Dhasarathy Parthasarathy, Karl Bäckström, Jens Henriksson, Sólrún Einarsdóttir</h4>文摘：汽车机电系统的测试部分采用软件在环方法，系统地覆盖被测系统的输入仍然是一个主要的挑战。在目前的实践中，有两种主要的输入刺激技术。一种方法是设计输入序列，这样可以简化测试过程的控制和反馈，但不能使系统暴露在真实的场景中。另一种方法是重放从野外作业中记录的序列，这种方法考虑到了实际情况，但需要收集一个标记良好的数据集，具有足够的容量，以供广泛使用，成本高昂。本文应用生成性对抗网络（GAN）的无监督学习框架，学习一个未标记的车内信号数据集，并将其用于合成输入刺激的生成。此外，还演示了一种基于度量的线性插值算法，该算法保证生成的刺激与指定的引用遵循可定制的相似关系。这两种技术的结合使得能够有控制地生成大量有意义和现实的输入模式，提高虚拟测试覆盖率，减少对昂贵的现场测试的需求。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06611">PDF</a>
<h3>No. 51	REST：基于RL空间变换的黑箱模型性能改进</h3><h4>Jae Myung Kim, Hyungjin Kim, Chanwoo Park, Jungwoo Lee</h4>文摘：近年来，深神经网络（DNN）已成为一个高度活跃的研究领域，并在各种计算机视觉任务上取得了显著的成绩。然而，已知dnn经常对分布外样本做出过度自信但不正确的预测，这可能是实际部署的一个主要障碍，因为与各种实际样本相比，训练数据集总是有限的。因此，在实际构造DNN模型时，必须保证对训练时间和测试时间之间的分布变化具有鲁棒性。此外，在许多情况下，深度学习模型被部署为黑箱，并且已经针对训练数据集优化了性能，因此改变黑箱本身可能导致性能下降。本文研究了在给定黑盒图像分类器的特定条件下对几何变换的鲁棒性。我们提出一个额外的学习者，将扭曲的输入数据转换成黑箱模型认为是分布的样本。我们的工作旨在通过在任何黑盒前面添加一个REST模块，并且只训练REST模块，而不以端到端的方式重新训练原始黑盒模型，即我们尝试将真实世界的数据转换为最适合黑盒模型性能的训练分布，从而提高鲁棒性。我们使用从黑箱模型中获得的置信分数来确定转换后的输入是否来自于in分布。实验表明，该方法在推广几何变换和样本效率方面具有优势。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06610">PDF</a>
<h3>No. 52	推荐系统的广义嵌入机</h3><h4>Enneng Yang, Xin Xin, Li Shen, Guibing Guo</h4>摘要：因子分解机（FM）是一种有效的基于特征的推荐模型，它利用内积来捕获二阶特征交互。然而，调频的一个主要缺点是不能捕获复杂的高阶交互信号。一个常见的解决方案是改变交互作用函数，例如在FM的顶部叠加深度神经网络。在这项工作中，我们提出了另一种在嵌入层模拟高阶交互信号的方法，即广义嵌入机（GEM）。GEM中的嵌入不仅对特征本身的信息进行编码，还对其他相关特征的信息进行编码。在这种情况下，嵌入成为高阶的。然后，我们可以将GEM与FM甚至其高级变体结合起来执行功能交互。更具体地说，本文利用图卷积网络（GCN）生成高阶嵌入。我们将GEM与几个基于FM的模型集成，并在两个真实数据集上进行了广泛的实验。结果表明，GEM的性能明显优于相应的基线。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06561">PDF</a>
<h3>No. 53	公平主成分分析与滤波器设计</h3><h4>Gad Zalcberg, Ami Wiesel</h4>文摘：考虑公平主成分分析（FPCA）问题，寻找一个公平地跨越多个目标向量的低维子空间。FPCA被定义为给定集合内最差投影目标范数的非凹最大化。该问题出现在信号处理中的滤波器设计，以及在将公平性纳入降维方案时。FPCA的最新方法是通过半定松弛，并涉及多项式但计算代价昂贵的优化。为了允许可伸缩性，我们建议使用朴素的次梯度下降来处理FPCA。在目标正交的情况下，我们分析了底层优化的景观。我们证明了景观是良性的，并且所有的局部极小值都是全局最优的。有趣的是，在这个简单的例子中，SDR方法会导致次优解。最后，讨论了正交FPCA与规范化紧框架设计的等价性。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06557">PDF</a>
<h3>No. 54	在嘈杂的标签面前学会不学习</h3><h4>Liu Ziyin, Blair Chen, Ru Wang, Paul Pu Liang, Ruslan Salakhutdinov, Louis-Philippe Morency, Masahito Ueda</h4>摘要：在存在标签噪声的情况下进行学习是一项具有挑战性的重要任务：设计在存在错误标签数据集的情况下具有鲁棒性的模型至关重要。在本文中，我们发现一类新的损失函数称为赌徒损失函数，它对各种腐败程度的标签噪声具有很强的鲁棒性。研究表明，利用这种损失函数进行训练，可以使模型避免对带有噪声标签的数据点进行学习，从而得到一种简单有效的方法，提高了模型的鲁棒性和泛化能力。此外，我们提出了两个实际扩展的方法：1）一个分析的早期停止标准，在噪声标签的记忆之前近似停止训练，以及2）用于设置不需要知道噪声损坏率的超参数的启发式算法。我们证明了我们的方法的有效性，通过与现有基线相比，在三个图像和文本分类任务中获得强的结果。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06541">PDF</a>
<h3>No. 55	双星：通过耦合双星激活减少双星激活网络中的梯度失配</h3><h4>Hyungjun Kim, Kyungsu Kim, Jinseok Kim, Jae-Joon Kim</h4>摘要：二进制神经网络（BNN）由于其计算成本的降低和内存的节省而受到人们的关注。然而，bnn的性能下降主要是由于二值化激活引起的梯度失配。以前的工作试图解决梯度失配问题，通过减少在前向激活函数和其在向后传递中使用的可微近似之间的差异，这是一种间接测量。在这项工作中，我们使用平滑损失函数的梯度来更好地估计量化神经网络中的梯度失配。使用梯度失配估计器的分析表明，使用更高的激活精度比修改激活函数的可微近似更有效。在此基础上，我们提出了一种新的二元激活网络训练方案，称为二元激活网络，在训练过程中，两个二元激活耦合成一个三元激活网络。实验结果表明，在相同的参数和计算代价下，binarydou在各种基准上都优于最新的BNNs。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06517">PDF</a>
<h3>No. 56	噪声相似标记数据的多类分类</h3><h4>Songhua Wu, Xiaobo Xia, Tongliang Liu, Bo Han, Mingming Gong, Nannan Wang, Haifeng Liu, Gang Niu</h4>摘要：相似性标签表示两个实例是否属于同一个类，而类标签表示实例的类。在没有类标签的情况下，通过元分类学习，可以从相似性标记的成对数据中学习多类分类器。然而，由于相似性标签的信息量比类标签少，因此它更容易产生噪声。深层神经网络可以很容易地记住有噪声的数据，导致分类的过度拟合。本文提出了一种仅从带噪声的相似标记数据中学习的方法。具体来说，为了对噪声进行建模，我们使用噪声转移矩阵来桥接干净数据和噪声数据之间的类后验概率。我们进一步从噪声数据中估计出转换矩阵，并建立了一个新的学习系统来学习一个分类器，该分类器可以为实例分配无噪声类标签。此外，我们从理论上证明了我们所提出的方法对于学习分类器是如何推广的。实验结果表明，该方法在基准模拟和真实噪声标签数据集上优于目前最先进的方法。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06508">PDF</a>
<h3>No. 57	约束深度强化学习策略空间的一阶优化</h3><h4>Yiming Zhang, Quan Vuong, Keith W. Ross</h4>摘要：在强化学习中，主体试图通过与环境的交互来学习高绩效的行为，这种行为通常以奖励函数的形式被量化。然而，行为的某些方面，例如那些被认为不安全且应避免的方面，最好通过约束来捕捉。我们提出了一种新的方法，称为策略空间中的一阶约束优化（Foops），它最大化代理的整体报酬，同时确保代理满足一组成本约束。FOCOPS首先利用当前策略生成的数据，通过求解非参数策略空间中的约束优化问题，找到最优更新策略。FOCOPS然后将更新策略投影回参数策略空间。我们的方法为整个培训过程中的约束满足提供了保证，并且是一级的，因此实现起来非常简单。我们提供的经验证据表明，与现有的方法相比，我们的算法在一组受限机器人机车任务上取得了更好的性能。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06506">PDF</a>
<h3>No. 58	神经网络逼近能力的进一步研究</h3><h4>Kai Fong Ernest Chong</h4>翻译后摘要：通用逼近定理，在其最一般的版本之一，说，如果我们只考虑连续激活函数$ \ sigma $，那么一个标准的前向神经网络与一个隐藏层能够近似任何连续的多元函数$f$到任何给定的近似阈值$\VaRePiSLon $，如果且仅如果$\sigma$是非多项式。本文给出了该定理的直接代数证明。此外，我们将明确量化近似所需的隐藏单位的数量。具体来说，如果$X\substeq\mathbb{R}^n$是紧凑的，那么一个包含$n$input units、$m$output units的神经网络，以及一个包含$\binom{n+d}{d}$hidden units的单隐层（独立于$m$和$\varepsilon$），可以一致地逼近任何多项式函数f:x\到\ Mththb{{r} m $，其总度数最多为$$$，用于其$M $坐标函数中的每一个。在$F$是任何连续函数的一般情况下，我们表明存在$N\\\MathCAL{O}（\VaRePiSLION ^ {N}）$（独立于$M $），使得$N$隐藏单元就足够接近$F$。我们还表明，这种均匀逼近性质（UAP）仍然保持在看似强加的条件下的权重。我们强调了几个结果：（i）对于任何$\delta>0$，如果我们将最后一层中的所有非偏移权重$w$限制为满足$| w |<\delta$，则UAP仍然有效。（ii）存在一些$lambda＞0美元（仅取决于$F$和$\σ$），使得如果我们在第一层中限制所有非偏置权重$W$以满足$W*>λ$，则UAP仍然持有。（iii）如果第一层中的非偏倚权重是{fixed}，并且是从适当的范围中随机选择的，则UAP的概率为$1$。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06505">PDF</a>
<h3>No. 59	具有最优传输的可微Top-k算子</h3><h4>Yujia Xie, Hanjun Dai, Minshuo Chen, Bo Dai, Tuo Zhao, Hongyuan Zha, Wei Wei, Tomas Pfister</h4>摘要：top-k操作是一种重要的模型构件，广泛应用于信息检索、机器学习和数据挖掘等领域。但是，如果top-k操作是以算法的方式实现的，例如使用bubble算法，则生成的模型不能使用流行的梯度下降算法进行端到端的训练。这是因为这些实现通常涉及交换索引，其梯度无法计算。此外，从输入分数到该元素是否属于top-k集的指标向量的对应映射本质上是不连续的。为了解决这个问题，我们提出了平滑近似，即软（可伸缩的基于最优传输的可微的）top-k算子。具体地，我们的软top-k算子逼近top-k操作的输出作为熵最优运输（EOT）问题的解。然后，基于EOT问题的最优性条件，可以有效地逼近软算子的梯度。将该算子应用于k近邻和波束搜索算法中，取得了较好的性能。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06504">PDF</a>
<h3>No. 60	带噪声标签的鲁棒学习自适应损失</h3><h4>Jun Shu, Qian Zhao, Keyu Chen, Zongben Xu, Deyu Meng</h4>摘要：鲁棒损失最小化是处理含噪标签鲁棒学习问题的重要策略。然而，目前的鲁棒损失函数不可避免地涉及到要通过交叉验证手动或启发式地调整的超参数，这使得它们很难在实际中得到普遍应用。此外，由于丢失带来的非凸性以及复杂的网络结构，使得它容易陷入陷入泛化能力较差的意外解决方案中。针对上述问题，我们提出了一种在鲁棒损失函数中自适应学习超参数的元学习方法。具体地说，该方法通过鲁棒损失超参数和网络参数的相互改进，可以同时对两者进行精细学习和协调，得到具有良好泛化能力的解。本文尝试将四种SOTA鲁棒损失函数集成到算法中，综合实验证明，与传统的超参数整定方法相比，该方法在精度和泛化性能上都具有普遍的有效性，即使是精心调整的超参数。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06482">PDF</a>
<h3>No. 61	相关对抗性模仿学习</h3><h4>Ari Azarafrooz</h4>文摘：将博弈论中的相关均衡思想应用到生成性对抗性模仿学习中，提出了一种新的模仿学习算法。该模拟学习算法与传统的单分类器单agent学习算法相比，具有多个分类器和多个agent的队列。相关均衡的实现是由于一种中介神经结构，它增加了鉴别器和代理队列所看到的观察结果。在训练的每一步中，中介网络都使用鉴别器和代理的奖励来计算反馈，从而相应地增加下一步的观察。通过游戏中的交互作用，将训练动态引导到更合适的区域。由此产生的模仿学习提供了三个重要的好处。首先，它使学习模型对新环境的适应性和可移植性变得简单明了。其次，它适合于模拟一个混合状态的动作轨迹。第三，避免了生成对抗型结构中鉴别器所面临的非凸优化问题。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06476">PDF</a>
<h3>No. 62	模拟学习和目标条件强化学习的普适值密度估计</h3><h4>Yannick Schroecker, Charles Isbell</h4>摘要：本研究考虑两种不同的情境：模仿学习和目标条件强化学习。在这两种情况下，有效的解决方案都要求代理可靠地达到指定的状态（目标）或状态集（演示）。本文将概率长期动力学与期望值函数联系起来，介绍了一种利用密度估计的最新进展来有效学习达到给定状态的方法。作为我们的第一个贡献，我们将此方法用于目标条件强化学习，并证明其在随机域中既有效又不受后见偏差的影响。作为我们的第二个贡献，我们将该方法扩展到模仿学习，并证明它在标准基准任务上实现了最先进的示范样本效率。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06473">PDF</a>
<h3>No. 63	支持向量机的核心集</h3><h4>Murad Tukan, Cenk Baykal, Dan Feldman, Daniela Rus</h4>文摘：针对大数据流应用中大规模支持向量机（SVM）训练问题，提出了一种有效的核心集构造算法。核心集是原始数据点的一个小的、有代表性的子集，因此在核心集上训练的模型与在原始数据集上训练的模型具有可证明的竞争性。由于核集的大小通常比原始核集小得多，因此我们的预处理-然后训练方案在训练支持向量机模型时有可能导致显著的加速。我们证明了支持向量机问题获得小数据摘要所需的核心集大小的上下界。作为推论，我们证明我们的算法可用于扩展任何现成的支持向量机解算器对流式、分布式和动态数据设置的适用性。我们评估了我们的算法在真实世界和合成数据集上的性能。实验结果验证了该算法良好的理论性能，证明了该算法在加速支持向量机训练方面的实用性。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06469">PDF</a>
<h3>No. 64	匹配平均的联合学习</h3><h4>Hongyi Wang, Mikhail Yurochkin, Yuekai Sun, Dimitris Papailiopoulos, Yasaman Khazaeni</h4>摘要：联邦学习允许边缘设备协作学习共享模型，同时将训练数据保存在设备上，将模型训练能力与将数据存储在云中的需求分离。针对卷积神经网络（CNNs）和LSTMs等现代神经网络结构的联合学习问题，提出了联邦匹配平均（FedMA）算法。FedMA通过匹配和平均具有相似特征提取特征的隐藏元素（即卷积层的通道；LSTM的隐藏状态；完全连接层的神经元）以层方式构建共享全局模型。我们的实验表明，FedMA不仅在基于真实世界数据集的深层CNN和LSTM体系结构上优于流行的最新联邦学习算法，而且还降低了总体通信负担。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06440">PDF</a>
<h3>No. 65	MRRC：基于R-CNN特征分布合成（FDC）的图像字幕多角色表示交叉解释</h3><h4>Chiranjib Sur</h4>摘要：通过机器进行图像字幕需要结构化的学习和解释的基础，而改进则需要以有意义的方式对多种上下文进行理解和处理。这项研究将为上下文组合提供一个新的概念，并将影响许多处理视觉特征的应用，将其作为对象、活动和事件描述的等价物。该体系结构由三部分组成：特征分布合成（FDC）层注意、多角色表示交叉（MRRC）注意层和语言解码器。FDC层注意有助于从RCNN特征中生成加权注意，MRRC注意层作为中间表示处理，有助于生成下一个单词注意，而语言解码器有助于估计句子中下一个可能单词的可能性。我们证明了FDC、MRRC、区域目标特征注意和强化学习对有效学习产生更好的图像字幕的有效性。模型的性能提高了35.3%，为基于逻辑、更好的可解释性和上下文的表示生成创造了新的标准和理论。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06436">PDF</a>
<h3>No. 66	量子强盗</h3><h4>Balthazar Casalé, Giuseppe Di Molfetta, Hachem Kadri, Liva Ralaivola</h4>摘要：我们考虑量子版的bandit问题，称为{em-best arm identification}（BAI）。我们首先提出了BAI问题的量子模型，假设学习主体和环境都是量子的，然后提出了一种基于量子振幅放大的算法来求解BAI问题。我们形式化地分析了算法在所有问题实例上的行为，特别地，我们证明了它能够比在经典情况下已知的更快地获得最优解。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06395">PDF</a>
<h3>No. 67	多任务多准则超参数优化</h3><h4>Kirill Akhmetzyanov, Alexander Yuzhakov</h4>文摘：提出了一种在多个任务和多个准则中寻找最优超参数的新方法。多任务多准则方法（MTMC）提供了多个Pareto最优解，其中一个解具有给定的准则显著性系数。本文首先给出了最优超参数选择问题的数学表达式。然后，介绍了MTMC方法解决这一问题的步骤。利用卷积神经网络对图像分类问题进行了评价。本文给出了各种准则显著性系数的最优超参数。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06372">PDF</a>
<h3>No. 68	分散数据的神经结构搜索</h3><h4>Mengwei Xu, Yuxin Zhao, Kaigui Bian, Gang Huang, Qiaozhu Mei, Xuanzhe Liu</h4>摘要：为了保护用户隐私，同时实现移动智能，人们提出了在分散数据上训练深层神经网络的技术。然而，对分散数据的训练使得神经结构的设计变得相当困难。在为异构移动平台设计和部署不同的神经体系结构时，这种困难进一步扩大。在这项工作中，我们提出了一个自动神经架构搜索到分散训练，作为一个新的DNN训练范例称为联邦神经架构搜索，即联邦NAS。为了解决客户端计算和通信资源有限的主要挑战，我们提出了一个高效联邦NAS的高度优化框架FedNAS。FedNAS充分利用了体系结构搜索过程中模型候选重新训练不足的关键机会，并结合了三个关键优化：部分客户端上的并行候选训练、性能较差的候选提前丢弃和动态轮数。FedNAS在大规模数据集和典型CNN体系结构上进行了测试，它达到了与最先进的NAS算法相当的模型精度，该算法使用集中数据训练模型，并且与联邦NAS的直接设计相比，它还将客户机成本降低了两个数量级。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06352">PDF</a>
<h3>No. 69	抱紧我！判别特征对深网络边界的影响</h3><h4>Guillermo Ortiz-Jimenez, Apostolos Modas, Seyed-Mohsen Moosavi-Dezfooli, Pascal Frossard</h4>摘要：对神经网络的可解释性及其性质的重要认识在于其决策边界的形成。在这项工作中，我们借用了对抗稳健性领域的工具，提出了一个新的框架，可以将数据集的特征与数据样本沿特定方向到决策边界的距离联系起来。我们证明了深度学习的归纳偏差倾向于产生沿数据集非判别方向不变的分类函数。更令人惊讶的是，我们进一步证明，对数据样本的小扰动进行训练足以完全改变决策边界。这实际上是所谓的对抗训练用来产生强大分类器的特点。我们的总体框架可以用来揭示特定数据集特征对深度模型宏观特性的影响，并更好地理解深度学习的成功和局限性。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06349">PDF</a>
<h3>No. 70	基于流形的图像分类器测试生成</h3><h4>Taejoon Byun, Abhishek Vijayakumar, Sanjai Rayadurgam, Darren Cofer</h4>文摘：在关键应用中，用于图像分类任务的神经网络必须用足够的真实数据进行测试，以确保其正确性。为了有效地测试一个图像分类神经网络，必须获得足够的真实测试数据，以激发人们的信心，即隐式需求和学习模型之间的差异会暴露出来。这就提出了两个挑战：第一，必须仔细选择足够的数据点子集，以激发信心；第二，必须有意义地将隐含的要求外推到超出显式训练集中的数据点。本文提出了一个新的框架来应对这些挑战。我们的方法是基于这样一个前提：在一个大的输入数据空间中的模式可以在一个较小的流形空间中有效地捕获，从这个流形空间中可以采样和生成相似但新颖的测试用例——输入和标签。利用条件变分自动编码器（CVAE）的一个变种来捕获具有生成函数的流形，并在该流形空间上应用搜索技术来有效地查找故障揭示输入。实验表明，即使对于训练有素的模型，这种方法也能有效地生成成千上万个真实的、揭示错误的测试用例。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06337">PDF</a>
<h3>No. 71	双曲正火流的潜变量模型</h3><h4>Avishek Joey Bose, Ariella Smofsky, Renjie Liao, Prakash Panangaden, William L. Hamilton</h4>文摘：近似后验分布的选择在随机变分推理（VI）中起着核心作用。一个有效的解决方案是使用正规化流{Eclipse空间上定义的{{} }来构造灵活的后验分布。然而，现有的归一化流的一个关键限制是它们被限制到欧几里得空间，并且不具备用于建模具有底层层次结构的数据的能力。为了解决这一基本限制，我们提出了规范化流到双曲空间的第一个推广。我们首先使用定义在切线束上的耦合变换将规范化流提升到双曲空间，称为切线耦合（$\mathcal{TC}$）。我们进一步介绍了包裹双曲面耦合（$\mathcal{W}\mathbb{H}C$），这是一种完全可逆且可学习的变换，它显式地利用了双曲空间的几何结构，允许在高效采样的同时表示后验。我们证明了我们的新规范化流对双曲VAEs和欧氏规范化流的有效性。我们的方法提高了密度估计的性能，并重建了真实世界的图形数据，显示出层次结构。最后，我们证明了我们的方法可以使用双曲型潜在变量在分层数据上对生成模型进行幂化。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06336">PDF</a>
<h3>No. 72	果冻豆世界：永无止境学习的试验台</h3><h4>Emmanouil Antonios Platanios, Abulhair Saparov, Tom Mitchell</h4>摘要：近年来，机器学习取得了越来越大的成功。然而，目前的机器学习系统是高度专业化的，针对特定的问题或领域进行训练，通常是在一个狭窄的数据集上。另一方面，人类的学习具有高度的普遍性和适应性。永无止境的学习是一种机器学习范式，旨在弥合这一鸿沟，目的是鼓励研究人员设计机器学习系统，使其能够在更复杂的环境中学习执行更广泛的相互关联的任务。到目前为止，还没有环境或试验台来帮助开发和评估永无止境的学习系统。为此，我们提出了果冻豆世界试验台。果冻豆世界允许在二维网格世界中进行实验，这些网格世界中充满了项目，代理可以在其中导航。这个测试平台提供了足够复杂的环境，在这些环境中，更一般的智能算法应该比当前最先进的强化学习方法执行得更好。它通过产生非平稳环境和促进多任务、多智能体、多模式和课程学习环境的实验来实现。我们希望这一新的免费软件将促进新的研究和兴趣，在开发和评估永无止境的学习系统和更广泛的通用智能系统。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06306">PDF</a>
<h3>No. 73	马尔可夫报酬过程中折现值的循环估计</h3><h4>Falcon Z. Dai, Matthew R. Walter</h4>文摘：在强化学习折扣设置中常用和研究的策略迭代算法的工作中心，策略评估步骤利用马尔可夫决策过程中遵循马尔可夫策略所诱导的马尔可夫奖赏过程的样本来估计状态值。我们提出一个简单而有效的估计器，称为{emph{loop估计器}，它利用Markov奖赏过程的再生结构，而不必显式地估计一个完整的模型。我们的方法的空间复杂度为O（1）$，当估计一个正正循环状态的值$$不同于TD（带O（S）$）或基于模型的方法（用O（S^ 2）$）。此外，再生结构使我们能够显示，而不依赖于生成模型方法，估计器在一个样本路径上具有$\广角{O}（\qRt{{TuuSs/t}）的实例依赖收敛速率，超过$$$在一个样本路径上，其中$\ Tuuis$是状态$s$的最大预期命中时间。在初步的数值实验中，环路估计器的性能优于TD（k）等无模型方法，并且与基于模型的估计器具有竞争性。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06299">PDF</a>
<h3>No. 74	至少让我了解一下你真正喜欢什么：在学习偏好时与吵闹的人类打交道</h3><h4>Sriram Gopalakrishnan, Utkarsh Soni</h4>摘要：学习人的偏好可以提高人与人的互动质量。可用于学习偏好的查询数量可能有限，特别是在与人交互时，因此必须进行主动学习。主动学习的一种方法是使用不确定性抽样来确定查询的信息性。本文提出了一种改进的不确定性抽样方法，利用期望输出值来加速偏好的学习。我们将我们的方法与不确定抽样基线进行比较，并进行消融研究以检验我们方法的每个组成部分的有效性。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06288">PDF</a>
<h3>No. 75	马尔可夫抽样下Adam型强化学习算法的非渐近收敛性</h3><h4>Huaqing Xiong, Tengyu Xu, Yingbin Liang, Wei Zhang</h4>文摘：尽管Adam在强化学习（RL）中有着广泛的应用，但Adam型RL算法的理论收敛性尚未建立。本文首次对包含AMSGrad更新（理论分析中Adam的标准替代）的策略梯度（PG）和时间差分（TD）学习两种基本RL算法（PG-AMSGrad和TD-AMSGrad）进行了收敛性分析。此外，我们的分析集中在两种算法的马尔可夫抽样上。我们表明，在一般非线性函数逼近下，具有常数步长的PG AMSGRAGE收敛到一个固定点的邻域，其速率为$\ MathCAL{O}（1／T）$（其中$ T$表示迭代次数），并且随着步长的减小，以$\ MathCAL{O}（\log 2 ^ /\SqRT {t}）的速率收敛到平稳点。此外，在线性函数逼近下，具有常数步长的TD-AMSGRAD收敛到以$\ MathCAL{O}（1／t）$的速率的全局最优的邻域，并且随着步长的减小，以$\ MathCAL{O}（\ log t/\qRt{t}）的速率收敛到全局最优值。我们的研究为分析马尔可夫抽样下的Adam型RL算法提供了新的技术。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06286">PDF</a>
<h3>No. 76	算法追索：从反事实解释到干预</h3><h4>Amir-Hossein Karimi, Bernhard Schölkopf, Isabel Valera</h4>摘要：随着机器学习越来越多地被用于辅助决策（如审前保释和贷款批准），解释系统是如何做出决定的，并提出实现有利决策的措施变得非常重要。反事实的解释——“为了达到理想的结果，世界将如何（不得不）变得不同”——旨在满足这些标准。现有的工作主要集中于设计算法，以获得广泛的设置的反事实解释。然而，“解释作为帮助数据主体行为而不仅仅是理解的手段”的主要目标之一却被忽视了。通俗地说，反事实的解释告诉一个人他们需要去哪里，而不是如何去那里。在这项工作中，我们依靠因果推理来警告不要使用反事实的解释作为一套建议的追索行动。相反，我们提出了一个范式的转变，从通过最近的反事实解释求助到通过最小的干预求助，将焦点从解释转移到建议。最后，我们为读者提供了一个广泛的讨论，即如何在结构干预之外实现实际的求助。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06278">PDF</a>
<h3>No. 77	两人零和对策的平均场分析</h3><h4>Carles Domingo-Enrich, Samy Jelassi, Arthur Mensch, Grant Rotskoff, Joan Bruna</h4>文摘：在两人零和连续博弈中寻找纳什均衡是机器学习中的一个核心问题，例如用于训练GANs模型和鲁棒模型。纯纳什平衡的存在需要强的条件，这在实践中通常不满足。混合纳什均衡存在更大的一般性，可以发现使用镜像下降。然而，这种方法并没有扩展到高维度。为了解决这一限制，我们将混合策略参数化为粒子的混合，粒子的位置和权重使用梯度下降-上升更新。我们将此动力学作为一个相互作用的梯度流，在具有Wasserstein-Fisher-Rao度量的测度空间上进行研究。我们建立全局收敛到近似平衡的相关Langevin梯度上升动态。我们证明了一个将粒子动力学与平均场动力学联系起来的大数定律。我们的方法在高维中识别混合平衡，并且对于训练混合甘氨酸是有效的。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06277">PDF</a>
<h3>No. 78	为什么深度残差网络比深度前馈网络更具普遍性？--神经切线核透视图</h3><h4>Kaixuan Huang, Yuqing Wang, Molei Tao, Tuo Zhao</h4>文摘：深度残差网络（ResNets）比深度前馈网络（FFNets）具有更好的泛化性能。然而，这种现象背后的理论在很大程度上仍是未知的。本文从“神经切核”的角度研究了深度学习中的这一基本问题。具体地说，我们首先证明在适当的条件下，当宽度趋于无穷大时，训练深度resnet可以看作是用某种核函数学习再生核函数。然后，我们比较了深度resnet和深度ffnet的核，发现当深度趋于无穷大时，由ffnet核所诱导的函数类是渐近不可学习的。与此相反，ResNets核所诱导的函数类并没有表现出这种简并性。我们的发现部分证明了深度重网在泛化能力上优于深度ffnet。数值结果支持我们的索赔。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06262">PDF</a>
<h3>No. 79	运动皮层刺激与肌肉反应的映射：一种深部神经网络建模方法</h3><h4>Md Navid Akbar, Mathew Yarossi, Marc Martinez-Gost, Marc A. Sommer, Moritz Dannhauer, Sumientra Rampersad, Dana Brooks, Eugene Tunik, Deniz Erdoğmuş</h4>文摘：深部神经网络（DNN）能够可靠地模拟相应脑刺激引起的肌肉反应，有可能为许多基础科学和应用案例增加协调运动控制的知识。这些案例包括了解由于中风造成的神经损伤而导致的异常运动模式，以及基于刺激的神经康复干预措施，如成对联合刺激。在这项工作中，我们探索了潜在的DNN模型，并推荐了最小平方误差的模型来优化M2M网络的性能，M2M网络是一个将运动皮层的经颅磁刺激映射到相应肌肉反应的网络，使用：有限元模拟，经验神经反应曲线，卷积自动编码器，一个单独的深度网络映射器，和多肌肉激活的记录。我们讨论了不同建模方法和架构背后的基本原理，并对比了它们的结果。此外，为了获得复杂性和性能分析之间的权衡的比较洞察力，我们探索不同的技术，包括扩展的两个经典的信息标准M2M网。最后，我们发现，当输入端使用神经反应曲线时，类似于将运动皮层刺激映射为与肌肉直接和协同连接的组合的模型表现最佳。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06250">PDF</a>
<h3>No. 80	积极主动的重症监护室转移的稳健政策</h3><h4>Julien Grand-Clement, Carri W. Chan, Vineet Goyal, Gabriel Escobar</h4>摘要：非计划转入重症监护病房（ICU）的病人，其死亡率比直接转入ICU的病人高。机器学习预测病人病情恶化的最新进展已经引入了将病人从病房转移到ICU的可能性。在这项工作中，我们研究了在优化以改善整体患者护理时，如何找到在统计估计中由于数据限制而导致不确定性的{emph{robust}患者转移策略的问题。我们提出一个马尔可夫决策过程模型来捕捉病人健康的演变，其中状态代表病人严重程度的度量。在相当一般的假设下，我们证明了最优转移策略有一个阈值结构，即它将超过一定严重程度的所有患者转移到ICU（取决于可用容量）。由于模型参数通常是根据实际数据的统计估计来确定的，因此它们在本质上会受到错误说明和估计误差的影响。我们通过推导一个稳健的策略来解释这个参数的不确定性，该策略在模型参数的所有可能值中优化最坏情况下的回报。我们证明在相当一般的假设下，稳健策略也有一个阈值结构。此外，与不考虑参数不确定性的最优名义策略相比，它在转移患者方面更具攻击性。我们使用21家KNPC医院的住院数据进行了计算实验，并提供了各种医院指标（死亡率、住院时间、平均ICU入住率）对参数微小变化的敏感性的经验证据。我们的工作提供了有用的见解，对参数不确定性的影响，推导出简单的政策，主动重症监护室转移，有很强的经验表现和理论保障。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06247">PDF</a>
<h3>No. 81	状态变量、Bandit问题与POMDPs</h3><h4>Warren B Powell</h4>摘要：状态变量是序列决策问题中最微妙的维度。在主动学习问题（bandit问题）中尤其如此，在这种情况下，决策会影响我们观察和学习的内容。我们描述了建模{it any}顺序决策问题的规范框架，并给出了允许我们声明的状态变量的定义：任何正确建模的顺序决策问题都是马尔可夫的。然后，我们提出了部分可观测马尔可夫决策问题（POMDPs）的一个新的两代理视角，它允许我们宣称：任何实际决策问题的模型（可能）都是非马尔可夫的。我们使用观察和治疗人群中流感的背景来说明这些观点，并在此背景下提供所有四类政策的示例。最后，我们将说明如何将这种思想扩展到多代理问题。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06238">PDF</a>
<h3>No. 82	基于多层感知器和鲸鱼优化算法混合模型的风速预测</h3><h4>Saeed Samadianfard, Sajjad Hashemi, Katayoun Kargar, Mojtaba Izadyar, Ali Mostafaeipour, Amir Mosavi, Narjes Nabipour, Shahaboddin Shamshirband</h4>摘要：风电作为一种可再生能源，具有众多的经济、环境和社会效益。为了提高和控制可再生风力发电，必须利用高精度的风速预测模型。由于忽略了数据预处理的要求和意义，忽略了单一预测模型的不足，许多传统模型在风速预测方面的性能较差。在目前的研究中，为了预测伊朗北部目标站的风速，将多层感知器模型（MLP）与鲸鱼优化算法（WOA）相结合，在有限的数据集上建立了新的方法（MLP-WOA）（2004-2014）。然后，在10个目标站中的每个站使用MLP-WOA模型，其中9个站用于训练，第10个站用于测试（即：Astara、Bandar-E-Anzali、Rasht、Manjil、Jirandeh、Talesh、Kiyashahr、Lahijan、Masuleh和Deylaman），以提高后续混合模型的准确性。比较了混合模型与无WOA优化的MLP模型在各目标站风速预测中的性能。为了确定确切的结果，使用了大量的统计性能。对于所有十个目标站，MLP-WOA模型比独立的MLP模型有精确的结果。该混合模型的RMSE、SI和RE参数较低，NSE、WI和KGE参数较高，性能良好。结果表明，WOA优化算法可以提高MLP模型的预测精度，可用于准确的风速预测。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06226">PDF</a>
<h3>No. 83	自我关注的窃电检测</h3><h4>Paulo Finardi, Israel Campiotti, Gustavo Plensack, Rafael Derradi de Souza, Rodrigo Nogueira, Gustavo Pinheiro, Roberto Lotufo</h4>文摘：针对国家电网公司提供的一个日用电量数据集，提出了一种新的基于不平衡现实数据集的窃电检测自关注机制模型。我们的主要贡献是引入了一种多头自注意机制，该机制与扩展卷积连接，并由核大小为$1$的卷积统一。此外，我们引入一个二进制输入通道（二进制掩码）来识别缺失值的位置，使网络能够学习如何处理这些值。我们的模型实现了0.926美元的AUC，比以前的基线工作提高了17%以上。该代码可以在GitHub上的这个https URL上找到<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06219">PDF</a>
<h3>No. 84	基于多智能体深度强化学习的无线网络资源管理</h3><h4>Navid Naderializadeh, Jaroslaw Sydir, Meryem Simsek, Hosein Nikopour</h4>文摘：提出了一种基于多智能体深度强化学习（RL）的无线网络分布式资源管理机制。我们为网络中的每个发射机配备了一个深度RL代理，该代理接收来自其关联用户的部分延迟观测，同时还与相邻的代理交换观测，并决定在每个调度间隔使用哪个用户和哪些发射功率。我们提出的框架使代理能够同时以分布式的方式做出决策，而不需要知道其他代理的并发决策。此外，我们对代理的观察和行动空间的设计是可伸缩的，因为在特定数量的发射器和接收器的场景中训练的代理可以容易地应用于具有不同数量的发射器和/或接收器的场景。仿真结果表明，与分散基线相比，本文提出的方法在平均用户速率和5^{th}$percentile用户速率之间的折衷方面具有优越性，同时性能接近，甚至在某些情况下优于集中式信息论调度算法。我们还表明，我们的训练有素的代理是健壮的，并在遇到培训和测试部署不匹配时保持其性能增益。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06215">PDF</a>
<h3>No. 85	基于互信息有效近似的快速公平回归</h3><h4>Daniel Steinberg, Alistair Reid, Simon O'Callaghan, Finnian Lattimore, Lachlan McCalman, Tiberio Caetano</h4>摘要：迄今为止，在算法公平性方面的大部分工作都集中在离散的结果上，比如决定是否给某人贷款。在这些分类设置中，可以通过比较不同亚群之间的结果率来直接衡量群体公平性标准，如独立性、分离性和充分性。然而，许多重要的问题都需要预测实际价值的结果，如风险分数或保险费。在这样的回归设置中，测量组公平性标准在计算上是有挑战性的，因为它需要估计条件概率密度函数之间的信息论分歧。本文介绍了从它们的（条件）互信息定义的回归模型的独立性、分离性和充分性组公平标准的快速近似，并使用这种近似作为正则化来在正则化风险最小化框架内执行公平性。在真实数据集上的实验表明，尽管我们的算法具有优越的计算效率，但仍然显示出最先进的精度/公平性折衷。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06200">PDF</a>
<h3>No. 86	精密浇口：动态双精度激活提高神经网络效率</h3><h4>Yichi Zhang, Ritchie Zhao, Weizhe Hua, Nayun Xu, G. Edward Suh, Zhiru Zhang</h4>文摘：提出了一种适用于深部神经网络的端到端可训练动态双精度量化技术——精密选通（PG）。PG以较低的精度计算大多数特征，而以较高的精度计算只有一小部分重要特征以保持精度。该方法适用于多种DNN体系结构，大大降低了DNN执行的计算成本，几乎没有精度损失。我们的实验表明，PG在CNNs上取得了很好的效果，包括静态压缩的移动友好网络，如ShuffleNet。与目前最先进的基于预测的量化方案相比，PG在ImageNet上的计算量减少了2.4美元，达到了相同或更高的精度。PG还适用于RNNs。与8位均匀量化相比，PG在PNN树银行数据集上对每一个字的困惑获得了1.2%的改善，2.7的计算成本降低了LSTM。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07136">PDF</a>
<h3>No. 87	基于图注意网络的单细胞疾病状态预测</h3><h4>Neal G. Ravindra, Arijit Sehanobish, Jenna L. Pappalardo, David A. Hafler, David van Dijk</h4>文摘：单细胞RNA序列分析（scRNA-seq）为生物学的发现带来了革命性的进展，它提供了组织中细胞异质性的无偏图像。虽然scRNA-seq被广泛用于提供对健康和疾病的洞察，但它并没有被用于疾病预测或诊断。图形注意网络通过从原始特征和图形结构中学习，已被证明在广泛的任务中具有多用途。在这里，我们提出了一个图表注意模型，用于预测多发性硬化（MS）患者的大数据集上的单细胞数据的疾病状态。MS是一种中枢神经系统疾病，很难诊断。我们利用从血液和脑脊液（CSF）中获得的单细胞数据为一组7名MS患者和6名健康成人（HA）训练我们的模型，得到66667个单个细胞。我们在预测MS方面达到了$\mathbf{92}$\%的准确率，优于其他最新的方法，如图卷积网络、随机森林和多层感知器。此外，我们使用学习的图形注意模型来洞察对预测非常重要的特征（细胞类型和基因）。图形注意模型还允许我们为细胞推断一个新的特征空间，强调这两个条件之间的差异。最后，我们使用注意权重来学习一个新的低维嵌入，我们用PHATE和UMAP进行可视化。据我们所知，这是第一次尝试使用图形注意和深度学习，从单细胞数据预测疾病状态。我们设想将这种方法应用于其他疾病的单细胞数据。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07128">PDF</a>
<h3>No. 88	XCAT解剖模型的4D心磁共振图像合成</h3><h4>Samaneh Abbasi-Sureshjani, Sina Amirrajab, Cristian Lorenz, Juergen Weese, Josien Pluim, Marcel Breeuwer</h4>文摘：提出了一种混合可控图像生成方法，用于合成具有解剖学意义的3D+t标记心脏磁共振（CMR）图像。我们的混合方法以机械性4D扩展心脏躯干（XCAT）心脏模型为解剖基础，通过数据驱动的生成性对抗网络（GAN）合成CMR图像。我们采用最新的空间自适应去规范化（SPADE）技术进行条件图像合成，以保留基本真实解剖的语义空间信息。使用XCAT心脏的参数化运动模型，我们在短轴视图的18个位置为一个心动周期产生心脏的25个时间帧的标签。随后，从这些标签生成真实图像，具有从真实CMR图像数据中学习到的模态特定特征。我们证明使用样式编码器网络可以从另一个心脏图像完成样式转换。由于XCAT在创建新心脏模型中的灵活性，这种方法可以导致现实的虚拟群体来解决医学图像分析研究社区所面临的不同挑战，例如昂贵的数据收集。本文提出的方法具有很好的应用潜力，可以合成具有注释和自适应样式的4D可控CMR图像，应用于医学图像分析中的各种有监督的多站点、多供应商应用。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07089">PDF</a>
<h3>No. 89	基于深度学习视觉分类的物理硬标签查询攻击</h3><h4>Ryan Feng, Jiefeng Chen, Nelson Manohar, Earlence Fernandes, Somesh Jha, Atul Prakash</h4>文摘：提出了一种在黑盒硬标签设置中的物理对抗示例算法生存选择算法，攻击者只能访问模型预测类标签。假设这种对模型的有限访问与之前的工作假设的白盒设置相比，对于专有网络物理和云系统等设置更为相关。利用物理攻击的特性，提出了一种基于物理变换扰动生存性的攻击方法。通过简单地查询硬标签预测模型，我们优化扰动以在许多不同的物理条件下生存，并表明即使在硬标签威胁模型中，对抗性示例仍然是网络物理系统（cps）的安全风险。我们证明了Survival OPT是一种高效且健壮的查询方法：使用少于200K的查询，我们成功地通过设置在98.5%的视频帧中攻击了一个被误分类为限速30km/hr的停车标志。生存OPT也优于现有的硬标签和物理方法的基线组合，这需要超过10倍的查询来获得不太健壮的结果。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07088">PDF</a>
<h3>No. 90	PCSGAN：用于热图像和近红外图像到可见光图像转换的感知循环合成生成对抗网络</h3><h4>Kancharagunta Kishan Babu, Shiv Ram Dubey</h4>摘要：在现实生活中，由于光照条件的影响，在可见光光谱中很难捕捉到图像。然而，在这种情况下，可以使用近红外（NIR）和热（THM）摄像机拍摄图像。近红外和THM图像包含有限的细节。因此，需要将图像从THM/NIR转换为VIS，以便更好地理解。然而，由于存在较大的领域差异和缺乏丰富的数据集，这是一项非平凡的任务。目前，生成性对抗网络（generativedepartarialnetwork，GAN）能够将图像从一个域转换到另一个域。现有的基于GAN的训练方法大多采用对抗性和像素损失（如L1或L2）相结合的方法作为训练目标函数。在THM/NIR-VIS变换的情况下，用这种目标函数变换后的图像质量仍然达不到要求。因此，需要更好的目标函数来提高变换图像的质量、细节和真实感。为了解决这一问题，提出了一种新的THM/NIR-VIS图像转换模型：感知循环合成生成对抗网络（PCSGAN）。PCSGAN使用感知（即基于特征的）损失、像素损失和对抗性损失的组合。采用定量和定性方法对PCSGAN模型在WHU-IIP人脸和RGB-NIR场景数据集上的性能进行了评价。所提出的PCSGAN在SSIM、MSE、PSNR和LPIPS评价指标方面优于现有的图像转换模型，包括Pix2pix、DualGAN、CycleGAN、PS2GAN和PAN。代码可在以下位置获得：url{this https url}。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07082">PDF</a>
<h3>No. 91	具有局部和全局约束的可伸缩二元独立模型</h3><h4>Florian Adriaens, Alexandru Mara, Jefrey Lijffijt, Tijl De Bie</h4>文摘：指数随机图（ERGs）领域的一个重要挑战是在大型网络上拟合非平凡ERGs。通过利用矩阵块近似技术，我们提出了一个近似框架，这样的非平凡的ERG，导致二元独立性（即，边缘无关）模型，同时能够有意义地建模本地信息（度）以及全局信息（聚类系数，分类等），如果需要的话。这使得我们能够有效地生成具有与观测网络相似特性的随机网络，可扩展到由数百万个节点组成的稀疏图。实证分析表明，该方法在准确度方面具有较强的竞争力。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07076">PDF</a>
<h3>No. 92	基于时频卷积神经网络的双线性池声场景分类</h3><h4>Xing Yong Kek, Cheng Siong Chin, Ye Li</h4>文摘：目前处理声场景分类（ASC）任务的方法可以分为两步：将音频波形预处理成对数mel谱图，然后将其作为卷积神经网络（CNN）的输入表示。这种范式转换发生在DCASE2016之后，该框架模型在（ESC-50）数据集上实现了ASC任务的最新结果，精度达到64.5%，比基线模型提高了20.5%，DCASE2016数据集的精度达到90.0%（开发）和86.2%（评估），这构成了与基线系统相比分别提高了6.4%和9%。本文探讨了利用和声与打击声源分离（HPSS）将音频分为和声与打击声，在音乐信息检索（MIR）领域得到了广泛的应用。在ASC任务中，虽然已经用HPSS作为CNN模型的输入表示做了一些工作，但本文进一步研究了利用分离的谐波分量和敲击分量，通过两个CNN来理解谐波和敲击音的自然形式的可能性，一个专门提取时偏域的深层特征，另一个专门提取频偏域的深层特征。从这两个cnn中提取的深层特征将使用双线性池进行组合。因此，提出了一种双流时频CNN结构的声场景分类方法。该模型正在DCASE 2019子任务1a数据集上进行评估，在开发数据集Kaggle Leadership Private and Public board上的平均得分为65%。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07065">PDF</a>
<h3>No. 93	生物随机游动：在疾病基因排序中整合异质数据</h3><h4>Michele Gentili, Leonardo Martini, Manuela Petti, Lorenzo Farina, Luca Becchetti</h4>摘要：本文提出了一个在基于网络传播的基因优先算法中利用生物信息的统一框架。乳腺癌数据的初步结果显示，与最先进的基线相比，基因的优先级有了显著的提高，例如未通过基于交互作用的算法确定为潜在候选基因，但似乎与乳腺癌有关/或可能与乳腺癌有关的基因的优先级，根据最近文献的功能分析。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07064">PDF</a>
<h3>No. 94	基于神经网络处理器结构的批处理加速优化调度体系结构</h3><h4>Phani Kumar Nyshadham, Mohit Sinha, Biswajit Mishra, H S Vijay</h4>摘要：在神经网络拓扑中，算法是在成批的数据张量上运行的。数据批通常被调度到并行执行的计算核心上。对于运行在成批数据上的算法，通过适当利用硬件资源，需要一个最优的成批调度体系结构，从而大大减少训练和推理时间。在本文中，我们建议通过一个调度架构来加速神经网络的批处理算法，以实现最佳的计算功率利用率。所提出的优化调度体系结构可以构建在硬件中，也可以单独在软件中实现，这可以用来加速批处理算法。结果表明，与以往的算法相比，该结构加快了批处理算法的速度。所提出的思想适用于任何用于神经网络的HPC架构。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07062">PDF</a>
<h3>No. 95	通过学习产生定理来学习证明定理</h3><h4>Mingzhe Wang, Jia Deng</h4>文摘：我们认为自动定理证明是人工智能的关键任务。深度学习对于训练定理证明者是有希望的，但是对于有监督的学习来说，人类书写的定理和证明是有限的。为了解决这一局限性，我们提出学习一个自动综合定理和证明的神经生成器，以训练定理证明器。在实际任务上的实验表明，该方法的综合数据改进了定理证明器，提高了元数学中定理自动证明的技术水平。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07019">PDF</a>
<h3>No. 96	用于音乐源分离的元学习提取器</h3><h4>David Samuel, Aditya Ganeshan, Jason Naradowsky</h4>文摘：提出了一种基于分层元学习的音乐源分离模型（meta-TasNet），该模型使用生成器模型来预测单个提取器模型的权重。这样可以实现有效的参数共享，同时还允许特定于仪器的参数化。Meta-TasNet被证明比独立训练或多任务环境下训练的模型更有效，并且实现了与最新方法相当的性能。与后者相比，我们的提取器包含的参数更少，运行时性能更快。我们讨论了重要的架构考虑因素，并探讨了这种方法的成本和好处。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07016">PDF</a>
<h3>No. 97	生成模型提出的分子可合成性</h3><h4>Wenhao Gao, Connor W. Coley</h4>摘要：功能分子的发现是一个昂贵而耗时的过程，小分子治疗性发现的成本不断上升就是一个例证。在新的深度学习方法的推动下，新的分子生成和优化技术是早期药物发现的一类越来越受关注的技术。这些技术可以建议新的分子结构，旨在最大化多目标函数，例如，适合于针对特定目标的治疗，而不依赖于化学空间的强力探索。然而，这些方法的实用性由于对可综合性的无知而受到阻碍。为了突出这个问题的严重性，我们使用一个数据驱动的计算机辅助合成规划程序来量化由最先进的生成模型提出的分子不容易合成的频率。我们的分析表明，尽管这些模型在流行的定量基准上表现良好，但仍有一些任务产生了不现实的分子结构。合成复杂性启发式可以成功地将生成偏向合成可处理的化学空间，虽然这样做必然减损了主要目标。分析表明，为了提高这些模型在实际发现工作流中的实用性，需要开发新的算法。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07007">PDF</a>
<h3>No. 98	约束自洽极小化的Newton-Frank-Wolfe方法</h3><h4>Deyi Liu, Volkan Cevher, Quoc Tran-Dinh</h4>文摘：利用约束集上的线性极小化oracles（LMO）证明了如何可标度地求解一类约束自洽极小化问题。证明了在L-光滑情形下，我们方法的LMO调用次数与Frank Wolfe方法的LMO调用次数几乎相同。具体来说，我们的Newton-Frank-Wolfe方法使用$\mathcal{O}（\epsilon^{-\nu}）$LMO，其中$\epsilon$是所需的精度，而$\nu:=1+O（1）$。此外，我们还演示了我们的算法如何利用基于LMO的方案的改进变体（包括远离步数）来获得线性收敛速度。我们还为具有竞争比率的投资组合设计、D-最优实验设计以及牛顿-弗兰克-沃尔夫（Newton-Frank-Wolfe）优于最新水平的弹性网络logistic回归提供了数值证据。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07003">PDF</a>
<h3>No. 99	二进制网络的学习结构</h3><h4>Kunal Pratap Singh, Dahyun Kim, Jonghyun Choi</h4>摘要：大多数二进制网络的骨干结构都是著名的浮点结构，如ResNet家族。针对浮点网络的体系结构不适合二进制网络的问题，我们提出了二进制网络体系结构（BNAS）的搜索方法。具体来说，在基于单元的搜索方法的基础上，我们定义了一组新的层类型，设计了一个新的单元模板，重新发现了零层的实用性，并提出使用零层来学习性能良好的二进制网络。此外，我们建议多样化的早期搜索，以学习性能更好的二进制架构。我们的搜索二进制网络在CIFAR10和ImageNet数据集上的性能优于最新的二进制网络。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06963">PDF</a>
<h3>No. 100	引文推荐：方法和数据集</h3><h4>Michael Färber, Adam Jatowt</h4>摘要：引文推荐是指对给定文本进行引文推荐的任务。由于近年来发表的科学著作一方面超载，另一方面在撰写科学文本时需要引用最合适的出版物，引文推荐已成为一个重要的研究课题。近年来，提出了几种方法和评价数据集。然而，据我们所知，没有对引文推荐进行明确的文献调查。本文对引文自动推荐的研究进行了深入的介绍。然后，我们对引文推荐的方法和数据集进行了概述，并使用不同的维度确定了差异和共性。最后，我们对评估方法进行了说明，并概述了评估中的一般挑战以及如何应对这些挑战。我们仅限于科学出版物的引文推荐，因为这类文献在这方面的研究最多。然而，本次调查中的许多观察和讨论也适用于其他类型的文本，如新闻文章和百科全书文章。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06961">PDF</a>
<h3>No. 101	政策梯度的自适应经验选择</h3><h4>Saad Mohamad, Giovanni Montana</h4>摘要：策略梯度强化学习（RL）算法在连续性控制等挑战性学习任务中取得了令人瞩目的成绩，但仍存在较高的样本复杂度。经验重演是提高样本效率的常用方法，但使用过去轨迹的梯度估计器通常具有高方差。现有的采样策略，如均匀采样或优先体验重放的经验重放没有明确尝试控制梯度估计的方差。本文提出了一种在线学习算法，即自适应经验选择（AES），以自适应地学习一个经验抽样分布，该分布能显式地最小化这种方差。使用后悔最小化方法，AES迭代更新经验抽样分布，以匹配假设具有最优方差的竞争对手分布的性能。针对样本非平稳性，提出了一种动态（即时变）竞争分布，并给出了一种闭式解。我们证明了AES是一个低后悔算法，具有合理的样本复杂度。在经验上，AES已经被用于深度确定的策略梯度和软参与者批评算法，并在OpenAI体育馆库中的8个连续控制任务上进行了测试。我们的结果显示，与目前可用的策略梯度经验抽样策略相比，AES显著提高了性能。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06946">PDF</a>
<h3>No. 102	放大神秘</h3><h4>Terence Broad, Frederic Fol Leymarie, Mick Grierson</h4>摘要：深度神经网络在制造逼真的深度假象方面已经变得非常出色，人们的图像（对未经训练的人来说）与真实的图像无法区分。这些是由学习区分真假图像的算法生成的，并经过优化以生成系统认为真实的样本。本文，以及由此产生的一系列艺术作品被挫败，探索了逆转这一过程，而不是优化系统，以产生它认为是假的图像的审美结果。最大化数据的不可能性，进而放大这些机器幻觉的不可思议性质。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06890">PDF</a>
<h3>No. 103	基于可解释神经网络回归的大型生物测量学</h3><h4>Taro Langner, Håkan Ahlström, Joel Kullberg</h4>摘要：英国生物银行的这项研究成功地为32000多名志愿者进行了颈部到膝盖的身体核磁共振成像。每次扫描都链接到大量的元数据，提供了对成像解剖学和相关健康状态的全面调查。尽管有研究的潜力，但这大量的数据对现有的评估方法提出了挑战，这些方法通常依赖于人工输入。迄今为止，心血管和代谢危险因素的参考值范围是不完整的。在这项工作中，神经网络被训练用于回归，以自动推断从颈部到膝盖的身体MRI的各种生物学指标。该方法无需人工干预或地面真相分割训练。研究领域涉及64个变量，这些变量来自人体测量、双能X射线吸收测量（DXA）、基于图谱的分割和专用肝脏扫描。标准化框架与ResNet50进行了7倍交叉验证，与目标值（中值R^2>0.97）非常吻合。对聚合显著性地图的解释表明，该网络正确地针对特定的身体区域和四肢，并学会了模拟不同的模式。在几个身体成分指标上，预测的质量在已建立的金标准技术之间观察到的变异范围内。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06862">PDF</a>
<h3>No. 104	抽象视觉推理的层次规则归纳网络</h3><h4>Sheng Hu, Yuqing Ma, Xianglong Liu, Yanlu Wei, Shihao Bai</h4>摘要：抽象推理是指对信息进行分析，在无形的层面上发现规律，以创新的方式解决问题的能力。Raven的渐进矩阵（RPM）测试通常用于检查抽象推理的能力。在测试中，要求受试者根据矩阵中的基本规则，从答案集中确定正确的选择，以填充RPM右下角缺少的面板（例如，3$\times$3矩阵）。近年来，利用卷积神经网络（CNNs）的优势，在解决转速测试问题上取得了可喜的进展。不幸的是，仅仅依赖于矩阵级的关系抽取，他们无法识别RPM中行/列内部或跨行/列的复杂属性模式。为了解决这一问题，本文提出了一种层次化的规则归纳网络（HriNet），它通过暗示人类的归纳策略。HriNet从不同层次提取多粒度规则嵌入，并通过门控嵌入融合模块进行集成。我们进一步引入了一种基于嵌入的规则相似度度量，使得HriNet不仅可以利用元组损失进行训练，而且可以根据相似度得分推断出最佳答案。为了全面评估HriNet，我们首先修复了最近RAVEN数据集中包含的缺陷，并生成了一个新的称为Balanced RAVEN的数据集。然后在大规模数据集PGM和我们的平衡RAVEN上进行了大量的实验，结果表明HriNet在很大程度上优于最新的模型。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06838">PDF</a>
<h3>No. 105	歌手识别中伴奏的混淆</h3><h4>Tsung-Han Hsieh, Kai-Hsiang Cheng, Zhe-Cheng Fan, Yu-Ching Yang, Yi-Hsuan Yang</h4>摘要：歌手识别是一项重要的工作，有着广泛的应用。然而，由于许多问题，这项任务仍然具有挑战性。一个主要的问题是，在音乐制作中，背景器乐与人声混用的混淆因素。歌手识别模型可以学习从歌曲的器乐部分提取非声乐相关特征，如果歌手只在特定的音乐环境（例如，流派）中演唱。因此，当歌手在看不见的环境中演唱时，这个模型就不能很好地概括。在本文中，我们试图解决这个问题。具体来说，我们使用开源的unmix工具，一个在源代码分离方面具有最先进性能的开源工具，来分离音乐的声乐和器乐曲目。然后，我们研究了两种方法来训练歌手识别模型：仅从分离的人声中学习，或从一组增加的数据中“洗牌和混音”不同歌曲的分离的人声轨迹和器乐轨迹，以人为地使歌手在不同的上下文中演唱。我们还结合了从声乐旋律轮廓学习到的旋律特征，以获得更好的表现。在一个名为artist20的基准数据集上的评估结果表明，这种数据增强方法大大提高了歌手识别的准确性。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06817">PDF</a>
<h3>No. 106	论说教与对抗性例子中深层学习表征的相似性</h3><h4>Pamela K. Douglas, Farzad Vasheghani Farahani</h4>文摘：深度神经网络（DNNs）的日益广泛应用促使了一项平行的努力：设计从成功的错误分类中获利的对手。然而，并非所有的对抗性例子都是出于恶意目的而精心设计的。例如，现实世界中的系统通常包含跨仪器的物理、时间和采样可变性。在野外对抗性的例子可能无意中证明对准确的预测模型有害。相反，自然发生的图像特征协方差可以用于教学目的。在这里，我们研究了深度学习表征在神经影像学分类中的稳定性，这种分类是在不同的教学和对抗条件下进行的。结果表明，在输入空间中，对抗性例子的出现频率不同，表现出的相似性和表现也不同。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06816">PDF</a>
<h3>No. 107	利用离线分析模拟ML系统的性能</h3><h4>Hongming Huang, Peng Cheng, Hong Xu, Yongqiang Xiong</h4>文摘：我们认为基于离线评测的仿真是一种有希望的方法，可以更好地理解和改进复杂的ML系统。我们的方法使用操作级分析和基于数据流的模拟，以确保为所有框架和ML模型提供一个统一和自动化的解决方案，并且通过考虑实际系统中的各种并行化策略也很精确。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06790">PDF</a>
<h3>No. 108	如何在业余时间拥有NAS</h3><h4>Sanghyun Hong, Michael Davinroy, Yiğitcan Kaya, Dana Dachman-Soled, Tudor Dumitraş</h4>摘要：新的数据处理管道和新的网络结构日益推动着深度学习的成功。因此，业界将性能最好的架构视为知识产权，并投入大量计算资源通过神经架构搜索（NAS）来发现此类架构。这为对手窃取这些新架构提供了激励；当在云中使用时，为了提供机器学习服务，对手也有机会通过利用一系列硬件侧通道来重建架构。然而，在不知道计算图（例如，层、分支或跳过连接）、结构参数（例如，卷积层中的滤波器数量）或特定预处理步骤（例如，嵌入）的情况下重建新的架构和管道是一项挑战。本文设计了一种新的深度学习系统的关键部件重构算法，该算法利用了缓存侧信道攻击Flush+Reload带来的少量信息泄漏。我们使用Flush+Reload来推断计算的轨迹和每次计算的时间。然后，我们的算法从跟踪中生成候选计算图，并通过参数估计过程消除不兼容的候选。我们在PyTorch和Tensorflow中实现了我们的算法。实验证明，我们可以重建MalConv（一种用于恶意软件检测的新型数据预处理管道）和ProxylessNAS-CPU（一种用于优化在CPU上运行的ImageNet分类的新型网络体系结构），而无需知道体系结构族。在这两种情况下，我们都会得到0%的误差。这些结果表明，硬件侧信道是一种实用的针对MLaaS的攻击载体，应进一步研究其对深度学习系统安全性的影响。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06776">PDF</a>
<h3>No. 109	正则化信息最大化的卷积神经网络超像素分割</h3><h4>Teppei Suzuki</h4>文摘：提出了一种在推理时间内优化随机初始化卷积神经网络（CNN）的无监督超像素分割方法。我们的方法通过CNN从没有任何标签的单一图像中生成超像素，通过最小化在推理时间内提出的超像素分割目标函数。与现有的许多方法相比，我们的方法有三个优点：（i）利用美国有线电视新闻网之前的图像进行超像素分割，（ii）根据给定的图像自适应地改变超像素的数量，以及（iii）通过向目标函数添加辅助成本来控制超像素的性质。我们在BSDS500和SBD数据集上定量和定性地验证了该方法的优势。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06765">PDF</a>
<h3>No. 110	（个人）公平性$k$-集群</h3><h4>Sepideh Mahabadi, Ali Vakilian</h4>文摘：从个体公平的角度出发，提出了一种基于局部搜索的$k$-中值（$k$-均值）聚类算法。更准确地说，对于$x$点集$P$的大小$n$，设$r（x）$为最小半径，使得以$x$为中心的半径$r（x）$球从$P$至少有$n/k$点。直观地说，如果从$P$中选择一组$k$随机点作为中心，则$x在P$中的每个点都希望有一个半径为$r（x）$的中心。单独的公平集群为P$中的每个点$x提供了这样的保证。这种公平的概念被引入[Jung等人，2019 ]，在这里他们展示了如何获得一个近似可行的$K$-聚类相对于这个公平条件。在这项工作中，我们展示了如何获得近似最优的这种公平的$ $ $聚类。我们的解决方案的$K$-中位数（$k$ -均值）是在一个最佳的公平$k $聚类的成本的常数因子内，并且我们的解决方案近似满足公平性条件（也在一个常数因子内）。此外，我们用实证评估来补充我们的理论界限。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06742">PDF</a>
<h3>No. 111	基于CNN的超声弹性成像自动帧选择</h3><h4>Abdelrahman Zayed, Guy Cloutier, Hassan Rivaz</h4>摘要：超声弹性成像是通过监测组织对外力或外力的响应来估计组织的力学性能。不同的组织类型根据其力学性质得到不同程度的变形，其中较硬的组织变形较小。在给定两个射频（RF）帧的变形前后，通过比较RF帧估计位移和应变图像。应变图像的质量取决于变形过程中发生的运动类型。平面内的轴向运动导致高质量的应变图像，而面外运动导致低质量应变图像。本文介绍了一种利用卷积神经网络（CNN）在5.4ms内确定一对RF帧在弹性成像中适用性的新方法，该方法还可用于自动选择最佳RF帧对，得到高质量的应变图像。美国有线电视新闻网在3818对射频帧上进行了训练，而在986对新的看不见的帧上进行了测试，达到了91%以上的准确率。从体模和活体数据中收集射频帧。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06734">PDF</a>
<h3>No. 112	随机正规化流</h3><h4>Hao Wu, Jonas Köhler, Frank Noé</h4>文摘：规范化流是一种流行的生成学习方法，它训练一个可逆函数，将简单的先验分布转化为复杂的目标分布。在这里，我们通过引入随机规范化流（SNF）-一个确定性可逆函数的任意序列和随机过程，如Markov链Monte Carlo（MCMC）或Langevin动力学，推广了该框架。这种组合可以是强大的，因为向流中添加随机性有助于克服所选确定性可逆函数的表达限制，而可训练流转换可以提高纯MCMC的采样效率。我们的方法的关键是，我们可以匹配一个边缘目标密度，而不必边缘化出所穿越路径的随机性。借鉴非平衡统计力学的思想，提出了一种只使用条件路径概率的训练方法。我们可以将SNF转化为Boltzmann生成器，通过对这些路径的重要性采样，对给定的目标密度进行渐近无偏采样。我们在几个基准上说明了SNFs的表示能力、采样效率和渐近正确性。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06707">PDF</a>
<h3>No. 113	高斯平滑语义特征（GSSF）——基于MSCOCO框架的印度语（孟加拉语）视觉字幕语言研究</h3><h4>Chiranjib Sur</h4>翻译后摘要：在这项工作中，我们引入了高斯平滑语义特征（GSSF）为更好的语义选择印度区域语言为基础的图像字幕，并介绍了一个过程中，我们使用现有的翻译和英语人群来源的句子进行培训。我们已经表明，这种体系结构是一种很有前途的替代资源，那里的资源紧张。我们的主要贡献是为孟加拉语（世界上第五种广泛使用的语言）开发具有完全不同语法和语言属性的深度学习架构。我们已经证明，这些方法对于复杂的应用程序（如从图像上下文生成语言）非常有效，并且可以通过引入约束、更广泛的特征和独特的特征空间使表示多样化。我们还证明，在传统的LSTM和特征分解网络中使用平滑语义张量可以获得绝对的精度和多样性。通过更好的学习架构，我们成功地建立了一个自动化的算法和评估程序，可以帮助评估合格的应用程序，而无需专业知识和人工干预。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06701">PDF</a>
<h3>No. 114	伪局部极小值的结构</h3><h4>Wei Qian, Yuqian Zhang, Yudong Chen</h4>摘要：k$-聚类是无监督学习中的一个基本问题。这个问题涉及到如何将数据点划分成$k$个集群，从而最小化集群内的变化。尽管它的重要性和广泛的适用性，理论上对$k$-意味着问题的理解并不完全令人满意。具有理论性能保证的现有算法通常依赖于复杂的（有时是人工的）算法技术和对数据的限制性假设。主要的挑战在于问题的非凸性；特别是，除了全局最优之外，还存在附加的局部解。此外，最简单和最流行的$k$-均值算法，即Lloyd算法，在理论和实践中通常会收敛到这种虚假的局部解。在本文中，我们从一个新的角度来探讨$k$-均值问题，通过研究这些伪局部解在具有$k$基本真值簇的概率生成模型下的结构。只要K＝3美元，伪造局部极小可证明存在，即使对于良好分离和平衡的集群。一个这样的局部最小值将两个中心放在一个真正的簇上，而第三个中心放在其他两个真正簇的中间。对于一般的$k$，一个本地最小值将多个中心放在一个真正的集群上，一个中心放在多个真正集群的中间。或许令人惊讶的是，我们证明了这是分离条件下唯一一类伪局部极小。我们的结果适用于混合高斯分布或有界分布的$k$-均值公式。我们的理论结果证实了现有的经验观察，并提供了一些改进的算法$ k$均值聚类的理由。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06694">PDF</a>
<h3>No. 115	面向自我网络分析的全局和局部特征学习</h3><h4>Fatemeh Salehi Rizi, Michael Granitzer, Konstantin Ziegler</h4>摘要：在自我网络中，个体（自我）在不同的群体（社交圈）中组织其朋友（改变）。在学习了自我的表征及其在低维、实向量空间中的变化之后，可以有效地分析这个社会网络。然后，这些表示很容易通过统计模型用于诸如社交圈检测和预测等任务。通过深度学习进行语言建模的最新进展激发了学习网络表示的新方法。这些方法可以捕捉网络的全局结构。在本文中，我们发展这些技术，也编码邻域的局部结构。因此，我们的本地表示捕获隐藏在大型网络的全局表示中的网络特性。我们证明，社交圈预测的任务得益于我们的技术产生的全局和局部特征的结合。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06685">PDF</a>
<h3>No. 116	预测活动出席率探索社会影响</h3><h4>Fatemeh Salehi Rizi, Michael Granitzer</h4>摘要：预测人们对现实世界事件的参与程度，为人类行为分析和事件相关广告提供了有价值的见解，受到了广泛的关注。如今，社交网络（如Twitter）广泛反映了人们与朋友讨论兴趣的大型热门事件。活动参与者通常会鼓励朋友加入到网络传播社会影响的活动中。在这篇文章中，我们建议建立朋友对出席活动的社会影响模型。除了社会群体结构之外，我们还考虑非地理标记的帖子来推断用户的出席率。为了充分利用网络拓扑信息，我们采用了node2vec、HARP和Poincar`e等最新的图形嵌入技术，描述了特征空间的设计方法，并将其反馈给神经网络。表演评估使用两个大型音乐节数据集进行，即VFestival和Creamfields。实验结果表明，我们的分类器优于最新的基线，对VFestival数据集的准确率达到89%。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06665">PDF</a>
<h3>No. 117	SBERT-WK：一种基于BERT模型的句子嵌入方法</h3><h4>Bin Wang, C.-C. Jay Kuo</h4>摘要：句子嵌入是自然语言处理（NLP）中的一个重要研究课题，它能将知识传递给下游任务。同时，一个被称为BERT的上下文化的单词表示在许多NLP任务中实现了最新的性能。然而，从基于BERT的词模型中生成高质量的句子表示是一个开放的问题。以往的研究表明，不同层次的BERT捕捉不同的语言属性。这使得我们可以跨层融合信息，以找到更好的句子表示。在这项工作中，我们研究了深层语境化模型的词表示的分层模式。然后，通过对单词表示所跨越的空间进行几何分析，对基于BERT的单词模型进行剖分，提出了一种新的句子嵌入方法。它被称为SBERT-WK方法。SBERT-WK无需进一步培训。我们评估了SBERT-WK的语义文本相似度和下游监督任务。此外，本文还提出了10个句子级的探究任务，用于详细的语言分析。实验表明，SBERT-WK达到了最先进的性能。我们的代码是公开的。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06652">PDF</a>
<h3>No. 118	最近邻规则的核心集</h3><h4>Alejandro Flores Velazco, David M. Mount</h4>文摘：最近邻凝聚问题是从一组标记点P中找到一个子集R，使得对于R中的每一个点P，P的最近邻R都具有与P相同的标记，这是由于分类应用的缘故，其中，最近邻规则将点集中最近邻的标签指定给未标记的查询点。在这种情况下，压缩的目的是减少对新点进行分类所需的集合的大小。然而，寻找这样的最小基数子集是NP困难的，而且大多数研究都集中在没有性能保证的实用启发式算法上。此外，总是使用精确的最近邻居，忽略了在最近的邻居被近似计算时的分类精度的影响。在本文中，我们提出这些缺点，提出新的近似敏感准则的最近邻凝聚问题，以及实用算法与可证明的性能保证。我们描述了足够的条件，保证正确分类未标记点使用近似最近邻查询这些子集，引入了概念集分类最近的邻居规则。此外，我们证明了具有这些特征的子集是NP难的，其基数近似于最小基数子集。此外，我们提出了新的算法来计算这样的子集，具有严格的近似因子在一般度量，以及改进因子倍度量和LpP度量与P>＝2。最后，我们展示了一种替代的实现方案，减少了最坏情况下的时间复杂度之一，这些算法，成为第一个真正的二次近似算法的最近邻凝聚问题。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06650">PDF</a>
<h3>No. 119	编解码框架下的语音转换</h3><h4>Jayneel Parekh, Preeti Rao, Yi-Hsuan Yang</h4>文摘：本文的目标是将一组口语台词转换成歌唱台词。与以往基于信号处理的方法不同，我们采用基于学习的方法来解决这个问题。这使我们能够自动地对转换的各个方面进行建模，从而克服对特定输入的依赖，例如高质量的歌唱模板或音素乐谱同步信息。具体来说，我们为我们的任务提出了一个编码器-解码器框架。给定语音的时频表示和目标旋律轮廓，我们学习编码，使我们能够综合歌唱，在遵守目标旋律的同时保留说话人的语言内容和音色。我们还提出了一个基于多任务学习的目标，以提高歌词的可懂度。我们对我们的框架进行了定量和定性分析。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06595">PDF</a>
<h3>No. 120	管道干预</h3><h4>Eshwar Ram Arunachaleswaran, Sampath Kannan, Aaron Roth, Juba Ziani</h4>文摘：介绍了由分层有向无环图和一组控制连续层间转换的随机矩阵定义的{管道干预}问题。这个图表是一个程式化的模型，用来描述来自不同人群的人们如何获得机会，最终获得某种回报。在我们的模型中，个体按照固定的概率分布出生在一个初始位置（即图的第一层中的某个节点），然后根据转移矩阵在图中随机前进，直到到达图的最后一层中的某个节点；最后一层中的每个节点都有一个与之关联的\emph{reward}。管道干预问题要求在预算约束下，如何通过图对控制人们随机转换的转换矩阵进行代价最大的更改。我们考虑两个目标：社会福利最大化，和公平动机最大值目标，寻求最大值的人口（起始节点）的EMPH{{}}期望值。我们考虑的最大值目标的两个变种，结果是不同的，这取决于我们是否需要确定性解决方案或允许随机化。对于每一个目标，我们给出了一个有效的近似算法（添加剂FPTAS）的恒定宽度网络。在我们的设置中，我们也严格地描述了“公平价格”：最高可实现的社会福利与最高社会福利之间的比率与最大值最优解的一致性。最后，我们表明，对于多项式宽度的网络，即使近似最大值目标到任何常数因子是NP-hard，即使对于具有恒定深度的网络。这说明在我们的实证结果中，对宽度的限制是必要的。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06592">PDF</a>
<h3>No. 121	将自然语言解析为一阶逻辑的神经模型探讨</h3><h4>Hrituraj Singh, Milan Aggrawal, Balaji Krishnamurthy</h4>摘要：语义分析是从自然语言文本中获取机器可解释表示的任务。我们考虑了一个这样的形式化表示-一阶逻辑（FOL），并探讨了神经模型在英语句子的FOL分析中的能力。我们将FOL分析建模为一个序列到序列的映射任务，在给定一个自然语言句子的情况下，它被编码成一个中间表示，使用LSTM，然后是一个解码器，解码器在相应的FOL公式中依次生成谓词。我们通过引入一种变量对齐机制来改进标准的编码器-解码器模型，使其能够在预测的FOL中跨谓词对齐变量。进一步证明了在每个解码器步骤中预测FOL实体Unary、二进制、变量和范围实体的类别的有效性，作为提高生成的FOL的一致性的辅助任务。我们进行严格的评估和广泛的消融。我们还将发布我们的代码以及大规模的FOL数据集和模型，以帮助进一步研究NLP中基于逻辑的解析和推理。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06544">PDF</a>
<h3>No. 122	随机二阶优化的分布平均法</h3><h4>Burak Bartan, Mert Pilanci</h4>文摘：我们考虑了分布优化问题，其中Hessian的形成在计算上具有挑战性，而通信是一个重要的瓶颈。我们发展了随机二阶优化的无偏参数平均方法，采用海森抽样和草图。现有的工作不考虑估计的偏倚，这限制了它们在大规模并行计算中的应用。我们提供了正则化参数和步长的闭式公式，这些公式可证明最小化了牛顿方向草图的偏差。本文还扩展了二阶平均法的框架，提出了一种适用于具有不同工作资源的异构计算系统的无偏分布式优化框架。此外，我们通过在无服务器计算平台上进行的大规模实验，证明了我们的理论发现的含义。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06540">PDF</a>
<h3>No. 123	隐私保护回归的分布式绘制方法</h3><h4>Burak Bartan, Mert Pilanci</h4>文摘：本文研究了大规模回归问题的分布式绘制方法。在异步分布式系统中，我们利用多个随机草图来减少问题的维数，同时保护隐私和提高散乱者的弹性。我们推导出新的近似保证经典草图方法，并分析参数的平均分布草图的准确性。在分布式环境下，我们考虑了随机矩阵，包括高斯、随机Hadamard、均匀采样和杠杆分数采样。此外，为了提高计算效率，我们提出了一种结合抽样和快速随机投影的混合方法。在无服务器计算平台上，通过大规模的实验验证了分布式草图的性能。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06538">PDF</a>
<h3>No. 124	黑箱分类器的主动贝叶斯评估</h3><h4>Disi Ji, Robert L. Logan IV, Padhraic Smyth, Mark Steyvers</h4>摘要：机器学习的最新进展导致黑盒分类器在各种应用中的应用越来越多。在许多这样的情况下，需要评估这些预先训练的模型的性能，例如确保足够的预测精度，或者类概率得到很好的校准。此外，由于标记的数据可能稀少或收集成本高，因此希望以有效的方式进行此类评估。本文介绍了一种满足这些要求的贝叶斯模型评估方法。我们开发了一些推理策略来量化常见评估指标的不确定性（准确性、误分类成本、预期校准误差），并提出了一个使用此不确定性进行主动评估的框架，以指导标记实例的有效选择。我们在评估现代神经分类器（如ResNet和BERT）在几种标准图像和文本分类数据集上的性能的实验中说明了我们的方法的优点。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06532">PDF</a>
<h3>No. 125	学习为输入句子生成多种风格的转换输出</h3><h4>Kevin Lin, Ming-Yu Liu, Ming-Ting Sun, Jan Kautz</h4>摘要：文本风格转换是指以不同的风格对给定文本进行重新措辞的任务。虽然已经提出了各种方法来提高技术水平，但它们通常假设传输输出遵循delta分布，因此它们的模型无法为给定的输入文本生成不同的样式传输结果。为了解决这个问题，我们提出了一个一对多的文本风格转换框架。与以往学习将输入句子转换为输出句子的一对一映射的工作不同，我们的方法学习一对多映射，可以将输入句子转换为多个不同的输出句子，同时保留输入内容。这是通过使用潜在分解方案的对抗性训练来实现的。具体来说，我们将输入语句的潜在表示分解为捕获语言风格变化的样式代码和编码语言风格无关内容的内容代码。然后，我们将内容代码与样式代码相结合，以生成样式传输输出。通过将相同的内容代码与不同的样式代码组合，我们生成不同的样式传输输出。大量的实验结果与使用不同性能度量集的多个公共数据集上的几种文本样式传输方法进行了比较，验证了所提方法的有效性。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06525">PDF</a>
<h3>No. 126	基于序数观测的张量去噪与补全</h3><h4>Chanwoo Lee, Miaoyan Wang</h4>摘要：高阶张量在神经影像学、推荐系统、社会网络分析、心理研究等应用中经常出现。我们考虑了不完全序值观测的低秩张量估计问题。研究了两个相关问题，一个是张量去噪问题，另一个是张量完备问题。我们提出了一个多线性累积链路模型，发展了一个秩约束M估计，并得到了理论上的精度保证。我们的均方误差界比以前的结果有更快的收敛速度，并且我们证明了在一类低秩模型下，所提出的估计是极大极小最优的。此外，所开发的过程是一种有效的完成方法，它保证了仅使用$\tilde{\mathcal{O}（K d）$噪声量化观测值的顺序-$K$$（d，ldots，d）$维低秩张量的一致恢复。我们证明了我们的方法在聚类和协作过滤任务上比以前的方法有更好的表现。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06524">PDF</a>
<h3>No. 127	基于因果估计的凸公平约束模型</h3><h4>Hikaru Ogura, Akiko Takeda</h4>摘要：近年来，关于机器学习公平性的研究越来越多。在这里，平均差（MD）或人口均等是最受欢迎的公平衡量标准之一。然而，MD不仅量化了歧视，而且量化了解释性偏差，解释性偏差是由解释性特征证明的结果差异。在本文中，我们设计了一个新的模型，称为公平模型，它在保留解释偏差的同时消除了歧视。这些模型是基于使用倾向得分分析的因果效应估计。证明了带平方损失的公平性理论上优于一个朴素的MD约束模型。我们提供了一个求解回归和二元分类任务中的公平性的有效算法。在我们的实验中，在这两个任务的合成和真实世界的数据，FIECESE优于现有的模型，认为在特定情况下的解释偏倚。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06501">PDF</a>
<h3>No. 128	盲对抗网络扰动</h3><h4>Milad Nasr, Alireza Bahramali, Amir Houmansadr</h4>文摘：深度神经网络（DNNs）由于其在很大程度上优于传统的（如统计）技术，因此被广泛应用于各种流量分析问题，如网站指纹识别和流量关联等。然而，深部神经网络很容易受到对抗性例子的攻击：由于小的对抗性扰动，模型错误地标记了对抗性输入到模型中。在本文中，我们首次证明对手可以通过在网络流量模式上应用对手扰动来击败基于DNN的流量分析技术。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06495">PDF</a>
<h3>No. 129	概率密度泛函的凸优化</h3><h4>Tomohiro Nishiyama</h4>文摘：在信息论中，一些优化问题导致了概率密度严格凸泛函上的凸优化问题。在这篇文章中，我们研究了这些问题，并给出了极小化因子的条件和极小值的唯一性，如果存在极小值的话。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06488">PDF</a>
<h3>No. 130	学习分组：一个自底向上的三维零件发现框架</h3><h4>Tiange Luo, Kaichun Mo, Zhiao Huang, Jiarui Xu, Siyu Hu, Liwei Wang, Hao Su</h4>摘要：我们解决了在不可见类别中发现物体的三维零件的问题。能够学习零件的几何先验知识，并将其转移到不可见的类别之前，对数据驱动的形状分割方法提出了根本性的挑战。作为一个上下文盗贼问题，我们提出了一个基于学习的聚集聚类框架，该框架学习一个分组策略，以自下而上的方式逐步将小部分提议分组为大的提议。我们方法的核心是限制用于提取零件级特征的局部上下文，这鼓励了对不可见类别的泛化。在大规模细粒度三维零件数据集PartNet上，我们证明了该方法可以在不看到任何标注样本的情况下，将从3个训练类别中学习到的零件知识转移到21个不可见的测试类别中。对四个形状分割基线的定量比较表明，我们的方法达到了最先进的性能。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06478">PDF</a>
<h3>No. 131	深度学习中的域内不确定性估计与集结陷阱</h3><h4>Arsenii Ashukha, Alexander Lyzhov, Dmitry Molchanov, Dmitry Vetrov</h4>文摘：不确定度估计与不确定度集成方法密切相关。不确定度估计是综合性能评估的主要基准之一。同时，深度学习集成在不确定性估计方面提供了最新的结果。在这项工作中，我们主要关注图像分类领域内的不确定性。我们探索其量化的标准，并指出现有度量的陷阱。为了避免这些陷阱，我们对不同的加密技术进行了广泛的研究。为了在本研究中提供更深入的见解，我们引入了深度系综等价分数（DEE），并证明许多复杂的系综技术在测试性能方面等同于仅由少数几个独立训练的网络组成的系综。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06470">PDF</a>
<h3>No. 132	高分辨率网：卫星图像多帧超分辨率的递归融合</h3><h4>Michel Deudon, Alfredo Kalaitzis, Israel Goytom, Md Rifat Arefin, Zhichao Lin, Kris Sankaran, Vincent Michalski, Samira E. Kahou, Julien Cornebise, Yoshua Bengio</h4>摘要：生成性深度学习已经引发了一股新的超分辨率（SR）算法浪潮，这种算法增强了单个图像，尽管具有虚构的细节，但其美学效果令人印象深刻。多帧超分辨率（MFSR）通过对多个低分辨率视图进行调节，为解决不适定问题提供了一种更为可靠的方法。这对于卫星监测人类对地球的影响——从毁林到侵犯人权——非常重要，而这些都依赖于可靠的图像。为此，我们提出了HighRes-net，这是MFSR的第一种深度学习方法，它以端到端的方式学习其子任务：（i）共注册，（ii）融合，（iii）上采样，和（iv）丢失时的注册。低分辨率视图的联合注册是通过参考帧通道隐式学习的，没有显式的注册机制。我们学习了一个全局融合算子，它递归地应用于任意数量的低分辨率对。通过学习通过ShiftNet将SR输出与一个基本事实对齐，我们引入了一个注册损失。研究表明，通过学习多视图的深度表示，可以对低分辨率信号进行超分辨率处理，提高对地观测数据的分辨率。我们的方法最近在欧洲航天局的实际卫星图像多功能遥感竞赛中名列前茅。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06460">PDF</a>
<h3>No. 133	相似选择的单调基数估计：一种深度学习方法</h3><h4>Yaoshu Wang, Chuan Xiao, Jianbin Qin, Xin Cao, Yifang Sun, Wei Wang, Makoto Onizuka</h4>摘要：由于深度学习技术在捕捉底层数据分布方面的突出能力，近年来被广泛应用于一系列传统的数据库问题中。本文探讨了利用深度学习进行相似性选择基数估计的可能性。准确、高效地解决这一问题对于许多数据管理应用，特别是查询优化是至关重要的。此外，在某些应用中，估计的基数应该是一致的和可解释的。因此，首选单调估计w.r.t.查询阈值。提出了一种适用于任意数据类型和距离函数的通用方法。该方法由特征提取模型和回归模型组成。特征提取模型将原始数据和阈值转换为Hamming空间，利用基于深度学习的回归模型，利用基数w.r.t.的增量特性，使阈值具有精度和单调性。我们开发了适合我们的模型的训练策略以及快速估计的技术。我们还讨论了如何处理更新。我们通过实验证明了该方法的准确性和效率，并说明了它如何提高查询优化器的性能。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06442">PDF</a>
<h3>No. 134	潜在变量的后验比估计</h3><h4>Yulong Zhang, Mingxuan Yi, Song Liu, Mladen Kolar</h4>摘要：密度比估计由于能够比较两个数据集的潜在分布而受到机器学习界的关注。然而，在某些应用中，我们希望比较只能从观测中推断出的{潜在}随机变量的分布。本文研究了一个潜在变量的两个后验概率密度函数之比的估计问题。特别是，我们假设后验比率函数可以很好地近似由参数模型，然后使用观测数据集和合成先验样本估计。证明了当先验样本数趋于无穷大时，估计量的相合性和估计参数的渐近正态性。最后，我们用数值实验验证了我们的理论，并通过一些实际应用证明了该方法的有效性。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06410">PDF</a>
<h3>No. 135	混合引文：一种上下文感知引文推荐的混合模型</h3><h4>Michael Färber, Ashwath Sampath</h4>摘要：引文推荐系统旨在为一篇完整的论文或一小部分被称为引文上下文的文本推荐引文。引文推荐过程被称为局部引文推荐，是本文研究的重点。本文首先研究了基于嵌入、主题建模和信息检索技术的引文推荐方法。根据我们的知识，我们首次将性能最好的算法组合成半遗传混合推荐系统，用于引文推荐。我们基于多个数据集对单一方法和混合方法进行了离线评估，如微软学术图（MAG）和结合arXiv和ACL的MAG。我们进一步进行用户研究，以评估我们的在线方法。我们的评估结果表明，包含嵌入和基于信息检索的组件的混合模型比其单独的组件和进一步的算法有很大的优势。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06406">PDF</a>
<h3>No. 136	基于CNN的云IaaS行为恶意软件检测技术分析</h3><h4>Andrew McDole, Mahmoud Abdelsalam, Maanak Gupta, Sudip Mittal</h4>摘要：云基础设施即服务（IaaS）由于暴露于外部对手而容易受到恶意软件的攻击，使其成为恶意参与者获利颇丰的攻击载体。感染恶意软件的数据中心可能会导致数据丢失和/或对其用户的服务造成重大中断。本文分析比较了各种卷积神经网络（CNNs）在云IaaS恶意软件在线检测中的应用。该检测基于行为数据，使用进程级性能指标（包括cpu使用率、内存使用率、磁盘使用率等）执行。我们使用最先进的DenseNets和ResNets有效地检测在线云系统中的恶意软件。CNN的设计目的是从运行在真实云环境中的实时恶意软件收集的数据中提取特征。实验是在OpenStack（一个云IaaS软件）测试台上进行的，这个测试台被设计用来复制一个典型的3层web架构。对本研究中使用的不同CNN模型的不同度量进行了比较分析。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06383">PDF</a>
<h3>No. 137	眼底图像病变自动分割与病理性近视分类</h3><h4>Cefas Rodrigues Freire, Julio Cesar da Costa Moura, Daniele Montenegro da Silva Barros, Ricardo Alexsandro de Medeiros Valentim</h4>文摘：本文提出了病理性近视（PM）的诊断算法，并对视网膜结构和病变如视神经盘（OD）、中央凹、萎缩、脱离等进行了检测。所有这些任务都是在PM患者的眼底成像中完成的，它们是参与病理性近视挑战（PALM）的必要条件。这项挑战是在意大利威尼斯举行的IEEE生物医学成像国际研讨会的卫星活动，为期半天。我们的方法在每项任务中应用不同的深度学习技术。所有任务都采用迁移学习，以异常为基线模型。同时，将YOLO结构的一些关键思想应用到光盘分割算法流水线中。我们根据AUC-ROC、F1分数、平均骰子分数和平均欧几里德距离的挑战规则来评估模型的性能。对于初始活动，我们的方法显示了令人满意的结果。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06382">PDF</a>
<h3>No. 138	基于物联网的大城市交通数据挖掘系统</h3><h4>Daniel. Firouzimagham, Mohammad. Sabouri, Fatemeh. Adhami</h4>摘要：目前，在包括伊朗在内的发展中国家，由于人口的增长，汽车的数量在不断增加。最近，这导致浪费时间陷入交通堵塞，每天上下班的时间增加，事故增加。因此，有必要由交警来控制交通拥堵，有效地拓宽道路，选择减少市民交通的最佳途径。因此，掌握每条车道上的瞬时交通量是很重要的。今天，许多交通组织服务，如交警和城市交通控制系统，使用交通摄像机、感应传感器、卫星图像、雷达传感器、超声波技术和射频识别（RFID）进行城市交通诊断。但该方法存在着受大气条件影响大流量时效率不高、无法检测出平行交通等问题。本文提出的基于物联网的交通拥堵检测方法，包含一个智能系统，通过计算该区域的空气污染量来检测交通拥堵。经实验验证，结果令人满意。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06374">PDF</a>
<h3>No. 139	UniViLM：多模态理解和生成的统一视频和语言预训练模型</h3><h4>Huaishao Luo, Lei Ji, Botian Shi, Haoyang Huang, Nan Duan, Tianrui Li, Xilin Chen, Ming Zhou</h4>文摘：提出了统一的视频和语言预训练模型UniViLM，用于多模态理解和生成。针对近年来基于BERT的NLP和图像语言预训练技术的成功应用，VideoBERT和CBT提出了一种基于叙事教学视频的视频和语言预训练BERT模型。与他们只进行理解任务预训练的工作不同，我们提出了一个统一的视频语言理解和生成任务预训练模型。我们的模型由4个部分组成，包括两个单模式编码器、一个交叉编码器和一个带变压器主干的解码器。我们首先对我们的模型进行预训练，以学习大型教学视频数据集上视频和语言的通用表示。然后，我们对模型进行了两个多模式任务的微调，包括理解任务（基于文本的视频检索）和生成任务（多模式视频字幕）。大量的实验表明，该方法可以提高理解任务和生成任务的性能，达到了最新的效果。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06353">PDF</a>
<h3>No. 140	基于条件循环一致对抗网络的多对多语音转换</h3><h4>Shindong Lee, BongGu Ko, Keonnyeong Lee, In-Chul Yoo, Dongsuk Yook</h4>摘要：语音转换是指在不改变话语语言内容的情况下，改变话语的说话人特征。许多关于语音转换的工作都需要并行训练数据，而这些数据的获取成本很高。近年来，循环一致对抗网络（cycle-consistent particial network，CycleGAN）已被应用于语音转换领域，显示了其最新的性能。然而，基于CycleGAN的语音转换只能用于一对扬声器，即两个扬声器之间的一对一语音转换。在本文中，我们通过调节扬声器上的网络来扩展CycleGAN。结果表明，该方法可以在一个生成性对抗网络（GAN）上实现多个说话人之间的多对多语音转换。与为每对扬声器建立多个循环相比，该方法在不影响转换语音质量的前提下，显著降低了计算和空间开销。基于VCC2018语料库的实验结果验证了该方法的有效性。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06328">PDF</a>
<h3>No. 141	基于小能量掩蔽的端到端语音识别改进神经网络训练</h3><h4>Chanwoo Kim, Kwangyoun Kim, Sathish Reddy Indurthi</h4>文摘：本文提出了一种小能量掩蔽（SEM）算法，它屏蔽了输入值低于某一阈值的情况。更具体地说，如果滤波器组能量小于某个能量阈值，则屏蔽时频滤波器组。采用均匀分布的方法，随机产生该能量阈值与每个话语的峰值滤波器组能量之比（分贝）。通过此掩蔽过程，将缩放未掩蔽的特征元素，以便特征值的总和保持不变。这个非常简单的算法在标准LibriSpeech测试clean和测试其他集上的字错误率（WER）分别比基线端到端语音识别系统提高了11.2%和13.5%。此外，与输入-退出算法相比，SEM算法在同一LibriSpeech test clean和test-other集上分别提高了7.7%和11.6%。采用改进的变压器LM浅熔技术，在LibriSpeech试验清洁集上获得了2.62%的功率，在LibriSpeech试验其他集上获得了7.87%的功率。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06312">PDF</a>
<h3>No. 142	军团：最佳的首次混合测试</h3><h4>Dongge Liu, Gidon Ernst, Toby Murray, Benjamin I. P. Rubinstein</h4>摘要：军团是一种灰盒混合工具，旨在平衡模糊和符号执行的互补性，以达到两者的最佳效果。提出了蒙特卡罗树搜索（MCTS）的一种新方法，即在不确定性条件下，在最优优先搜索策略的指导下，将程序探索定义为顺序决策。它依赖于近似路径保持模糊化，一种新的约束随机测试实例，它快速生成许多可能针对感兴趣的程序部分的不同输入。在2020年的测试中，该原型在22个类别中有9个类别的最佳分数的90%以内完成。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06311">PDF</a>
<h3>No. 143	基于反对称SoftMax近似的极值分类</h3><h4>Robert Bamler, Stephan Mandt</h4>摘要：在大量的类上训练分类器，即所谓的“极端分类”，已经成为技术、科学和电子商务应用中的一个重要课题。传统的softmax回归会导致与类数成正比的梯度成本$C$，这通常是非常昂贵的。一种流行的可扩展的SUMTTMAX近似依赖于均匀的负采样，其由于信噪比较差而收敛缓慢。本文提出了一种简单的训练方法，通过从模拟数据分布的对抗模型中提取负样本来显著增强梯度信号。我们的贡献是三方面的：（i）一种对抗性采样机制，它以成本仅为对数（单位：加元）生成负样本，从而仍然导致廉价的梯度更新；（ii）一个数学证明，这种对抗性采样可以最小化梯度方差，而非均匀采样造成的任何偏差都可以消除；（iii）在大规模数据集上的实验结果表明，相对于几个竞争基线，训练时间减少了一个数量级。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06298">PDF</a>
<h3>No. 144	基于面分裂的超图高阶共现张量</h3><h4>Bryan Bischof</h4>文摘：计算成对共生矩阵的一个常用技巧是关联矩阵及其转置的乘积。我们提出了一种模拟高阶元组共现的方法，使用面分裂积，或者称为转置Khatri-Rao积。这些高阶共现编码了令牌与其他令牌的共同性，从而概括了共同研究的信息。我们通过一个流行的NLP模型和相似的超图模型来演示这个张量的使用。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06285">PDF</a>
<h3>No. 145	基于功能近红外光谱的深度学习精确应力评估</h3><h4>Mahya Mirbagheri, Ata Jodeiri, Naser Hakimi, Vahid Zakeri, Seyed Kamaledin Setarehdan</h4>摘要：压力是威胁人类健康的主要因素之一。为了通过分析大脑和心脏相关信号来评估或缓解压力，已经进行了大量的研究。本研究利用10名健康志愿者脑功能近红外光谱（fNIRS）所产生的信号，通过深度学习系统对蒙特利尔成像应激任务所诱发的应激进行评估。本文提出的深度学习系统主要由两部分组成：一是利用一维卷积神经网络建立信息特征映射。然后，用一组深全连接层预测应力存在概率。实验结果表明，训练后的fNIRS模型进行应力分类的准确率达到88.52-+0.77%。所提出的深度学习系统在FNIRS测量上的训练导致比在FNIRS研究中提出的现有方法中更高的应力分类精度，其中已经使用了相同的实验过程。该方法具有较好的稳定性和较低的预测偏差。此外，该方法计算量小，为实时应力评估提供了可能。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06282">PDF</a>
<h3>No. 146	Twin BERT：将知识提取到双结构BERT模型以实现高效检索</h3><h4>Wenhao Lu, Jian Jiao, Ruofei Zhang</h4>文摘：BERT等预训练语言模型在各种NLP任务中取得了巨大的成功，但其优越的性能对计算资源提出了更高的要求，阻碍了其在低延迟IR系统中的应用。本文提出了一种有效的twin BERT检索模型，该模型采用双结构的类BERT编码来分别表示查询和文档，并通过交叉层来组合嵌入，产生相似度得分。与BERT不同，TwinBERT将两个输入语句连接在一起并进行编码，在编码过程中对它们进行解耦，独立生成查询和文档所需的嵌入，这使得文档嵌入可以离线预计算并缓存在内存中。因此，留给运行时的计算仅来自查询编码和查询文档交叉。这种改变可以节省大量的计算时间和资源，从而显著提高服务效率。此外，本文还提出了一些精心设计的网络层和训练策略，进一步降低了计算量，同时保持了BERT模型的良好性能。最后，我们开发了两个版本的TwinBERT，分别用于检索和相关任务，它们都达到了与BERT基模型接近或相当的性能。该模型遵循师生框架进行训练，并使用一个主要搜索引擎的数据进行评估。实验结果表明，在cpu上，推理时间明显缩短，并首先控制在20ms左右，同时保留了微调BERT基模型的性能增益。将这些模型集成到生产系统中也证明了相关性度量的显著改进，对延迟的影响可以忽略不计。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06275">PDF</a>
<h3>No. 147	用于人脸识别的深卷积神经网络编码中的单单元状态：稀疏性的重新定义</h3><h4>Connor J. Parde, Y. Ivette Colón, Matthew Q. Hill, Carlos D. Castillo, Prithviraj Dhar, Alice J. O'Toole</h4>文摘：用于人脸识别的深卷积神经网络（DCNNs）在保留被试（如性别）和图像（如视点）信息的同时，发展了对可变图像的泛化表示。在人脸识别网络的“神经单元”和集成层上研究了身份、性别和视点编码。在单元层次上，通过删除单元在顶层创建可变大小的随机采样子空间来测量识别、性别分类和视点估计。3531个身份的识别仍然很高（ROC下面积约1），随着维度的下降，从512个单位减少到16个（0.95）、4个（0.80个）和2个（0.72个）单元。在每一个顶层单元上都有统计上分离的个体身份。跨单位反应的相关性最小，表明单位编码非冗余的身份线索。这种“分布式”代码只需要一个稀疏的、随机的单元样本就可以准确地识别人脸。随着维度的降低，性别分类逐渐下降，观点估计急剧下降。个体单位对性别和观点的预测能力很弱，但合奏被证明是有效的预测因素。因此，分布式和稀疏代码共存于网络单元中，以表示不同的面部属性。在集成层次上，人脸表示的主成分分析表明，身份、性别和视点信息被分解成高维子空间，按解释方差排序。身份、性别和观点信息对所有个体的反应都有贡献，削弱了面部特征的神经调节类比。从DCNNs和类似的高级视觉编码中对类神经编码的解释，不能从单个单位的反应中推断出来。相反，“意义”是由高维空间中的方向编码的。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06274">PDF</a>
<h3>No. 148	TPLVM：学生$t$-过程潜在变量模型的投资组合构建</h3><h4>Yusuke Uchiyama, Kei Nakagawa</h4>摘要：资产优化配置是现代金融理论中的一个重要课题。为了实现投资者规避风险的最优资产配置，人们提出了多种组合构建方法。近年来，机器学习在金融领域的应用迅速发展。本文提出用低维潜在变量描述金融时间序列非高斯波动的Student$t$-过程潜在变量模型（TPLVM）。随后，我们将TPLVM应用于最小方差组合，作为现有非线性因素模型的替代。为了检验所提出的投资组合的性能，我们构建了基于TPLVM或高斯过程潜在变量模型的全球股市指数的最小方差投资组合。通过比较这些投资组合，我们证实了所提出的投资组合优于现有的高斯过程隐变量模型。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06243">PDF</a>
<h3>No. 149	社会WaGDAT：基于Wasserstein图双注意网络的交互感知轨迹预测</h3><h4>Jiachen Li, Hengbo Ma, Zhihao Zhang, Masayoshi Tomizuka</h4>文摘：智能移动系统（如自主车辆和社会机器人）在高度交互性和拥挤的场景中导航时，对环境的有效理解和对周围动态障碍物的准确轨迹预测是实现安全、高质量规划的必要条件。由于场景演化中频繁交互和不确定性的存在，期望预测系统能够在不同实体上进行关系推理，并为每个代理提供未来轨迹的分布。本文提出了一个通用的多智能体轨迹预测生成神经系统（Social WaGDAT），该系统通过将关联归纳偏差与动态图表示相结合，同时利用轨迹和场景上下文信息，向显式交互建模迈进了一步。我们还采用了一个有效的运动约束层应用于车辆轨迹预测，不仅保证了物理上的可行性，而且提高了模型的性能。该系统在三个公共基准数据集上进行评估，用于轨迹预测，其中代理包括行人、骑自行车者和道路车辆。实验结果表明，该模型在预测精度方面优于各种基线方法。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06241">PDF</a>
<h3>No. 150	增强的局部敏感哈希：用于源分离的区分二进制代码</h3><h4>Sunwoo Kim, Haici Yang, Minje Kim</h4>摘要：随着深度学习技术的进步，语音增强任务得到了显著的改善，但是计算复杂度的增加也带来了代价。在本研究中，我们提出一种自适应的boosting方法来学习局部敏感的杂凑码，以有效地表示音频频谱。我们将学习的散列码用于单通道语音去噪任务，以替代复杂的机器学习模型，特别是解决资源受限的环境。我们的自适应boosting算法学习简单的logistic回归作为弱学习者。经过训练，他们的二值分类结果将每个测试噪声语音谱转换成一个位串。简单的位运算计算Hamming距离，在训练有噪语音谱的字典中找到K-最近匹配帧，其相关的理想二值掩码被平均以估计该测试混合的去噪掩码。我们提出的学习算法与AdaBoost的不同之处在于，训练投影的目的是最小化散列码的自相似矩阵与原始谱的自相似矩阵之间的距离，而不是降低误分类率。我们评估我们的歧视性哈希码的TIMIT语料库与各种噪声类型，并表现出比较深刻的学习方法在降噪性能和复杂性方面的性能。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06239">PDF</a>
<h3>No. 151	波斯语社交媒体中情感分析的卷积神经网络</h3><h4>Morteza Rohanian, Mostafa Salehi, Ali Darzi, Vahid Ranjbar</h4>摘要：随着社会化媒体参与度的不断提高，由此产生的数据可以作为分析和理解我们周围不同现象的丰富资源。情绪分析系统利用这些数据来发现社交媒体用户对给定文档中某些实体的态度。本文提出了一种基于前向人工神经网络卷积神经网络（CNN）的波斯语文本情感分析方法，该方法通过不同的滤波器对输入数据进行一层卷积，将句子分为两类和五类（考虑其强度）。我们使用曲线下面积度量对三个不同的波斯社交媒体文本数据集进行了评估。最后的结果显示了使用CNN在开发波斯文本情感分类特别是短文本的传统机器学习方法方面的优势。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06233">PDF</a>
<h3>No. 152	甘斯的Top-K培训：通过减少批评来改进发电机</h3><h4>Samarth Sinha, Anirudh Goyal, Colin Raffel, Augustus Odena</h4>文摘：我们对生成性对抗网络（GAN）训练算法进行了一个简单的（一行代码）修改，在不增加计算成本的情况下显著地提高了训练结果：当更新生成器参数时，我们简单地从批元素中剔除梯度贡献，该批元素被批评者评为“最少”现实主义。通过对许多不同GAN变体的实验，我们表明这种top-k更新过程是一种普遍适用的改进。为了理解改进的本质，我们对一个简单的高斯混合数据集进行了广泛的分析，并发现了一些有趣的现象。其中之一是，当使用得分最差的批处理元素计算梯度更新时，实际上可以将样本推离其最近的模式更远。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06224">PDF</a>
<h3>No. 153	集成切片采样</h3><h4>Minas Karamanis, Florian Beutler</h4>文摘：切片抽样是一种功能强大的马尔可夫链蒙特卡罗算法，它以最小的手动调整适应目标分布的特点。但是，切片采样的性能对用户指定的初始长度比例超参数非常敏感。此外，切片取样通常难以处理低比例或强相关分布。本文介绍了一种新的集成切片采样算法，该算法通过自适应地调整长度尺度来避开这些困难。此外，集成切片采样的性能不受线性相关的影响。这些算法构造简单，无需人工调整，并且可以在并行计算环境中轻松实现。实验结果表明，与传统的MCMC方法相比，集成切片采样在高相关目标分布（如1阶自回归过程和相关漏斗分布）上可以提高效率一个数量级以上。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06212">PDF</a>
<h3>No. 154	注意事项2vec：神经注意用户表示</h3><h4>Oren Barkan, Avi Caciularu, Ori Katz, Noam Koenigstein</h4>文摘：推荐系统的因子分解方法倾向于将用户表示为单个潜在向量。但是，用户行为和兴趣可能会在向用户提供的建议的上下文中发生变化。例如，在电影推荐的情况下，以前的用户数据通常比最近的数据信息量少。然而，在一部流行的续集电影面前，某部早期电影可能会突然变得更加相关。这只是一个例子，展示了在潜在的新建议出现时，各种可能动态改变用户兴趣的情况。在这项工作中，我们提出了注意项2vec（a I2V）-一个新的注意项2vec（I2V）的版本。AI2V采用上下文-目标-注意机制，以学习和捕捉用户历史行为（上下文）相对于潜在推荐项（目标）的不同特征。注意上下文目标机制使得最终的神经注意用户表示成为可能。我们在几个数据集上证明了AI2V的有效性，在这些数据集上，AI2V的性能优于其他基线。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06205">PDF</a>
<h3>No. 155	参数模态回归的隐函数学习方法</h3><h4>Yangchen Pan, Ehsan Imani, Martha White, Amir-massoud Farahmand</h4>文摘：对于多值函数，如给定输入的目标上的条件分布是多模态的，标准回归方法并不总是可取的，因为它们提供了条件均值。模态回归的目的是寻找条件模态，但仅限于非参数方法。这样的方法很难缩放，不能受益于参数函数逼近，如神经网络，它可以学习复杂的输入和目标之间的关系。在这项工作中，我们提出了一个参数化的模态回归算法，利用隐函数定理来发展一个学习输入和目标联合参数化函数的目标。我们在几个综合问题上的经验证明，我们的方法（i）可以学习多值函数并产生条件模式，（ii）可以很好地扩展到高维输入，（iii）对于某些单峰问题更有效，特别是对于高频数据，输入和目标之间的联合函数可以更好地捕捉它们之间的复杂关系。然后我们证明我们的方法在实际的模态回归问题中是实用的。我们的结论是，我们的方法对目标上具有不对称分布的两个回归数据集提供了小的改进。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06195">PDF</a>
<h3>No. 156	分段凸函数估计与模型选择</h3><h4>Kurt S. Riedel</h4>文摘：在给定噪声数据的情况下，当未知函数先验地由少数凸或凹区域组成时，考虑函数估计。当区域先验已知时，该估计在对偶空间中降为有限维凸优化。当区域的数目未知时，模型选择问题是确定凸性变化点的数目。我们使用基于期望的假拐点数目的导频估计器。<br><a href = "http://xxx.itp.ac.cn/pdf/1803.03903">PDF</a><h2>2020-02-18</h2>
<h3>No. 1	再培训还是不培训？--深CNN网络的有效剪枝方法</h3><h4>Marcin Pietron, Maciej Wielgosz</h4>摘要：卷积神经网络（CNN）在图像分类、目标检测、语义分割等图像处理任务中发挥着重要作用。CNN网络通常有几百个堆叠的层和几兆字节的权重。减少复杂性和内存占用的一种可能方法是修剪。剪枝是一个去除网络中连接两个相邻层神经元的权值的过程。当DL模型具有较高的卷积层数时，寻找具有指定精度下降的近似最优解的过程会更加复杂。本文对基于再培训和非再培训的几种方法进行了描述和比较。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07051">PDF</a>
<h3>No. 2	多任务协同智能的位分配</h3><h4>Saeed Ranjbar Alvar, Ivan V. Bajić</h4>文摘：近年来的研究表明，协作智能（CI）是一种很有前途的在移动设备上部署基于人工智能（AI）的服务的框架。在CI中，在移动设备和云之间分割出一个深层神经网络。在移动设备上获得的深层特征被压缩并传输到云端以完成推理。到目前为止，文献中的方法主要集中在将单个深度特征张量从移动设备转移到云上。这种方法不适用于一些具有多分支和跳跃连接的高性能网络。本文提出了多流、多任务CI的第一位分配方法。我们首先建立了一个多个任务的联合失真模型，作为分配给不同深度特征张量的比特率的函数。然后，利用该模型求解了总速率约束下的速率失真优化问题，得到了待传输张量之间的最优速率分配。实验结果表明，与几种不同的比特分配方法相比，该方案是有效的。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07048">PDF</a>
<h3>No. 3	基于图像结构的对象变形测试</h3><h4>Adrian Wildandyawan, Yasuharu Nishi</h4>摘要：由于需要大量生成测试用例并为其提供测试oracle，测试软件往往成本高昂。这通常被称为oracle问题。为了缓解oracle问题，人们提出了一种方法：变形测试。变质测试通过改变现有的测试用例来产生新的测试用例，并利用被测试系统（SUT）的输入和输出之间的变质关系来预测所产生的测试用例的预期输出。变形测试通常用于图像处理软件，其中对图像的属性应用更改以创建带有与原始图像相同的注释的新测试用例。我们将现有的方法称为基于图像的变形测试。在本研究中，我们提出一个基于物件的变质主义测试和一个复合变质主义测试，结合不同的变质主义测试方法，以相对增加测试覆盖率。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07046">PDF</a>
<h3>No. 4	深部张量压缩的前后预测</h3><h4>Hyomin Choi, Robert A. Cohen, Ivan V. Bajic</h4>摘要：近年来人工智能的应用，如协同智能和神经网络，涉及到在不同的计算设备之间传递深层特征张量。这就需要张量压缩来优化设备之间带宽受限信道的使用。本文提出了一种针对深特征张量的预测方案，称为前后（BaF）预测，它能显著减小张量的大小，提高张量的压缩性。我们使用最先进的目标检测器进行的实验表明，所提出的方法可以显著减少压缩从模型内部深层提取的特征张量所需的比特数，而检测性能的退化可以忽略不计，并且不需要重新训练网络权值。在保证网络精度损失分别小于1%和2%的情况下，张量减小了62%和75%。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07036">PDF</a>
<h3>No. 5	为知识跟踪提供适当的查询、键和值计算</h3><h4>Youngduck Choi, Youngnam Lee, Junghyun Cho, Jineon Baek, Byungsoo Kim, Yeongmin Cha, Dongmin Shin, Chan Bae, Jaewe Heo</h4>摘要：知识追踪是计算机辅助教育领域中一个广泛研究的问题，是通过学习活动来模拟学生知识的行为。尽管带有注意机制的模型比传统的方法（如贝叶斯知识跟踪和协作过滤）有更好的性能，但它们有两个共同的局限性。首先，这些模型依赖于浅层的注意力，无法捕捉到随着时间推移练习和反应之间的复杂关系。其次，没有广泛探讨用于知识追踪的自我注意层的查询、键和值的不同组合。通常将练习和交互（练习-响应对）分别用作查询和键/值的做法缺乏经验支持。本文提出了一种新的基于变压器的知识跟踪模型SAINT：分离自关注神经知识跟踪。SAINT具有编译码结构，其中运动和响应嵌入序列分别进入编码器和解码器，允许多次堆叠注意层。据我们所知，这是第一个提出一个用于知识跟踪的编码器-解码器模型的工作，该模型将深层的自我关注层分别应用于练习和响应。对一个大规模知识跟踪数据集的实证评估表明，SAINT在知识跟踪方面取得了最新的性能，与现有的最新模型相比，AUC提高了1.8%。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07033">PDF</a>
<h3>No. 6	基于多元时间序列分类的结构健康监测全卷积网络</h3><h4>Luca Rosafalco, Andrea Manzoni, Stefano Mariani, Alberto Corigliano</h4>文摘：提出了一种新的结构健康监测方法，旨在从普适传感器系统获取的数据中自动识别损伤敏感特征。将损伤检测和定位问题描述为分类问题，并通过完全卷积网络（FCNs）进行处理。基于物理模型（扮演被监控结构的数字孪生兄弟角色）的数值模拟数据，针对不同的损伤场景，对所提出的网络体系结构进行监督训练。基于这种简化的结构模型，在FCN的训练阶段考虑了多种载荷条件，设计了FCN的结构来处理不同长度的时间序列。神经网络的训练是在监测系统开始工作之前完成的，因此能够进行实时损伤分类。以八层剪力楼为算例，在两种荷载作用下，对该方法的数值性能进行了评估，其中一种荷载作用是模拟低能地震引起的随机振动。在结构响应中加入测量噪声，以模拟实际监测系统的输出。显示了非常好的分类能力：在九种可能的备选方案中（以健康状态和任何楼层的损伤为代表），损伤在高达95%的情况下被正确分类，从而显示了所提出的方法在实际应用中的强大潜力。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07032">PDF</a>
<h3>No. 7	眼跟踪数据处理中的强化学习</h3><h4>Wolfgang Fuhl</h4>文摘：提出了一种基于强化学习的眼动跟踪数据处理方法。它基于两个相反的代理，其中一个代理试图正确分类数据，另一个代理在数据中寻找模式，这些模式被操纵以隐藏特定信息。我们证明我们的方法是成功地适用于保护一个主题的隐私。此外，我们的方法可以评估眼睛跟踪数据的时间和空间信息对于特定分类目标的重要性。一般来说，这种方法也可用于刺激操作，使其对注视引导感兴趣。为此，本文提供了理论依据，这也是为什么我们还整合了一节如何应用这种方法进行凝视引导。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06806">PDF</a>
<h3>No. 8	基于w-LPPD-SVM集成的嵌入式稀疏自编码器</h3><h4>Yongming Li, Yan Lei, Pin Wang, Yuchuan Liu</h4>文摘：深度学习是一种具有强非线性特征变换的特征学习方法，在人工智能的许多领域中越来越重要。深度自动编码器是深度学习方法的代表方法之一，能够有效地提取数据集的抽象信息。但是，在深度特征变换过程中没有考虑深度特征与原始特征之间的互补性。此外，它还存在小样本问题。为了解决这些问题，本文提出了一种新的深度自动编码器-混合特征嵌入式叠置稀疏自动编码器（HESSAE）。在训练过程中，HFESAE能够通过嵌入原始特征来过滤弱隐层输出，从而学习鉴别深层特征。针对小样本问题限制了抽象信息的类表示能力的问题，设计了一种将HFESAE学习到的抽象信息与原始特征相结合，获得混合特征进行特征约简的特征融合策略。该策略是基于L1正则化的混合特征选择策略，其次是支持向量机（SVM）集成模型，在每个基分类器上设计并使用加权局部判别保持投影（w_-LPPD）。最后，利用几个具有代表性的公共数据集验证了算法的有效性。实验结果表明，所提出的特征学习方法与现有和最先进的特征学习算法（包括一些有代表性的深度自编码方法）相比，具有更好的性能。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06761">PDF</a>
<h3>No. 9	分散数据的神经结构搜索</h3><h4>Mengwei Xu, Yuxin Zhao, Kaigui Bian, Gang Huang, Qiaozhu Mei, Xuanzhe Liu</h4>摘要：为了保护用户隐私，同时实现移动智能，人们提出了在分散数据上训练深层神经网络的技术。然而，对分散数据的训练使得神经结构的设计变得相当困难。在为异构移动平台设计和部署不同的神经体系结构时，这种困难进一步扩大。在这项工作中，我们提出了一个自动神经架构搜索到分散训练，作为一个新的DNN训练范例称为联邦神经架构搜索，即联邦NAS。为了解决客户端计算和通信资源有限的主要挑战，我们提出了一个高效联邦NAS的高度优化框架FedNAS。FedNAS充分利用了体系结构搜索过程中模型候选重新训练不足的关键机会，并结合了三个关键优化：部分客户端上的并行候选训练、性能较差的候选提前丢弃和动态轮数。FedNAS在大规模数据集和典型CNN体系结构上进行了测试，它达到了与最先进的NAS算法相当的模型精度，该算法使用集中数据训练模型，并且与联邦NAS的直接设计相比，它还将客户机成本降低了两个数量级。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06352">PDF</a>
<h3>No. 10	运动皮层刺激与肌肉反应的映射：一种深部神经网络建模方法</h3><h4>Md Navid Akbar, Mathew Yarossi, Marc Martinez-Gost, Marc A. Sommer, Moritz Dannhauer, Sumientra Rampersad, Dana Brooks, Eugene Tunik, Deniz Erdoğmuş</h4>文摘：深部神经网络（DNN）能够可靠地模拟相应脑刺激引起的肌肉反应，有可能为许多基础科学和应用案例增加协调运动控制的知识。这些案例包括了解由于中风造成的神经损伤而导致的异常运动模式，以及基于刺激的神经康复干预措施，如成对联合刺激。在这项工作中，我们探索了潜在的DNN模型，并推荐了最小平方误差的模型来优化M2M网络的性能，M2M网络是一个将运动皮层的经颅磁刺激映射到相应肌肉反应的网络，使用：有限元模拟，经验神经反应曲线，卷积自动编码器，一个单独的深度网络映射器，和多肌肉激活的记录。我们讨论了不同建模方法和架构背后的基本原理，并对比了它们的结果。此外，为了获得复杂性和性能分析之间的权衡的比较洞察力，我们探索不同的技术，包括扩展的两个经典的信息标准M2M网。最后，我们发现，当输入端使用神经反应曲线时，类似于将运动皮层刺激映射为与肌肉直接和协同连接的组合的模型表现最佳。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06250">PDF</a>
<h3>No. 11	精密浇口：动态双精度激活提高神经网络效率</h3><h4>Yichi Zhang, Ritchie Zhao, Weizhe Hua, Nayun Xu, G. Edward Suh, Zhiru Zhang</h4>文摘：提出了一种适用于深部神经网络的端到端可训练动态双精度量化技术——精密选通（PG）。PG以较低的精度计算大多数特征，而以较高的精度计算只有一小部分重要特征以保持精度。该方法适用于多种DNN体系结构，大大降低了DNN执行的计算成本，几乎没有精度损失。我们的实验表明，PG在CNNs上取得了很好的效果，包括静态压缩的移动友好网络，如ShuffleNet。与目前最先进的基于预测的量化方案相比，PG在ImageNet上的计算量减少了2.4美元，达到了相同或更高的精度。PG还适用于RNNs。与8位均匀量化相比，PG在PNN树银行数据集上对每一个字的困惑获得了1.2%的改善，2.7的计算成本降低了LSTM。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07136">PDF</a>
<h3>No. 12	基于深度学习视觉分类的物理硬标签查询攻击</h3><h4>Ryan Feng, Jiefeng Chen, Nelson Manohar, Earlence Fernandes, Somesh Jha, Atul Prakash</h4>文摘：提出了一种在黑盒硬标签设置中的物理对抗示例算法生存选择算法，攻击者只能访问模型预测类标签。假设这种对模型的有限访问与之前的工作假设的白盒设置相比，对于专有网络物理和云系统等设置更为相关。利用物理攻击的特性，提出了一种基于物理变换扰动生存性的攻击方法。通过简单地查询硬标签预测模型，我们优化扰动以在许多不同的物理条件下生存，并表明即使在硬标签威胁模型中，对抗性示例仍然是网络物理系统（cps）的安全风险。我们证明了Survival OPT是一种高效且健壮的查询方法：使用少于200K的查询，我们成功地通过设置在98.5%的视频帧中攻击了一个被误分类为限速30km/hr的停车标志。生存OPT也优于现有的硬标签和物理方法的基线组合，这需要超过10倍的查询来获得不太健壮的结果。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07088">PDF</a>
<h3>No. 13	PCSGAN：用于热图像和近红外图像到可见光图像转换的感知循环合成生成对抗网络</h3><h4>Kancharagunta Kishan Babu, Shiv Ram Dubey</h4>摘要：在现实生活中，由于光照条件的影响，在可见光光谱中很难捕捉到图像。然而，在这种情况下，可以使用近红外（NIR）和热（THM）摄像机拍摄图像。近红外和THM图像包含有限的细节。因此，需要将图像从THM/NIR转换为VIS，以便更好地理解。然而，由于存在较大的领域差异和缺乏丰富的数据集，这是一项非平凡的任务。目前，生成性对抗网络（generativedepartarialnetwork，GAN）能够将图像从一个域转换到另一个域。现有的基于GAN的训练方法大多采用对抗性和像素损失（如L1或L2）相结合的方法作为训练目标函数。在THM/NIR-VIS变换的情况下，用这种目标函数变换后的图像质量仍然达不到要求。因此，需要更好的目标函数来提高变换图像的质量、细节和真实感。为了解决这一问题，提出了一种新的THM/NIR-VIS图像转换模型：感知循环合成生成对抗网络（PCSGAN）。PCSGAN使用感知（即基于特征的）损失、像素损失和对抗性损失的组合。采用定量和定性方法对PCSGAN模型在WHU-IIP人脸和RGB-NIR场景数据集上的性能进行了评价。所提出的PCSGAN在SSIM、MSE、PSNR和LPIPS评价指标方面优于现有的图像转换模型，包括Pix2pix、DualGAN、CycleGAN、PS2GAN和PAN。代码可在以下位置获得：url{this https url}。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07082">PDF</a>
<h3>No. 14	基于神经网络处理器结构的批处理加速优化调度体系结构</h3><h4>Phani Kumar Nyshadham, Mohit Sinha, Biswajit Mishra, H S Vijay</h4>摘要：在神经网络拓扑中，算法是在成批的数据张量上运行的。数据批通常被调度到并行执行的计算核心上。对于运行在成批数据上的算法，通过适当利用硬件资源，需要一个最优的成批调度体系结构，从而大大减少训练和推理时间。在本文中，我们建议通过一个调度架构来加速神经网络的批处理算法，以实现最佳的计算功率利用率。所提出的优化调度体系结构可以构建在硬件中，也可以单独在软件中实现，这可以用来加速批处理算法。结果表明，与以往的算法相比，该结构加快了批处理算法的速度。所提出的思想适用于任何用于神经网络的HPC架构。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07062">PDF</a>
<h3>No. 15	用于音乐源分离的元学习提取器</h3><h4>David Samuel, Aditya Ganeshan, Jason Naradowsky</h4>文摘：提出了一种基于分层元学习的音乐源分离模型（meta-TasNet），该模型使用生成器模型来预测单个提取器模型的权重。这样可以实现有效的参数共享，同时还允许特定于仪器的参数化。Meta-TasNet被证明比独立训练或多任务环境下训练的模型更有效，并且实现了与最新方法相当的性能。与后者相比，我们的提取器包含的参数更少，运行时性能更快。我们讨论了重要的架构考虑因素，并探讨了这种方法的成本和好处。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07016">PDF</a>
<h3>No. 16	二进制网络的学习结构</h3><h4>Kunal Pratap Singh, Dahyun Kim, Jonghyun Choi</h4>摘要：大多数二进制网络的骨干结构都是著名的浮点结构，如ResNet家族。针对浮点网络的体系结构不适合二进制网络的问题，我们提出了二进制网络体系结构（BNAS）的搜索方法。具体来说，在基于单元的搜索方法的基础上，我们定义了一组新的层类型，设计了一个新的单元模板，重新发现了零层的实用性，并提出使用零层来学习性能良好的二进制网络。此外，我们建议多样化的早期搜索，以学习性能更好的二进制架构。我们的搜索二进制网络在CIFAR10和ImageNet数据集上的性能优于最新的二进制网络。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06963">PDF</a>
<h3>No. 17	引文推荐：方法和数据集</h3><h4>Michael Färber, Adam Jatowt</h4>摘要：引文推荐是指对给定文本进行引文推荐的任务。由于近年来发表的科学著作一方面超载，另一方面在撰写科学文本时需要引用最合适的出版物，引文推荐已成为一个重要的研究课题。近年来，提出了几种方法和评价数据集。然而，据我们所知，没有对引文推荐进行明确的文献调查。本文对引文自动推荐的研究进行了深入的介绍。然后，我们对引文推荐的方法和数据集进行了概述，并使用不同的维度确定了差异和共性。最后，我们对评估方法进行了说明，并概述了评估中的一般挑战以及如何应对这些挑战。我们仅限于科学出版物的引文推荐，因为这类文献在这方面的研究最多。然而，本次调查中的许多观察和讨论也适用于其他类型的文本，如新闻文章和百科全书文章。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06961">PDF</a>
<h3>No. 18	放大神秘</h3><h4>Terence Broad, Frederic Fol Leymarie, Mick Grierson</h4>摘要：深度神经网络在制造逼真的深度假象方面已经变得非常出色，人们的图像（对未经训练的人来说）与真实的图像无法区分。这些是由学习区分真假图像的算法生成的，并经过优化以生成系统认为真实的样本。本文，以及由此产生的一系列艺术作品被挫败，探索了逆转这一过程，而不是优化系统，以产生它认为是假的图像的审美结果。最大化数据的不可能性，进而放大这些机器幻觉的不可思议性质。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06890">PDF</a>
<h3>No. 19	基于可解释神经网络回归的大型生物测量学</h3><h4>Taro Langner, Håkan Ahlström, Joel Kullberg</h4>摘要：英国生物银行的这项研究成功地为32000多名志愿者进行了颈部到膝盖的身体核磁共振成像。每次扫描都链接到大量的元数据，提供了对成像解剖学和相关健康状态的全面调查。尽管有研究的潜力，但这大量的数据对现有的评估方法提出了挑战，这些方法通常依赖于人工输入。迄今为止，心血管和代谢危险因素的参考值范围还不完整。在这项工作中，神经网络被训练用于回归，以自动推断从颈部到膝盖的身体MRI的各种生物学指标。该方法无需人工干预或地面真相分割训练。研究领域涉及64个变量，这些变量来自人体测量、双能X射线吸收测量（DXA）、基于图谱的分割和专用肝脏扫描。标准化框架与ResNet50进行了7倍交叉验证，与目标值（中值R^2>0.97）非常吻合。对聚合显著性地图的解释表明，该网络正确地针对特定的身体区域和四肢，并学会了模拟不同的模式。在几个身体成分指标上，预测的质量在已建立的金标准技术之间观察到的变异范围内。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06862">PDF</a>
<h3>No. 20	抽象视觉推理的层次规则归纳网络</h3><h4>Sheng Hu, Yuqing Ma, Xianglong Liu, Yanlu Wei, Shihao Bai</h4>摘要：抽象推理是指对信息进行分析，在无形的层面上发现规律，以创新的方式解决问题的能力。Raven的渐进矩阵（RPM）测试通常用于检查抽象推理的能力。在测试中，要求受试者根据矩阵中的基本规则，从答案集中确定正确的选择，以填充RPM右下角缺少的面板（例如，3$\times$3矩阵）。近年来，利用卷积神经网络（CNNs）的优势，在解决转速测试问题上取得了可喜的进展。不幸的是，仅仅依赖于矩阵级的关系抽取，他们无法识别RPM中行/列内部或跨行/列的复杂属性模式。为了解决这一问题，本文提出了一种层次化的规则归纳网络（HriNet），它通过暗示人类的归纳策略。HriNet从不同层次提取多粒度规则嵌入，并通过门控嵌入融合模块进行集成。我们进一步引入了一种基于嵌入的规则相似度度量，使得HriNet不仅可以利用元组损失进行训练，而且可以根据相似度得分推断出最佳答案。为了全面评估HriNet，我们首先修复了最近RAVEN数据集中包含的缺陷，并生成了一个新的称为Balanced RAVEN的数据集。然后在大规模数据集PGM和我们的平衡RAVEN上进行了大量的实验，结果表明HriNet在很大程度上优于最新的模型。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06838">PDF</a>
<h3>No. 21	歌手识别中伴奏的混淆</h3><h4>Tsung-Han Hsieh, Kai-Hsiang Cheng, Zhe-Cheng Fan, Yu-Ching Yang, Yi-Hsuan Yang</h4>摘要：歌手识别是一项重要的工作，有着广泛的应用。然而，由于许多问题，这项任务仍然具有挑战性。一个主要的问题是，在音乐制作中，背景器乐与人声混用的混淆因素。歌手识别模型可以学习从歌曲的器乐部分提取非声乐相关特征，如果歌手只在特定的音乐环境（例如，流派）中演唱。因此，当歌手在看不见的环境中演唱时，这个模型就不能很好地概括。在本文中，我们试图解决这个问题。具体来说，我们使用开源的unmix工具，一个在源代码分离方面具有最先进性能的开源工具，来分离音乐的声乐和器乐曲目。然后，我们研究了两种方法来训练歌手识别模型：仅从分离的人声中学习，或从一组增加的数据中“洗牌和混音”不同歌曲的分离的人声轨迹和器乐轨迹，以人为地使歌手在不同的上下文中演唱。我们还结合了从声乐旋律轮廓学习到的旋律特征，以获得更好的表现。在一个名为artist20的基准数据集上的评估结果表明，这种数据增强方法大大提高了歌手识别的准确性。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06817">PDF</a>
<h3>No. 22	利用离线分析模拟ML系统的性能</h3><h4>Hongming Huang, Peng Cheng, Hong Xu, Yongqiang Xiong</h4>文摘：我们认为基于离线评测的仿真是一种有希望的方法，可以更好地理解和改进复杂的ML系统。我们的方法使用操作级分析和基于数据流的模拟，以确保为所有框架和ML模型提供一个统一和自动化的解决方案，并且通过考虑实际系统中的各种并行化策略也很精确。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06790">PDF</a>
<h3>No. 23	如何在业余时间拥有NAS</h3><h4>Sanghyun Hong, Michael Davinroy, Yiğitcan Kaya, Dana Dachman-Soled, Tudor Dumitraş</h4>摘要：新的数据处理管道和新的网络结构日益推动着深度学习的成功。因此，业界将性能最好的架构视为知识产权，并投入大量计算资源通过神经架构搜索（NAS）来发现此类架构。这为对手窃取这些新架构提供了激励；当在云中使用时，为了提供机器学习服务，对手也有机会通过利用一系列硬件侧通道来重建架构。然而，在不知道计算图（例如，层、分支或跳过连接）、结构参数（例如，卷积层中的滤波器数量）或特定预处理步骤（例如，嵌入）的情况下重建新的架构和管道是一项挑战。本文设计了一种新的深度学习系统的关键部件重构算法，该算法利用了缓存侧信道攻击Flush+Reload带来的少量信息泄漏。我们使用Flush+Reload来推断计算的轨迹和每次计算的时间。然后，我们的算法从跟踪中生成候选计算图，并通过参数估计过程消除不兼容的候选。我们在PyTorch和Tensorflow中实现了我们的算法。实验证明，我们可以重建MalConv（一种用于恶意软件检测的新型数据预处理管道）和ProxylessNAS-CPU（一种用于优化在CPU上运行的ImageNet分类的新型网络体系结构），而无需知道体系结构族。在这两种情况下，我们都会得到0%的误差。这些结果表明，硬件侧信道是一种实用的针对MLaaS的攻击载体，应进一步研究其对深度学习系统安全性的影响。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06776">PDF</a>
<h3>No. 24	正则化信息最大化的卷积神经网络超像素分割</h3><h4>Teppei Suzuki</h4>文摘：提出了一种在推理时间内优化随机初始化卷积神经网络（CNN）的无监督超像素分割方法。我们的方法通过CNN从没有任何标签的单一图像中生成超像素，通过最小化在推理时间内提出的超像素分割目标函数。与现有的许多方法相比，我们的方法有三个优点：（i）利用美国有线电视新闻网之前的图像进行超像素分割，（ii）根据给定的图像自适应地改变超像素的数量，以及（iii）通过向目标函数添加辅助成本来控制超像素的性质。我们在BSDS500和SBD数据集上定量和定性地验证了该方法的优势。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06765">PDF</a>
<h3>No. 25	高斯平滑语义特征（GSSF）——基于MSCOCO框架的印度语（孟加拉语）视觉字幕语言研究</h3><h4>Chiranjib Sur</h4>翻译后摘要：在这项工作中，我们引入了高斯平滑语义特征（GSSF）为更好的语义选择印度区域语言为基础的图像字幕，并介绍了一个过程中，我们使用现有的翻译和英语人群来源的句子进行培训。我们已经表明，这种体系结构是一种很有前途的替代资源，那里的资源紧张。我们的主要贡献是为孟加拉语（世界上第五种广泛使用的语言）开发具有完全不同语法和语言属性的深度学习架构。我们已经证明，这些方法对于复杂的应用程序（如从图像上下文生成语言）非常有效，并且可以通过引入约束、更广泛的特征和独特的特征空间使表示多样化。我们还证明，在传统的LSTM和特征分解网络中使用平滑语义张量可以获得绝对的精度和多样性。通过更好的学习架构，我们成功地建立了一个自动化的算法和评估程序，可以帮助评估合格的应用程序，而无需专业知识和人工干预。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06701">PDF</a>
<h3>No. 26	SBERT-WK：一种基于BERT模型的句子嵌入方法</h3><h4>Bin Wang, C.-C. Jay Kuo</h4>摘要：句子嵌入是自然语言处理（NLP）中的一个重要研究课题，它能将知识传递给下游任务。同时，一个被称为BERT的上下文化的单词表示在许多NLP任务中实现了最新的性能。然而，从基于BERT的词模型中生成高质量的句子表示是一个开放的问题。以往的研究表明，不同层次的BERT捕捉不同的语言属性。这使得我们可以跨层融合信息，以找到更好的句子表示。在这项工作中，我们研究了深层语境化模型的词表示的分层模式。然后，通过对单词表示所跨越的空间进行几何分析，对基于BERT的单词模型进行剖分，提出了一种新的句子嵌入方法。它被称为SBERT-WK方法。SBERT-WK无需进一步培训。我们评估了SBERT-WK的语义文本相似度和下游监督任务。此外，本文还提出了10个句子级的探究任务，用于详细的语言分析。实验表明，SBERT-WK达到了最先进的性能。我们的代码是公开的。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06652">PDF</a>
<h3>No. 27	最近邻规则的核心集</h3><h4>Alejandro Flores Velazco, David M. Mount</h4>文摘：最近邻凝聚问题是从一组标记点P中找到一个子集R，使得对于R中的每一个点P，P的最近邻R都具有与P相同的标记，这是由于分类应用的缘故，其中，最近邻规则将点集中最近邻的标签指定给未标记的查询点。在这种情况下，压缩的目的是减少对新点进行分类所需的集合的大小。然而，寻找这样的最小基数子集是NP困难的，而且大多数研究都集中在没有性能保证的实用启发式算法上。此外，总是使用精确的最近邻居，忽略了在最近的邻居被近似计算时的分类精度的影响。在本文中，我们提出这些缺点，提出新的近似敏感准则的最近邻凝聚问题，以及实用算法与可证明的性能保证。我们描述了足够的条件，保证正确分类未标记点使用近似最近邻查询这些子集，引入了概念集分类最近的邻居规则。此外，我们证明了具有这些特征的子集是NP难的，其基数近似于最小基数子集。此外，我们提出了新的算法来计算这样的子集，具有严格的近似因子在一般度量，以及改进因子倍度量和LpP度量与P>＝2。最后，我们展示了一种替代的实现方案，减少了最坏情况下的时间复杂度之一，这些算法，成为第一个真正的二次近似算法的最近邻凝聚问题。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06650">PDF</a>
<h3>No. 28	编解码框架下的语音转换</h3><h4>Jayneel Parekh, Preeti Rao, Yi-Hsuan Yang</h4>文摘：本文的目标是将一组口语台词转换成歌唱台词。与以往基于信号处理的方法不同，我们采用基于学习的方法来解决这个问题。这使我们能够自动地对转换的各个方面进行建模，从而克服对特定输入的依赖，例如高质量的歌唱模板或音素乐谱同步信息。具体来说，我们为我们的任务提出了一个编码器-解码器框架。给定语音的时频表示和目标旋律轮廓，我们学习编码，使我们能够综合歌唱，在遵守目标旋律的同时保留说话人的语言内容和音色。我们还提出了一个基于多任务学习的目标，以提高歌词的可懂度。我们对我们的框架进行了定量和定性分析。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06595">PDF</a>
<h3>No. 29	管道干预</h3><h4>Eshwar Ram Arunachaleswaran, Sampath Kannan, Aaron Roth, Juba Ziani</h4>文摘：介绍了由分层有向无环图和一组控制连续层间转换的随机矩阵定义的{管道干预}问题。这个图表是一个程式化的模型，用来描述来自不同人群的人们如何获得机会，最终获得某种回报。在我们的模型中，个体按照固定的概率分布出生在一个初始位置（即图的第一层中的某个节点），然后根据转移矩阵在图中随机前进，直到到达图的最后一层中的某个节点；最后一层中的每个节点都有一个与之关联的\emph{reward}。管道干预问题要求在预算约束下，如何通过图对控制人们随机转换的转换矩阵进行代价最大的更改。我们考虑两个目标：社会福利最大化，和公平动机最大值目标，寻求最大值的人口（起始节点）的EMPH{{}}期望值。我们考虑的最大值目标的两个变种，结果是不同的，这取决于我们是否需要确定性解决方案或允许随机化。对于每一个目标，我们给出了一个有效的近似算法（添加剂FPTAS）的恒定宽度网络。在我们的设置中，我们也严格地描述了“公平价格”：最高可实现的社会福利与最高社会福利之间的比率与最大值最优解的一致性。最后，我们表明，对于多项式宽度的网络，即使近似最大值目标到任何常数因子是NP-hard，即使对于具有恒定深度的网络。这说明在我们的实证结果中，对宽度的限制是必要的。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06592">PDF</a>
<h3>No. 30	将自然语言解析为一阶逻辑的神经模型探讨</h3><h4>Hrituraj Singh, Milan Aggrawal, Balaji Krishnamurthy</h4>摘要：语义分析是从自然语言文本中获取机器可解释表示的任务。我们考虑了一个这样的形式化表示-一阶逻辑（FOL），并探讨了神经模型在英语句子的FOL分析中的能力。我们将FOL分析建模为一个序列到序列的映射任务，在给定一个自然语言句子的情况下，它被编码成一个中间表示，使用LSTM，然后是一个解码器，解码器在相应的FOL公式中依次生成谓词。我们通过引入一种变量对齐机制来改进标准的编码器-解码器模型，使其能够在预测的FOL中跨谓词对齐变量。进一步证明了在每个解码器步骤中预测FOL实体Unary、二进制、变量和范围实体的类别的有效性，作为提高生成的FOL的一致性的辅助任务。我们进行严格的评估和广泛的消融。我们还将发布我们的代码以及大规模的FOL数据集和模型，以帮助进一步研究NLP中基于逻辑的解析和推理。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06544">PDF</a>
<h3>No. 31	隐私保护回归的分布式绘制方法</h3><h4>Burak Bartan, Mert Pilanci</h4>文摘：本文研究了大规模回归问题的分布式绘制方法。在异步分布式系统中，我们利用多个随机草图来减少问题的维数，同时保护隐私和提高散乱者的弹性。我们推导出新的近似保证经典草图方法，并分析参数的平均分布草图的准确性。在分布式环境下，我们考虑了随机矩阵，包括高斯、随机Hadamard、均匀采样和杠杆分数采样。此外，为了提高计算效率，我们提出了一种结合抽样和快速随机投影的混合方法。在无服务器计算平台上，通过大规模的实验验证了分布式草图的性能。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06538">PDF</a>
<h3>No. 32	学习为输入句子生成多种风格的转换输出</h3><h4>Kevin Lin, Ming-Yu Liu, Ming-Ting Sun, Jan Kautz</h4>摘要：文本风格转换是指以不同的风格对给定文本进行重新措辞的任务。虽然已经提出了各种方法来提高技术水平，但它们通常假设传输输出遵循delta分布，因此它们的模型无法为给定的输入文本生成不同的样式传输结果。为了解决这个问题，我们提出了一个一对多的文本风格转换框架。与以往学习将输入句子转换为输出句子的一对一映射的工作不同，我们的方法学习一对多映射，可以将输入句子转换为多个不同的输出句子，同时保留输入内容。这是通过使用潜在分解方案的对抗性训练来实现的。具体来说，我们将输入语句的潜在表示分解为捕获语言风格变化的样式代码和编码语言风格无关内容的内容代码。然后，我们将内容代码与样式代码相结合，以生成样式传输输出。通过将相同的内容代码与不同的样式代码组合，我们生成不同的样式传输输出。大量的实验结果与使用不同性能度量集的多个公共数据集上的几种文本样式传输方法进行了比较，验证了所提方法的有效性。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06525">PDF</a>
<h3>No. 33	盲对抗网络扰动</h3><h4>Milad Nasr, Alireza Bahramali, Amir Houmansadr</h4>文摘：深度神经网络（DNNs）由于其在很大程度上优于传统的（如统计）技术，因此被广泛应用于各种流量分析问题，如网站指纹识别和流量关联等。然而，深部神经网络很容易受到对抗性例子的攻击：由于小的对抗性扰动，模型错误地标记了对抗性输入到模型中。在本文中，我们首次证明对手可以通过在网络流量模式上应用对手扰动来击败基于DNN的流量分析技术。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06495">PDF</a>
<h3>No. 34	学习分组：一个自底向上的三维零件发现框架</h3><h4>Tiange Luo, Kaichun Mo, Zhiao Huang, Jiarui Xu, Siyu Hu, Liwei Wang, Hao Su</h4>摘要：我们解决了在不可见类别中发现物体的三维零件的问题。能够学习零件的几何先验知识，并将其转移到不可见的类别之前，对数据驱动的形状分割方法提出了根本性的挑战。作为一个上下文盗贼问题，我们提出了一个基于学习的聚集聚类框架，该框架学习一个分组策略，以自下而上的方式逐步将小部分提议分组为大的提议。我们方法的核心是限制用于提取零件级特征的局部上下文，这鼓励了对不可见类别的泛化。在大规模细粒度三维零件数据集PartNet上，我们证明了该方法可以在不看到任何标注样本的情况下，将从3个训练类别中学习到的零件知识转移到21个不可见的测试类别中。对四个形状分割基线的定量比较表明，我们的方法达到了最先进的性能。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06478">PDF</a>
<h3>No. 35	相似选择的单调基数估计：一种深度学习方法</h3><h4>Yaoshu Wang, Chuan Xiao, Jianbin Qin, Xin Cao, Yifang Sun, Wei Wang, Makoto Onizuka</h4>摘要：由于深度学习技术在捕捉底层数据分布方面的突出能力，近年来被广泛应用于一系列传统的数据库问题中。本文探讨了利用深度学习进行相似性选择基数估计的可能性。准确、高效地解决这一问题对于许多数据管理应用，特别是查询优化是至关重要的。此外，在某些应用中，估计的基数应该是一致的和可解释的。因此，首选单调估计w.r.t.查询阈值。提出了一种适用于任意数据类型和距离函数的通用方法。该方法由特征提取模型和回归模型组成。特征提取模型将原始数据和阈值转换为Hamming空间，利用基于深度学习的回归模型，利用基数w.r.t.的增量特性，使阈值具有精度和单调性。我们开发了适合我们的模型的训练策略以及快速估计的技术。我们还讨论了如何处理更新。我们通过实验证明了该方法的准确性和效率，并说明了它如何提高查询优化器的性能。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06442">PDF</a>
<h3>No. 36	混合引文：一种上下文感知引文推荐的混合模型</h3><h4>Michael Färber, Ashwath Sampath</h4>摘要：引文推荐系统旨在推荐一篇完整的论文或一小部分被称为引文上下文的文本的引文。引文推荐过程被称为局部引文推荐，是本文研究的重点。本文首先研究了基于嵌入、主题建模和信息检索技术的引文推荐方法。根据我们的知识，我们首次将性能最好的算法组合成半遗传混合推荐系统，用于引文推荐。我们基于多个数据集对单一方法和混合方法进行了离线评估，如微软学术图（MAG）和结合arXiv和ACL的MAG。我们进一步进行用户研究，以评估我们的在线方法。我们的评估结果表明，包含嵌入和基于信息检索的组件的混合模型比其单独的组件和进一步的算法有很大的优势。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06406">PDF</a>
<h3>No. 37	基于物联网的大城市交通数据挖掘系统</h3><h4>Daniel. Firouzimagham, Mohammad. Sabouri, Fatemeh. Adhami</h4>摘要：目前，在包括伊朗在内的发展中国家，由于人口的增长，汽车的数量在不断增加。最近，这导致浪费时间陷入交通堵塞，每天上下班的时间增加，事故增加。因此，有必要由交警来控制交通拥堵，有效地拓宽道路，选择减少市民交通的最佳途径。因此，掌握每条车道上的瞬时交通量是很重要的。今天，许多交通组织服务，如交警和城市交通控制系统，使用交通摄像机、感应传感器、卫星图像、雷达传感器、超声波技术和射频识别（RFID）进行城市交通诊断。但该方法存在着受大气条件影响大流量时效率不高、无法检测出平行交通等问题。本文提出的基于物联网的交通拥堵检测方法，包含一个智能系统，通过计算该区域的空气污染量来检测交通拥堵。经实验验证，结果令人满意。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06374">PDF</a>
<h3>No. 38	UniViLM：多模态理解和生成的统一视频和语言预训练模型</h3><h4>Huaishao Luo, Lei Ji, Botian Shi, Haoyang Huang, Nan Duan, Tianrui Li, Xilin Chen, Ming Zhou</h4>文摘：提出了统一的视频和语言预训练模型UniViLM，用于多模态理解和生成。针对近年来基于BERT的NLP和图像语言预训练技术的成功应用，VideoBERT和CBT提出了一种基于叙事教学视频的视频和语言预训练BERT模型。与他们只进行理解任务预训练的工作不同，我们提出了一个统一的视频语言理解和生成任务预训练模型。我们的模型由4个部分组成，包括两个单模式编码器、一个交叉编码器和一个带变压器主干的解码器。我们首先对我们的模型进行预训练，以学习大型教学视频数据集上视频和语言的通用表示。然后，我们对模型进行了两个多模式任务的微调，包括理解任务（基于文本的视频检索）和生成任务（多模式视频字幕）。大量的实验表明，该方法可以提高理解任务和生成任务的性能，达到了最新的效果。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06353">PDF</a>
<h3>No. 39	基于条件循环一致对抗网络的多对多语音转换</h3><h4>Shindong Lee, BongGu Ko, Keonnyeong Lee, In-Chul Yoo, Dongsuk Yook</h4>摘要：语音转换是指在不改变话语语言内容的情况下，改变话语的说话人特征。许多关于语音转换的工作都需要并行训练数据，而这些数据的获取成本很高。近年来，循环一致对抗网络（cycle-consistent particial network，CycleGAN）已被应用于语音转换领域，显示了其最新的性能。然而，基于CycleGAN的语音转换只能用于一对扬声器，即两个扬声器之间的一对一语音转换。在本文中，我们通过调节扬声器上的网络来扩展CycleGAN。结果表明，该方法可以在一个生成性对抗网络（GAN）上实现多个说话人之间的多对多语音转换。与为每对扬声器建立多个循环相比，该方法在不影响转换语音质量的前提下，显著降低了计算和空间开销。基于VCC2018语料库的实验结果验证了该方法的有效性。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06328">PDF</a>
<h3>No. 40	基于小能量掩蔽的端到端语音识别改进神经网络训练</h3><h4>Chanwoo Kim, Kwangyoun Kim, Sathish Reddy Indurthi</h4>文摘：本文提出了一种小能量掩蔽（SEM）算法，它屏蔽了输入值低于某一阈值的情况。更具体地说，如果滤波器组能量小于某个能量阈值，则屏蔽时频滤波器组。采用均匀分布的方法，随机产生该能量阈值与每个话语的峰值滤波器组能量之比（分贝）。通过此掩蔽过程，将缩放未掩蔽的特征元素，以便特征值的总和保持不变。这个非常简单的算法在标准LibriSpeech测试clean和测试其他集上的字错误率（WER）分别比基线端到端语音识别系统提高了11.2%和13.5%。此外，与输入-退出算法相比，SEM算法在同一LibriSpeech test clean和test-other集上分别提高了7.7%和11.6%。采用改进的变压器LM浅熔技术，在LibriSpeech试验清洁集上获得了2.62%的功率，在LibriSpeech试验其他集上获得了7.87%的功率。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06312">PDF</a>
<h3>No. 41	军团：最佳的首次混合测试</h3><h4>Dongge Liu, Gidon Ernst, Toby Murray, Benjamin I. P. Rubinstein</h4>摘要：军团是一种灰盒混合工具，旨在平衡模糊和符号执行的互补性，以达到两者的最佳效果。提出了蒙特卡罗树搜索（MCTS）的一种新方法，即在不确定性条件下，在最优优先搜索策略的指导下，将程序探索定义为顺序决策。它依赖于近似路径保持模糊化，一种新的约束随机测试实例，它快速生成许多可能针对感兴趣的程序部分的不同输入。在2020年的测试中，该原型在22个类别中有9个类别的最佳分数的90%以内完成。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06311">PDF</a>
<h3>No. 42	基于功能近红外光谱的深度学习精确应力评估</h3><h4>Mahya Mirbagheri, Ata Jodeiri, Naser Hakimi, Vahid Zakeri, Seyed Kamaledin Setarehdan</h4>摘要：压力是威胁人类健康的主要因素之一。为了通过分析大脑和心脏相关信号来评估或缓解压力，已经进行了大量的研究。本研究利用10名健康志愿者脑功能近红外光谱（fNIRS）所产生的信号，通过深度学习系统对蒙特利尔成像应激任务所诱发的应激进行评估。本文提出的深度学习系统主要由两部分组成：一是利用一维卷积神经网络建立信息特征映射。然后，用一组深全连接层预测应力存在概率。实验结果表明，训练后的fNIRS模型进行应力分类的准确率达到88.52-+0.77%。所提出的深度学习系统在FNIRS测量上的训练导致比在FNIRS研究中提出的现有方法中更高的应力分类精度，其中已经使用了相同的实验过程。该方法具有较好的稳定性和较低的预测偏差。此外，该方法计算量小，为实时应力评估提供了可能。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06282">PDF</a>
<h3>No. 43	Twin BERT：将知识提取到双结构BERT模型以实现高效检索</h3><h4>Wenhao Lu, Jian Jiao, Ruofei Zhang</h4>文摘：BERT等预训练语言模型在各种NLP任务中取得了巨大的成功，但其优越的性能对计算资源提出了更高的要求，阻碍了其在低延迟IR系统中的应用。本文提出了一种有效的twin BERT检索模型，该模型采用双结构的类BERT编码来分别表示查询和文档，并通过交叉层来组合嵌入，产生相似度得分。与BERT不同，TwinBERT将两个输入语句连接在一起并进行编码，在编码过程中对它们进行解耦，独立生成查询和文档所需的嵌入，这使得文档嵌入可以离线预计算并缓存在内存中。因此，留给运行时的计算仅来自查询编码和查询文档交叉。这种改变可以节省大量的计算时间和资源，从而显著提高服务效率。此外，本文还提出了一些精心设计的网络层和训练策略，进一步降低了计算量，同时保持了BERT模型的良好性能。最后，我们开发了两个版本的TwinBERT，分别用于检索和相关任务，它们都达到了与BERT基模型接近或相当的性能。该模型遵循师生框架进行训练，并使用一个主要搜索引擎的数据进行评估。实验结果表明，在cpu上，推理时间明显缩短，并首先控制在20ms左右，同时保留了微调BERT基模型的性能增益。将这些模型集成到生产系统中也证明了相关性度量的显著改进，对延迟的影响可以忽略不计。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06275">PDF</a>
<h3>No. 44	用于人脸识别的深卷积神经网络编码中的单单元状态：稀疏性的重新定义</h3><h4>Connor J. Parde, Y. Ivette Colón, Matthew Q. Hill, Carlos D. Castillo, Prithviraj Dhar, Alice J. O'Toole</h4>文摘：用于人脸识别的深卷积神经网络（DCNNs）在保留被试（如性别）和图像（如视点）信息的同时，发展了对可变图像的泛化表示。在人脸识别网络的“神经单元”和集成层上研究了身份、性别和视点编码。在单元层次上，通过删除单元在顶层创建可变大小的随机采样子空间来测量识别、性别分类和视点估计。3531个身份的识别仍然很高（ROC下面积约1），随着维度的下降，从512个单位减少到16个（0.95）、4个（0.80个）和2个（0.72个）单元。在每一个顶层单元上都有统计上分离的个体身份。跨单位反应的相关性最小，表明单位编码非冗余的身份线索。这种“分布式”代码只需要一个稀疏的、随机的单元样本就可以准确地识别人脸。随着维度的降低，性别分类逐渐下降，观点估计急剧下降。个体单位对性别和观点的预测能力很弱，但合奏被证明是有效的预测因素。因此，分布式和稀疏代码共存于网络单元中，以表示不同的面部属性。在集成层次上，人脸表示的主成分分析表明，身份、性别和视点信息被分解成高维子空间，按解释方差排序。身份、性别和观点信息对所有个体的反应都有贡献，削弱了面部特征的神经调节类比。从DCNNs和类似的高级视觉编码中对类神经编码的解释，不能从单个单位的反应中推断出来。相反，“意义”是由高维空间中的方向编码的。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06274">PDF</a>
<h3>No. 45	社会WaGDAT：基于Wasserstein图双注意网络的交互感知轨迹预测</h3><h4>Jiachen Li, Hengbo Ma, Zhihao Zhang, Masayoshi Tomizuka</h4>文摘：智能移动系统（如自主车辆和社会机器人）在高度交互性和拥挤的场景中导航时，对环境的有效理解和对周围动态障碍物的准确轨迹预测是实现安全、高质量规划的必要条件。由于场景演化中频繁交互和不确定性的存在，期望预测系统能够在不同实体上进行关系推理，并为每个代理提供未来轨迹的分布。本文提出了一个通用的多智能体轨迹预测生成神经系统（Social WaGDAT），该系统通过将关联归纳偏差与动态图表示相结合，同时利用轨迹和场景上下文信息，向显式交互建模迈进了一步。我们还采用了一个有效的运动约束层应用于车辆轨迹预测，不仅保证了物理上的可行性，而且提高了模型的性能。该系统在三个公共基准数据集上进行评估，用于轨迹预测，其中代理包括行人、骑自行车者和道路车辆。实验结果表明，该模型在预测精度方面优于各种基线方法。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06241">PDF</a>
<h3>No. 46	增强的局部敏感哈希：用于源分离的区分二进制代码</h3><h4>Sunwoo Kim, Haici Yang, Minje Kim</h4>摘要：随着深度学习技术的进步，语音增强任务得到了显著的改善，但是计算复杂度的增加也带来了代价。在本研究中，我们提出一种自适应的boosting方法来学习局部敏感的杂凑码，以有效地表示音频频谱。我们将学习的散列码用于单通道语音去噪任务，以替代复杂的机器学习模型，特别是解决资源受限的环境。我们的自适应boosting算法学习简单的logistic回归作为弱学习者。经过训练，他们的二值分类结果将每个测试噪声语音谱转换成一个位串。简单的位运算计算Hamming距离，在训练有噪语音谱的字典中找到K-最近匹配帧，其相关的理想二值掩码被平均以估计该测试混合的去噪掩码。我们提出的学习算法与AdaBoost的不同之处在于，训练投影的目的是最小化散列码的自相似矩阵与原始谱的自相似矩阵之间的距离，而不是降低误分类率。我们评估我们的歧视性哈希码的TIMIT语料库与各种噪声类型，并表现出比较深刻的学习方法在降噪性能和复杂性方面的性能。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06239">PDF</a>
<h3>No. 47	波斯语社交媒体中情感分析的卷积神经网络</h3><h4>Morteza Rohanian, Mostafa Salehi, Ali Darzi, Vahid Ranjbar</h4>摘要：随着社会化媒体参与度的不断提高，由此产生的数据可以作为分析和理解我们周围不同现象的丰富资源。情绪分析系统利用这些数据来发现社交媒体用户对给定文档中某些实体的态度。本文提出了一种基于前向人工神经网络卷积神经网络（CNN）的波斯语文本情感分析方法，该方法通过不同的滤波器对输入数据进行一层卷积，将句子分为两类和五类（考虑其强度）。我们使用曲线下面积度量对三个不同的波斯社交媒体文本数据集进行了评估。最后的结果显示了使用CNN在开发波斯文本情感分类特别是短文本的传统机器学习方法方面的优势。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06233">PDF</a>
<h3>No. 48	分段凸函数估计与模型选择</h3><h4>Kurt S. Riedel</h4>文摘：在给定噪声数据的情况下，当未知函数先验地由少数凸或凹区域组成时，考虑函数估计。当区域先验已知时，该估计在对偶空间中降为有限维凸优化。当区域的数目未知时，模型选择问题是确定凸性变化点的数目。我们使用基于期望的假拐点数目的导频估计器。<br><a href = "http://xxx.itp.ac.cn/pdf/1803.03903">PDF</a>
</body></html>