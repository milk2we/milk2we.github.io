<!DOCTYPE html><html><head><meta charset="utf-8"><title>CS.LG</title></head><body>
<h2>2020-02-22</h2>
<h3>No. 1	利用梯度的非均匀次采样提高随机梯度MCMC方法的采样精度</h3><h4>Ruilin Li, Xin Wang, Hongyuan Zha, Molei Tao</h4>文摘：常用的随机梯度MCMC方法是通过均匀次采样的数据点，用随机梯度逼近梯度。我们提出非均匀子抽样可以减少随机近似带来的方差，从而使目标分布的抽样更加精确。基于随机梯度和批量梯度分别匹配SG-MCMC方法的转移核，提出了一种指数加权随机梯度方法（EWSG）。结合二阶Langevin方程，给出了EWSG的一个应用实例。在我们的方法中，非均匀子采样是通过数据索引上的Metropolis Hasting链有效地完成的，该链与采样算法相耦合。从理论上分析了该方法在降低局部方差方面的高概率性。给出了一种非渐近全局误差分析方法。文中还给出了基于合成数据集和真实数据集的数值实验，证明了所提方法的有效性。虽然统计精度有所提高，但根据经验观察，收敛速度至少与统一版本相当。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08949">PDF</a>
<h3>No. 2	大规模支持向量机的Nystrém子空间学习</h3><h4>Weida Li, Mingxia Liu, Daoqiang Zhang</h4>文摘：作为Nystr{o}m方法的一种实现，Nystr{o}m计算正则化（NCR）应用于核分类和核岭回归，证明了Nystr{o}m计算正则化能够在大规模统计学习环境中达到最优界，同时具有更好的时间复杂度。在这项研究中，我们提出了一个Nystr{o}m子空间学习（NSL）框架，以揭示在任何核支持向量机上使用Nystr{o}m方法（包括NCR）所需的全部是将有效的现成线性支持向量机解算器用作黑盒。在分析的基础上，将Nystr{o}m方法的界与NSL联系起来，明确了Nystr{o}m方法的两种不同实现之间的分析差异。此外，NSL也为聚类Nystr“{o}m方法带来了更清晰的理论结果。最后，执行回归和分类任务来比较Nystr“{o}m方法的两个实现。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08937">PDF</a>
<h3>No. 3	混合线性回归的元学习</h3><h4>Weihao Kong, Raghav Somani, Zhao Song, Sham Kakade, Sewoong Oh</h4>摘要：在现代有监督学习中，任务数量庞大，但许多任务只与少量的标注数据相关联。其中包括来自医学图像处理和机器人交互的数据。即使每一个单独的任务都不能单独进行有意义的训练，人们还是试图通过利用一些相似性，从过去的经验中跨任务进行元学习。我们研究了一个基本的问题：小数据的大量任务何时能弥补大数据任务的不足？我们关注一个典型的场景，其中每个任务都是从一个混合的$k$线性回归中提取的，并确定了这样一个优雅的交换保持的充分条件；只有小数据任务所需的示例总数的比例与大数据任务可用时的比例类似。为此，我们引入了一种新的谱方法，并证明在$tilde\Omega（k^{3/2}）$中等数据任务的帮助下，我们可以有效地利用每个$tilde\Omega（k^{1/2}）$示例。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08936">PDF</a>
<h3>No. 4	在线高阶矩阵完成</h3><h4>Jicong Fan, Madeleine Udell</h4>文摘：利用低维（非线性）潜在结构，矩阵完备化的最新进展使全秩矩阵的数据插补成为可能。本文提出了一种新的高阶矩阵完备化（HRMC）模型，采用批处理和在线的方法对模型进行拟合，并通过样本外扩展完成新的数据。该方法的工作原理是（隐式地）使用核技巧将数据映射到高维多项式特征空间；重要的是，即使原始数据矩阵是满秩的，数据在该特征空间中也占据低维子空间。我们引入了这个低维子空间的显式参数化和一个在线拟合过程，以降低与现有技术相比的计算复杂度。在线方法也可以处理流或序列数据，适应非平稳的潜在结构。我们为这些方法成功所需的采样率提供指导。对合成数据和运动捕获数据的实验结果验证了所提方法的性能。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08934">PDF</a>
<h3>No. 5	多步在线无监督域自适应</h3><h4>J. H. Moon, Debasmit Das, C. S. George Lee</h4>文摘：本文研究了一类在线无监督域自适应（OUDA）问题，其中目标数据是无标记的，并且是按顺序到达的。传统的处理OUDA问题的方法主要是将每个到达的目标数据转换到源域，没有充分考虑到到达目标数据之间的时间相关性和累积统计性。针对欧氏空间的几何解释，提出了一种新的计算平均目标子空间的方法。该平均目标子空间包含到达目标数据之间的累积时间信息。此外，将从平均目标子空间计算出的变换矩阵作为预处理步骤应用于下一个目标数据，使目标数据更接近源域。在四个数据集上的实验证明了我们所提出的多步骤OUDA框架中每个步骤的贡献及其相对于以前方法的性能。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08930">PDF</a>
<h3>No. 6	基于松弛内射概率流的正则化自编码</h3><h4>Abhishek Kumar, Ben Poole, Kevin Murphy</h4>文摘：基于可逆流的生成模型是一种学习生成样本的有效方法，同时可以进行简单的似然计算和推理。然而，可逆性要求限制了模型具有与输入相同的潜在维数。这就增加了大量的架构、内存和计算成本，使得它们比其他类型的生成模型（如变分自动编码器（vae））更难扩展。我们提出了一个基于概率流的生成模型，它不需要模型的双射性要求，只假设模型的内射性。这也为正则化自编码器（RAEs）提供了另一个视角，我们的最终目标类似于RAEs，具有通过概率流目标下边界导出的特定正则化器。我们通过实验证明了该模型的可行性，在样品质量方面优于VAEs和AEs。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08927">PDF</a>
<h3>No. 7	耗散符号模型：用耗散控制编码哈密顿动力学</h3><h4>Yaofeng Desmond Zhong, Biswadip Dey, Amit Chakraborty</h4>文摘：本文介绍了耗散符号模型，它是一种能从观测到的状态轨迹中推断耗散物理系统动力学的深层学习结构。为了在减小网络规模的同时提高预测精度，耗散SymODEN将端口哈密顿动力学与能量耗散和外部输入一起编码到其计算图的设计中，并以结构化的方式学习动力学。学习的模型，通过揭示系统的关键方面，如惯性、耗散和势能，为基于能量的控制器铺平了道路。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08860">PDF</a>
<h3>No. 8	对抗性例子的Bayes最优观</h3><h4>Eitan Richardson, Yair Weiss</h4>摘要：利用输入的微小扰动来愚弄现代CNN分类器的能力，导致了大量候选防御机制的发展，并且常常出现相互矛盾的解释。本文从Bayes最优分类的角度来考察对抗性例子。我们构造了真实的图像数据集，从而可以有效地计算贝叶斯最优分类器，并得到分布的解析条件，从而使最优分类器既具有鲁棒性，又具有脆弱性。通过在这些数据集上训练不同的分类器（已知“黄金标准”最优分类器），我们可以分离出可能的脆弱源，避免在常用数据集中可能出现的精度-稳健性权衡。我们的结果表明，即使最优分类器是鲁棒的，标准CNN训练也能始终如一地学习易受攻击的分类器。同时，对于完全相同的训练数据，RBF-SVMs一致地学习一个鲁棒分类器。在真实图像的实验中也观察到了同样的趋势。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08859">PDF</a>
<h3>No. 9	从热带几何学角度看深层神经网络的决策边界</h3><h4>Motasem Alfarra, Adel Bibi, Hasan Hammoud, Mohamed Gaafar, Bernard Ghanem</h4>文摘：解决了具有分段线性非线性激活的神经网络的决策边界的刻画和理解问题。我们使用热带几何学，代数几何学领域的一个新发展，来描述一个简单的神经网络形式（仿射，ReLU，仿射）的决策边界。我们的主要发现是决策边界是热带超曲面的一个子集，它与两个区域的凸包形成的多面体密切相关。这些区域的生成器是神经网络参数的函数。这个几何特征为三个任务提供了新的视角。具体地说，我们提出了一个新的热带视角的彩票假设，我们看到不同的初始化对热带几何表示的网络的决策边界的影响。此外，我们利用这一特性提出了一组新的热带正则化器，它直接处理网络的决策边界。我们研究了这些正则化器在神经网络剪枝（通过去除不影响决策边界的热带几何表示的网络参数）和产生对抗性输入攻击（通过产生明显干扰决策边界几何的输入扰动，并最终更改网络的预测）。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08838">PDF</a>
<h3>No. 10	无遗憾与激励相容的在线学习</h3><h4>Rupert Freeman, David M. Pennock, Chara Podimata, Jennifer Wortman Vaughan</h4>摘要：我们研究了在线学习环境，在这种环境中，专家们通过潜在的误报他们对一系列二元事件的信念，策略性地采取行动，以最大限度地提高他们对学习算法预测的影响。我们的目标是双重的。首先，我们希望学习算法在事后对最佳固定专家没有遗憾。其次，我们需要激励相容性，这是一个保证，即每个专家的最佳策略是报告他对每个事件实现的真实信念。为了实现这一目标，我们在文献的基础上研究了一种多智能体的评分规则下注机制。我们为近视专家提供了在全部和部分信息设置下实现无遗憾和激励兼容性的算法。在对五个八分之一样本集的实验中，我们的算法与经典的不后悔算法相比，具有不相容的激励性。最后，我们为前瞻性策略代理人找出一个激励相容的演算法，在实务中表现出减少遗憾。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08837">PDF</a>
<h3>No. 11	微分动态规划神经优化器</h3><h4>Guan-Horng Liu, Tianrong Chen, Evangelos A. Theodorou</h4>文摘：将深度神经网络（DNNs）训练问题解释为非线性动力系统的最优控制问题，近年来受到了广泛的关注，但算法的发展相对有限。在这项工作中，我们试图沿着这条路线，重新制定训练程序，从轨迹优化的角度。我们首先证明了最广泛使用的dnn训练算法可以与微分动态规划（DDP）相结合，DDP是一种著名的基于近似动态规划的二阶轨迹优化算法。在这方面，我们提出了一种新的DDP变体，它可以接受训练前馈网络的批优化，同时自然地结合曲率逼近的最新进展。该算法采用分层反馈策略，与现有方法相比，提高了收敛速度，降低了对超参数的敏感性。我们证明了该算法与现有的一阶和二阶方法相比是有竞争力的。我们的工作为基于最优控制理论的算法设计开辟了新的途径。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08809">PDF</a>
<h3>No. 12	支持加权对抗性模仿学习</h3><h4>Ruohan Wang, Carlo Ciliberto, Pierluigi Amadori, Yiannis Demiris</h4>摘要：对抗性模仿学习（AIL）是一个广泛的模仿学习方法家族，旨在通过示范模仿专家的行为。尽管AIL在模仿学习方面表现出了最先进的水平，但它面临着一些实际挑战，如潜在的训练不稳定性和隐性奖励偏差。为了解决这一问题，我们提出了支持加权对手模拟学习（SAIL）的一般框架，该框架利用专家策略支持估计的信息来扩展给定的AIL算法。SAIL通过将对手的奖励与专家策略的支持度估计的置信度进行权衡，提高了增强信号的质量。我们还表明，SAIL算法的效率至少与SAIL用于学习对手奖赏的底层AIL算法一样高。实验结果表明，该方法在多个基准控制任务上均取得了比基线方法更好的性能和训练稳定性。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08803">PDF</a>
<h3>No. 13	条件元学习的结构化预测方法</h3><h4>Ruohan Wang, Yiannis Demiris, Carlo Ciliberto</h4>摘要：基于优化的元学习算法是一类强大的学习应用的方法，如少镜头学习。他们利用从先前观察到的任务中获得的经验来解决培训数据的有限可用性。然而，当一组共享元参数无法捕获任务分布的复杂性时，现有方法可能无法完全适应目标任务。我们从一个新的视角来探讨这个问题，即基于结构化预测的条件元学习。我们提出任务适应性结构元学习（TASML），这是一个原则性的估计器，它根据目标任务来衡量元训练数据，以设计定制的元学习目标。此外，我们引入算法改进来解决现有方法的关键计算限制。实验表明，无论在精度还是效率上，TASML都优于现有的基准数据集方法。消融研究量化了模型组分的个体贡献，并为元学习提供了有用的实践建议。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08799">PDF</a>
<h3>No. 14	如何避免被咕噜吃掉：文本冒险代理的探索策略</h3><h4>Prithviraj Ammanabrolu, Ethan Tien, Zhaochen Luo, Mark O. Riedl</h4>摘要：基于文本的游戏——其中一个代理通过文本自然语言与世界交互——给我们提出了一个组合大小的动作空间的问题。目前大多数强化学习算法都不能有效地处理每轮可能出现的大量动作。因此，样本效率低下会导致代理无法通过瓶颈状态，因为它们看不到正确的操作序列，无法通过足够的时间来充分增强瓶颈状态，从而无法继续。在此基础上，我们引入了两种新的博弈状态探索策略。我们将我们的探索策略与经典文本冒险游戏Zork1上的强大基线进行比较，在这个游戏中，先前的代理无法通过一个瓶颈，代理被一个咕噜吃掉。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08795">PDF</a>
<h3>No. 15	贝叶斯深度学习与概率泛化</h3><h4>Andrew Gordon Wilson, Pavel Izmailov</h4>摘要：贝叶斯方法的关键区别是边缘化，而不是使用单一的权值设置。贝叶斯边缘化特别能提高现代深部神经网络的精度和校准，这些神经网络通常不受数据的约束，并且可以代表许多令人信服但不同的解决方案。我们证明了深度集合为近似贝叶斯边缘化提供了一种有效的机制，并提出了一种相关的方法，该方法通过在吸引域内边缘化来进一步改善预测分布，而不需要显著的开销。我们还研究了神经网络权值上的模糊分布所隐含的先验过函数，从概率的角度解释了这类模型的泛化性质。从这个角度出发，我们解释了一些被认为是神秘的、与神经网络泛化不同的结果，例如用随机标签来拟合图像的能力，并表明这些结果可以用高斯过程来重现。最后，我们提供了一个贝叶斯的观点回火校准预测分布。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08791">PDF</a>
<h3>No. 16	动态联合学习</h3><h4>Elsa Rizk, Stefan Vlaski, Ali H. Sayed</h4>摘要：联邦学习是多智能体环境下集中协调策略的总称。虽然许多联邦学习体系结构以在线方式处理数据，因此本质上是自适应的，但大多数性能分析都假设存在静态优化问题，并且在问题解决方案或数据特性中存在漂移时无法提供保证。我们考虑一个联邦学习模型，其中在每个迭代中，可用代理的随机子集根据其数据执行本地更新。在集合优化问题的真极小化上的非平稳随机游走模型下，我们建立了体系结构的性能由三个因素决定，即每个代理的数据可变性，所有代理的模型可变性，以及与学习率成反比的跟踪项算法。结果阐明了收敛性和跟踪性能之间的权衡。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08782">PDF</a>
<h3>No. 17	Set2Graph：从集合学习图形</h3><h4>Hadar Serviansky, Nimrod Segol, Jonathan Shlomi, Kyle Cranmer, Eilam Gross, Haggai Maron, Yaron Lipman</h4>文摘：机器学习中的许多问题可以归结为集到图，或者更广泛地说是超图的学习函数，简而言之，就是集2图函数。例如聚类，学习图的顶点和边特征，以及学习集合中的三元组数据。目前逼近集合2图函数的神经网络模型主要来自两个子领域：等变学习和相似学习。等变模型通常在计算上具有挑战性甚至不可行，而相似学习模型的表达能力有限。本文提出了一个集2图函数学习的神经网络模型族，它既实用又具有最大的表达能力（通用性），即在紧集上逼近任意连续集2图函数。在不同的机器学习任务上测试我们的模型，包括粒子物理的应用，我们发现它们有利于现有的基线。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08772">PDF</a>
<h3>No. 18	知识图中的错误检测：路径排序，嵌入还是两者兼有？</h3><h4>R. Fasoulis, K. Bougiatiotis, F. Aisopos, A. Nentidis, G. Paliouras</h4>文摘：对知识图错误检测的不同方法进行了比较和综合。知识图是表示大型异构数据中关系信息的主流方法，但在自动构造知识图时可能会包含大量的输入噪声。为了解决这个问题，人们提出了不同的错误检测方法，主要集中在路径排序和表示学习上。这项工作提出了各种主流的方法，并提出了一种新的混合和模块方法学的任务。我们在两个基准和一个真实的生物医学出版物数据集上比较了这些方法，展示了我们的方法的潜力，并对知识图中错误检测的最新技术提出了见解<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08762">PDF</a>
<h3>No. 19	走向可认证的对抗性样本检测</h3><h4>Ilia Shumailov, Yiren Zhao, Robert Mullins, Ross Anderson</h4>摘要：卷积神经网络（CNN）在越来越多的分类系统中得到了应用，但对抗性样本往往会被恶意地构造出来欺骗，成为一种真正的威胁。为了提高CNNs的对抗稳健性，人们提出了各种各样的建议，但这些建议都会受到性能惩罚或其他限制。本文提出了一种新的可认证的对抗性检测方案，即可认证的禁忌陷阱（CTT）。该系统可以在合理的假设下，即训练数据与测试数据具有相同的分布，为检测特定的$l{\infty}$大小的对抗输入提供可证明的保证。我们开发和评估了几个版本的CTT，包括一系列的防御能力、训练费用和对抗性样本的可认证性。在对抗具有各种$lèp$规范的对手时，CTT的性能优于单纯着眼于提高网络健壮性的现有防御方法。我们发现CTT在干净的测试数据上有很小的假阳性率，在部署时计算开销最小，并且可以支持复杂的安全策略。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08740">PDF</a>
<h3>No. 20	双峰分布去除与遗传算法在乳腺癌神经网络诊断中的应用</h3><h4>Ke Quan</h4>摘要：乳腺癌的诊断在过去一直是研究的热点。设计了多个线性规划模型来逼近细胞特征与肿瘤恶性程度之间的关系。然而，这些模型在处理非线性相关性方面能力较弱。相反，神经网络在处理复杂的非线性相关性方面非常强大。因此，用基于神经网络的模型来解决这一癌症诊断问题无疑是有益的。特别是在神经网络训练过程中引入偏差被认为是提高训练效率的重要手段。在许多常用的引入人工偏压的方法中，双峰分布去除（BDR）具有理想的效率改进效果和公平的实现简单性。然而，本文检验了BDR对目标癌症诊断分类问题的有效性，并表明BDR过程实际上对分类性能有负面影响。此外，本文还探讨了遗传算法作为一种有效的特征选择工具，与没有任何特征选择的基线模型相比，它能产生更好的结果<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08729">PDF</a>
<h3>No. 21	在达到零训练错误之后，我们需要零训练损失吗？</h3><h4>Takashi Ishida, Ikko Yamane, Tomoya Sakai, Gang Niu, Masashi Sugiyama</h4>摘要：超参数化深度网络具有记忆训练数据的能力，训练误差为零。即使在记忆之后，训练损失仍然接近于零，使得模型过于自信，测试性能下降。由于现有的正则化并不直接以避免零训练损失为目标，因此它们常常无法保持中等程度的训练损失，最终导致太小或太大的损失。我们提出了一个直接的解决方案，称之为洪泛，当训练损失达到一个相当小的值（我们称之为洪泛水平）时，故意防止进一步减少。我们的方法使损失像往常一样在洪水位附近浮动，但如果训练损失低于洪水位，则梯度上升。这可以用一行代码实现，并且与任何随机优化器和其他正则化器兼容。在洪水泛滥的情况下，该模型将继续以相同的非零训练损失“随机游走”，我们期望它会漂移到一个损失平坦的区域，从而导致更好的泛化。实验结果表明，驱油提高了系统的性能，作为副产品，试验损失呈双倍下降曲线。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08709">PDF</a>
<h3>No. 22	嵌入式gpu的性能感知卷积神经网络信道剪枝</h3><h4>Valentin Radu, Kuba Kaszyk, Yuan Wen, Jack Turner, Jose Cano, Elliot J. Crowley, Bjorn Franke, Amos Storkey, Michael O'Boyle</h4>摘要：卷积神经网络（CNN）以其优越的识别精度，正成为许多应用和服务领域的普遍存在。它们越来越多地被用于移动设备上，很多时候只是通过移植为服务器空间设计的大型模型，尽管已经考虑了几种模型压缩技术。一种旨在减少计算的模型压缩技术是信道修剪。移动和嵌入式系统现在有了gpu，gpu非常适合于神经网络的并行计算，并且可以降低每次操作的能耗。专门的库通过高度优化的例程执行这些神经网络计算。正如我们在实验中发现的，这些库针对最常见的网络形状进行了优化，使得无结构的信道修剪效率低下。我们评估高级库，分析卷积层的输入特性，在此基础上生成优化的OpenCL（Arm计算库和TVM）和CUDA（cuDNN）代码。然而，在现实中，这些特性和随后的优化选择可能会产生相反的效果。我们表明，在某些情况下，卷积信道的数量减少，即减少初始大小的12%，对性能不利，导致2倍的速度减慢。另一方面，我们还发现了一些示例，其中性能感知剪枝达到了预期的效果，cuDNN的性能加速比为3倍，Arm计算库和TVM的性能加速比为10倍以上。我们的发现揭示了需要硬件指导的神经网络修剪。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08697">PDF</a>
<h3>No. 23	正则Wasserstein估计的随机优化</h3><h4>Marin Ballu, Quentin Berthet, Francis Bach</h4>最优运输是最优化中的一个基本问题，它允许在考虑几何方面比较概率分布。它的最优目标值Wasserstein距离提供了分布之间的一个重要损失，这种损失在机器学习和统计的许多应用中都得到了应用。最近在这个问题上的算法进展及其规则化版本使得这些工具越来越流行。然而，现有的技术需要求解一个优化问题来获得单一的损失梯度，从而减缓一阶方法以最小化损失之和，这就需要许多这样的梯度计算。在这项工作中，我们引入一个算法来解决这个问题的正则化版本的Wasserstein估计量，在问题的自然维度中，每一步的时间是次线性的。我们引入了一个对偶公式，并用可直接从样本计算的随机梯度步长对其进行优化，而不必在每一步求解额外的优化问题。这样，估计和计算任务被联合执行。结果表明，该算法可以推广到其他任务，包括Wasserstein重心的估计。通过对合成数据的实验验证了算法的有效性。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08695">PDF</a>
<h3>No. 24	无监督多类域自适应：理论、算法与实践</h3><h4>Yabin Zhang, Bin Deng, Hui Tang, Lei Zhang, Kui Jia</h4>文摘：本文研究了无监督多类领域自适应（multi-classeuda）的形式化，它是近年来一些学习目标只受到经验激励的算法的基础。通过对多类分类中的绝对边际违规行为进行聚合，提出了一种多类评分不一致（MCSD）散度，该散度能够充分刻画任意一对多类评分假设之间的关系。利用MCSD作为域距离的度量，我们建立了一个新的多类UDA的域适应界及其数据依赖的、可能是近似正确的界，这自然意味着对抗性学习目标要在源域和目标域之间调整条件特征分布。因此，本文提出了一个多类领域对抗性学习网络（McDalNets）的算法框架，其通过代理学习目标的不同实例要么与最近流行的几种方法相一致，要么类似，从而（部分）强调了它们的实际有效性。基于我们同样的多类UDA理论，我们还提出了一种新的域对称网络（SymmNets）算法，它具有一种新的域混淆和区分的对抗策略。SymmNets提供了简单的扩展，这些扩展在闭集、部分集或开放集UDA的问题设置下同样有效。我们进行了细致的实证研究，比较了McDalNets和我们新引入的SymmNets的不同算法。实验验证了我们的理论分析，并证明了我们提出的对称网的有效性。我们公开我们的实现代码。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08681">PDF</a>
<h3>No. 25	可微扰动优化器学习</h3><h4>Quentin Berthet, Mathieu Blondel, Olivier Teboul, Marco Cuturi, Jean-Philippe Vert, Francis Bach</h4>摘要：机器学习流水线通常依赖于优化过程来做出离散的决策（例如排序、挑选最近的邻居、寻找最短路径或最佳匹配）。尽管这些离散决策很容易以正向方式计算，但它们不能用于使用一阶优化技术修改模型参数，因为它们破坏了计算图的反向传播。为了扩大可端到端方式解决的学习问题的范围，我们提出了一种系统方法，将输出最优离散决策的块转换为可微操作。我们的方法依赖于这些参数的随机扰动，并且不需要特别的正则化或平滑就可以很容易地在现有的解算器中使用。这些扰动优化器产生的解是可微的，而不是局部不变的。平滑度的大小可以通过选择的噪声幅度来调整，我们分析了噪声幅度的影响。这些摄动解的导数可以有效地计算。我们还展示了该框架如何与结构化预测中产生的一系列损失联系起来，并描述了如何在无监督和有监督的学习中使用这些损失，并提供了理论保证。通过对合成数据和真实数据的实验，证明了该方法在多个机器学习任务中的性能。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08676">PDF</a>
<h3>No. 26	基于判别流形嵌入和对齐的无监督域自适应</h3><h4>You-Wei Luo, Chuan-Xian Ren, Pengfei Ge, Ke-Kun Huang, Yu-Feng Yu</h4>摘要：无监督域自适应是一种有效的将源域的丰富信息转化为无监督目标域的方法。尽管深度学习和对抗策略在特征适应性方面取得了重大突破，但仍有两个问题有待进一步探讨。首先，目标域上硬分配的伪标签对内部数据结构有风险。第二，深度学习中的批式训练方式限制了对全局结构的描述。本文提出了一个黎曼流形学习框架，以一致地实现可传递性和可判别性。对于第一个问题，该方法通过软标签在目标域上建立概率判别准则。此外，将此准则推广到第二个问题的全局近似方案，这样的近似也节省了内存。利用流形度量对齐与嵌入空间相容。导出了便于对准的理论误差界。通过大量的实验研究，验证了一致流形学习框架的优越性。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08675">PDF</a>
<h3>No. 27	图嵌入的计算可处理黎曼流形</h3><h4>Calin Cruceru, Gary Bécigneul, Octavian-Eugen Ganea</h4>文摘：将图表示为某些曲线黎曼流形中的节点嵌入集，由于其理想的几何归纳偏差（例如，层次结构得益于双曲几何），近年来在机器学习中获得了发展势头。然而，超越具有恒定截面曲率的嵌入空间，虽然可能更具代表性，但证明是一项挑战，因为人们很容易失去可计算工具的吸引力，如测地线距离或黎曼梯度。在这里，我们探索计算有效的矩阵流形，展示如何学习和优化这些黎曼空间中的图嵌入。在经验上，我们证明了对欧几里德几何的一致性改进，同时基于捕获不同图形属性的各种度量，我们的嵌入通常优于双曲和椭圆嵌入。我们的结果为机器学习管道中非欧氏嵌入的好处提供了新的证据。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08665">PDF</a>
<h3>No. 28	通用数据聚类的自适应图形自动编码</h3><h4>Xuelong Li, Hongyuan Zhang, Rui Zhang</h4>摘要：基于图的聚类在聚类领域占有重要地位。最近关于图卷积神经网络的研究在图型数据上取得了显著的成功。然而，在传统的聚类任务中，数据的图结构并不存在，因此图的构造策略对性能至关重要。另外，现有的基于图自动编码的方法对加权图的性能较差，在基于图的聚类中得到了广泛的应用。针对一般数据聚类问题，提出了一种局部结构保持的图自动编码方法，能够自适应地更新构造的图。自适应过程的设计充分利用了非欧几里德结构。将图嵌入的生成模型和基于图的聚类相结合，提出了一种新的图自动编码器和解码器，并在加权图应用场景中取得了良好的效果。大量实验证明了该模型的优越性。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08648">PDF</a>
<h3>No. 29	用多目标进化算法揭示分类核心集</h3><h4>Pietro Barbiero, Giovanni Squillero, Alberto Tonda</h4>摘要：核心集是训练集的一个子集，利用它，机器学习算法可以获得与它在整个原始数据上训练时所能获得的性能相似的性能。Coreset发现是一个活跃而开放的研究领域，因为它可以提高算法的训练速度，并可能有助于人类理解结果。在前人工作的基础上，提出了一种新的方法：对候选球衣进行迭代优化，添加和移除样本。由于训练规模的限制和训练结果的质量之间存在明显的权衡关系，采用多目标进化算法同时最小化训练集上的点数和分类误差。在非平凡基准上的实验结果表明，与目前最先进的核心集发现技术相比，该方法能够获得较低的错误率和较好的对未观察数据的泛化能力。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08645">PDF</a>
<h3>No. 30	基于邻接共享的联合聚类嵌入图自动编码器</h3><h4>Xuelong Li, Hongyuan Zhang, Rui Zhang</h4>文摘：图卷积网络引起了人们的广泛关注，提出了几种基于图自动编码的属性图聚类模型。然而，现有的方法大多将图形自动编码器的聚类和优化分为两个独立的步骤。本文提出了一种基于图卷积网络的聚类模型，即通过邻接共享嵌入具有联合聚类的图自动编码器（EGAE-JOCAS）。对于嵌入模型，我们提出了一种新的联合聚类方法，该方法结合了松弛k-均值和谱聚类，适用于学习嵌入。提出的联合聚类在图卷积层中共享相同的邻接关系。通过执行SGD和交替采用闭式解同时优化两部分，以保证快速收敛。此外，我们的模型可以自由地将任何机制（例如，注意）合并到图形自动编码器中。通过大量实验证明了EGAE-JOCAS的优越性。本文提供了足够的理论分析来支持这一结果。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08643">PDF</a>
<h3>No. 31	一种新的应用基因选择框架</h3><h4>Tanya Motwani, Manojkumar Parmar</h4>摘要：生成性对抗网络是当前研究的热点。知识体是碎片化的，导致在为给定场景选择合适的GAN时采用试错方法。我们从一开始就全面总结了GANs的演化，解决了模式崩溃、消失梯度、不稳定训练和不收敛等问题。本文还从应用的角度，对各种GANs的行为和实现细节进行了比较。我们提出了一个新的基于架构、损失、正则化和发散的框架来识别特定用例的候选gan。我们还通过一个例子讨论了该框架的应用，并证明了搜索空间的显著减少。这种确定潜在GANs的有效方法降低了组织人工智能开发的单位经济性。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08641">PDF</a>
<h3>No. 32	成对判别器在对抗性训练中的优势</h3><h4>Shangyuan Tong, Timur Garipov, Tommi Jaakkola</h4>摘要：对抗性训练方法通常是通过求解两人博弈来调整分布。然而，在大多数现有的公式中，即使生成器与数据完全对齐，次优鉴别器仍然可以将两者分开。如果没有额外的正则化，不稳定性可以表现为一个永无止境的博弈。本文利用成对判别器引入一类目标，并证明只有生成器需要收敛。如果实现对齐，将使用任何鉴别器来保持对齐。我们提供了局部收敛的充分条件；刻画了指导鉴别器和生成器选择的容量平衡；构造了最小充分鉴别器的例子。在实证方面，我们通过综合实例来说明我们的理论和方法的有效性。此外，我们还证明了由我们的方法得到的实用方法可以更好地生成更高分辨率的图像。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08621">PDF</a>
<h3>No. 33	超球面嵌入促进对抗性训练</h3><h4>Tianyu Pang, Xiao Yang, Yinpeng Dong, Kun Xu, Hang Su, Jun Zhu</h4>摘要：对抗性训练是提高深度学习模型对抗性稳健性最有效的防御手段之一。为了提高对抗训练模型的可靠性，我们提出通过引入超球嵌入（HE）来增强AT，将对抗特征正则化到紧超球流形上。我们正式证明AT和HE是良好耦合的，这从几个方面调节了AT的学习动态。我们通过将其嵌入流行的AT框架（包括PGD-AT、ALP和TRADES）以及FreeAT和FastAT策略，全面验证了HE的有效性和普遍性。在实验中，我们在CIFAR-10和ImageNet数据集上对我们的方法进行了评估，并验证了集成HE可以在不增加额外计算的情况下，一致地提高由每个AT框架训练的模型的性能。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08619">PDF</a>
<h3>No. 34	多样性抽样是核方法的隐式正则化</h3><h4>Michaël Fanuel, Joachim Schreurs, Johan A.K. Suykens</h4>文摘：利用Nystr“om方法和预处理技术，核方法在大规模回归和分类问题上取得了很好的效果。基于地标子集的Nystr“om近似给出了核矩阵的低阶近似，并且已知它提供了一种隐式正则化形式。我们进一步阐述了在有监督和无监督核方法中，采样不同的标记对构造Nystr“om近似的影响。利用行列式点过程进行采样，我们得到了关于多样性和正则化之间相互作用的额外理论结果。在实验上，我们证明了基于不同点子集的核训练方法的优势。特别是，如果数据集具有密集的块和稀疏的尾部，我们表明，对于均匀的地标采样，具有不同地标的Nystr“om核回归提高了数据集稀疏区域回归的准确性。当精确的DPP抽样不可行时，本文还提出了一种贪婪的启发式算法来选择大数据集中不同大小的样本。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08616">PDF</a>
<h3>No. 35	用自适应代理优化黑盒度量</h3><h4>Qijia Jiang, Olaoluwa Adigun, Harikrishna Narasimhan, Mahdi Milani Fard, Maya Gupta</h4>文摘：通过将度量表示为少数易优化代理的单调函数，解决了具有黑盒和难以优化度量的训练模型问题。我们将训练问题作为松弛代理空间上的优化问题，通过估计度量的局部梯度和执行不精确的凸投影来求解。我们分析了基于有限差分和局部线性插值的梯度估计，并证明了我们的方法在光滑性假设下相对于替代项的收敛性。在分类和排序问题上的实验结果验证了该方案的性能与已知数学公式的方法相当，并且在度量形式未知时增加了显著值。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08605">PDF</a>
<h3>No. 36	关于对称元的学习集</h3><h4>Haggai Maron, Or Litany, Gal Chechik, Ethan Fetaya</h4>摘要：无序集学习是一种基础性的学习方式，越来越受到人们的关注。这一领域的研究主要集中在集合元素由特征向量表示的情况下，而对于集合元素本身具有一定对称性的常见情况则很少有人关注。这种情况与许多应用相关，从去模糊图像爆发到多视图三维形状识别和重建。本文提出了一种学习一般对称元集合的原理方法。我们首先刻画了线性层的空间，线性层对元素的重新排序和元素的固有对称性都是等价的，比如图像的平移。我们进一步证明了由这些层组成的网络，称为对称元层的深集（DSS），是不变和等变函数的普遍逼近。DSS层也易于实现。最后，通过一系列图像、图形和点云的实验，我们证明它们比现有的集合学习体系结构有所改进。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08599">PDF</a>
<h3>No. 37	基于机器学习的医疗预测模型的可解释性</h3><h4>Gregor Stiglic, Primoz Kocbek, Nino Fijacko, Marinka Zitnik, Katrien Verbert, Leona Cilar</h4>摘要：需要保证机器学习模型的可解释性。模型的可解释性越高，最终用户就越容易理解和解释未来的预测。此外，可解释的机器学习模型允许医疗专家做出合理的、数据驱动的决策，以提供个性化的决策，从而最终提高医疗服务质量。一般来说，我们可以将可解释性方法分为两类，第一类侧重于个性化解释（局部可解释性），而第二类侧重于总体水平上的预测模型（全局可解释性）。或者，我们可以将可解释性方法分为特定于模型的技术，这些技术用于解释特定模型（如神经网络）生成的预测，以及模型不可知的方法，这些方法提供了对任何机器学习模型生成的预测的易于理解的解释。在这里，我们概述了可解释性方法，并提供了机器学习在不同医疗领域的实际可解释性示例，包括预测与健康相关的结果、优化治疗或提高特定条件筛选的效率。此外，我们概述了可解释机器学习的未来方向，并强调了开发算法解决方案的重要性，该解决方案可使机器学习驱动的决策在高风险医疗问题中得以实现。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08596">PDF</a>
<h3>No. 38	随机情境决斗中的后悔最小化</h3><h4>Aadirupa Saha, Aditya Gopalan</h4>文摘：我们研究了上下文环境中的随机$K$-武装决斗强盗问题，在每一轮中，学习者被呈现一个由$K$项组成的上下文集，每个上下文集由$d$-维特征向量表示，学习者的目标是确定每个上下文集的最佳手臂。然而，与经典的上下文盗贼设置不同，我们的框架只允许学习者根据他们（嘈杂的）偏好接收项目反馈——著名的研究是决斗盗贼，这是各种在线决策场景中的实际兴趣，例如推荐系统、信息检索、锦标赛排名，更容易得出项目的相对强度，而不是它们的绝对分数。然而，据我们所知，这项工作是第一次考虑潜在无限决策空间中上下文决斗强盗的后悔最小化问题，并给出可证明的最优算法和匹配的下界分析。我们提出了两种设置算法，分别具有遗憾保证$\tilde O（d\sqrt{T}）$和$\tildeo（\sqrt{dT\log K}）$。随后我们还证明了$\Omega（\sqrt{dT}）$实际上是这个问题的基本性能限制，这意味着我们的第二个算法是最优性的。然而，我们对第一种算法的分析比较简单，而且从经验上来看，它常常表现出优于前者。最后，我们用适当的实验证实了所有的理论结果。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08583">PDF</a>
<h3>No. 39	基于数据扰动的差异私有ERM</h3><h4>Yilin Kang, Yong Liu, Lizhong Ding, Xinwang Liu, Xinyi Tong, Weiping Wang</h4>文摘：本文通过观察不同的训练数据实例对机器学习模型的影响程度，试图从一个新的角度提高差异私人经验风险最小化（DP-ERM）的性能。具体来说，我们在最终的机器学习模型上测量各种训练数据实例的贡献，并选择其中一些实例来添加随机噪声。考虑到我们的方法的关键是分别测量每个数据实例，我们提出了一种新的基于数据扰动的DP-ERM模型：在原始训练数据中加入随机噪声，在最终的机器学习模型上实现（$\epsilon，delta$）差分隐私，同时保留原始数据。通过引入影响函数（IF），定量地度量了训练数据对最终模型的影响。理论和实验结果表明，我们提出的DBDP-ERM范式显著提高了模型的性能。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08578">PDF</a>
<h3>No. 40	输入扰动：中心与局部差异隐私的新范式</h3><h4>Yilin Kang, Yong Liu, Ben Niu, Xinyi Tong, Likun Zhang, Weiping Wang</h4>摘要：传统上，关于差异隐私的研究有两种模型：中心模型和局部模型。中心模型以机器学习模型为中心，局部模型以训练数据为中心。本文研究了微分私有经验风险最小化（DP-ERM）中的输入扰动法，它保留了中心模型的隐私性。通过在原始训练数据中添加噪声，并使用“扰动数据”进行训练，我们在最终模型上实现了（$\epsilon$，$\delta$）-差异隐私，以及原始数据上的某种隐私。我们发现局部模型和中心模型之间有一个有趣的联系：原始数据的扰动导致梯度的扰动，最后是模型参数的扰动。这意味着我们的方法在局部模型和中心模型之间架起了一座桥梁，同时保护了数据、梯度和模型，比以往的中心方法更优越。详细的理论分析和实验表明，该方法在保护隐私的前提下，取得了与以往一些最好的中心方法几乎相同（甚至更好）的性能，是一个很有吸引力的结果。此外，我们将我们的方法推广到一个更一般的情况：损失函数满足Polyak-Lojasiewicz条件，这比以往大多数工作中对损失函数的约束强凸性更一般。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08570">PDF</a>
<h3>No. 41	分散系统中的拜占庭弹性学习</h3><h4>Shangwei Guo, Tianwei Zhang, Xiaofei Xie, Lei Ma, Tao Xiang, Yang Liu</h4>摘要：随着物联网和边缘计算的普及，分散学习越来越有希望。在设计分布式学习系统时，需要考虑的一个主要挑战是拜占庭容错（BFT）。过去的工作已经研究了集中分布式学习的拜占庭弹性解决方案。然而，在分散系统中，目前还没有一个具有很强的效率和安全性的令人满意的解决方案。本文提出了一种在分散学习系统中实现BFT的新算法Mozi。具体来说，Mozi为良性节点提供了一个统一的拜占庭弹性聚合规则，用于在每次训练迭代中选择有用的参数更新并过滤掉恶意的参数更新。它保证了分散系统中的每一个良性节点都能在具有任意数量故障节点的强拜占庭攻击下训练出正确的模型。通过理论分析证明了算法的一致收敛性。实验结果表明，与现有的解决方案相比，Mozi具有较高的安全性和效率。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08569">PDF</a>
<h3>No. 42	自供电可持续边缘计算系统的多智能体元强化学习</h3><h4>Md. Shirajum Munir, Nguyen H. Tran, Walid Saad, Choong Seon Hong</h4>文摘：移动边缘计算（MEC）应用和功能的严格要求决定了MEC主机向未来无线网络的高容量、高密度部署。然而，运行这样高容量的MEC主机会显著增加能耗。因此，BS单元可以充当自供电BS。研究了一种有效的具有边缘计算能力的自供电无线网络能量分配机制。首先，以满足能源需求时系统总能耗费用最小为目标，建立了两阶段线性随机规划问题。其次，通过开发一种新的多智能体元强化学习（MAMRL）框架，提出了一种半分布式数据驱动的解决方案。特别是，每个BS扮演本地代理的角色，在每个BS向元代理传输时变特征的同时，探索能量消耗和生成的Markovian行为。接着，元代理通过只接受来自每个本地代理的具有其自身状态信息的观察来优化（即，利用）能量分配决策。同时，每个BS代理通过应用元代理的学习参数来估计自己的能量分配策略。最后，通过分析确定性、非对称性和随机性环境下的不可再生能源使用、能源成本和准确性，对所提出的MAMRL框架进行了基准测试。实验结果表明，与其他基线方法相比，该模型可以减少11%的不可再生能源使用，降低22.4%的能源成本（预测精度为95.8%）。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08567">PDF</a>
<h3>No. 43	非线性动力系统的非渐近精确学习</h3><h4>Yahya Sattar, Samet Oymak</h4>文摘：研究了由非线性状态方程$h{t+1}=\phi（h{t，u{t；\theta）+w}控制的可镇定系统的学习问题。这里$\theta$是未知系统动力学，$h_t$是状态，$u t$是输入，$w_t$是加性噪声矢量。我们研究基于梯度的算法，从单个有限轨迹的样本中学习系统动力学$\theta$。如果系统是由一个稳定的输入策略运行的，我们证明通过使用混合时间参数的截断参数，时间相关样本可以由i.i.d.样本近似。然后，我们为经验损失梯度的一致收敛性发展了新的保证。与现有的工作不同，我们的边界是噪声敏感的，这允许以高精度和小样本复杂度学习地面真实动态。总之，我们的结果有助于在稳定策略下有效地学习一般非线性系统。我们专门研究了入口非线性激活的保证，并在各种数值实验中验证了我们的理论<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08538">PDF</a>
<h3>No. 44	安全反事实强化学习</h3><h4>Yusuke Narita, Shota Yasui, Kohei Yata</h4>文摘：针对不同算法可能产生的历史数据，提出了一种预测强化学习和bandit算法性能的方法。我们的估计器具有这样的性质：当样本量增加$N$时，它的预测在快速$\sqrt{N}$速率下以概率收敛到反事实算法的真实性能。我们还展示了一种正确的方法来估计我们预测的方差，从而允许分析师量化预测中的不确定性。即使分析员不知道在大量潜在的重要状态变量中哪一个是真正重要的，这些属性仍然有效。这些理论保证使我们的估计器可以安全使用。最后将其应用于某大型广告公司的广告设计改进。我们发现我们的方法产生的均方误差比最新的方法小。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08536">PDF</a>
<h3>No. 45	非均匀分布数据集的自适应抽样分布随机方差降阶</h3><h4>Ilqar Ramazanli, Han Nguyen, Hai Pham, Sashank Reddi, Barnabas Poczos</h4>文摘：为了使分布在多台机器上的{emph{异构}函数的平均值最小化，我们研究了分布式优化算法，重点是通信效率。在这种情况下，单纯地使用经典随机梯度下降（SGD）或其变体（如SVRG）对机器进行均匀采样通常会产生较差的性能。它常常导致收敛速度依赖于器件梯度的最大Lipschitz常数。在这篇文章中，我们提出了一种新的适合这些设置的机器的emph{自适应}采样。我们的方法依赖于基于过去梯度信息的局部Lipschitz常数的自适应估计。结果表明，新方法提高了机器收敛速度对最大Lipschitz常数到emph{average}Lipschitz常数的依赖性，从而显著加快了收敛速度。实验表明，该方法确实加快了标准SVRG算法在异构环境下的收敛速度。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08528">PDF</a>
<h3>No. 46	纳塔克！绕过基于GAN的网络入侵检测分类器的对抗性攻击</h3><h4>Aritran Piplai, Sai Sree Laya Chukkapalli, Anupam Joshi</h4>文摘：随着人工智能和机器学习的发展，利用机器学习方法可以检测出网络流量的异常。在机器学习兴起之前，人们使用精心设计的规则检测出可能意味着攻击的网络异常。具有网络防御领域知识的攻击者可以进行有根据的猜测，有时可以准确预测网络防御机制正在查看的网络流量数据的哪些特定特征。利用这些信息，攻击者可以绕过基于规则的网络防御系统。然而，随着网络异常的机器学习技术的发展，人们很难理解如何绕过网络防御系统。近年来，对抗性攻击已经越来越普遍地用来击败机器学习算法。在本文中，我们证明了即使我们建立了一个分类器，并用对抗性的例子对其进行训练，我们也可以使用对抗性攻击并成功地破坏系统。提出了一种基于生成性对抗网络（GAN）的数据生成算法来训练一种高效的基于神经网络的分类器，并利用对抗性攻击对系统进行了破坏。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08527">PDF</a>
<h3>No. 47	可伸缩约束贝叶斯优化</h3><h4>David Eriksson, Matthias Poloczek</h4>摘要：黑箱约束下高维黑箱函数的全局优化是机器学习、控制和工程中普遍存在的问题。这些问题是困难的，因为可行集是典型的非凸的，很难找到，除了维数的诅咒和潜在函数的异质性。特别是，这些特性极大地影响了贝叶斯优化方法的性能，否则贝叶斯优化方法已成为无约束条件下样本有效优化的事实标准。由于缺乏有效的样本方法，实践者通常会求助于进化策略或启发式方法。我们提出了可伸缩约束贝叶斯优化（SCBO）算法，该算法通过函数的数据无关转换来解决上述问题，并遵循最近局部贝叶斯优化的主题。综合实验评价表明，SCBO方法取得了良好的效果，优于目前最先进的方法。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08526">PDF</a>
<h3>No. 48	避免核不动点：用ELU和GELU无限网络计算</h3><h4>Russell Tsuchida, Tim Pearce, Christopher Van Der Heide, Fred Roosta, Marcus Gallagher</h4>文摘：用无限宽的神经网络产生的高斯过程进行分析和计算，最近重新流行起来。尽管如此，现代网络中使用的具有激活函数的网络的许多显式协方差函数仍然是未知的。此外，虽然深网络的核可以迭代计算，但缺乏对深核的理论理解，特别是在不动点动力学方面。首先，我们推导了具有指数线性单位和高斯误差线性单位的mlp的协方差函数，并在一些基准上评估了极限高斯过程的性能。其次，更广泛地说，我们引入了一个框架来分析对应于广泛激活函数的迭代核的不动点动力学。我们发现，与以往研究的一些神经网络核不同，这些新核具有非平凡的不动点动力学，这些不动点动力学反映在有限宽度神经网络中。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08517">PDF</a>
<h3>No. 49	跟踪梯度下降估计训练数据的影响</h3><h4>Garima Pruthi, Frederick Liu, Mukund Sundararajan, Satyen Kale</h4>文摘：介绍了一种称为TrackIn的方法，该方法通过跟踪在使用感兴趣的训练样本时，测试点的损失在训练过程中的变化，计算训练样本对模型预测的影响。我们结合以下几个关键思想，提供TrackIn的可扩展实现：（a）精确计算的一阶近似，（b）使用随机投影加速大型模型的一阶近似计算，（c）使用标准训练过程的保存检查点，和（d）樱桃采摘层的深层神经网络。实验结果表明，TrackIn比其它相关方法（如影响函数和抑制点）更能有效地识别错误标记的训练样本。我们还讨论了将该方法应用于视觉、回归和自然语言任务的见解。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08484">PDF</a>
<h3>No. 50	以弱胜强：用弱监督快速学习</h3><h4>Joshua Robinson, Stefanie Jegelka, Suvrit Sra</h4>文摘：研究了弱监督学习的泛化性质。也就是说，学习只有几个“强”标签（我们预测的实际目标）存在，但有更多的“弱”标签可用。特别是，我们表明，访问弱标签可以显著加快强任务的学习速度，使其达到快速的$\mathcal{O}（\nicefrac1n）$，其中$n$表示强标签数据点的数量。即使强标记数据本身只允许较慢的$\mathcal{O}（\nicefrac{1}{\sqrt{n}}）$速率，也可能发生这种加速。实际的加速持续地取决于可用的弱标签的数量，以及这两个任务之间的关系。我们的理论结果在一系列任务中得到了实证性的反映，并说明了弱标签如何加速强任务的学习。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08483">PDF</a>
<h3>No. 51	AdvMS：对抗性攻击的多源多代价防御</h3><h4>Xiao Wang, Siyue Wang, Pin-Yu Chen, Xue Lin, Peter Chin</h4>文摘：随着深层神经网络在恶意软件检测、汽车自动驾驶等安全关键领域的迅速发展，设计有效的防御措施成为一个重要课题。传统的防御方法，虽然被证明是有前途的，但在很大程度上受限于其单一来源单一成本的性质：当防御变得越来越强大而成本趋于放大时，鲁棒性提升趋于平稳。本文研究了利用多个防御组件提高防御性能的多源多代价方案设计原则。基于这一动机，我们提出了一种多源、多代价的防御方案，即对抗训练模型切换（AdvMS），它继承了两种主要方案的优点：对抗训练和随机模型切换。我们证明AdvMS的多源特性缓解了性能停滞的问题，并且多成本特性使得能够在不同因素上的灵活和可调整的成本组合下提高健壮性，从而更好地适应实际中的特定限制和需求。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08439">PDF</a>
<h3>No. 52	PrivacyFL：一个用于隐私保护和安全联邦学习的模拟器</h3><h4>Vaikkunth Mugunthan, Anton Peraire-Bueno, Lalana Kagal</h4>摘要：联合学习是一种使分布式客户机能够在保持训练数据本地化的同时协同学习共享机器学习模型的技术。这降低了数据隐私风险，然而，由于可能从训练模型的权重或参数中泄漏有关训练数据集的信息，隐私问题仍然存在。建立一个联邦学习环境，特别是有安全和隐私保证的环境，是一个耗时的过程，有许多配置和参数可以操作。为了帮助客户确保协作是可行的，并检查协作是否提高了模型的准确性，需要一个用于隐私保护和安全联邦学习的真实世界模拟器。本文介绍了PrivacyFL，它是一个可扩展、易配置、可扩展的联邦学习环境模拟器。其关键特性包括延迟模拟、对客户端离开的鲁棒性、对集中和分散学习的支持，以及基于差异隐私和安全多方计算的可配置隐私和安全机制。在本文中，我们激发了我们的研究，描述了模拟器和相关协议的体系结构，并讨论了它在许多场景中的评估，突出了它的广泛功能和优势。我们的论文解决了一个重要的现实问题：在各种情况下检查参与联合学习环境的可行性。它还具有很强的实际影响，因为医院、银行和研究机构等拥有大量敏感数据并愿意合作的组织，将从拥有一个能够以保护隐私和安全的方式这样做的系统中受益匪浅。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08423">PDF</a>
<h3>No. 53	从混杂的数据中获取侧面信息的热启动盗贼</h3><h4>Nihal Sharma, Soumya Basu, Karthikeyan Shanmugam, Sanjay Shakkottai</h4>文摘：研究了多臂匪徒问题的一个变种，即在每个臂的平均值上以边界的形式提供边信息。我们描述了这些方法的界限是如何有效地用于暖启动强盗。具体地说，我们提出了新的UCB-SI算法，并在理论上和经验上说明了在存在非平凡边信息的情况下，相对于标准UCB算法在累积遗憾方面的改进。如（Zhang&Bareinboim，2017）中所述，例如，当我们事先记录了武器数据时，就会出现此类信息，但这些数据是根据一项政策收集的，该政策的武器选择基于潜在变量，无法再获得这些变量。我们进一步提供了一种新的方法，在一些温和的假设下，从先前的部分混淆数据中获得这种界限。我们通过对来自真实数据集的数据进行半合成实验来验证我们的发现。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08405">PDF</a>
<h3>No. 54	继续做有用的事情：离线强化学习的行为建模优先级</h3><h4>Noah Y. Siegel, Jost Tobias Springenberg, Felix Berkenkamp, Abbas Abdolmaleki, Michael Neunert, Thomas Lampe, Roland Hafner, Martin Riedmiller</h4>摘要：非策略强化学习算法有望应用于只有固定数据集（批）的环境交互而无法获得新经验的环境中。这种特性使得这些算法对现实世界中的机器人控制等问题具有很强的吸引力。然而，在实践中，标准的非策略算法在连续控制的批处理设置中失败。在本文中，我们提出了一个简单的解决方案。它允许使用由任意行为策略生成的数据，并使用已学习的先验优势加权行为模型（ABM）将RL策略偏向于先前已执行并可能成功执行新任务的操作。我们的方法可以看作是最近批处理RL工作的一个扩展，它支持从冲突的数据源进行稳定的学习。我们发现在各种RL任务（包括标准连续控制基准和模拟和现实世界机器人的多任务学习）中，竞争基线有了改进。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08396">PDF</a>
<h3>No. 55	从很少的测量数据预测量子系统的许多性质</h3><h4>Hsin-Yuan Huang, Richard Kueng, John Preskill</h4>摘要：预测复杂、大规模量子系统的性质是发展量子技术的关键。我们提出了一个有效的方法来构造一个量子态的近似经典描述使用很少的状态测量。此描述称为经典阴影，可用于预测许多不同的属性：order$\log M$测量值足以准确预测$M$状态的不同函数，成功率很高。测量的次数与系统的大小无关，并且饱和了信息论的下界。此外，在测量完成后，可以选择要预测的目标特性。我们用大量的数值实验来支持我们的理论发现。我们应用经典阴影来预测量子保真度、纠缠熵、两点相关函数、局部观测的期望值以及多体局部哈密顿量的能量方差，这使得应用可以加速变分量子算法。数值结果突出了传统阴影方法相对于已知方法的优点。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08953">PDF</a>
<h3>No. 56	I-SPEC：一个端到端的框架，用于学习可移植的、移位稳定的模型</h3><h4>Adarsh Subbaswamy, Suchi Saria</h4>文摘：环境在开发和部署之间的转换导致经典的有监督学习产生的模型不能很好地推广到新的目标分布。近年来，许多求解不变预测分布的方法得到了发展。其中，基于图的方法不需要来自目标环境的数据，并且可以捕获比寻找稳定特征集的替代方法更稳定的信息。然而，这些方法假设数据生成过程是以完全因果图的形式已知的，而事实并非如此。在本文中，我们提出了一个端到端的框架I-SPEC，它通过使用数据学习部分祖先图（PAG）来解决这个缺点。使用PAG，我们开发了一种算法，该算法确定了一个对所声明的位移稳定的介入分布；这包括了现有的方法，这些方法可以找到不太准确的稳定特征集。我们将I-SPEC应用于一个死亡率预测问题，以证明它可以学习一个对位移具有鲁棒性的模型，而无需预先了解完全因果DAG。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08948">PDF</a>
<h3>No. 57	超参数优化的Lasso型模型的隐式微分</h3><h4>Quentin Bertrand, Quentin Klopfenstein, Mathieu Blondel, Samuel Vaiter, Alexandre Gramfort, Joseph Salmon</h4>文摘：为套索型估计量设置正则化参数是众所周知的困难，但在实际应用中至关重要。最流行的超参数优化方法是使用保留的验证数据进行网格搜索。但是，网格搜索需要为每个参数选择一个预定义的网格，该网格在参数数量上呈指数级缩放。另一种方法是将超参数优化问题转化为两级优化问题，通过梯度下降法求解。这些方法的关键挑战是对超参数梯度的估计。通过前向或后向自动微分计算这种梯度是可能的，但通常会受到高内存消耗的影响。另外，隐式微分通常涉及求解一个线性系统，该系统在高维时可能是禁止的，并且在数值上是不稳定的。此外，隐式微分通常假定光滑损失函数，而套索问题则不是这样。这项工作介绍了一个有效的隐式微分算法，不需要矩阵反演，适合于套索型问题。我们的方法通过利用解决方案的稀疏性来扩展高维数据。实验结果表明，该方法优于大量的标准方法，即Stein无偏风险估计器（SURE）。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08943">PDF</a>
<h3>No. 58	Wavesplit：基于说话人聚类的端到端语音分离</h3><h4>Neil Zeghidour, David Grangier</h4>文摘：介绍了一种端到端语音分离系统Wavesplit。从混合语音的单个记录中，该模型推断并聚类每个说话人的表示，然后根据推断的表示估计每个源信号。该模型在原始波形上进行训练，以共同执行这两项任务。我们的模型通过聚类推断出一组说话人表示，这解决了语音分离的基本排列问题。此外，与以前的方法相比，序列宽的说话人表示提供了对长的、具有挑战性的序列的更健壮的分离。我们表明，在2个或3个扬声器（WSJ0-2mix，WSJ0-3mix）的干净混合物以及在嘈杂（WHAM！）中，Wavesplit优于先前的最新技术回荡（哇！）条件。作为一个额外的贡献，我们进一步改进了我们的模型，引入了在线数据增强分离。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08933">PDF</a>
<h3>No. 59	插补器：基于插补和动态规划的序列建模</h3><h4>William Chan, Chitwan Saharia, Geoffrey Hinton, Mohammad Norouzi, Navdeep Jaitly</h4>文摘：提出了一种通过输入迭代产生输出序列的神经序列模型——输入器。输入端是一个迭代生成模型，只需要与输入或输出标记数无关的恒定生成步骤数。可以训练输入者在输入和输出序列以及所有可能的生成顺序之间的所有可能对齐上近似边缘化。我们提出了一个可处理的动态规划训练算法，它给出了对数边际似然的一个下界。当应用于端到端语音识别时，该输入函数的性能优于已有的非自回归模型，并取得了与自回归模型相媲美的结果。在LibriSpeech测试中，输入功率达到11.1wer，在13.0wer下优于CTC，在12.5wer下优于seq2seq。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08926">PDF</a>
<h3>No. 60	你能在语言模型的参数中包含多少知识？</h3><h4>Adam Roberts, Colin Raffel, Noam Shazeer</h4>文摘：近年来有研究表明，在非结构化文本上训练的神经语言模型可以利用自然语言查询隐式地存储和检索知识。在这篇短文中，我们通过微调预先训练的模型来衡量这种方法的实用性，以回答问题，而不需要访问任何外部环境或知识。我们表明，这种方法与模型大小的比例惊人地好，并且优于显式查找自然问题和web问题的开放域变量的知识的模型。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08910">PDF</a>
<h3>No. 61	领域：检索增强语言模型预训练</h3><h4>Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat, Ming-Wei Chang</h4>摘要：语言模型的预训练已经被证明能够捕捉到大量的世界知识，这对于NLP任务如问答至关重要。然而，这些知识被隐式地存储在神经网络的参数中，需要更大的网络来覆盖更多的事实。为了以更模块化和可解释的方式获取知识，我们在语言模型的预训练中增加了一个潜在的知识检索器，它允许模型从一个大的语料库（如维基百科）中检索和处理文档，用于预训练、微调和推理。我们首次展示了如何以无监督的方式预先训练这样的知识检索器，使用蒙面语言建模作为学习信号，并通过考虑数百万文档的检索步骤进行反向传播。通过对开放域问答（Open QA）这一具有挑战性的任务进行微调，我们证明了检索增强语言模型预训练（REALM）的有效性。我们对比了三个流行的开放式QA基准上的显式和隐式知识存储的最新模型，发现我们在提供可解释性和模块性等质量优势的同时，显著优于所有以前的方法（4-16%的绝对准确性）。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08909">PDF</a>
<h3>No. 62	二阶条件梯度</h3><h4>Alejandro Carderera, Sebastian Pokutta</h4>文摘：约束二阶凸优化算法是一类需要高精度求解的问题，由于其二次收敛速度快，在接近最优解时具有良好的收敛性。这些算法需要在每次迭代中求解一个约束二次型子问题。在可行域只能通过线性优化oracle有效访问的情况下，虽然计算函数的一阶信息是可能的，但是代价很高，约束二阶梯度算法和条件梯度算法的耦合使得竞争算法具有坚实的理论保证和良好的性能数值性能。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08907">PDF</a>
<h3>No. 63	预训练模型在命名实体识别中的应用</h3><h4>Yu Wang, Yining Sun, Zuchang Ma, Lisheng Gao, Yang Xu, Ting Sun</h4>文摘：命名实体识别是从非结构化数据中提取实体的基本自然语言处理任务。以往的神经网络学习方法都是基于机器学习或深度学习。最近，训练前的模型在多个NLP任务上显著提高了性能。本文首先介绍了四种常见的预训练模型BERT、ERNIE、ERNIE2.0-tiny和RoBERTa的体系结构和预训练任务。然后，我们通过微调将这些预训练模型应用到NER任务中，并比较不同模型结构和预训练任务对NER任务的影响。实验结果表明，RoBERTa在MSRA-2006数据集上取得了最新的结果。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08902">PDF</a>
<h3>No. 64	在严重精神病患者队列中鉴别身体健康共病：SemEHR的应用</h3><h4>Rebecca Bendayan, Honghan Wu, Zeljko Kraljevic, Robert Stewart, Tom Searle, Jaya Chaturvedi, Jayati Das-Munshi, Zina Ibrahim, Aurelie Mascio, Angus Roberts, Daniel Bean, Richard Dobson</h4>摘要：心理健康服务中的多发病率研究需要来自身体健康状况的数据，而传统的心理健康保健电子健康记录是有限的。在这项研究中，我们的目的是从使用SemEHR的临床笔记中提取身体健康状况的数据。数据从伦敦南部和Maudsley生物医学研究中心（SLaM BRC）的临床记录交互搜索（CRIS）系统中提取，该队列由2007年至2018年间接受过严重精神疾病一级或二级诊断的所有个人组成。三对注释者注释了2403个文档，平均Cohen's Kappa为0.757。结果表明，不同疾病区（F1为0.601～0.954）的NLP表现不同，说明不同疾病组的语言模式或术语对同一NLP任务提出了不同的技术挑战。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08901">PDF</a>
<h3>No. 65	SynFi：自动合成指纹生成</h3><h4>M. Sadegh Riazi, Seyed M. Chavoshian, Farinaz Koushanfar</h4>摘要：基于人体指纹的身份认证和识别方法在从政府机构到消费品等多个系统中普遍存在。这些系统的性能和可靠性直接取决于它们被证实的数据量。不幸的是，由于许多隐私和安全问题，大量的指纹数据库无法公开。本文介绍了一种自动生成高保真合成指纹的新方法。我们的方法依赖于（i）生成性对抗网络来估计人类指纹的概率分布，（ii）超分辨率方法来合成精细纹理。我们对我们的系统进行了严格的测试，结果表明我们的方法是第一个生成在计算上与真实指纹不可区分的指纹的方法，这是现有技术无法完成的任务。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08900">PDF</a>
<h3>No. 66	MA-DST:基于多注意力的可伸缩对话状态跟踪</h3><h4>Adarsh Kumar, Peter Ku, Anuj Kumar Goyal, Angeliki Metallinou, Dilek Hakkani-Tur</h4>摘要：面向任务的对话代理为用户提供了一个自然的语言接口来完成他们的目标。对话状态跟踪（DST）通常是这些系统的核心组件，它在整个对话过程中跟踪系统对用户目标的理解。为了实现准确的多域DST，该模型需要对过去话语和时隙语义之间的依赖关系进行编码，并理解对话上下文，包括远程跨域引用。为此，我们提出了一种新的结构，通过在多个粒度上使用注意机制，使会话历史和时隙语义的编码更加可靠。特别地，我们使用交叉注意在不同的语义层次上建立上下文和时隙之间的关系模型，并使用自我注意来解决跨域互指。此外，我们提出的架构不依赖于预先了解领域本体，也可以用于新领域或未看到时隙值的零快照设置。与MultiWoZ 2.1数据集的最新技术相比，我们的模型在全数据设置中的联合目标精度提高了5%（绝对），在零炮设置中的联合目标精度提高了2%（绝对）。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08898">PDF</a>
<h3>No. 67	具有冗余数据分配的可靠分布式集群</h3><h4>Venkata Gandikota, Arya Mazumdar, Ankit Singh Rawat</h4>文摘：本文提出了一种分布式广义聚类算法，该算法能在多台机器之间处理大规模数据，而不必考虑机器的分散性和不可靠性。我们提出了一种新的数据分配方案，使我们能够获得关于整个数据的全局信息，即使在某些机器无法对分配的本地计算结果作出响应的情况下。这种分配方案使得分布式算法能够很好地逼近各种聚类和降维问题。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08892">PDF</a>
<h3>No. 68	多智能体强化学习作为语言进化研究的计算工具：历史背景与未来挑战</h3><h4>Clément Moulin-Frier, Pierre-Yves Oudeyer</h4>摘要：由于多智能体强化学习（MARL）的最新进展，智能体群体中紧急通信的计算模型正受到机器学习界的关注。然而，目前的研究成果仍然与早期的理论和计算文献相对脱节，这些文献旨在理解语言是如何从一种语言前的物质中产生的。本文的目的是将近年来MARL的贡献放在语言进化研究的历史背景下，并从这一理论和计算背景中提炼出未来研究的一些挑战。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08878">PDF</a>
<h3>No. 69	近似最优无参数单调包含的Halpern迭代及变分不等式的强解</h3><h4>Jelena Diakonikolas</h4>文摘：利用非扩张映射、单调Lipschitz算子和近端映射之间的联系，得到了求解单调包含问题的近最优（即迭代复杂度方面的最优多对数因子）和无参数方法。这些结果立即转化为逼近变分不等式问题强解、逼近凸凹极小极大优化问题和最小化极小极大优化问题梯度范数的近似最优保证。我们的分析基于一个新的简单的基于势的Halpern迭代收敛性证明，这是一个寻找非扩张映射不动点的经典迭代。此外，我们还提供了一系列算法简化，突出了不同问题类别之间的联系，并得出了证明所研究方法接近最优的下界。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08872">PDF</a>
<h3>No. 70	快速可微排序与排序</h3><h4>Mathieu Blondel, Olivier Teboul, Quentin Berthet, Josip Djolonga</h4>文摘：排序操作是计算机程序设计中最基本、最常用的组成部分之一。在机器学习中，它通常用于稳健统计。然而，作为一个函数，它是分段线性的，因此包含许多不可微的扭结。更麻烦的是相关的排名运算符，通常用于订单统计和排名度量。它是一个分段常数函数，意味着它的导数为空或未定义。虽然许多工作都提出了排序和排序的可微代理，但它们并没有达到排序和排序操作所期望的$O（n\logn）$时间复杂性。在本文中，我们提出了具有$O（n\logn）$时间和$O（n）$空间复杂度的第一可微排序和排序算子。此外，我们的建议具有精确的计算和微分。我们通过构造可微排序和排序算子作为对置换的凸壳置换面的投影，并使用降阶等渗优化来实现这一点。在经验上，我们确认我们的方法比现有方法快一个数量级，并展示了两个新的应用：可微Spearman秩相关系数和软最小二乘法。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08871">PDF</a>
<h3>No. 71	普遍句表征的语境宽容</h3><h4>Jamie Kiros</h4>文摘：什么使通用句子编码器具有通用性？通用文本编码的概念似乎与动态世界中语言使用的内在语境化和非永久性相矛盾。然而，将句子映射成通用的固定长度向量，用于下游相似度和检索任务，已经取得了丰硕的成果，特别是对于多语言应用程序。我们如何应对这种困境？在这项工作中，我们提出了语境Lensing，一种诱导面向语境的通用句子向量的方法。我们将通用句子向量的构造分解为一个核心的、可变长度的句子矩阵表示，并配备一个自适应的“镜头”，从中可以将固定长度的向量归纳为镜头上下文的函数。我们证明，在给定核心通用矩阵表示的情况下，可以将语言相似性的概念集中到少数镜头参数中。例如，我们演示了将跨多种语言的句子翻译相似度编码为单个权重矩阵的能力，即使核心编码器没有看到并行数据。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08866">PDF</a>
<h3>No. 72	带提前停止的非凸优化的期望运行时间的界</h3><h4>Thomas Flynn, Kwang Min Yu, Abid Malik, Nicolas D'Imperio, Shinjae Yoo</h4>摘要：本文研究了基于随机梯度的优化算法的收敛性，该算法使用基于验证函数的早期停止。我们考虑的早期停止形式是当验证函数的梯度范数低于阈值时，优化终止。我们导出了保证该停止规则定义良好的条件，并提供了满足该条件所需的迭代次数和梯度计算的边界。保证说明了训练集和验证集之间的距离，用Wasserstein距离来衡量。我们在一阶优化算法的一般设定下发展了该方法，在几何漂移条件下，更新方向可能有偏差。然后，我们推导了几种算法（包括随机梯度下降（SGD）、分散SGD（DSGD）和随机方差减少梯度（SVRG）算法）的早期停止变量的期望运行时间的界。最后，我们考虑了早期停止返回的迭代的泛化性质。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08856">PDF</a>
<h3>No. 73	极稀疏网络的一般成对比较模型</h3><h4>Ruijian Han, Yiming Xu, Kani Chen</h4>文摘：利用成对比较数据进行统计推断是分析复杂稀疏网络的有效方法。本文提出了概率网络中相互作用建模的一般框架，该框架在参数化方面具有很大的灵活性。在此基础上，我们证明了在网络稀疏的近似最小条件下，被试潜在得分的最大似然估计（MLE）是一致一致的。这个条件对于描述稀疏性的前导阶渐近是尖锐的。该证明采用了一种新的基于误差诱导度量和比较图结构仔细计数的链式技术。我们的结果保证了MLE是一个有效的估计在大规模比较网络的数据是渐近不足的推断。数值模拟补充了理论分析。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08853">PDF</a>
<h3>No. 74	拍卖中的上下文保留价格优化</h3><h4>Joey Huchette, Haihao Lu, Hossein Esfandiari, Vahab Mirrokni</h4>文摘：研究了在给定上下文信息的情况下，通过学习线性模型来确定拍卖底价，使拍卖的预期收益最大化的问题。首先，我们证明除非指数时间假设失败，否则不可能在多项式时间内解决这个问题。其次，我们提出了一个强混合整数规划（MIP）公式，它能够精确地模拟非凸和不连续的期望报酬函数。此外，我们还证明了这种MIP公式是收益函数的理想公式（可能是最强的公式）。由于精确求解MIP公式计算量大，本文还研究了它的线性规划（LP）松弛性能。我们证明，不幸的是，在最坏的情况下，线性规划松弛的目标间隔可以是实际问题的最优目标的$O（n）$倍，其中$n$是样本数。最后，我们给出了计算结果，表明混合整数规划公式及其线性规划松弛能够在真实数据集和合成数据集上同时优于最新算法的样本内和样本外性能。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08841">PDF</a>
<h3>No. 75	PA-Cache：边缘网络中基于学习的流行感知内容缓存</h3><h4>Qilin Fan, Jian Li, Xiuhua Li, Qiang He, Shu Fu, Sen Wang</h4>摘要：随着智能环境的迅猛发展，边缘设备产生了大量的数据。因此，内容交付很快被推到了网络边缘。与传统的内容分发网络相比，规模较小的边缘缓存通常会受到更多的突发请求，这使得传统的缓存算法在边缘网络中的性能较差。本文旨在提出一种有效的缓存决策策略PA-Cache，该策略利用进化的深度学习自适应地学习时变的内容流行度，以决定在缓存满时要逐出哪些内容。不同于以往的基于学习的方法，前者使用一组小的特征进行决策，要么要求整个训练数据集可用于学习一个经过微调但可能过时的预测模型，PA-Cache加权一组大的关键特征，以进化的方式训练神经网络，以满足边缘要求伴随着波动和爆发。我们通过对一家大型商业视频点播服务提供商的真实数据跟踪的大量实验，证明了PA缓存的有效性。计算结果表明，PA-Cache在较低的计算开销下，比现有方法提高了命中率。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08805">PDF</a>
<h3>No. 76	对话行为预测的顺序引导注意模型</h3><h4>Pierre Colombo, Emile Chapuis, Matteo Manica, Emmanuel Vignon, Giovanna Varni, Chloe Clavel</h4>文摘：基于会话对话的对话行为预测（DA）任务是会话代理开发的关键组成部分。准确预测DAs需要对会话和全局标记依赖关系进行精确建模。我们利用SEQ2SEQ方法广泛采用的神经机器翻译（NMT），以改善标签序列的建模。已知Seq2seq模型学习复杂的全局依赖性，而目前提出的方法仅使用线性条件随机场（CRF）对局部标记依赖性建模。在这项工作中，我们介绍了一个为DA分类量身定制的seq2seq模型：一个分层编码器、一个新的引导注意机制和一个用于训练和推理的波束搜索。与最先进的技术相比，我们的模型不需要手工制作的功能，并且经过端到端的培训。此外，该方法在SwDA上的准确度得分为85%，在MRDA上的准确度得分为91.6%。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08801">PDF</a>
<h3>No. 77	修剪未经训练的神经网络：原理与分析</h3><h4>Soufiane Hayou, Jean-Francois Ton, Arnaud Doucet, Yee Whye Teh</h4>摘要：超参数化神经网络显示了最新的性能。然而，越来越需要更小、节能、神经网络能够在计算资源有限的设备上使用机器学习应用程序。一种流行的方法是使用修剪技术。而这些技术传统上集中在修剪预先训练好的神经网络（如LeCun等人。（1990）和Hassabi等人。（1993年），Lee等人最近的工作。（2018）显示了在初始化时执行修剪的有希望的结果。然而，这些过程仍然不令人满意，因为由此产生的修剪网络可能难以训练，例如，这些过程并不阻止一个层被完全修剪。本文对稀疏结构的初始化剪枝和训练进行了全面的理论分析。这一分析使我们能够提出新的原则性方法，并在各种网络架构上进行实验验证。我们特别表明，我们可以修剪高达99.9%的权重，同时保持模型的可训练性。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08797">PDF</a>
<h3>No. 78	你遵守人工智能吗？--学习算法的个性化解释及其对员工遵从行为的影响</h3><h4>NIklas Kuhl, Jodie Lobana, Christian Meske</h4>摘要：机器学习算法是人工智能的关键技术。由于其固有的复杂性，这些学习算法表现为黑箱，难以理解，从而影响了遵从行为。因此，遵守这些工件的建议（这些工件可能会对员工的任务绩效产生重大影响）仍然需要进行研究——在这方面，人工智能解释的个性化似乎是一个很有前途的概念。在我们的工作中，我们假设，基于不同的背景，如训练、领域知识和人口统计学特征，个体对学习算法有不同的理解，因此有不同的心理模型。人工智能解释的个人化，与个体的心理模型相关，因此可能是一种工具，影响遵从性，从而影响员工的任务绩效。我们的初步结果已经表明了个性化解释在行业环境中的重要性，并强调了这项研究工作的重要性。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08777">PDF</a>
<h3>No. 79	提出、检验、发布：高概率差异私人估计</h3><h4>Victor-Emmanuel Brunel, Marco Avella-Medina</h4>文摘：基于Dwork和Lei（2009）提出的“提议、检验、释放”（PTR）机制，我们导出了差异私有中值和均值估计的集中不等式。我们引入了一个新的PTR机制的通用版本，它允许我们导出微分私有估计的高概率误差界。我们的算法提供了第一个统计保证，在没有任何有界假设的情况下，在没有假设目标种群参数位于某个已知有界区间的情况下，对中值和均值进行差分私有估计。我们的程序不依赖于数据的任何截断，并为可能的重尾随机变量的微分私有中值和均值估计提供了第一次亚高斯高概率界。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08774">PDF</a>
<h3>No. 80	非局部注意的物体6D姿态估计</h3><h4>Jianhan Mei, Henghui Ding, Xudong Jiang</h4>文摘：提出了一种基于单个RGB图像的6D目标姿态估计方法。在基于深度学习的目标检测方法的激励下，我们提出了一个简洁有效的网络，将6D目标位姿参数估计集成到目标检测框架中。此外，为了提高遮挡估计的鲁棒性，引入了非局部自注意模块。实验结果表明，该方法在YCB视频和Linemod数据集上达到了最新的性能。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08749">PDF</a>
<h3>No. 81	APTER：通过指数加权的聚集性预后</h3><h4>Kristiaan Pelckmans, Liu Yang</h4>文摘：本文研究的是如何根据患者的微阵列表达水平来判断患者的预后。该方法是最近在理论机器学习文献中提出的聚合方法的一种应用，具有计算方便和处理高维数据的能力。文中对该方法进行了形式化分析，得到了与传统方法相似的收敛速度，同时证明了该方法能够很好地处理指数级的大量特征。这些结果得到了一系列公开的生存微阵列数据集的数值模拟的支持。实验结果表明，该技术与最近提出的预处理技术相结合，具有良好的性能。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08731">PDF</a>
<h3>No. 82	图像分类中的半监督、自监督和无监督技术综述</h3><h4>Lars Schmarje, Monty Santarossa, Simon-Martin Schröder, Reinhard Koch</h4>摘要：虽然深度学习策略在计算机视觉任务中取得了显著的效果，但仍然存在一个问题。当前的策略在很大程度上依赖于大量的标记数据。在现实世界的许多问题中，创建这么多标记的训练数据是不可行的。因此，研究人员试图将未标记的数据纳入到训练过程中，以较少的标记达到相同的效果。由于大量的并行研究，很难跟踪最近的发展。在这项调查中，我们提供了一个使用较少标签的图像分类中常用的技术和方法的概述。我们比较了21种方法。在我们的分析中，我们确定了三大趋势。一。最先进的方法可以根据其准确性扩展到现实世界的应用程序。2。为了达到与使用所有标签相当的效果所需的监督程度正在下降。三。所有的方法都有共同的技术，只有很少的方法结合这些技术来获得更好的性能。基于这三种趋势，我们发现了未来的研究机会。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08721">PDF</a>
<h3>No. 83	基于强化学习和树搜索的机器人辅助手术姿态自动识别</h3><h4>Xiaojie Gao, Yueming Jin, Qi Dou, Pheng-Ann Heng</h4>文摘：手术姿态自动识别是提高机器人辅助手术智能化的基础，它可以完成复杂的手术监控和技能评估任务。然而，目前的方法对每一个框架都是单独处理的，没有对未来的信息进行有效的考虑就产生了结果。本文提出了一种基于强化学习和树搜索的关节外科手势分割与分类框架。训练一个代理以类人的方式分割和分类手术视频，并通过树搜索适当地重新考虑其直接决策。我们提出的树搜索算法将设计的两个神经网络，即策略和值网络的输出统一起来。通过集成不同模型的互补信息，我们的框架能够获得比使用任一神经网络的基线方法更好的性能。从整体上看，我们所开发的方法在准确性、编辑评分和F1评分方面均优于现有的方法。我们的研究强调了树搜索在外科机器人应用强化学习框架中的应用。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08718">PDF</a>
<h3>No. 84	Conv-TasNet的实证研究</h3><h4>Berkan Kadioglu, Michael Horgan, Xiaoyu Liu, Jordi Pons, Dan Darcy, Vivek Kumar</h4>摘要：Conv-TasNet是最近提出的一种基于波形的深度神经网络，它在语音源分离方面取得了最新的性能。它的体系结构包括一个可学习的编码器/解码器和一个在该学习空间上操作的分隔符。对塔斯奈特的转换提出了各种改进措施。然而，它们主要集中在分隔符上，使其编码器/解码器成为（浅层）线性运算符。本文对Conv-TasNet进行了实证研究，提出了一种基于Conv-TasNet的（深度）非线性变量的编译码器改进方案。此外，我们还对更大、更多样化的LibriTTS数据集进行了实验，并研究了在更大的数据集上训练时所研究模型的泛化能力。我们建议跨数据集评估，包括评估与WSJ0-2mix、LibriTTS和VCTK数据库的分离。我们的结果表明，对编码器/解码器的增强可以将平均SI-SNR性能提高1db以上。此外，我们还深入探讨了Conv-TasNet的泛化能力以及改进编码器/解码器的潜在价值。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08688">PDF</a>
<h3>No. 85	用乘法权学习高斯图形模型</h3><h4>Anamay Chaturvedi, Jonathan Scarlett</h4>摘要：马尔可夫随机场中的图形模型选择是统计学和机器学习中的一个基本问题。两个特别突出的模型，伊辛模型和高斯模型，已经使用不同的（尽管经常相关的）技术大量并行开发，并且已经为每个模型建立了几个具有严格样本复杂度边界的实用算法。在本文中，我们采用最近提出的Klivans和Meka算法（FOCS，2017），基于乘性权重更新方法，从伊辛模型到高斯模型，通过对算法及其分析的非平凡修改。该算法具有与文献中其他算法质量相似的样本复杂度界限，在$m$samples和$p$nodes的情况下具有较低的运行时$O（mp^2）$，并且可以简单地在线实现。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08663">PDF</a>
<h3>No. 86	群体计算设计</h3><h4>Yuki Koyama, Takeo Igarashi</h4>摘要：计算设计的目的是利用计算技术支持或自动化设计过程。然而，有些设计任务类涉及的标准仅在计算机上难以处理。例如，寻求实现审美目标的视觉设计任务很难纯粹用计算机处理。一种有前途的方法是利用人工计算；也就是说，将人工输入纳入计算过程。众包平台提供了一种将这种人工计算集成到工作系统中的便捷方法。在这一章中，我们将讨论在视觉设计中参数调整任务领域中的群体计算设计。参数调整通常是为了最大限度地提高设计对象的美学质量。群体驱动的计算设计可以利用人的计算来解决这一最大化问题。我们用两个例子讨论了群体计算设计的机遇和挑战：（1）估计目标函数（具体来说，从群体的成对比较中学习偏好）有助于设计师进行交互式设计探索；（2）直接搜索使目标函数最大化的最优参数设置（具体来说，循环中的群体贝叶斯优化）。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08657">PDF</a>
<h3>No. 87	捆绑式多变压器的成本效益平衡</h3><h4>Raj Dabre, Raphael Rubino, Atsushi Fujita</h4>文摘：提出并评价了一种新的训练多变压器的方法，该方法将多个模型压缩为一个模型，从而在解码过程中动态地选择编解码层数。在序列到序列建模中，通常，N层编码器的最后一层的输出被馈送到M层解码器，最后一层解码器的输出被用于计算损耗。相反，我们的方法计算由NxM损耗组成的单个损耗，其中每个损耗是从连接到N个编码器层之一的M个解码器层之一的输出计算得出的。该模型包含具有不同数量的编解码器层的NxM模型，并且可以用于小于最大数量的编解码器层的解码。在此基础上，提出了一种基于先验的编解码层数选择机制，并对模型压缩中的层数循环叠加和知识提取进行了探讨。本文对神经网络机器翻译的成本效益进行了分析，结果表明，该方法在保证翻译质量的同时降低了解码成本。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08614">PDF</a>
<h3>No. 88	高丽：日本前现代艺术面部表情数据集</h3><h4>Yingtao Tian, Chikahiko Suzuki, Tarin Clanuwat, Mikel Bober-Irizar, Alex Lamb, Asanobu Kitamoto</h4>摘要：从手写数字的分类到文本字符串的生成，长期以来受到机器学习界关注的数据集在主题上有很大的不同。这激发了人们对建立与社会和文化相关的数据集的新兴趣，因此算法研究可能会对社会产生更直接和直接的影响。历史和人文学科就是这样一个领域，在那里，更好和相关的机器学习模型可以加速各个领域的研究。为此，人们提出了新的基准和模型，用于抄写日本历史草书，但就整个领域而言，对日本历史艺术品使用机器学习仍然是一个很大的未知领域。为了弥补这一差距，我们提出了一个新的数据集KaoKore，它由从前现代日本艺术品中提取的人脸组成。我们展示了它作为图像分类数据集以及创造性和艺术性数据集的价值，我们使用生成模型对其进行了探索。此https URL提供数据集<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08595">PDF</a>
<h3>No. 89	基于多图卷积网络的中医证候推荐</h3><h4>Yuanyuan Jin, Wei Zhang, Xiangnan He, Xinyu Wang, Xiaoling Wang</h4>摘要：中药推荐在中医治疗过程中起着至关重要的作用，其目的是推荐一套治疗患者症状的中药。虽然已有多种机器学习方法被用于草药推荐，但它们仅限于对草药与症状之间的相互作用进行建模，而忽略了中医证候诱导的中间过程。在进行中医诊断时，经验丰富的医生通常会从患者的症状中归纳出症状，然后根据所归纳出的症状推荐草药。因此，我们认为，对症状的全面描述，即证候的归纳，对于药草的推荐是重要的，应该得到适当的处理。然而，由于证候归纳的模糊性和复杂性，大多数方剂缺乏明确的证候基础真理。本文提出了一种将内隐证候诱导过程考虑在内的中药推荐方法。给定一组要治疗的症状，我们的目标是通过有效地融合集合中所有症状的嵌入来生成一个整体的症状表示，以模拟医生如何诱导这些症状。在症状嵌入学习中，我们从输入的处方中构造一个症状-症状图来获取症状之间的关系，然后在症状-症状和症状-药草图上建立图形卷积网络（GCNs）来学习症状嵌入。同样，我们构建了一个药草图，并在药草图和症状药草图上建立GCNs来学习药草嵌入，最后将其与中医证候表示相互作用来预测药草的得分。这样可以得到更全面的表示。我们在一个公开的中医药数据集上进行了广泛的实验，显示出与最先进的草药推荐方法相比的显著改进。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08575">PDF</a>
<h3>No. 90	连续范畴：一个新的单值指数族</h3><h4>Elliott Gordon-Rodriguez, Gabriel Loaiza-Ganem, John P. Cunningham</h4>摘要：单纯形值数据贯穿于统计学和机器学习中，例如在深层网络的传输学习和压缩中。这类数据的现有模型依赖于Dirichlet分布或其他相关的损失函数；这里，我们显示这些标准选择系统地受到许多限制，包括偏见和数值问题，这些问题阻碍了在这些分布的上游使用灵活的网络模型。我们通过引入一个新的指数分布族来解决这些局限性，该族用于建模单值数据-连续范畴，它是最近发现的连续Bernoulli的一个非平凡的多元推广。与Dirichlet和其他典型的选择不同，连续的分类结果产生了一个性能良好的概率损失函数，它产生无偏估计，同时保持了Dirichlet的数学简单性。在探索其理论性质的同时，我们还介绍了适用于该分布的可再参数化方法的采样方法，并对其性能进行了评估。最后，通过一个模拟研究，一个多党选举的应用实例，以及一个神经网络压缩任务，我们证明了连续分类在经验上优于标准选择。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08563">PDF</a>
<h3>No. 91	联合预训练和基于多个筒仓临床笔记的BERT微调</h3><h4>Dianbo Liu, Tim Miller</h4>摘要：近年来，大规模的上下文表示模型（如BERT）在自然语言处理（NLP）领域取得了显著的进展。然而，在医疗保健等领域，由于隐私和监管方面的原因，从多个机构访问各种大规模文本数据极具挑战性。在本文中，我们展示了在不移动数据的情况下，以联邦方式使用来自不同筒仓的临床文本对BERT模型进行预训练和微调是可能的。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08562">PDF</a>
<h3>No. 92	学会用最少的人力在现实世界中行走</h3><h4>Sehoon Ha, Peng Xu, Zhenyu Tan, Sergey Levine, Jie Tan</h4>摘要：可靠稳定的运动一直是腿型机器人面临的最根本的挑战之一。深度强化学习（Deep-RL）是一种很有前途的自主开发控制策略的方法。在本文中，我们开发了一个在现实世界中用最少的人力来学习具有深度RL的腿运动策略的系统。机器人学习系统的关键问题是数据的自动采集和安全性。我们通过开发一个多任务学习过程、一个自动重置控制器和一个安全约束的RL框架来克服这两个挑战。我们测试了我们的系统，学习在三种不同的地形上行走：平坦的地面、柔软的床垫和有裂缝的门垫。我们的系统可以在不需要人工干预的情况下，在小型牛头机器人上自动有效地学习运动技能。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08550">PDF</a>
<h3>No. 93	我们真的需要访问源数据吗？无监督域自适应的源假设转移</h3><h4>Jian Liang, Dapeng Hu, Jiashi Feng</h4>摘要：无监督域适配（UDA）的目的是利用从标记源数据集中学习到的知识来解决新的无标记域中的相似任务。以前的UDA方法在学习适应模型时通常需要访问源数据，这使得它们对于分散的私有数据来说具有风险且效率低下。在这项工作中，我们解决了一个新的设置，其中只有一个训练的源模型是可用的，并研究如何有效地利用这样一个模型，没有源数据来解决UDA问题。为此，我们提出了一个简单而通用的表示学习框架，称为源假设转移（SHOT）。具体地说，SHOT冻结了源模型的分类器模块（假设），并通过利用信息最大化和自监督伪标记来将目标域的表示隐式地与源假设对齐来学习目标特定的特征提取模块。这样，学习的目标模型可以直接预测目标数据的标签。我们进一步研究了几种优化网络结构的技术，以参数化源模型以获得更好的传输性能。为了验证SHOT的通用性，我们评估了各种适应情况下的SHOT，包括闭集、部分集和开集域适应。实验表明，在多域自适应基准中，SHOT产生了最新的结果。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08546">PDF</a>
<h3>No. 94	一种可扩展的无收缩稀疏聚类框架</h3><h4>Zhiyue Zhang, Kenneth Lange, Jason Xu</h4>摘要：聚类是无监督学习中的一项基本活动，在高维特征空间中是一个非常困难的问题。幸运的是，在许多现实场景中，只有少数特性与区分集群相关。这推动了稀疏聚类技术的发展，该技术通常依赖于计算复杂度较高的外部算法中的k-均值。当前的技术还需要仔细调整收缩参数，从而进一步限制其可伸缩性。在本文中，我们提出了一个新的稀疏k-均值聚类框架，该框架直观、易于实现，并且与最新算法相竞争。结果表明，该算法具有一致性和收敛性保证。我们的核心方法很容易推广到一些特定于任务的算法，如属性子集上的聚类和部分观测数据设置中的聚类。我们通过模拟实验和基准数据集以及一个关于小鼠蛋白质表达的案例研究来展示这些贡献。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08541">PDF</a>
<h3>No. 95	线性函数逼近的自适应时间差分学习</h3><h4>Tao Sun, Han Shen, Tianyi Chen, Dongsheng Li</h4>文摘：针对强化学习中的策略评价问题，提出了一种改进的时间差分学习算法。一般来说，普通TD算法的性能对步长的选择是敏感的。TD经常会遇到收敛速度慢的问题。由于TD学习算法与随机梯度方法之间的紧密联系，我们发展了TD学习算法的第一个自适应变量，即我们称之为AdaTD的线性函数逼近。与原始TD相比，AdaTD对步长的选择是稳健的或不太敏感的。通过分析，我们确定要达到$\epsilon$精度，需要的迭代次数是$\tilde{O}（\epsilon^2\ln^4\frac{1}{\epsilon}/\ln^4\frac{1}{\rho}）$，其中$\rho$表示底层马尔可夫链收敛到平稳分布的速度。这意味着在最坏的情况下，AdaTD的迭代复杂度并不比TD差。除了TD，我们还进一步开发了TD（$\lambda$）的自适应变体，称为AdaTD（$\lambda$）。我们在OpenAI Gym中评估了ADTD和ADTD（$\lambda$）在几种标准强化学习任务中的线性和非线性函数逼近的经验性能，证明了我们的新方法比现有方法的有效性。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08537">PDF</a>
<h3>No. 96	朝向物理一致的、数据驱动的对流模型</h3><h4>Tom Beucler, Michael Pritchard, Pierre Gentine, Stephan Rasp</h4>文摘：数据驱动算法，特别是神经网络，如果在高分辨率气候模拟中训练，可以模拟粗分辨率气候模型中子网格尺度过程的影响。然而，他们可能会违反关键的身体约束，缺乏在训练范围之外进行概括的能力。这里，我们证明了在神经网络中，物理约束可以通过调整损失函数近似地实现，也可以通过调整结构来实现机器精度。由于这些物理约束不足以保证可推广性，我们还提出了一个寻找可应用于训练和验证数据的物理规范化的框架，以提高神经网络对未知气候的推广能力。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08525">PDF</a>
<h3>No. 97	很少特征的机器学习脉冲星检测</h3><h4>Haitao Lin, Xiangru Li, Ziying Luo</h4>文摘：随着数据量的指数增长，基于机器学习（ML）的脉冲星检测方法的研究是现代测量中的一个热点问题。为了提高检测性能，需要专门研究ML模型的输入特征。在现有的基于ML方法的脉冲星检测研究中，主要有两种特征设计：经验特征和统计特征。然而，由于多个特征的组合效应，现有特征中存在一些冗余甚至不相关的成分，这会降低脉冲星探测模型的精度。因此，有必要从一组可用的候选特征中选择相关特征的子集，称为{itshape feature selection.}在本文中，提出了两种特征选择算法----\texit{Grid Search}（GS）和{texit{Recursive feature Elimination}（RFE），通过删除冗余和不相关的特征。该算法在南方高时间分辨率大学（HTRU-S）的五个脉冲星探测模型上进行了评估。实验结果验证了本文提出的特征选择算法的有效性和有效性。在GS中，只有两个特征的模型的召回率高达99%，误报率低达0.65%；在RFE中，只有三个特征的模型在pulsar候选分类中的召回率为99%，误报率为0.16%。此外，这项工作还调查了我们的模型所需的特征数量以及错误分类的脉冲星。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08519">PDF</a>
<h3>No. 98	网络干扰下的因果推理</h3><h4>Yunpu Ma, Yuyi Wang, Volker Tresp</h4>摘要：根据随机试验数据估计个体化治疗效果是因果推理的关键。稳定单位处理值假设（SUTVA）通常是在因果推理中作出的。然而，当一个单元上的指定处理影响相邻单元的潜在结果时，干扰会引入偏差。这种干扰现象被称为经济学中的溢出效应或社会科学中的同伴效应。通常，在随机实验或相互关联的观察研究中，人们只能在干扰下观察治疗反应。因此，在存在干扰的情况下，如何估计叠加的因果效应，恢复个体的治疗效应，成为因果推理中一个具有挑战性的课题。在本文中，我们使用GNNs来研究一般网络干扰下的因果效应估计，它是捕获图中依赖关系的有力工具。在推导因果效应估计量的基础上，进一步研究了能力约束下图的干预策略改进。在网络干扰和处理能力约束下，给出了策略后悔界。此外，还给出了基于GNN因果估计的启发式图结构相关误差界。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08506">PDF</a>
<h3>No. 99	广义对策中的随机后悔最小化</h3><h4>Gabriele Farina, Christian Kroer, Tuomas Sandholm</h4>摘要：蒙特卡罗反事实后悔最小化（MCCFR）是一种最先进的算法，用于求解对于全树遍历来说太大的序列博弈。它通过使用可以通过采样计算的梯度估计来工作。然而，除了MCCFR之外，序列对策的随机方法还没有得到广泛的研究。本文提出了一个随机后悔最小化方法的新框架。该框架允许我们使用任何遗憾最小化算法，并结合任何梯度估计。MCCFR算法可以作为我们框架中的一个特例进行分析，这一分析使得收敛性理论显著增强，同时给出了一个简化的证明。我们的框架允许我们实例化几个新的随机方法来求解序列对策。我们在三个游戏中展示了大量的实验，其中我们的方法的一些变体优于MCCFR。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08493">PDF</a>
<h3>No. 100	特征值问题迭代方法的渐近收敛性</h3><h4>Vasileios Charisopoulos, Austin R. Benson, Anil Damle</h4>摘要：机器学习、统计学等领域中的一些问题依赖于特征向量的计算。对于大规模问题，这些特征向量的计算通常是通过子空间迭代或Krylov方法等迭代格式进行的。虽然有关于谱范数的子空间收敛保证的经典和综合分析，但在许多现代应用中，子空间距离的其他概念更为合适。最近的理论工作集中在$\ell{2\to\infty}$范数中测量的子空间的扰动上，但没有考虑特征向量的实际计算。在这里，我们讨论了当距离以$\ell{2\to\infty}$范数度量时，子空间迭代的收敛性，并给出了确定的界。我们用一个实际的停止准则来补充我们的分析，并通过数值实验证明其适用性。我们的结果表明，一个人可以在下游任务上获得可比的性能，同时需要较少的迭代，从而节省大量的计算时间。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08491">PDF</a>
<h3>No. 101	情感交流中的信息</h3><h4>Alison Duncan Kerr, Kevin Scharp</h4>摘要：动物利用情感进行交流时，传递了多少信息？很明显，情绪在人类和其他物种中被用作交流系统。本文提出的情感信息的量化理论是基于Shannon的通信系统信息数学理论。这一理论解释了情感交流的方方面面，为研究提供了几十个新的方向。它优于目前占主导地位的情绪传播的“传染”理论。情感交流信息理论的一个重要应用是，它允许开发社交网络的情感安全系统，以防止我们今天在网上看到的广泛的情感操纵。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08470">PDF</a>
<h3>No. 102	欧洲联盟篮球比赛与篮球观众智慧的描述性预测分析</h3><h4>Georgios Giasemidis</h4>摘要：本研究以机器学习模式预测欧洲联盟篮球比赛为研究对象。预测是一个二元分类问题，预测一场比赛是1胜（主场）还是2胜（客场）。数据从欧洲联盟官方网站收集，涵盖2016-2017、2017-2018和2018-2019赛季，即在新格式时代。从匹配数据中提取特征，并应用现成的监督机器学习技术。我们校准并验证我们的模型。我们发现简单的机器学习模型在测试集上的准确率不超过67%，比一些复杂的基准模型差。此外，本研究的重要性在于「篮球人群的智慧」，并且我们展示了一群篮球爱好者的预测能力如何能超越本研究所讨论的机器学习模式。我们认为，为什么这组“专家”的准确度水平应该作为未来用机器学习预测（欧洲）篮球比赛的研究基准。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08465">PDF</a>
<h3>No. 103	不完全信息博弈中从Poincaré递推到收敛的正则化方法</h3><h4>Julien Perolat, Remi Munos, Jean-Baptiste Lespiau, Shayegan Omidshafiei, Mark Rowland, Pedro Ortega, Neil Burch, Thomas Anthony, David Balduzzi, Bart De Vylder, Georgios Piliouras, Marc Lanctot, Karl Tuyls</h4>文摘：研究了序贯不完全信息博弈（IIG）中的跟随正则化领导动力学。我们将Poincar递推的已有结果从正规形式的对策推广到零和二人不完全信息对策和其他序贯对策。然后，我们研究了在单调对策中，如何通过调整对策的报酬（通过增加正则项）来提供强收敛性保证。我们继续展示如何利用这种奖励适应技术来构建精确收敛到纳什均衡的算法。最后，我们展示了如何将这些见解直接用于构建零和两人不完全信息博弈（IIG）的最新无模型算法。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08456">PDF</a>
<h3>No. 104	SD-GAN：结构和去噪GAN显示咬合下的面部部分</h3><h4>Samik Banerjee, Sukhendu Das</h4>摘要：某些面部特征在外观上是显著的（独特的），这在很大程度上有助于对主体的整体认识。这些显著部分的遮挡会降低人脸识别算法的性能。本文提出了一种生成模型来重建被遮挡的人脸缺失部分。提出的生成模型（SD-GAN）重建了一个人脸，保留了人脸的光照变化和身份。针对双峰互斥产生式对抗网络（GAN）模型，设计了一种新的对抗训练算法，以加快收敛速度。提出了一种新的对抗性“结构性”损失函数，由整体损失和局部损失两部分组成，其特征是SSIM和分块MSE。对真实和综合遮挡的人脸数据集的消融研究表明，我们提出的方法在提高人脸识别性能的同时，在很大程度上优于竞争方法。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08448">PDF</a>
<h3>No. 105	海量数据的同时推理：分布式Bootstrap</h3><h4>Yang Yu, Shih-Kang Chao, Guang Cheng</h4>文摘：提出了一种适用于大量机器上分布式处理海量数据的bootstrap方法。这种新方法计算效率高，因为我们在主计算机上引导而不进行过度重采样，这通常是现有方法所要求的{kleiner2014scalable，sengupta2016subsampled}，同时可以证明在最小通信量的情况下实现最佳统计效率。我们的方法不需要重复地重新拟合模型，而只在主机器中对从工作机器接收到的梯度应用乘法器引导。仿真验证了我们的理论。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08443">PDF</a>
<h3>No. 106	超声图像分割的微调U-Net：哪一层？</h3><h4>Mina Amiri, Rupert Brooks, Hassan Rivaz</h4>摘要：为了克服医学应用中数据稀缺和昂贵的问题，对在大数据集上训练过的网络进行微调是完全训练的一种替代方法。虽然网络的浅层通常保持不变，但深层则根据新的数据集进行修改。这种方法可能不适用于超声图像，因为它们的外观截然不同。在本研究中，我们探讨了在乳房超音波影像分割中，对训练好的U-Net的不同层进行微调对自然影像分割的影响。与固定收缩部分和调整膨胀部分相比，调整收缩部分和固定膨胀部分可以获得更好的效果。此外，我们还发现，开始从浅层微调U-Net，并逐渐包含更多的层，将比从深层微调网络返回浅层带来更好的性能。我们在X射线图像分割上没有观察到相同的结果，与超声相比，X射线图像具有不同的显著特征，因此更适合对浅层进行微调，而不是对深层进行微调。浅层学习低层特征（包括斑点模式，可能还有噪声和伪影特性），这些特征在这种模式的自动分割中至关重要。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08438">PDF</a>
<h3>No. 107	Bandit算法的剩余Bootstrap探索</h3><h4>Chi-Hua Wang, Yang Yu, Botao Hao, Guang Cheng</h4>文摘：在有界或无界报酬的bandit算法中，本文提出了一种新的基于扰动的探测方法，称为剩余bootstrap探测法（\texttt{ReBoot}）。\texttt{ReBoot}通过基于残差的扰动机制注入数据驱动的随机性，从而实施探索。这种新的机制捕获了拟合误差的潜在分布特性，更重要的是，通过以一种{非常规}的方式膨胀方差水平，促进了从次优解（对于小样本）逃逸的探索。理论上，在适当的方差膨胀水平下，在高斯多臂盗贼中，texttt{ReBoot}可证明地保证了依赖实例的对数遗憾。我们评估了不同的合成多武装匪徒问题中的{ReBoot}，并观察到{ReBoot}比{kveton2018garbage}和{kveton2019inburted}更能获得无限的回报，也更可靠，计算效率与Thompson抽样方法相当。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08436">PDF</a>
<h3>No. 108	基于相关高斯过程的弱监督多输出回归</h3><h4>Seokhyun Chung, Raed Al Kontar, Zhenke Wu</h4>摘要：多输出回归试图利用来自多个组/源的数据推断多个潜在函数，同时考虑组间的潜在相似性。本文考虑弱监督下的多输出回归问题，其中多组数据点的子集是无标记的。对于由具有共享潜在过程的卷积构造的多个输出，我们使用依赖高斯过程。我们对未观测标签的多项式概率引入超先验，并对超参数进行优化，我们给出了改进的估计。我们得到了两个变分界：（i）模型推理中快速稳定收敛的修正变分界；（ii）一个可伸缩的、适于随机优化的变分界。通过对合成数据和真实数据的实验表明，该模型在多个潜在函数和不可观测标记的精确估计方面优于现有模型。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08412">PDF</a>
<h3>No. 109	具有复合运输距离的高斯混合约化统一框架</h3><h4>Qiong Zhang, Jiahua Chen</h4>文摘：高斯混合约化（GMR）是用较少的分量逼近有限高斯混合的问题。它广泛应用于密度估计、非参数信念传播和贝叶斯递归滤波。虽然基于优化和聚类的GMR算法已经被提出，但它们要么计算代价高，要么缺乏理论支持。在这项工作中，我们建议通过最小化两种混合物之间的熵正则化复合输运距离来实现GMR。我们展示了我们的方法为GMR提供了一个统一的框架，这个框架既可解释又可计算。我们的工作还填补了GMR优化和基于聚类的方法之间的空白。本文针对我们的优化问题，提出了一种优化最小化算法，并建立了它的理论收敛性。实验结果也表明了GMR的有效性。研究了运输成本的选择对GMR性能的影响。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08410">PDF</a>
<h3>No. 110	随机特征模型的隐式正则化</h3><h4>Arthur Jacot, Berfin Şimşek, Francesco Spadaro, Clément Hongler, Franck Gabriel</h4>文摘：利用随机特征模型作为核方法的有效参数逼近。利用随机矩阵理论，研究了高斯RF模型与核岭回归（KRR）之间的关系。对于具有$P$features、$N$data points和ridge$\lambda$的高斯RF模型，我们表明平均（即预期）RF预测值接近具有有效ridge$\tilde{\lambda}$的KRR预测值。我们证明了$\tilde{\lambda}>\lambda$和$\tilde{\lambda}\searrow\lambda$随着$P$的增长而单调变化，从而揭示了有限射频采样的隐式正则化效应。然后，我们将$\tilde{\lambda}$-KRR预测值的风险（即测试误差）与$\lambda$-RF预测值的平均风险进行比较，并获得其差异的精确和明确的界限。最后，我们在经验上发现平均$\lambda$-RF predictor和$\tilde{\lambda}$-KRR predictor的测试误差之间有非常好的一致性。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08404">PDF</a>
<h3>No. 111	单张布局：从一张图片开始的Amodal场景布局</h3><h4>Kaustubh Mani, Swapnil Daga, Shubhika Garg, N. Sai Shankar, Krishna Murthy Jatavallabhula, K. Madhava Krishna</h4>文摘：在本文中，我们讨论了一个新颖的、极具挑战性的问题，即如何估计复杂城市驾驶场景的布局。给定一幅从驾驶平台拍摄的单色图像，我们的目标是预测道路和其他交通参与者的鸟瞰图布局。估计的布局应该超出图像中可见的范围，并补偿由于投影而丢失的三维信息。我们把这个问题称为一个动态场景布局估计问题，它涉及到即使是在图像中被遮挡的世界部分的“幻觉”场景布局。为此，我们提出了一种深度神经网络，用于从单个图像实时估计amodal场景布局。我们将场景布局表示为一个多通道语义占有网格，并利用对抗性特征学习来幻觉被遮挡图像部分的似是而非的完成。由于缺乏公平的基线方法，我们将鸟瞰图中道路布局和车辆占用率估计的几种最新方法扩展到amodal设置以进行严格的评估。通过利用时间传感器融合来生成训练标签，我们在许多数据集上明显优于当前的art。在KITTI和Argoverse数据集上，我们的表现大大超过了所有基线。我们还将所有注释和代码公开。本文的视频摘要可通过此https URL获取。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08394">PDF</a>
<h3>No. 112	序列嵌入的比较视觉分析在病案评估中的应用</h3><h4>Rongchen Guo, Takanori Fujiwara, Yiran Li, Kelly M. Lima, Soman Sen, Nam K. Tran, Kwan-Liu Ma</h4>摘要：为了提供更好的医疗服务，医学界对数据驱动诊断的机器学习进行了积极的研究。对于临床医生来说，支持与正在接受治疗的患者相似的患者队列分析是一项重要的任务，它可以帮助他们以高度的信心做出决定。然而，由于病案的高维性、时间不规则性、稀疏性等特点，这种分析并不简单。为了解决这一难题，我们提出了一种病案相似度计算方法。我们的方法使用事件和序列嵌入。当我们使用一个自动编码器来嵌入事件时，我们使用它的变体和自关注机制来嵌入序列。此外，为了更好地处理数据的不规则性，我们在考虑不同时间间隔的情况下，增强了自我注意机制。我们开发了一个可视化分析系统来支持患者记录的比较研究。为了便于比较不同长度的序列，我们的系统采用了序列比对方法。通过其交互界面，用户可以快速识别感兴趣的患者，并方便地查看患者记录的时间和多个方面。我们使用加州大学戴维斯分校新生儿重症监护室的真实数据集，通过案例研究证明了我们的设计和系统的有效性。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08356">PDF</a>
<h3>No. 113	温起动顺序选择的最优多次停车规则</h3><h4>Mathilde Fekom, Nicolas Vayatis, Argyris Kalogeratos</h4>文摘：针对标准的在线选择问题，提出了一种基于动态规划的温启动动态阈值算法。该问题允许工作岗位在流程开始时处于空闲状态或已被占用状态。在整个选拔过程中，决策者一个接一个地对新候选人进行面试，并为每个候选人显示一个质量分数。根据这些信息，她可以立即做出不可撤销的决定，最多一次重新分配每项工作。我们放宽了动态规划算法的硬性要求，通过对部分和无信息情况的扩展，使决策者能够在面试候选人时顺序地学习潜在的分数分布，从而完全了解候选人分数的分布。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.05160">PDF</a><h2>2020-02-21</h2>
<h3>No. 1	论对抗性范例防御的自适应攻击</h3><h4>Florian Tramer, Nicholas Carlini, Wieland Brendel, Aleksander Madry</h4>摘要：适应性攻击已经（理所当然地）成为评估对抗性例子防御的事实标准。然而，我们发现，典型的适应性评估是不完整的。我们证明，最近在ICLR、ICML和NeurIPS上发表的13种防御措施——为了说明和教学目的而选择的——尽管尝试使用自适应攻击进行评估，但可以被规避。先前的评估论文主要关注的是最终结果——表明防御是无效的——而本文则侧重于阐述执行自适应攻击所需的方法和途径。我们希望这些分析能为如何正确地针对对抗性的例子进行适应性攻击提供指导，从而使社区在建立更健壮的模型方面取得进一步进展。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08347">PDF</a>
<h3>No. 2	Schoenberg-Rao距离：基于熵和几何感知的统计Hilbert距离</h3><h4>Gaëtan Hadjeres, Frank Nielsen</h4>文摘：在机器学习中，考虑样本空间几何结构的概率分布之间的距离，如Wasserstein距离或最大平均差（MMD）距离，受到了广泛的关注，因为它们可以用来比较不相交支持下的概率分布。本文研究了一类统计Hilbert距离，我们称之为Schoenberg-Rao距离，这是MMD的一个推广，它允许我们考虑一类更广泛的核，即条件负半定核。特别地，我们引入了一种构造此类核的原则性方法，并推导了高斯分布混合物之间的新的闭合形式距离。这些距离由凹Rao的二次熵导出，具有很好的理论性质，并具有可解释的超参数，可根据具体应用进行调整。我们的方法是Wasserstein距离的一种实用替代方法，并且我们在许多机器学习任务上证明了它的有效性，如密度估计、生成建模和混合简化。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08345">PDF</a>
<h3>No. 3	神经结构：识别用于训练先验稀疏网络的理想拓扑</h3><h4>Mihailo Isakov, Michel A. Kinsy</h4>摘要：深层神经网络训练时间长是机器学习研究的瓶颈。快速训练的主要障碍是对密集层和卷积层的信息带宽的内存和计算需求的二次增长。最近，训练“先验”稀疏网络被提出作为一种允许层保持高信息带宽，同时保持低内存和低计算的方法。然而，在这些网络中应该使用哪种稀疏拓扑结构还不清楚。本工作为层间拓扑结构的选择提供了理论基础。首先，我们推导了一个新的稀疏神经网络初始化方案，它允许我们探索非常深的稀疏网络的空间。接下来，我们评估了几个拓扑，并表明看似相似的拓扑通常在可达到的精度上有很大的差异。为了解释这些差异，我们开发了一种无数据启发式算法，它可以独立于网络将要训练的数据集来评估拓扑。然后，我们得到一组要求，这些要求构成一个好的拓扑，并得到一个满足所有这些要求的单一拓扑。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08339">PDF</a>
<h3>No. 4	基于变形真值和插补反馈的去噪自编码多重插补</h3><h4>Haw-minn Lu (1), Giancarlo Perrone (1), José Unpingco (1) ((1) Gary and Mary West Health Institute)</h4>摘要：虽然数据可能很丰富，但由于缺少列或行，完整的数据就不那么丰富了。这种缺失会破坏下游数据产品的性能，这些产品要么忽略不完整的情况，要么创建派生的完整数据以供后续处理。为了充分利用和正确使用数据，需要适当地管理丢失的数据。我们提出了一个多重插补模型，利用去噪自编码器来学习数据的内部表示。此外，我们还利用变形真值和插补反馈的新机制来保持属性的统计完整性并消除学习过程中的偏差。我们的方法探索了插补对各种缺失机制和缺失数据模式的影响，在许多标准测试案例中优于其他方法。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08338">PDF</a>
<h3>No. 5	价值驱动的事后模型</h3><h4>Arthur Guez, Fabio Viola, Théophane Weber, Lars Buesing, Steven Kapturowski, Doina Precup, David Silver, Nicolas Heess</h4>摘要：价值评估是强化学习范式的重要组成部分。如何有效地从数据中学习价值预测是RL界研究的主要问题之一，不同的方法以不同的方式利用问题域的结构。模型学习可以利用观测序列中丰富的过渡结构，但这种方法通常对报酬函数不敏感。相比之下，无模型方法直接利用未来的兴趣量，但必须与潜在的弱标量信号（回报的估计）组合。本文提出了一种介于这两个极端之间的RL表示学习方法：我们提出用一种能直接帮助价值预测的方法来学习建模。为此，我们确定未来轨迹的哪些特征为预测相关收益提供了有用的信息。这为我们提供了与任务直接相关的可处理的预测目标，从而可以加速价值函数的学习。这个想法可以理解为事后诸葛亮的推理，关于未来观察的哪些方面可以帮助过去的价值预测。我们展示了即使在简单的策略评估设置中，这也能极大地帮助您。然后我们在具有挑战性的领域中测试我们的方法，包括57个Atari2600游戏。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08329">PDF</a>
<h3>No. 6	基于变分编码器的可靠分类</h3><h4>Chitresh Bhushan, Zhaoyuan Yang, Nurali Virani, Naresh Iyer</h4>摘要：机器学习模型提供了统计上令人印象深刻的结果，这些结果可能是个别不可靠的。为了提供可靠性，我们提出了一个认知分类器（EC），该分类器可以利用训练数据集的支持和重建质量来证明其信念。我们的方法是基于改进的变分自动编码器，它可以识别语义上有意义的低维空间，其中感知上相似的实例在$ell_2$-距离内也很接近。结果表明，与基于softmax阈值的基线方法相比，该方法提高了对抗性攻击样本预测和鲁棒识别的可靠性。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08289">PDF</a>
<h3>No. 7	图神经网络回归的结果相关性</h3><h4>Junteng Jia, Austin Benson</h4>文摘：在训练过程中，图形神经网络利用对标记顶点的监督，在顶点邻域中聚集特征，学习所有顶点的矢量表示。然后，预测器是向量表示的函数，并且在未标记的节点上独立地进行预测。这种被广泛采用的方法隐含地假设顶点标签在对其邻域进行条件化之后是独立的。我们证明，这种强假设在许多真实的图形数据集上是不正确的，并且严重限制了对一些回归任务的预测能力。鉴于传统的基于图的半监督学习方法通过显式地建模预测结果中的相关性而以相反的方式操作，这种限制可能并不令人惊讶。在这里，我们用一个简单且可解释的框架来解决这个问题，该框架可以通过在回归结果残差中建模相关结构来改进任何图神经网络结构。具体地说，我们使用参数化的多元高斯模型来模拟顶点上的结果残差的联合分布，其中参数是通过最大化观测标签的边缘似然来估计的。我们的模型极大地提高了图神经网络的性能，并且学习到的参数也可以解释为连接顶点之间的关联强度。为了使我们能够扩展到大型网络，我们设计了基于随机跟踪估计的低方差无偏模型参数估计的线性时间算法。我们还提供了我们的方法的一个简化版本，它对相关结构做出了更有力的假设，但是非常容易实现，并且在一些情况下提供了很好的实际性能。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08274">PDF</a>
<h3>No. 8	分子注意变压器</h3><h4>Łukasz Maziarka, Tomasz Danel, Sławomir Mucha, Krzysztof Rataj, Jacek Tabor, Stanisław Jastrzębski</h4>文摘：设计一种单一的神经网络结构，在一系列分子性质预测任务中具有竞争力，这在很大程度上仍是一个开放的挑战，其解决方案可能会在药物研发行业中开启深度学习的广泛应用。为了实现这一目标，我们提出了分子注意力变压器（MAT）。我们的主要创新是利用原子间距离和分子图结构来增强变压器的注意机制。实验表明，MAT在一系列不同的分子预测任务上具有竞争力。最重要的是，通过简单的自我监督预训练，MAT只需要调整几个超参数值，就可以在下游任务上获得最先进的性能。最后，我们证明了MAT学习到的注意权重可以从化学的角度来解释。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08264">PDF</a>
<h3>No. 9	背包内蒸馏修剪</h3><h4>Yonathan Aflalo, Asaf Noy, Ming Lin, Itamar Friedman, Lihi Zelnik</h4>文摘：神经网络剪枝减少了过参数化网络的计算量，提高了网络的效率。常用的方法有$\ell 1$-范数稀疏化和神经结构搜索（NAS）。在这项工作中，我们提出了一种新的剪枝方法，优化了剪枝网络的最终精度，并从过度参数化的父网络的内层提取知识。为了实现这种方法，我们将网络剪枝作为一个背包问题，优化神经元重要性与其相关计算成本之间的权衡。然后在保持网络高层结构的同时对网络信道进行剪枝。修剪后的网络在父网络的监督下利用其内部网络知识进行微调，我们称之为内部知识蒸馏技术。我们的方法可以在ImageNet、CIFAR-10和CIFAR-100上使用ResNet主干得到最新的修剪结果。为了剪除复杂的网络结构，如具有跳跃链接的卷积和深度卷积，我们提出了一种块分组方法来处理这些结构。通过这一点，我们产生了与EfficientNet-B0和MobileNetV3相同的触发器的紧凑架构，但精确度更高，在ImageNet上分别为$1\%$和$0.3\%$，在GPU上运行更快。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08258">PDF</a>
<h3>No. 10	从局部对比解释中学习全局透明模型</h3><h4>Tejaswini Pedapati, Avinash Balakrishnan, Karthikeyan Shanmugam, Amit Dhurandhar</h4>文摘：关于复杂模型的局部点对点对比/反事实解释的文献越来越多。这些方法强调了证明分类正确和/或产生改变最终分类的对比点的重要性。其他的工作试图通过使用数据进行有效的模型搜索，或者通过使用类似于蒸馏的方法从复杂模型传输信息，直接构建决策树和规则列表等全局可解释的模型。尽管这些可解释的全局模型可能有用，但它们可能与所选择的特定复杂模型的局部解释不一致。在这项工作中，我们探讨了这样一个问题：我们能否产生一个透明的、与局部解释一致/可由局部解释导出的全局模型？基于一个关键的见解，我们提出了一种新的方法，使得每一个局部对比/反事实解释都可以转化为布尔特征。这些布尔特征是二值化特征的稀疏连接。这样构造的数据集与设计的局部解释是一致的，可以在其上训练决策树这样的可解释模型。我们注意到，这种方法由于只依赖于稀疏的局部解释而严格地丢失了信息，然而，我们从经验上证明，在许多情况下，它仍然可以在复杂模型的性能和直接从原始数据集学习的其他方法方面具有竞争力。我们的方法还提供了一种以量化方式对本地解释方法进行基准测试的途径。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08247">PDF</a>
<h3>No. 11	带Bandit反馈的乐观策略优化</h3><h4>Yonathan Efroni, Lior Shani, Aviv Rosenberg, Shie Mannor</h4>摘要：策略优化方法是应用最广泛的一类强化学习算法。然而，到目前为止，这些方法大多是从优化的角度进行分析的，没有解决探索的问题，也没有对与环境的相互作用作出强有力的假设。本文考虑了具有未知跃迁和bandit反馈的表格式有限层位MDP设置中基于模型的RL。对于这种情况，我们提出了一个乐观信任域策略优化（TRPO）算法，我们为随机报酬建立了$tilde O（\sqrt{S^2a H^4k}）$遗憾。此外，我们还证明了$tilde O（\sqrt{S^2 A H^4}K^{2/3}）$对于对抗性奖励的后悔。有趣的是，这个结果与先前为bandit反馈情况导出的边界相匹配，但具有已知的转换。就我们所知，这两个结果是第一次得到的子线性后悔界，对于未知的转移和bandit反馈的策略优化算法。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08243">PDF</a>
<h3>No. 12	工业4.0预测维修综述</h3><h4>Christian Krupitzer (1), Tim Wagenhals (2), Marwin Züfle (1), Veronika Lesch (1), Dominik Schäfer (3), Amin Mozaffarin (4), Janick Edinger (2), Christian Becker (2), Samuel Kounev (1) ((1) University of Würzburg, Würzburg, Germany, (2) University of Mannheim, Mannheim, Germany, (3) Syntax Systems GmbH, Weinheim, Germany, (4) MOZYS Engineering GmbH, Würzburg)</h4>摘要：2016年，大众汽车的生产问题导致每周高达4亿欧元的销售大幅亏损。这个例子显示了一个工作生产设施对公司的巨大财务影响。尤其是在工业4.0和工业物联网（带智能连接机器）的数据驱动领域，传统的静态维护计划似乎过时了。本文综述了工业4.0预测维修技术的发展现状。在结构化文献调查的基础上，我们提出了工业4.0背景下预测性维修的分类，并讨论了这一领域的最新发展。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08224">PDF</a>
<h3>No. 13	SYMOG：学习对称混合高斯模以改进不动点量化</h3><h4>Lukas Enderich, Fabian Timm, Wolfram Burgard</h4>摘要：深度神经网络（DNNs）已被证明在几种机器学习基准上优于经典方法。然而，它们的计算复杂度很高，需要强大的处理单元。尤其是在嵌入式系统上部署时，模型的大小和推理时间必须大大减少。我们提出对称高斯模混合（symo），通过低比特定点量化显著降低DNNs的复杂度。SYMOG是一种新的软量化方法，它能同时解决学习任务和量化问题。在训练过程中，权值分布由单峰高斯分布变为对称的高斯混合分布，其中每个平均值属于一个特定的不动点模式。我们在公共基准数据集（MNIST、CIFAR-10、CIFAR-100）上用不同的架构（LeNet5、VGG7、VGG11、DenseNet）评估我们的方法，并与最新的量化方法进行比较。我们在CIFAR-10和CIFAR-100上分别获得了5.71%和27.65%的错误率，取得了优异的结果并优于2位最新性能。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08204">PDF</a>
<h3>No. 14	空中联合学习：无人机群联合功率分配与调度</h3><h4>Tengchan Zeng, Omid Semiari, Mohammad Mozaffari, Mingzhe Chen, Walid Saad, Mehdi Bennis</h4>摘要：无人机群体必须利用机器学习技术来完成从协调航迹规划到协同目标识别等多种任务。然而，由于无人机群和地面基站（BSs）之间缺乏连续的连接，使用集中式ML将是一项挑战，特别是在处理大量数据时。本文提出了一种新的无人机群结构来实现分布式联邦学习算法。随后的每一架无人机根据其收集的数据训练一个本地飞行模型，然后将该训练的本地模型发送给领先的无人机，后者将汇总接收的模型，生成一个全局飞行模型，并通过群内网络将其发送给跟随者。为了确定由风和机械振动引起的衰落、传输延迟和无人机天线角度偏差等无线因素如何影响FL的性能，对FL进行了严格的收敛性分析。在此基础上，提出了一种联合功率分配与调度的设计方案，以优化FL的收敛速度，同时考虑到收敛过程中的能量消耗和群控制系统的延迟要求。仿真结果验证了FL收敛性分析的有效性，表明联合设计策略与基线设计相比，可以减少收敛所需的通信轮数35%。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08196">PDF</a>
<h3>No. 15	利用后见之明在持续学习中巩固过去的知识</h3><h4>Arslan Chaudhry, Albert Gordo, Puneet K. Dokania, Philip Torr, David Lopez-Paz</h4>摘要：在持续学习中，学习者面对的是一个数据流，其分布随时间而变化。众所周知，现代神经网络在这种情况下会受到影响，因为它们很快就会忘记以前获得的知识。为了解决这种灾难性遗忘，许多连续学习方法实现了不同类型的经验重放，即对存储在称为情景记忆的小缓冲区中的过去数据进行再学习。在这项工作中，我们用一个新的目标来补充经验回放，我们称之为锚定，学习者使用双层优化来更新当前任务的知识，同时保持对过去任务的某些锚定点的预测不变。这些锚定点是通过基于梯度的优化来学习的，以最大化遗忘，这是通过微调当前训练的模型对过去任务的情节记忆来近似的。对几种有监督的连续学习学习基准的实验表明，我们的方法在准确度和遗忘度以及不同大小的情景记忆方面都提高了标准经验重放。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08165">PDF</a>
<h3>No. 16	卷积语音识别模型综合内省的梯度调整神经元激活谱</h3><h4>Andreas Krug, Sebastian Stober</h4>摘要：基于深度学习的自动语音识别（ASR）模型非常成功，但难以解释。为了更好地理解人工神经网络（ann）是如何完成其任务的，人们提出了内省方法。将这种技术从计算机视觉应用到语音识别并非一帆风顺，因为语音数据比图像数据更复杂，解释性也更低。在这项工作中，我们引入梯度调整的神经元激活轮廓（GradNAPs）来解释深部神经网络的特征和表示。梯度是神经网络对特定输入组的特征性反应，它包含了神经元对预测的相关性。我们将展示如何利用渐变来了解如何在ann中处理数据。这包括可视化特征的不同方式和梯度的聚类，以比较给定网络的任何层中不同输入组的嵌入。我们使用一个完全卷积的ASR模型来演示我们提出的技术。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08125">PDF</a>
<h3>No. 17	所有形状和大小的随机平滑</h3><h4>Greg Yang, Tony Duan, Edward Hu, Hadi Salman, Ilya Razenshteyn, Jerry Li</h4>摘要：随机平滑是最近提出的一种对抗攻击的防御方法，它对$ell_2$扰动具有最先进的可证明鲁棒性。不久之后，许多工作为其他度量设计了新的随机平滑方案，例如$\ell 1$或$\ell infty$；但是，对于每个几何体，都需要大量的工作来获得新的稳健性保证。这就引出了一个问题：我们能找到随机平滑的一般理论吗？本文提出了一种新的随机平滑方案设计与分析框架，并在实际应用中验证了其有效性。我们的理论贡献如下：（1）证明了对于一个适当的“最优”概念，任何“nice”范数的最优平滑分布都具有由该范数的*Wulff晶体*给出的水平集。（2） 我们提出了两种新的互补方法来推导任意光滑分布的可证明鲁棒半径。最后，利用Banach空间同型态理论，给出了当前随机平滑技术的基本极限。通过结合（1）和（2），我们显著提高了标准数据集上$ell_1$的最新认证精度。另一方面，利用（3），我们表明，在随机输入扰动下，如果没有比标签统计更多的信息，当输入维数$d$较大时，随机平滑无法获得针对$\ell\infty$-norm$\Omega（1/\sqrt d）$扰动的非平凡认证精度。我们在github.com/tonyduan/rs4a中提供代码。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08118">PDF</a>
<h3>No. 18	分层量化自动编码器</h3><h4>Will Williams, Sam Ringer, Tom Ash, John Hughes, David MacLeod, Jamie Dougherty</h4>摘要：尽管神经网络在有损图像压缩方面的训练取得了进展，但目前的方法不能在很低的比特率下保持感知质量和高层次特征。由于最近在矢量量化变分自编码（VQ-VAEs）中学习离散表示的成功，我们鼓励使用VQ-VAEs的层次来获得高压缩因子。我们证明了量化和层次潜在结构的结合有助于基于似然的图像压缩。这使得我们引入了一个更具概率性的VQ-VAE框架，而之前的工作是一个极限情况。我们的层次结构产生了一系列马尔可夫的潜在变量，这些变量可以重建保留语义意义特征的高质量图像。这些延迟可以进一步用于生成真实的样本。我们对CelebA和MNIST数据集的重建和样本进行定性和定量评估。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08111">PDF</a>
<h3>No. 19	随机图上的神经网络</h3><h4>Romuald A. Janik, Aleksandra Nowak</h4>文摘：我们对神经网络进行了大规模的评估，其结构对应于各种类型的随机图。除了经典的随机图族（包括随机图、无标度图和小世界图）外，我们提出了一种新的、灵活的直接生成随机有向无环图（DAG）的算法，并研究了一类由函数静息状态fMRI网络导出的图。大多数表现最好的网络确实是在这些新家庭中。我们还提出了一个将图转化为前馈神经网络所必需的DAG的一般过程。我们研究了图的各种结构和数值特性与神经网络测试精度的关系。由于经典的数值图不变量本身似乎不允许挑选出最佳网络，我们引入了新的数值特征，选择了一组准一维图，这些图是性能最好的网络中的大多数。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08104">PDF</a>
<h3>No. 20	学习线性二次调节器的对数遗憾</h3><h4>Asaf Cassel (1), Alon Cohen (2), Tomer Koren (1) ((1) School of Computer Science, Tel Aviv University, (2) Google Research, Tel Aviv)</h4>文摘：研究了过渡参数初始未知的线性二次型控制系统的学习问题。最近在这方面的研究结果已经证明了有效的学习算法，并且遗憾地随着决策步骤数的平方根的增长而增长。我们提出了新的有效算法，在两种情况下，当只有状态转移矩阵$A$未知，当只有状态作用转移矩阵$B$未知，且最优策略满足一定的非简并条件时，可能令人惊讶地实现了仅随步数对数缩放（poly）。另一方面，我们给出了一个下界，它表明当违反后一个条件时，平方根遗憾是不可避免的。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08095">PDF</a>
<h3>No. 21	解剖神经节律</h3><h4>Stefano Massaroli, Michael Poli, Jinkyoo Park, Atsushi Yamashita, Hajime Asama</h4>摘要：连续的深度学习结构最近重新出现作为神经常微分方程（Neural ods）的变体。这些模型提供的无限深度方法在理论上弥合了深度学习和动态系统之间的鸿沟；然而，破译它们的内部工作仍然是一个开放的挑战，它们的大多数应用目前仅限于作为通用黑盒模块的包含。在这项工作中，我们“开箱”并提供了一个系统理论的观点，包括状态增强策略和鲁棒性，目的是澄清几个设计选择对底层动力学的影响。我们还介绍了新的体系结构：其中，Galerkin启发的深度变化参数模型和具有数据控制向量场的神经网络节点。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08071">PDF</a>
<h3>No. 22	符号梯度下降几何</h3><h4>Lukas Balles, Fabian Pedregosa, Nicolas Le Roux</h4>文摘：基于符号的优化方法由于其在分布式优化中具有良好的通信代价和在神经网络训练中令人惊讶的良好性能，在机器学习中得到了广泛的应用。此外，它们与Adam等所谓的自适应梯度方法密切相关。最近关于signSGD的工作使用了一个非标准的“可分离平滑度”假设，而一些较老的工作研究符号梯度下降作为相对于$\ell\infty$-范数的最陡下降。在这项工作中，我们通过显示可分离光滑性和$\ell\infty$-光滑性之间的密切联系来统一这些现有的结果，并认为后者是较弱且更自然的假设。然后，我们继续研究相对于$\ell\infty$-范数的平滑常数，从而分离出影响基于符号的方法性能的目标函数的几何性质。简而言之，如果（i）Hessian在某种程度上集中在其对角线上，并且（ii）其最大特征值远大于平均特征值，则基于符号的方法优于梯度下降法。这两种特性在深层网络中都很常见。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08056">PDF</a>
<h3>No. 23	部分标签学习中真标签的渐进识别</h3><h4>Jiaqi Lv, Miao Xu, Lei Feng, Gang Niu, Xin Geng, Masashi Sugiyama</h4>摘要：部分标签学习是一个重要的弱监督学习问题，每个训练实例都有一组包含真实标签的候选标签。现有的大多数方法都将学习目标精心设计为必须以特定方式解决的约束优化，这使得它们的计算复杂性成为扩展到大数据的瓶颈。本文的目的是提出一种新的无隐式模型假设或优化算法的局部标号学习框架。更具体地说，我们提出了分类风险的一般估计，从理论上分析了分类一致性，并建立了估计误差界。然后，我们探索了一种渐进辨识方法来近似最小化所提出的风险估计器，其中模型的更新和真实标签的辨识是以无缝的方式进行的。所得算法与模型无关，与损失无关，且与随机优化相容。深入的实验证明它开创了新的艺术境界。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08053">PDF</a>
<h3>No. 24	通过在无监督域自适应中增加一个额外的类来扩大区分能力</h3><h4>Hai H. Tran, Sumyeong Ahn, Taeyoung Lee, Yung Yi</h4>文摘：本文研究了无监督域自适应问题，目的是利用源域的有标记数据和目标域的无标记数据建立目标域的预测模型。基于特征提取的思想，近年来出现了一系列的研究，这些特征不仅对两个领域都具有不变性，而且对目标领域也具有很高的识别能力。本文提出了一种增强区分能力的思想：加入一个新的人工类，并结合新类的GAN生成样本对数据进行模型训练。基于新类样本的训练模型能够通过在目标域中重新定位当前类的数据，从而更有效地提取出判别性更强的特征，从而绘制出决策边界。我们的思想是高度通用的，因此与许多现有的方法如DANN、VADA和DIRT-T兼容。我们对用于评估无监督域自适应的标准数据进行了各种实验，并证明我们的算法在许多情况下都达到了SOTA性能。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08041">PDF</a>
<h3>No. 25	通过政策转移实现有效的深度强化学习</h3><h4>Tianpei Yang, Jianye Hao, Zhaopeng Meng, Zongzhang Zhang, Weixun Wang, Yujing Hu, Yingfeng Cheng, Changjie Fan, Zhaodong Wang, Jiajie Peng</h4>摘要：迁移学习（TL）利用以往学习到的相关任务策略中的先验知识，在促进强化学习（RL）方面显示出巨大的潜力。现有的传输方法要么显式计算任务之间的相似性，要么选择适当的源策略为目标任务提供指导性的探索。然而，如何通过交替地利用来自适当源策略的知识而不显式地度量相似度来直接优化目标策略，目前还缺少。本文利用这一思想，提出了一种新的策略转移框架（PTF）来加速RL。我们的框架通过将多策略转移建模为选项学习问题，来学习何时和哪一个源策略是对目标策略最好的重用，以及何时终止它。PTF可以很容易地与现有的深RL方法相结合。实验结果表明，无论是在离散的还是连续的行为空间中，它都显著地加快了学习过程，并且在学习效率和最终性能方面都超过了最新的策略转移方法。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08037">PDF</a>
<h3>No. 26	一个固定的观点：基于模型的聚类框架</h3><h4>Jianhao Ding, Lansheng Han</h4>摘要：随着数据的膨胀，聚类分析作为无监督学习的一个分支，对其数学规律缺乏统一的认识和应用。本文从不动点的观点出发，重新阐述了基于模型的聚类方法，提出了一个统一的聚类框架。为了寻找不动点作为聚类中心，该框架迭代地构造了压缩映射，有力地揭示了算法的收敛机制和算法之间的相互联系。通过指定一个压缩映射，高斯混合模型（GMM）可以作为一个应用映射到框架。我们希望这个不动点框架能帮助我们设计未来的聚类算法。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08032">PDF</a>
<h3>No. 27	图卷积网络中通过毒害邻域的间接对抗攻击</h3><h4>Tsubasa Takahashi</h4>摘要：图卷积神经网络是一种在相邻节点上学习聚集的神经网络，在节点分类任务中取得了良好的性能。然而，最近的研究表明，这种图卷积节点分类器会被图上的对抗性扰动所欺骗。滥用图卷积，一个节点的分类结果可能会受到毒害其邻居的影响。给定一个属性图和一个节点分类器，我们如何评估这种间接对抗攻击的鲁棒性？我们能否产生强大的对抗性扰动，这种扰动不仅对一跳邻居有效，而且对离目标更远的邻居有效？在本文中，我们证明了节点分类器可以通过毒害距离目标较远的一个节点甚至两个跳或更远的节点而被高置信度欺骗。为了实现攻击，我们提出了一种新的方法，它只在远离目标的单个节点上搜索较小的扰动。在我们的实验中，我们提出的方法在两个数据集中，在距离目标两个跳的范围内，攻击成功率达到99%。我们还证明了m层图卷积神经网络有机会被我们在m跳邻居中的间接攻击所欺骗。所提出的攻击可作为未来防御尝试的基准，以开发具有对手鲁棒性的图形卷积神经网络。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08012">PDF</a>
<h3>No. 28	对随机强盗的行动操纵攻击：攻击与防御</h3><h4>Guanlin Liu, Lifeng lai</h4>文摘：由于随机多臂bandit模型的广泛应用，了解敌方攻击的影响，设计对攻击具有鲁棒性的bandit算法是该模型安全应用的关键。本文介绍了一种新的攻击类型，即操作攻击。在此攻击中，对手可以更改用户选择的动作信号。结果表明，在不知道武器平均回报的情况下，我们提出的攻击只需花费对数代价，就可以操纵广泛使用的bandit算法UCB（Upper Confidence Bound）。为了防御这类攻击，我们提出了一种新的算法，在给定攻击总代价的上界时，该算法对操作操作攻击具有鲁棒性。我们证明了我们的算法有一个伪后悔上界$\mathcal{O}（\max{\log T，a}）$，其中$T$是总轮数，$a$是总攻击代价的上界。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08000">PDF</a>
<h3>No. 29	具有子集选择的随机效用模型的最优项学习</h3><h4>Aadirupa Saha, Aditya Gopalan</h4>文摘：我们考虑了PAC从n$个项目池中学习最有价值的项目的问题，使用k$个项目子集的顺序、自适应选择的播放，当播放子集时，学习者接收根据一般随机效用模型（RUM）采样的相对反馈，该模型对潜在项目效用具有独立的噪声扰动。我们确定了这种RUM的一个新性质，称为最小优势，它有助于根据项目对的相对盈亏经验计数来描述项目对分离的复杂性，并且可以仅作为噪声分布的函数来限定。我们给出了一个基于项目的成对相对计数和层次消去的通用RUMs学习算法，以及一个新的PAC样本复杂度保证$O（\frac{n}{c^2\epsilon^2}\log\frac{k}{delta}）$轮来识别一个$\epsilon$-具有置信度$1-\delta$的最优项目，当RUM中的最坏情况成对优势对项目的参数间隙具有至少$c$的敏感度时。PAC样本复杂度的基本下界表明，就其对$n、k$和$c$的依赖性而言，这是接近最优的。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07994">PDF</a>
<h3>No. 30	梯度增强神经网络：GrowNet</h3><h4>Sarkhan Badirli, Xuanqing Liu, Zhengming Xing, Avradeep Bhowmik, Sathiya S. Keerthi</h4>文摘：提出了一种新的梯度增强框架，该框架采用浅层神经网络作为弱学习者。在此统一框架下考虑了一般损失函数，并给出了分类、回归和学习排序的具体实例。为了弥补经典梯度提升决策树贪心函数逼近的缺陷，引入了一个完全修正步骤。该模型在多个数据集上完成了所有这三个任务。进行了消融研究，揭示了各模型成分和模型超参数的影响。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07971">PDF</a>
<h3>No. 31	关于范畴概率的贝叶斯</h3><h4>Taejong Joo, Uijung Chung, Min-Gwan Seo</h4>文摘：神经网络在分类任务中以软极大值为基础，存在过度自信问题，缺乏不确定性表示能力。作为softmax的贝叶斯替代，我们考虑了类标签上的一个分类概率随机变量。在这个框架中，先验分布显式地对观察到的标签中固有的假定噪声进行建模，从而在多个具有挑战性的任务中提供一致的泛化性能增益。该方法继承了贝叶斯方法的优点，可以获得更好的不确定性估计和模型校正。与带交叉熵损失函数的softmax相比，我们的方法可以实现为一个即插即用损失函数，计算开销可以忽略不计。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07965">PDF</a>
<h3>No. 32	时序图的归纳表示学习</h3><h4>Da Xu, Chuanwei Ruan, Evren Korpeoglu, Sushant Kumar, Kannan Achan</h4>摘要：时间图归纳表示学习是面向现实动态网络的可销售机器学习的重要一步。时态动态图的演化本质要求处理新的节点以及捕获时态模式。节点嵌入现在是时间的函数，它应该同时表示静态节点特征和演化的拓扑结构。此外，节点和拓扑特征也可以是时态的，节点嵌入还应该捕获其模式。我们提出时间图注意（TGAT）层来有效地聚集时间拓扑邻域特征以及学习时间特征之间的相互作用。对于TGAT，我们以自关注机制为基础，在经典Bochner谐波分析定理的基础上，提出了一种新的函数时间编码技术。通过叠加TGAT层，该网络将节点嵌入识别为时间函数，并能随着图的演化归纳出新节点和观测节点的嵌入。该方法同时处理节点分类和链路预测任务，并且可以自然地扩展到包含时间边缘特征。在两个基准和一个工业数据集的时间背景下，我们对我们的方法进行了评估。我们的TGAT模型与目前最先进的基线以及之前的时间图嵌入方法相比具有优势。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07962">PDF</a>
<h3>No. 33	梯度元强化学习课程</h3><h4>Bhairav Mehta, Tristan Deleu, Sharath Chandra Raparthy, Chris J. Pal, Liam Paull</h4>摘要：基于梯度的元学习者，如模型不可知元学习（MAML）在有监督和强化学习环境中表现出了很强的少镜头学习性能。然而，特别是在元强化学习（meta-RL）的情况下，我们可以证明基于梯度的元学习者对任务分布非常敏感。在错误的课程设置下，代理人会受到元过度适应、浅适应和适应不稳定的影响。在这项工作中，我们首先强调基于梯度的元RL的有趣的失败案例，并表明任务分布可以广泛地影响算法的输出、稳定性和性能。为了解决这个问题，我们利用最近关于领域随机化的文献中的见解，提出了元主动领域随机化（meta-ADR），它学习基于梯度的meta-RL的任务课程，类似于ADR学习sim2real转移。结果表明，该方法在各种模拟的移动和导航任务上能产生更稳定的策略。我们对分布内和分布外的泛化进行了评估，发现即使在非结构化任务空间中，学习到的任务分布也大大提高了MAML的自适应性能。最后，我们激发了meta-RL中更好的基准测试的需求，该基准测试优先于单个任务的适应性能。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07956">PDF</a>
<h3>No. 34	个性化联合学习：一种元学习方法</h3><h4>Alireza Fallah, Aryan Mokhtari, Asuman Ozdaglar</h4>摘要：联邦学习的目标是设计多个代理以隐私保护的方式与一个中心节点通信的算法，以最小化它们的平均损失函数。在这种方法中，每个节点不仅共享所需的计算预算，而且可以访问更大的数据集，从而提高了生成模型的质量。然而，这种方法只为所有代理开发一个公共输出，因此不能使模型适应每个用户的数据。这是一个重要的缺失特性，特别是考虑到不同代理的底层数据分布的异构性。在本文中，我们研究了一种个性化的联邦学习变体，我们的目标是以分布式的方式找到一个共享的初始模型，该模型可以由当前用户或新用户通过对其自身的损失函数执行一步或几步梯度下降来稍微更新。这种方法保留了联邦学习体系结构的所有优点，同时为每个用户带来了更个性化的模型。我们证明这个问题可以在模型不可知元学习（MAML）框架下进行研究。受此启发，我们提出了一个著名的联邦平均算法的个性化变体，并用非凸损失函数的梯度范数来评估其性能。此外，我们还描述了用户数据的基本分布的紧密性如何影响这种性能，这些分布是根据分布距离（如总变差和1-Wasserstein度量）来测量的。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07948">PDF</a>
<h3>No. 35	具有深生成先验的源分离</h3><h4>Vivek Jayaram, John Thickstun</h4>摘要：尽管在信号源分离方面取得了实质性进展，但对于结构丰富的数据，其结果仍然包含可感知的伪影。相比之下，最近的深度生成模型可以在不同的域中生成真实的样本，这些域与数据分布的样本无法区分。本文介绍了一种基于贝叶斯方法的信源分离方法，该方法以生成模型作为信源混合物成分的先验，并利用Langevin动态系统对给定混合物的信源后验分布进行采样。这将源分离问题与生成模型分离开来，使我们能够直接使用最新的生成模型作为优先级。该方法实现了MNIST数字分离的最新性能。介绍了在较丰富数据集上评价分离质量的新方法，给出了在CIFAR-10上对分离结果的定量评价。我们还提供了关于LSUN的定性结果。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07942">PDF</a>
<h3>No. 36	用神经网络权值控制标签噪声信息提高泛化能力</h3><h4>Hrayr Harutyunyan, Kyle Reing, Greg Ver Steeg, Aram Galstyan</h4>摘要：在有噪声或错误标签的情况下，神经网络具有记忆噪声信息的不良倾向。标准的正则化技术，如辍学、体重衰减或数据增加，有时会有帮助，但不能阻止这种行为。如果将神经网络权值视为依赖于训练数据和随机性的随机变量，则可以用权值与给定输入的所有训练标签向量之间的Shannon互信息来量化记忆信息量，$I（w:\ mathbf{y}\mid\mathbf{x}）。我们证明，对于任何训练算法，这个项的低值对应于标签噪声记忆的减少和更好的泛化界。为了获得这些低值，我们提出了训练算法，该算法使用一个辅助网络，在不访问标签的情况下预测分类器最后一层的梯度。我们在MNIST、CIFAR-10和CIFAR-100的不同版本上以及在一个有噪声标签的大数据集Clothing1M上说明了我们的方法的有效性。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07933">PDF</a>
<h3>No. 37	基于变分LSTM网络的短期交通流预测</h3><h4>Mehrdad Farahani, Marzieh Farahani, Mohammad Manthouri, Okyay Kaynak</h4>摘要：交通流特性是一个地区最重要的决策和交通警务因素之一。对交通流预测状态的认识在交通管理和交通信息部门具有重要意义。本研究的目的是提出一个基于历史资料的深度学习交通流量预测模型。2019年从Caltrans绩效测量系统（PeMS）收集的6个月历史数据。所提出的预测模型是一个变分的长短期存储器编码器，与其它常规方法相比，VLSTM-E试图准确估计流量。VLSTM-E可以考虑分布和缺失值，提供更可靠的短期交通流。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07922">PDF</a>
<h3>No. 38	块交换：一种用于深度学习安全的随机方法</h3><h4>Xiao Wang, Siyue Wang, Pin-Yu Chen, Xue Lin, Peter Chin</h4>摘要：近年来对抗性攻击的研究揭示了现代深度学习模型的脆弱性。也就是说，精心设计的输入扰动可以使经过训练的高精度网络产生任意的错误预测，同时保持对人类视觉系统的不可察觉性。本文介绍了一种基于随机性的对抗攻击防御策略——块交换（BS）。BS用多个并行信道替换一个模型层块，而活动信道在运行时被随机分配，因此不可预测。实验结果表明，与随机激活剪枝（SAP）等随机防御方法相比，BS具有更分散的输入梯度分布和更好的防御效果。与其他防御相比，BS还具有以下特点：（i）BS导致较少的测试精度下降；（ii）BS独立于攻击，并且（iii）BS与其他防御兼容，可以与其他防御联合使用。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07920">PDF</a>
<h3>No. 39	信息浓缩主动学习</h3><h4>Siddhartha Jain, Ge Liu, David Gifford</h4>文摘：介绍了一种针对深度贝叶斯主动学习的批处理模式不可知主动学习方法，即信息凝聚主动学习法，该方法着重于获取尽可能多的关于未知点的信息。ICAL使用Hilbert-Schmidt独立性准则（HSIC）来度量候选批点与未标记集之间的依赖强度。我们开发了关键优化，使我们能够将我们的方法扩展到大型未标记集。我们在模型精度和负对数似然（NLL）方面与目前最先进的深度学习批处理模式AL方法相比有了显著的改进。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07916">PDF</a>
<h3>No. 40	自监督主动域随机化自动生成课程</h3><h4>Sharath Chandra Raparthy, Bhairav Mehta, Florian Golemo, Liam Paull</h4>文摘：目标定向强化学习（RL）传统上是考虑一个与环境交互的agent，给一个agent规定一个与某个目标的完成成比例的实值奖励。目标导向的RL由于易于重用或通过提出目标生成新体验，在样本效率方面有了很大的提高。在这项工作中，我们建立在自我游戏的框架上，允许一个代理与自己交互，以便在一些未知的任务上取得进展。我们使用主动领域随机化和自我游戏来创建一个新颖的、耦合的环境目标课程，在该课程中，代理通过逐步增加的困难任务和环境变化来学习。我们的方法，自我监督的主动领域随机化（SS-ADR），产生了一个不断增长的课程，鼓励代理人尝试超出其当前能力的任务，同时建立一个领域随机化课程，使最先进的结果对各种简单的转移任务。我们的研究结果显示，一个环境困难与在每个环境中设定的目标的困难共同演变的课程，在测试目标导向的任务中提供了实际的好处。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07911">PDF</a>
<h3>No. 41	原因：使用归因方法从事件序列中学习Granger因果关系</h3><h4>Wei Zhang, Thomas Kobber Panum, Somesh Jha, Prasad Chalasani, David Page</h4>文摘：研究了从异步、相互依存、多类型的事件序列中学习事件类型之间格兰杰因果关系的问题。现有的研究要么是模型的灵活性有限，要么是模型的可解释性差，因此无法揭示具有不同事件相关性的各种事件序列之间的Granger因果关系。为了解决这些缺点，我们提出了一个新的研究任务框架CAUSE（事件序列归因的因果关系）。因果关系的核心思想是先通过拟合神经点过程隐式地捕捉潜在的事件相关性，然后用公理化的归因方法从过程中提取Granger因果关系统计。在充满不同事件相关性的多个数据集中，我们证明CAUSE在一系列最新方法上正确推断类型间Granger因果关系方面取得了优异的性能。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07906">PDF</a>
<h3>No. 42	基于超图的实证政策评估</h3><h4>Daniel Vial, Vijay Subramanian</h4>文摘：设计并分析了强化学习中的经验策略评价问题的算法。我们的算法从高成本状态向后探索以找到高价值状态，而不是从所有状态向前探索。虽然有几篇论文已经从经验上证明了反向探索的实用性，但是我们进行了严格的分析，结果表明我们的算法可以将平均案例样本复杂度从$O（S\logs）$降低到$O（\logs）$。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07905">PDF</a>
<h3>No. 43	深度变换与度量学习网络：深度字典学习与神经网络的结合</h3><h4>Wen Tang, Emilie Chouzenoux, Jean-Christophe Pesquet, Hamid Krim</h4>文摘：字典学习及其相关的稀疏优化问题由于在推理任务和去噪应用方面取得了许多成功，引起了广泛的研究兴趣。虽然大多数解决方案都集中在单层字典上，但最近提出的改进的Deep DL（DDL）方法在一些问题上也有不足。在此，我们提出了一种新的DDL方法，其中每个DL层可以表示为一个线性层和一个递归神经网络（RNN）的组合。RNN灵活地解释了相关层和学习度量。我们提出的工作揭示了对神经网络和DDL的新见解，并提供了一种新的、有效的和有竞争力的方法来共同学习深度转换和推理应用的度量。通过大量的实验证明，该方法不仅可以优于现有的DDL算法，而且可以获得最新的通用CNNs。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07898">PDF</a>
<h3>No. 44	一种具有零阶自然梯度下降的高效黑盒敌手查询方法</h3><h4>Pu Zhao, Pin-Yu Chen, Siyue Wang, Xue Lin</h4>文摘：尽管现代深神经网络（DNNs）取得了巨大的成就，但目前最先进的DNNs的脆弱性和鲁棒性在许多需要高可靠性的应用领域引起了人们的安全关注。为了破坏DNN模型的学习性能，提出了各种对抗性攻击。其中，黑盒对抗攻击方法以其实用性和简单性受到了特别的关注。黑盒攻击通常倾向于较少的查询，以保持隐蔽性和低成本。然而，目前的黑盒攻击方法大多采用一阶梯度下降法，可能存在收敛速度慢、对超参数设置敏感度高等缺点。本文提出了一种零阶自然梯度下降（ZO-NGD）方法来设计对抗性攻击，该方法结合了针对黑箱攻击场景的零阶梯度估计技术和二阶自然梯度下降技术，以获得更高的查询效率。对图像分类数据集的实证评估表明，ZO-NGD与目前最先进的攻击方法相比，能够获得显著降低的模型查询复杂度。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07891">PDF</a>
<h3>No. 45	一个宽层金字塔拓扑深网络的全局收敛性</h3><h4>Quynh Nguyen, Marco Mondelli</h4>文摘：最近的一系列研究为梯度下降算法在过度参数化的情况下提供了收敛保证，在这种情况下，所有隐层的宽度都要求在训练样本数中多项式地大。然而，实际的深度网络的宽度往往只在第一层较大，然后开始向输出层减小。这就提出了一个有趣的开放性问题：在这种经验相关的背景下，类似的结果是否也成立。现有的理论观点表明，这类网络的损耗面表现良好，但这些结果通常不能为优化提供直接的算法保证。在本文中，我们通过证明一个宽层后接一个金字塔深网络拓扑足以使梯度下降找到一个具有几何速率的全局最小值来缩小这一差距。我们的证明基于Polyak-Lojasiewicz不等式的一个弱形式，它适用于全秩权矩阵流形中的深金字塔网络。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07867">PDF</a>
<h3>No. 46	数值模拟中的学习相似度量</h3><h4>Georg Kohl, Kiwon Um, Nils Thuerey</h4>文摘：提出了一种基于神经网络的方法来计算稳定的广义度量（LSiM），以比较各种数值模拟源的现场数据。我们的方法采用了暹罗网络结构，该结构是由度量的数学特性驱动的。我们利用带有偏微分方程（PDE）解算器的可控数据生成设置，从受控环境中的参考仿真创建越来越不同的输出。我们学习的度量的一个核心部分是一个专门的损失函数，它将有关单个数据样本之间相关性的知识引入到训练过程中。为了证明所提出的方法在向量空间和其他基于图像的学习度量方面优于现有的简单度量，我们在大量测试数据上评估了不同的方法。此外，我们还分析了泛化的好处以及可调训练数据难度的影响。通过对三个真实数据集的评估，证明了LSiM的鲁棒性。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07863">PDF</a>
<h3>No. 47	本地SGD比小批量SGD好吗？</h3><h4>Blake Woodworth, Kumar Kshitij Patel, Sebastian U. Stich, Zhen Dai, Brian Bullins, H. Brendan McMahan, Ohad Shamir, Nathan Srebro</h4>文摘：研究了一种自然的、常用的随机分布优化方法局部SGD（又称并行SGD和联邦平均）。它的理论基础目前缺乏，我们强调如何在现有的错误保证在凸设置主要由一个简单的基线，小批量SGD。（1） 对于二次型目标，我们证明了局部SGD严格控制小批量SGD，并且加速局部SGD对于二次型是最小极大最优的；（2）对于一般凸目标，我们提供了至少有时比小批量SGD改进的第一个保证；（3）我们证明了局部SGD确实不控制小批量SGD低于小批量SGD保证的本地SGD性能下限。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07839">PDF</a>
<h3>No. 48	多步模型不可知元学习：收敛性与改进算法</h3><h4>Kaiyi Ji, Junjie Yang, Yingbin Liang</h4>摘要：模型不可知元学习（MAML）算法作为一种流行的元学习方法，因其简单有效而得到了广泛的应用。然而，一般多步MAML的收敛性仍有待进一步研究。本文提出了一个新的理论框架，在此框架下，我们描述了多步MAML的收敛速度和计算复杂度。结果表明，虽然随机元梯度的估计偏差和方差包含指数因子$N$（内阶梯度更新次数），但在适当选择内阶步长的情况下，当复杂度仅随$N$线性增加时，MAML仍能达到收敛。然后，我们采取进一步的步骤，以开发一个更有效的无黑森MAML。我们首先证明了现有的零阶Hessian估计包含一个恒定的水平估计误差，因此MAML算法可以执行不稳定。针对这一问题，我们提出了一种新的基于梯度的高斯平滑的Hessian估计方法，并证明了该方法具有更小的估计偏差和方差，并且在温和的条件下得到了与原始MAML相同的性能保证。我们的实验验证了我们的理论，并证明了所提出的Hessian估计的有效性。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07836">PDF</a>
<h3>No. 49	核流神经网络内层的深度正则化和直接训练</h3><h4>Gene Ryan Yoo, Houman Owhadi</h4>文摘：提出了一种基于核流的人工神经网络正则化方法。在回归/克里格算法中，KFs是一种基于将随机批数据中的插值点数减半而导致的精度损失最小化的核选择方法。正在为ANN的组成结构的函数表示编写$f{（n）}{\theta{n}\circ f{（n-1）}{\theta{n-1}\circ f{（1）}\circ f{\theta{1}\big）（x）$，h^{（i）}（x）-h^{（i）}（x'）\|u 2^2）$。当与一批数据集相结合时，这些内核产生KF损失$e^2^{（i）}$（使用该批的任意一半预测另一半而产生的$L^2$回归误差），这取决于内层的参数$\theta 1、\ldots、\theta i$（和$\gamma i$）。所提出的方法只是将这些KF损失的一个子集与一个经典的输出损失相加。在不改变结构和输出分类器的情况下，我们在CNNs和WRNs上测试了所提出的方法，并报告了在不显著增加计算复杂度的情况下，减少了测试误差、减小了泛化间隙和增强了对分布移位的鲁棒性。我们怀疑，这些结果可能是由以下事实解释的：虽然传统训练只使用数据集定义的经验分布的线性函数（广义矩），并且容易陷入神经切线核区域（在过度参数化的情况下），所提出的损失函数（定义为经验分布的非线性函数）有效地训练CNN定义的底层核，而不是用该核对数据进行回归。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08335">PDF</a>
<h3>No. 50	基于强化学习的个性化产品智能选配装配</h3><h4>Caterina Neef, Dario Luipers, Jan Bollenbacher, Christian Gebel, Anja Richert</h4>摘要：个性化制造作为满足消费者日益多样化、个性化的需求和期望的一种手段，正成为一种重要的途径。虽然制造过程的实施有多种解决方案，例如添加剂制造，但随后的自动化装配仍然是一项具有挑战性的任务。作为解决这一问题的一种方法，我们旨在通过实施强化学习，教一个协作机器人成功地执行拣选和放置任务。对于在不断变化的制造环境中装配个性化产品，模拟的几何参数和动力学参数会发生变化。利用元学习的强化学习算法，首先对任务进行模拟训练。然后，它们将在真实环境中执行，其中引入了新的因素，这些因素在训练中没有模拟，以确认算法的稳健性。机器人将从触觉传感器、区域扫描摄像机和用于生成环境和物体高度图的三维摄像机获取输入数据。本文的工作包括机器学习算法和硬件组件的选择，以及实现上述生产场景的进一步研究问题。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08333">PDF</a>
<h3>No. 51	福克斯：保护个人隐私，防止未经授权的深度学习模式</h3><h4>Shawn Shan, Emily Wenger, Jiayun Zhang, Huiying Li, Haitao Zheng, Ben Y. Zhao</h4>摘要：如今，功能强大的面部识别模型层出不穷，对个人隐私构成了真正的威胁。正如Clearview.ai所展示的，任何人都可以在互联网上寻找数据，并在不知情的情况下训练我们高度精确的面部识别模型。我们需要一些工具来保护自己免受未经授权的面部识别系统及其无数潜在误用的侵害。不幸的是，相关领域的工作在实用性和有效性方面受到限制。在这篇文章中，我们提出福克斯，一个系统，允许个人接种自己的未经授权的面部识别模型。福克斯通过帮助用户在在线发布照片之前，在自己的照片中添加不可察觉的像素级变化（我们称之为“斗篷”）来实现这一点。当被第三方“追踪器”收集并用于训练面部识别模型时，这些“隐形”图像生成的功能模型会持续错误地识别用户。实验证明，无论追踪器如何训练模型，福克斯都能提供95%以上的用户识别保护。即使当干净的、未被屏蔽的图像被“泄露”到跟踪器并用于训练时，福克斯仍然可以保持80%以上的保护成功率。事实上，我们对当今最先进的面部识别服务进行了真正的实验，并取得了100%的成功。最后，我们展示了福克斯对各种试图探测或破坏斗篷的反制措施的鲁棒性。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08327">PDF</a>
<h3>No. 52	基于时态GPU脉动阵列积分的DNN加速度平衡效率与灵活性</h3><h4>Cong Guo, Yangjie Zhou, Jingwen Leng, Yuhao Zhu, Zidong Du, Quan Chen, Chao Li, Minyi Guo, Bin Yao</h4>文摘：深神经网络专用硬件加速器由于其优越的性能和效率，近年来引起了人们的研究兴趣。然而，今天的DNN加速器主要关注于加速特定的“核”，如卷积和矩阵乘法，它们是端到端DNN应用程序的关键但只是一部分。在整个应用程序中有意义的加速通常需要支持计算，这些计算虽然大量并行，但不适合DNN加速器。集成通用处理器（如CPU或GPU）会产生大量的数据移动开销，并导致DNN加速器上的资源利用率不足。我们提出了同步多模式架构（SMA），这是一种新的架构设计和执行模型，它在DNN加速器上提供通用的可编程性，以加速端到端的应用。SMA的关键是收缩执行模型和类GPU的SIMD执行模型的时间集成。SMA利用了脉动阵列加速器和GPU之间共享的公共组件，并提供了在两种模式之间就地切换的轻量级重新配置能力。SMA的性能提高高达63%，同时比采用TensorCore的基本Volta架构能耗低23%。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08326">PDF</a>
<h3>No. 53	2020年网络安全人工智能研讨会论文集</h3><h4>Dennis Ross, Arunesh Sinha, Diane Staheli, Bill Streilein</h4>摘要：本次研讨会将集中讨论人工智能在网络安全问题上的应用。AICS 2020的重点将放在网络安全问题背景下的人机合作上，并将特别探索人类操作员与人工智能技术之间的合作。研讨会将讨论人工智能的应用领域，如机器学习、博弈论、自然语言处理、知识表示、自动和辅助推理以及人机交互。此外，网络安全应用领域，特别强调人机协作的特征和部署将是重点。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08320">PDF</a>
<h3>No. 54	基于度量嵌入和最优传输的不一致分布距离</h3><h4>Mokhtar Z. Alaya, Maxime Bérar, Gilles Gasso, Alain Rakotomamonjy</h4>文摘：我们提出了一种新的方法来比较支持度不一定在同一度量空间上的分布。与Gromov-Wasserstein（GW）距离不同，我们考虑了一种将度量度量空间嵌入公共欧氏空间并计算嵌入分布上的最优传输（OT）的方法。这就产生了我们所说的子嵌入健壮Wasserstein（SERW）。在某些条件下，SERW是一个距离，它考虑了使用公共度量的（低失真）嵌入分布的OT距离。除了这一概括了最近几项OT工作的新建议外，我们的贡献还基于几个理论分析：i）我们刻画了嵌入空间来定义用于分布对齐的SERW距离；ii）我们证明了SERW模拟了几乎相同的GW距离的性质，并且我们给出了GW和SERW之间的成本关系。本文还提供了一些数值实验来说明SERW在实际匹配问题中的行为。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08314">PDF</a>
<h3>No. 55	后门DNNs的广谱靶向治疗</h3><h4>Akshaj Kumar Veldanda, Kang Liu, Benjamin Tan, Prashanth Krishnamurthy, Farshad Khorrami, Ramesh Karri, Brendan Dolan-Gavitt, Siddharth Garg</h4>文摘：提出了一种新的针对后门神经网络（BadNet s）的两级防御（NNoculation），它不同于现有防御，对后门触发器的形状、大小和位置以及BadNet的功能作了最小的假设。在预部署阶段，NNoculation使用从干净的验证集提取的输入的“广谱”随机扰动来重新训练网络，以部分减少后门的对抗性影响。在部署后阶段，NNoculation通过记录原始和部署前修补网络之间的分歧来检测和隔离后门测试输入。然后训练CycleGAN学习干净验证输入和隔离输入之间的转换；也就是说，它学习向干净验证图像添加触发器。这组经过转换的后门验证图像及其正确的标签被用于进一步重新训练BadNet，从而产生我们的最终防御。当攻击者绕过限制性假设时，NNoculation的性能优于我们所展示的最先进的神经清洁和人工大脑模拟（ABS）。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08313">PDF</a>
<h3>No. 56	多小波残差密集卷积神经网络图像去噪</h3><h4>Shuo-Fei Wang, Wen-Kai Yu, Ya-Xin Li</h4>摘要：近年来，具有大接收场（RF）的网络显示出了更高的拟合能力。在这项工作中，我们利用短期残差学习方法来改善网路对于影像去噪工作的效能与稳健性。在这里，我们选择了一个多小波卷积神经网络（MWCNN）作为骨干网络，它是一个具有大RF的最新网络之一，并在其每一层中插入剩余密集块（rdb）。我们称之为多小波残差密集卷积神经网络（MWRDCNN）。与其他基于RDB的网络相比，它可以从相邻层中提取更多的目标特征，保留较大的RF，提高计算效率。同时，这种方法也提供了在一个网络中吸收多个体系结构的优点而不发生冲突的可能性。该方法的性能已在大量实验中得到验证，并与现有技术进行了比较。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08301">PDF</a>
<h3>No. 57	MLModelScope：一个大规模的模型评估和基准测试的分布式平台</h3><h4>Abdul Dakkak, Cheng Li, Jinjun Xiong, Wen-mei Hwu</h4>摘要：机器学习（ML）和深度学习（DL）的创新正以如此之快的速度被引入，以至于研究人员很难对它们进行分析和研究。评估创新的复杂过程，以及缺乏标准和有效的方法来指定和提供ML/DL评估，是社区的一个主要“痛点”。本文提出了MLModelScope，这是一个开源的、框架/硬件无关的、可扩展的和可定制的设计，它支持可重复的、公平的和可伸缩的模型评估和基准测试。我们实现了支持所有主要框架和硬件的分布式设计，并为其配备了web、命令行和库接口。为了演示MLModelScope的功能，我们执行并行评估，并展示对模型评估管道的细微更改如何影响准确性，以及软硬件堆栈选择如何影响性能。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08295">PDF</a>
<h3>No. 58	当放射科报告生成遇到知识图时</h3><h4>Yixiao Zhang, Xiaosong Wang, Ziyue Xu, Qihang Yu, Alan Yuille, Daguang Xu</h4>文摘：近年来，为了减轻医生的工作量，放射科报告的自动生成一直是计算机辅助诊断领域的研究热点。自然图像字幕的深度学习技术已成功地应用于生成放射学报告。然而，放射学图像报告与自然图像字幕任务在两个方面有所不同：1）与自然图像字幕中每个单词的同等重要性相比，在放射学图像报告中，阳性疾病关键词提及的准确性至关重要；2）报告质量的评估应更侧重于匹配疾病关键字及其相关属性，而不是计算N-gram的发生率。基于这些考虑，我们建议在多个疾病发现上使用预先构建的图嵌入模块（用图卷积神经网络建模）来辅助报告的生成。知识图的合并允许对每个疾病发现和它们之间的关系建模进行专门的特征学习。此外，我们还提出了一个新的评估指标，以帮助放射影像报告的同一组成图。实验结果表明，与传统的图像字幕评价方法和我们提出的方法相比，在可公开访问的胸片数据集（IU-RR）上集成图形嵌入模块的方法具有更好的性能。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08277">PDF</a>
<h3>No. 59	部分Gromov-Wasserstein及其在正无标记学习中的应用</h3><h4>Laetitia Chapel, Mokhtar Z. Alaya, Gilles Gasso</h4>摘要：最优传输（OT）框架允许定义概率分布之间的相似性，并提供诸如Wasserstein和Gromov-Wasserstein差异等度量。经典OT问题寻求一个保持总质量的运输图，要求源和目标分布的质量相同。在某些应用中，例如颜色或形状匹配中，这可能限制太多，因为分布可能具有任意质量，或者只需要运输总质量的一小部分。已经设计了一些算法来计算非平衡Wasserstein度量，但是当涉及Gromov-Wasserstein问题时，还没有部分公式可用。这就排除了使用不在同一度量空间中的分布或需要对旋转或平移保持不变性的情况。本文针对部分Gromov-Wasserstein问题，提出了一种求解该问题的算法。我们在一个积极的无标签（PU）学习应用程序中展示了新的公式。据我们所知，这是本文中最优传输的第一个应用，我们首先强调基于Wasserstein的部分度量在通常的PU学习环境中证明是有效的。然后我们证明了部分Gromov-Wasserstein度量在点云来自不同领域或具有不同特征的情况下是有效的。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08276">PDF</a>
<h3>No. 60	多logue网：一种用于会话中多模态情感检测和情感分析的上下文感知RNN</h3><h4>Aman Shenoy, Ashish Sardana</h4>摘要：会话中的情感分析和情感检测是许多实际应用中的关键，不同的应用利用不同的数据来实现合理准确的预测。多模态情感检测和情感分析特别有用，因为应用程序将能够根据可用数据使用可用模式的特定子集，以生成相关预测。当前处理多模态功能的系统无法通过所有模式、对话中的当前说话者和听众以及通过适当的融合机制可用模式之间的相关性和关系来利用和捕获对话的上下文。在本文中，我们提出了一个递归神经网络架构，它试图考虑到上述所有的缺点，并跟踪对话的上下文、对话者的状态以及对话者在对话中所表达的情绪。我们提出的模型在两个基准数据集上对各种精度和回归度量进行了最新的测试。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08267">PDF</a>
<h3>No. 61	基于矩域自适应的学习界</h3><h4>Werner Zellinger, Bernhard A Moser, Susanne Saminger-Platz</h4>文摘：针对训练数据较少的目标领域，设计了一种领域自适应算法，通过对训练数据较多的源领域的模型进行自适应，最大限度地降低了判别模型的误分类风险。标准方法基于源域和目标域中经验概率分布之间的距离度量来度量适应差异。在这一背景下，我们讨论了在面向实践的一般条件下，关于潜在概率分布的学习界的推导问题。结果，我们得到了基于有限多个矩和光滑条件的域自适应学习界。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08260">PDF</a>
<h3>No. 62	用于微调的深网络基于距离的正则化</h3><h4>Henry Gouk, Timothy M. Hospedales, Massimiliano Pontil</h4>文摘：我们研究了深度神经网络微调过程中的正则化方法。首先，我们提供一个基于Rademacher复杂度的神经网络泛化界，它使用权重从初始值移动的距离。当应用于卷积网络时，这个界不直接依赖于权值的数目，并且与其他界相比是有利的。我们的界限与微调高度相关，因为提供基于转移学习的良好初始化的网络意味着学习可以较少地修改权重，从而实现更严格的泛化。受此启发，我们开发了一个简单而有效的微调算法，将假设类约束在一个以初始预训练权重为中心的小球体上，从而获得比传统转移学习更好的泛化性能。实验结果表明，我们的算法运行良好，验证了我们的理论结果。它不仅优于最先进的微调竞争对手，而且我们展示的基于惩罚的替代方案也不直接限制搜索空间的半径。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08253">PDF</a>
<h3>No. 63	研讨会报告：深入学习海洋生物声学的检测和分类</h3><h4>Fabio Frazao, Bruno Padovese, Oliver S. Kirsebom</h4>摘要：2019年11月21日至22日，约30名研究人员齐聚加拿大不列颠哥伦比亚省维多利亚市，参加由MERIDIAN组织、加拿大海洋网络主办的“海洋生物声学深度学习中的检测和分类”研讨会。来自加拿大海岸和美国的海洋生物学家、数据科学家和计算机科学家出席了研讨会，他们代表了包括大学、政府（加拿大渔业和海洋局、国家海洋和大气管理局）、工业（JASCO应用科学公司、谷歌，Axiom数据科学）和非营利组织（Orcasound，OrcaLab）。包括口头陈述、公开讨论和实践指导，研讨会项目为来自不同领域的专家提供了一个难得的机会，他们可以就深度学习及其在水声探测和分类算法发展方面的潜力进行交流。在本研讨会报告中，我们总结了演讲和讨论会的要点。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08249">PDF</a>
<h3>No. 64	洗牌型梯度法的统一收敛性分析</h3><h4>Lam M. Nguyen, Quoc Tran-Dinh, Dzung T. Phan, Phuong Ha Nguyen, Marten van Dijk</h4>文摘：针对机器学习中常用的有限和极小化问题，给出了一类洗牌型梯度法的统一收敛性分析。该算法包括各种变体，如随机重新洗牌、单洗牌和循环/增量梯度方案。我们考虑两种不同的情形：强凸和非凸问题。我们的主要贡献包括一类求解非凸和强凸问题的一般洗牌型梯度方法的新的非渐近和渐近收敛速度。虽然我们在非凸问题中的速率是新的（即在标准假设下还不知道），但是在强凸情况下的速率（直到常数）匹配最著名的结果。然而，与此方向的现有工作不同，我们仅使用平滑性和强凸性等标准假设。最后，我们通过一个非凸logistic回归和神经网络实例来实证说明学习率的影响。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08246">PDF</a>
<h3>No. 65	量子统计查询学习</h3><h4>Srinivasan Arunachalam, Alex B. Grilo, Henry Yuen</h4>文摘：我们提出了一种量子统计学习QSQ模型，它将Kearns引入的SQ学习模型推广到量子环境中。我们的模型也可以看作是量子PAC学习模型的一个限制：在这里，学习者不能直接访问量子示例，只能获得它们的测量统计估计。理论上，这个模型提供了一个简单而富有表现力的环境来探索量子例子在机器学习中的威力。从实际的角度来看，由于需要更简单的操作，QSQ模型中的学习算法更适合在近期量子器件上实现。我们证明了QSQ学习模型的一些结果。我们首先证明了奇偶函数（log n）-juntas和多项式大小的DNF公式在QSQ模型中是有效可学习的，与经典的难以证明的情形相比。这意味着量子PAC学习的许多优点甚至可以在更受限的量子SQ学习模型中实现。众所周知，用WSQDIM（C）表示的弱统计查询维数表征了经典SQ模型中C类概念学习的复杂性。我们证明了log（WSQDIM（C））是QSQ学习复杂性的一个下界，而且对于某些概念类C是紧的。此外，我们还证明了这个量为积分布下的小偏差量子通信模型提供了强下界。最后，我们引入了私有量子PAC学习的概念，其中量子PAC学习者必须是差异私有的。我们证明了QSQ模型中的可学习性意味着量子私有PAC模型中的可学习性。此外，我们还证明在私有PAC学习环境中，经典和量子样本的复杂度是相等的，直到常数因子。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08240">PDF</a>
<h3>No. 66	求解非线性扩散系数和Biot方程的物理信息神经网络</h3><h4>Teeratorn Kadeethum, Thomas M Jorgensen, Hamidreza M Nick</h4>文摘：介绍了应用物理信息神经网络解决生物医学工程、地震预报、地下能量采集等领域所必需的非线性多物理问题的潜力。具体地说，我们研究如何扩展物理信息神经网络的方法来求解非线性扩散系数和Biot方程的正问题和反问题。研究了不同训练样本大小和超参数选择下的物理信息神经网络的精度。研究了不同训练实现方式之间随机变化的影响。在相反的情况下，我们还研究了噪声测量的影响。此外，我们还讨论了选择逆模型超参数的挑战，并说明了如何将此挑战与为正向模型选择超参数联系起来。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08235">PDF</a>
<h3>No. 67	学习公平评分函数：公平定义、算法和二部排序的推广界</h3><h4>Robin Vogel, Aurélien Bellet, Stéphan Clémençon</h4>摘要：人工智能的许多应用，从信用贷款到通过累犯预测设计医疗诊断支持工具，都涉及到使用其属性的学习函数对个体进行评分。这些预测风险得分用于对一组人进行排序，和/或根据得分是否超过某个阈值（可能取决于所做决策的上下文）对他们进行个人决策。授予这种制度的授权程度将在很大程度上取决于如何回答公平问题。虽然这种关注在分类设置中得到了很多关注，但是针对学习评分函数的公平约束设计问题却没有得到太多的研究。本文针对二元标记数据的评分问题，提出了一种灵活的群体公平性方法，这是一种称为二元排序的标准学习任务。我们认为，ROC曲线的功能性质，即衡量排名绩效的金标准，导致了制定公平约束的几种可能方法。在二部排序中引入了一般的公平条件类，并建立了在这种约束下学习的评分规则的推广界。在理论公式和结果的基础上，我们设计了实用的学习算法，并通过数值实验说明了我们的方法。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08159">PDF</a>
<h3>No. 68	基于贝叶斯算术编码的可变比特率神经压缩</h3><h4>Yibo Yang, Robert Bamler, Stephan Mandt</h4>摘要：深度贝叶斯潜在变量模型为模型和数据压缩提供了新的途径。在这里，我们提出了一种新的算法来压缩后处理中的深层概率模型中的潜在表示，例如变分自编码。因此，该方法将模型设计和训练从压缩任务中分离出来。我们的算法将算术编码推广到连续域，使用自适应离散化精度，利用后验不确定性估计。我们方法的“即插即用”性质的一个结果是，可以通过一个单一的训练模型来实现各种速率失真的权衡，从而消除了为不同比特率训练多个模型的需要。我们的实验结果证明了考虑后验不确定性的重要性，并且表明，在仅使用一个机器学习模型的情况下，使用该算法的图像压缩在很大的比特率范围内优于JPEG。进一步的贝叶斯神经单词嵌入实验证明了该方法的通用性。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08158">PDF</a>
<h3>No. 69	基于互信息神经估计的隐式模型贝叶斯实验设计</h3><h4>Steven Kleinegesse, Michael U. Gutmann</h4>摘要：隐式随机模型是自然科学中普遍存在的一种模型，它的数据生成分布是不易处理的，但抽样是可能的。这些模型通常有自由参数，需要从科学实验收集的数据中推断出来。一个基本的问题是如何设计实验，使收集到的数据最有用。贝叶斯实验设计领域主张，理想情况下，我们应该选择最大化数据和参数之间相互信息（MI）的设计。然而，对于隐式模型，这种方法受到计算后验和最大化MI的高计算成本的严重阻碍，特别是当我们有多个设计变量需要优化时。本文提出了一种新的隐式模型贝叶斯实验设计方法，利用神经MI估计的最新进展来解决这些问题。我们证明，训练一个神经网络以使MI的下界最大化，可以让我们共同决定最优设计和后验。仿真研究表明，该方法将隐式模型的贝叶斯实验设计扩展到更高的设计维度。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08129">PDF</a>
<h3>No. 70	带语言偏差的Rnn变换器在汉英语码转换语音识别中的应用</h3><h4>Shuai Zhang, Jiangyan Yi, Zhengkun Tian, Jianhua Tao, Ye Bai</h4>文摘：近年来，人们利用语言身份信息来提高端到端码转换（CS）语音识别的性能。然而，以往的研究多采用附加的语言识别（LID）模型作为辅助模块，导致系统复杂。在这项工作中，我们提出了一个改进的带有语言偏差的递归神经网络转换器（RNN-T）模型来缓解这个问题。我们使用语言恒等式来偏向模型来预测CS点。这促进了该模型直接从转录中学习语言身份信息，不需要额外的LID模型。我们对一个汉英CS语料库seam进行了评价。与我们的RNN-T基线相比，该方法在两个测试集上的相对误差分别降低了16.2%和12.9%。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08126">PDF</a>
<h3>No. 71	BB U疏散：基于快速位置敏感行为的建筑物疏散</h3><h4>Subhra Mazumdar, Arindam Pal, Francesco Parisi, V.S. Subrahmanian</h4>摘要：过去关于疏散计划的工作假设疏散人员会遵守指示——然而，有充分的证据表明情况并非如此。有些人会按照指示行事，有些人则会按照自己的意愿行事。本文给出了一个基于行为的疏散问题（BBEP）的形式化定义，其中在规划疏散时考虑了人的行为模型。我们证明了一种特定形式的约束可以用来表达这种行为。我们证明，bbep可以通过一个称为BB_-IP的整数程序精确求解，而通过一个称为BB_-Evac的更快的算法则可以精确求解。我们对两种应用于建筑物的算法进行了详细的实验评估（尽管原则上算法可以应用于任何图形），并表明后者比BB_IP快一个数量级，同时在一个真实的建筑物图形和几个综合的建筑物图形上产生的结果几乎一样好生成的图表。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08114">PDF</a>
<h3>No. 72	走向低成本、稳定的区块链网络</h3><h4>Minghong Fang, Jia Liu</h4>摘要：区块链网络被认为是分布式系统的未来，近年来受到了业界和学术界越来越多的关注。然而，区块链开采过程消耗大量能源，研究表明，比特币开采消耗的能源量几乎与爱尔兰使用的电力量相同。针对区块链网络的高挖掘能耗问题，提出了一种区块链挖掘资源分配算法，以降低基于PoW（工作证明）的区块链网络的挖掘成本。我们首先对一般的区块链排队模型进行了系统的研究。在我们的排队模型中，事务随机到达队列，并以批处理的方式提供服务，其概率分布未知，对任何优先级机制都不可知。然后，利用Lyapunov优化技术，提出了一种动态挖掘资源分配算法（DMRA），该算法由一个参数$K>0$来参数化。结果表明，该算法在性能延迟上达到了$[O（1/K），O（K）]$的折衷。仿真结果也证明了DMRA在降低采矿成本方面的有效性。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08027">PDF</a>
<h3>No. 73	基于影响函数的数据中毒攻击对Top-N推荐系统的影响</h3><h4>Minghong Fang, Neil Zhenqiang Gong, Jia Liu</h4>文摘：推荐系统是web服务吸引用户的重要组成部分。流行的推荐系统使用大量的众包用户-项目交互数据（如评分）对用户偏好和项目属性进行建模；然后向用户推荐与用户偏好最匹配的顶级-N$项目。在这项工作中，我们证明攻击者可以通过向伪用户注入精心编制的用户项交互数据，向推荐系统发起数据中毒攻击，以根据攻击者的需要提出建议。具体来说，攻击者可以欺骗推荐系统，向尽可能多的普通用户推荐目标项。基于矩阵分解的推荐系统在工业上得到了广泛的应用。考虑到攻击者可以注入的假用户的数量，我们将假用户的评分作为一个优化问题来制定。然而，该优化问题是一个非凸整数规划问题，求解难度很大。为了应对这一挑战，我们开发了几种近似求解优化问题的技术。例如，我们利用影响函数来选择对推荐有影响的正常用户的子集，并基于这些有影响的用户来解决我们提出的优化问题。结果表明，我们的攻击是有效的，并优于现有的方法。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08025">PDF</a>
<h3>No. 74	非自回归对话状态跟踪</h3><h4>Hung Le, Richard Socher, Steven C.H. Hoi</h4>摘要：面向任务对话的对话状态跟踪（DST）研究已经向开放词汇或基于生成的方法发展，在这种方法中，模型可以从对话历史本身生成候选时隙值。这些方法显示了良好的性能增益，特别是在具有动态时隙值的复杂对话域中。然而，它们在两个方面存在不足：（1）它们不允许模型显式地跨域和时隙学习信号，以检测（域、时隙）对之间的潜在依赖性；（2）现有模型遵循自回归方法，当对话在多域和多圈上演化时，会产生较高的时间代价。本文提出了一种新的非自回归对话状态跟踪（NADST）框架，该框架可以考虑域和时隙之间潜在的依赖关系，以优化模型，从而更好地将对话状态预测为一个完整的集，而不是单独的时隙。特别是，我们的方法的非自回归特性不仅使得并行解码能够显著地减少DST的延迟，以便实时生成对话响应，而且还可以检测令牌级别的时隙之间以及时隙和域级别的依赖关系。我们的实验结果表明，我们的模型在MultiWOZ 2.1语料库上实现了跨领域的最新联合精度，并且随着对话历史的延长，我们的模型的延迟比以前的水平低一个数量级。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08024">PDF</a>
<h3>No. 75	基于自适应多尺度集成学习的游客季节趋势预测</h3><h4>Shaolong Suna, Dan Bi, Ju-e Guo, Shouyang Wang</h4>摘要：准确预测旅游者的季节和趋势是一项极具挑战性的任务。鉴于季节性和趋势性预测在旅游客源预测中的重要性，以往的研究工作对其重视不够。在本研究中，我们提出一种新的自适应多尺度集合（AME）学习方法，将变分模式分解（VMD）与最小二乘支援向量回归（LSSVR）相结合，来预测短期、中期及长期的季节及趋势。在我们开发的AME学习方法的公式中，首先将原始的游客到达序列分解为趋势、季节和剩余波动分量。然后利用ARIMA对趋势分量进行预测，SARIMA对12个月周期的季节性分量进行预测，LSSVR对剩余波动分量进行预测。最后，利用基于LSSVR的非线性集合方法，将三个分量的预测结果进行聚合，生成游客到达量的集合预测。此外，采用直接策略进行多步预测。通过两种精度测度和Diebold-Mariano检验，实证结果表明，本文提出的AME学习方法与本研究中使用的其他基准相比，能够获得更高的水平和方向预测精度，这表明我们的方法是一个很有前途的模型，预测游客人数具有很高的季节性和波动性。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08021">PDF</a>
<h3>No. 76	基于局部功率迭代的分布式SVD通信效率</h3><h4>Xiang Li, Shusen Wang, Kun Chen, Zhihua Zhang</h4>文摘：研究了截断奇异值分解（SVD）的分布计算。为了提高通信效率，我们开发了一个称为\texttt{LocalPower}的算法。具体地说，我们在$m$节点之间统一地划分数据集，并在多个（准确地说$p$）局部幂迭代和一个全局聚合之间交替。我们从理论上证明，在某些假设下，texttt{LocalPower}会将所需的通信次数降低$p$一个因子，以达到一定的精度。我们还展示了周期性衰减$p$的策略有助于提高\texttt{LocalPower}的性能。我们进行了实验，以证明\texttt{LocalPower}的有效性。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08014">PDF</a>
<h3>No. 77	基于游客注意力的旅游需求预测：一种集成的深度学习方法</h3><h4>Shaolong Sun, Yanzhao Li, Shouyang Wang, Ju-e Guo</h4>摘要：大量的旅游相关数据对旅游需求预测提出了一系列挑战，包括数据不足、多重共线性、计算时间长等。为了解决这一问题，提出了一种基于Bagging的多元集成深度学习模型。采用来京游客历史数据、经济指标和游客在线行为变量对四国来京游客进行预测。四个来源国的实证结果表明，我们提出的B-SAKE模型无论在水平精度、方向精度还是统计显著性上都优于基准模型。套袋和叠层自动编码都能提高模型的预测性能。并利用多步超前预报方案对模型的预报性能进行了评价，结果一致。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07964">PDF</a>
<h3>No. 78	基于渐进生长GANs的21cm断层扫描样本生成与参数推断的统一框架</h3><h4>Florian List, Geraint F. Lewis</h4>文摘：考虑到所涉及的天体物理过程的范围和可能要探测的高维参数空间，为一系列再电离历史建立一个21厘米亮度-温度信号的数据库是一项复杂和计算成本高昂的任务。我们使用一种特定类型的神经网络，一种逐步增长的生成对抗网络（PGGAN），在提高采收率期间生成21cm亮度温度的真实层析图像，覆盖一个连续的三维参数空间，该空间模拟不同的X射线发射率、Lyman波段发射率以及硬与软之间的比率X光片。GPU训练的网络以每秒$\sim 3'$的分辨率（在笔记本电脑CPU上）生成新样本，得到的全局21cm信号、功率谱和像素分布函数与21SSD目录{Semelin2017}中的训练数据非常一致。最后，我们展示了如何利用经过训练的PGGAN通过近似贝叶斯计算从21cm断层样本中推断参数。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07940">PDF</a>
<h3>No. 79	局部卷积GAN</h3><h4>Łukasz Struski, Szymon Knop, Jacek Tabor, Wiktor Daniec, Przemysław Spurek</h4>文摘：本文构造了一个完全卷积的GAN模型：LocoGAN，它的潜在空间是由可能不同分辨率的噪声图像给出的。学习是局部的，即我们处理的不是整个噪声图像，而是固定大小的子图像。因此，LocoGAN可以生成任意尺寸的图像，例如LSUN卧室数据集。我们方法的另一个优点来自于我们使用的位置通道，它允许生成完全周期的（例如圆柱全景图像）或几乎周期的、无限长的“图像”（例如墙纸）。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07897">PDF</a>
<h3>No. 80	观测不可辨识性、广义似然与自由能</h3><h4>A.E. Allahverdyan</h4>文摘：研究了具有观测不可辨识性的混合模型的参数估计问题：完全模型（也包含隐变量）是可辨识的，而边际模型（观测）不是可辨识的。因此，边际似然的全局极大值是（无限）退化的，边际似然的预测不是唯一的。我们通过引入一个有效温度，使其与自由能相似，来说明如何推广边际似然。这种推广解决了观测的不可识别性，因为它的最大化导致的唯一结果比边缘似然的一个退化极大值的随机选择或在许多这样的极大值上的平均更好。广义似然方法继承了一般似然方法的许多特点，如它具有条件性原理，通过适当的改进期望最大化方法可以寻找其局部极大值。广义似然最大化与熵优化有关。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07884">PDF</a>
<h3>No. 81	基于深度学习特征的CBIR</h3><h4>Subhadip Maji, Smarajit Bose</h4>摘要：在基于内容的图像检索系统中，任务是从给定查询图像的大型数据库中检索相似图像。通常的步骤是从查询图像中提取一些有用的特征，并检索具有相似特征集的图像。为此，选择一个合适的相似度度量方法，对相似度较高的图像进行检索。当然，这些特征的选择对系统的成功起着非常重要的作用，需要高层次的特征来减少语义鸿沟。在本文中，我们建议使用从为一个大型图像分类问题训练的深度学习卷积网络的预先训练的网络模型中得到的特征。这种方法似乎为各种数据库产生了非常优越的结果，并且它优于许多当代的CBIR系统。我们分析了该方法的检索时间，并提出了一种基于上述特征的数据库预聚类方法，在大多数情况下，在更短的时间内得到了可比的结果。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07877">PDF</a>
<h3>No. 82	自闭症和其他任务中大型、混合位点fMRI数据集的集成深度学习</h3><h4>Matthew Leming, Juan Manuel Górriz, John Suckling</h4>摘要：用于磁共振分类的深度学习模型面临着两个反复出现的问题：它们通常受样本量的限制，并且被自身的复杂性所抽象（“黑箱问题”）。在本文中，我们训练了一个卷积神经网络（CNN），它包含有史以来最大的多源功能磁共振（fMRI）连接组数据集，由43858个数据点组成。我们将此模型应用于自闭症（ASD）与典型发育期（TD）对照的横断面比较，这些对照被证明难以用推论统计来描述。为了将这些发现具体化，我们还对性别和任务与休息进行了分类。利用类平衡建立训练集，我们在一个集成模型中训练了3$乘以300美元的修正CNN，对ASD与TD、性别和任务与休息的总体AUROC分别为0.6774、0.7680和0.9222的功能磁共振连接性矩阵进行分类。此外，我们的目标是解决这个背景下的黑箱问题，使用两种可视化方法。首先，类激活图显示了我们的模型在进行分类时关注的大脑功能连接。其次，通过分析隐藏层的最大激活，我们还能够探索该模型如何组织一个大型的混合中心数据集，发现它将隐藏层的特定区域用于处理不同的数据协变量（取决于所分析的自变量），以及其他混合不同来源数据的领域。我们的研究发现，区分ASD和TD对照的深度学习模型主要集中在颞叶和小脑连接，尤其是右尾状核和中央旁沟。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07874">PDF</a>
<h3>No. 83	统计学习技术在儿童阻塞性睡眠呼吸暂停中的应用</h3><h4>Emily T. Winn, Marilyn Vazquez, Prachi Loliencar, Kaisa Taipale, Xu Wang, Giseon Heo</h4>摘要：儿童阻塞性睡眠呼吸暂停症约影响1-5%的小学生，并可能导致其他有害的健康问题。快速的诊断和治疗对孩子的成长和发展至关重要，但症状的多样性和现有数据的复杂性使这成为一个挑战。我们通过关注调查问卷和颅面测量的廉价数据，在简化这一过程中迈出了第一步。在探索性数据分析过程中，我们应用了相关网络、拓扑数据分析中的映射算法和奇异值分解。然后，我们应用各种有监督和无监督的学习技术，从统计、机器学习和拓扑，从支持向量机到贝叶斯分类器和流形学习。最后，我们分析了每种方法的结果，并讨论了向前移动的多数据源算法的含义。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07873">PDF</a>
<h3>No. 84	基于高斯过程的安全临界系统参数在线估计</h3><h4>Mouhyemen Khan, Abhijit Chatterjee</h4>文摘：参数估计是复杂动态系统建模、跟踪和控制的关键。然而，在依赖于标称参数值的控制器下，参数不确定性会影响系统性能。通常情况下，参数是用数值回归方法作为反问题来估计的。然而，由于存在多个局部最优解、对梯度的依赖、大量的实验数据或稳定性问题，它们具有非唯一性。针对这些缺点，我们提出了一个基于高斯过程（GPs）的贝叶斯优化框架，用于在线参数估计。它在参数空间中对响应曲面使用一种有效的搜索策略来寻找具有最小函数估计的全局最优解。利用GPs在噪声数据上建立响应面相关代理模型。利用GP后验预测方差进行智能自适应采样。这平衡了勘探与开发之间的权衡，这是在有限的预算下达到全球最优的关键。我们在一个驱动的平面摆上演示了我们的技术，并在改变参数的模拟中演示了安全临界四旋翼。我们还使用内点法和序列二次规划将结果与求解器进行了比较。通过迭代地用新的优化参数重新配置控制器，我们大大改善了系统相对于标称情况和其他解算器的轨迹跟踪。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07870">PDF</a><h2>2020-02-20</h2>
<h3>No. 1	论对抗性范例防御的自适应攻击</h3><h4>Florian Tramer, Nicholas Carlini, Wieland Brendel, Aleksander Madry</h4>摘要：适应性攻击已经（理所当然地）成为评估对抗性例子防御的事实标准。然而，我们发现，典型的适应性评估是不完整的。我们证明，最近在ICLR、ICML和NeurIPS上发表的13种防御措施——为了说明和教学目的而选择的——尽管尝试使用自适应攻击进行评估，但可以被规避。先前的评估论文主要关注的是最终结果——表明防御是无效的——而本文则侧重于阐述执行自适应攻击所需的方法和途径。我们希望这些分析能为如何正确地针对对抗性的例子进行适应性攻击提供指导，从而使社区在建立更健壮的模型方面取得进一步进展。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08347">PDF</a>
<h3>No. 2	Schoenberg-Rao距离：基于熵和几何感知的统计Hilbert距离</h3><h4>Gaëtan Hadjeres, Frank Nielsen</h4>文摘：在机器学习中，考虑样本空间几何结构的概率分布之间的距离，如Wasserstein距离或最大平均差（MMD）距离，受到了广泛的关注，因为它们可以用来比较不相交支持下的概率分布。本文研究了一类统计Hilbert距离，我们称之为Schoenberg-Rao距离，这是MMD的一个推广，它允许我们考虑一类更广泛的核，即条件负半定核。特别地，我们引入了一种构造此类核的原则性方法，并推导了高斯分布混合物之间的新的闭合形式距离。这些距离由凹Rao的二次熵导出，具有很好的理论性质，并具有可解释的超参数，可根据具体应用进行调整。我们的方法是Wasserstein距离的一种实用替代方法，并且我们在许多机器学习任务上证明了它的有效性，如密度估计、生成建模和混合简化。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08345">PDF</a>
<h3>No. 3	神经结构：识别用于训练先验稀疏网络的理想拓扑</h3><h4>Mihailo Isakov, Michel A. Kinsy</h4>摘要：深层神经网络训练时间长是机器学习研究的瓶颈。快速训练的主要障碍是密集层和卷积层的存储和计算需求相对于其信息带宽的二次增长。最近，训练“先验”稀疏网络被提出作为一种允许层保持高信息带宽，同时保持低内存和低计算的方法。然而，在这些网络中应该使用哪种稀疏拓扑结构还不清楚。本工作为层间拓扑结构的选择提供了理论基础。首先，我们推导了一个新的稀疏神经网络初始化方案，它允许我们探索非常深的稀疏网络的空间。接下来，我们评估了几个拓扑，并表明看似相似的拓扑通常在可达到的精度上有很大的差异。为了解释这些差异，我们开发了一种无数据启发式算法，它可以独立于网络将要训练的数据集来评估拓扑。然后，我们得到一组要求，这些要求构成一个好的拓扑，并得到一个满足所有这些要求的单一拓扑。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08339">PDF</a>
<h3>No. 4	基于变形真值和插补反馈的去噪自编码多重插补</h3><h4>Haw-minn Lu (1), Giancarlo Perrone (1), José Unpingco (1) ((1) Gary and Mary West Health Institute)</h4>摘要：虽然数据可能很丰富，但由于缺少列或行，完整的数据就不那么丰富了。这种缺失会破坏下游数据产品的性能，这些产品要么忽略不完整的情况，要么创建派生的完整数据以供后续处理。为了充分利用和正确使用数据，需要适当地管理丢失的数据。我们提出了一个多重插补模型，利用去噪自编码器来学习数据的内部表示。此外，我们还利用变形真值和插补反馈的新机制来保持属性的统计完整性并消除学习过程中的偏差。我们的方法探索了插补对各种缺失机制和缺失数据模式的影响，在许多标准测试案例中优于其他方法。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08338">PDF</a>
<h3>No. 5	价值驱动的事后模型</h3><h4>Arthur Guez, Fabio Viola, Théophane Weber, Lars Buesing, Steven Kapturowski, Doina Precup, David Silver, Nicolas Heess</h4>摘要：价值评估是强化学习范式的重要组成部分。如何有效地从数据中学习价值预测是RL界研究的主要问题之一，不同的方法以不同的方式利用问题域的结构。模型学习可以利用观测序列中丰富的过渡结构，但这种方法通常对报酬函数不敏感。相比之下，无模型方法直接利用未来的兴趣量，但必须与潜在的弱标量信号（回报的估计）组合。本文提出了一种介于这两个极端之间的RL表示学习方法：我们提出用一种能直接帮助价值预测的方法来学习建模。为此，我们确定未来轨迹的哪些特征为预测相关收益提供了有用的信息。这为我们提供了与任务直接相关的可处理的预测目标，从而可以加速价值函数的学习。这个想法可以理解为事后诸葛亮的推理，关于未来观察的哪些方面可以帮助过去的价值预测。我们展示了即使在简单的策略评估设置中，这也能极大地帮助您。然后我们在具有挑战性的领域中测试我们的方法，包括57个Atari2600游戏。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08329">PDF</a>
<h3>No. 6	基于变分编码器的可靠分类</h3><h4>Chitresh Bhushan, Zhaoyuan Yang, Nurali Virani, Naresh Iyer</h4>摘要：机器学习模型提供了统计上令人印象深刻的结果，这些结果可能是个别不可靠的。为了提供可靠性，我们提出了一个认知分类器（EC），该分类器可以利用训练数据集的支持和重建质量来证明其信念。我们的方法是基于改进的变分自动编码器，它可以识别语义上有意义的低维空间，其中感知上相似的实例在$ell_2$-距离内也很接近。结果表明，与基于softmax阈值的基线方法相比，该方法提高了对抗性攻击样本预测和鲁棒识别的可靠性。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08289">PDF</a>
<h3>No. 7	图神经网络回归的结果相关性</h3><h4>Junteng Jia, Austin Benson</h4>文摘：在训练过程中，图形神经网络利用对标记顶点的监督，在顶点邻域中聚集特征，学习所有顶点的矢量表示。然后，预测器是向量表示的函数，并且在未标记的节点上独立地进行预测。这种被广泛采用的方法隐含地假设顶点标签在对其邻域进行条件化之后是独立的。我们证明，这种强假设在许多真实的图形数据集上是不正确的，并且严重限制了对一些回归任务的预测能力。鉴于传统的基于图的半监督学习方法通过显式地建模预测结果中的相关性而以相反的方式操作，这种限制可能并不令人惊讶。在这里，我们用一个简单且可解释的框架来解决这个问题，该框架可以通过在回归结果残差中建模相关结构来改进任何图神经网络结构。具体地说，我们使用参数化的多元高斯模型来模拟顶点上的结果残差的联合分布，其中参数是通过最大化观测标签的边缘似然来估计的。我们的模型极大地提高了图神经网络的性能，并且学习到的参数也可以解释为连接顶点之间的关联强度。为了使我们能够扩展到大型网络，我们设计了基于随机跟踪估计的低方差无偏模型参数估计的线性时间算法。我们还提供了我们的方法的一个简化版本，它对相关结构做出了更有力的假设，但是非常容易实现，并且在一些情况下提供了很好的实际性能。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08274">PDF</a>
<h3>No. 8	分子注意变压器</h3><h4>Łukasz Maziarka, Tomasz Danel, Sławomir Mucha, Krzysztof Rataj, Jacek Tabor, Stanisław Jastrzębski</h4>文摘：设计一种单一的神经网络结构，在一系列分子性质预测任务中具有竞争力，这在很大程度上仍是一个开放的挑战，其解决方案可能会在药物研发行业中开启深度学习的广泛应用。为了实现这一目标，我们提出了分子注意力变压器（MAT）。我们的主要创新是利用原子间距离和分子图结构来增强变压器的注意机制。实验表明，MAT在一系列不同的分子预测任务上具有竞争力。最重要的是，通过简单的自我监督预训练，MAT只需要调整几个超参数值，就可以在下游任务上获得最先进的性能。最后，我们证明了MAT学习到的注意权重可以从化学的角度来解释。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08264">PDF</a>
<h3>No. 9	背包内蒸馏修剪</h3><h4>Yonathan Aflalo, Asaf Noy, Ming Lin, Itamar Friedman, Lihi Zelnik</h4>文摘：神经网络剪枝减少了过参数化网络的计算量，提高了网络的效率。常用的方法有$\ell 1$-范数稀疏化和神经结构搜索（NAS）。在这项工作中，我们提出了一种新的剪枝方法，优化了剪枝网络的最终精度，并从过度参数化的父网络的内层提取知识。为了实现这种方法，我们将网络剪枝作为一个背包问题，优化神经元重要性与其相关计算成本之间的权衡。然后在保持网络高层结构的同时对网络信道进行剪枝。修剪后的网络在父网络的监督下利用其内部网络知识进行微调，我们称之为内部知识蒸馏技术。我们的方法可以在ImageNet、CIFAR-10和CIFAR-100上使用ResNet主干得到最新的修剪结果。为了剪除复杂的网络结构，如具有跳跃链接的卷积和深度卷积，我们提出了一种块分组方法来处理这些结构。通过这一点，我们产生了与EfficientNet-B0和MobileNetV3相同的触发器的紧凑架构，但精确度更高，在ImageNet上分别为$1\%$和$0.3\%$，在GPU上运行更快。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08258">PDF</a>
<h3>No. 10	从局部对比解释中学习全局透明模型</h3><h4>Tejaswini Pedapati, Avinash Balakrishnan, Karthikeyan Shanmugam, Amit Dhurandhar</h4>文摘：关于复杂模型的局部点对点对比/反事实解释的文献越来越多。这些方法强调了证明分类正确和/或产生改变最终分类的对比点的重要性。其他的工作试图通过使用数据进行有效的模型搜索，或者通过使用类似于蒸馏的方法从复杂模型传输信息，直接构建决策树和规则列表等全局可解释的模型。尽管这些可解释的全局模型可能有用，但它们可能与所选择的特定复杂模型的局部解释不一致。在这项工作中，我们探讨了这样一个问题：我们能否产生一个透明的、与局部解释一致/可由局部解释导出的全局模型？基于一个关键的见解，我们提出了一种新的方法，使得每一个局部对比/反事实解释都可以转化为布尔特征。这些布尔特征是二值化特征的稀疏连接。这样构造的数据集与设计的局部解释是一致的，可以在其上训练决策树这样的可解释模型。我们注意到，这种方法由于只依赖于稀疏的局部解释而严格地丢失了信息，然而，我们从经验上证明，在许多情况下，它仍然可以在复杂模型的性能和直接从原始数据集学习的其他方法方面具有竞争力。我们的方法还提供了一种以量化方式对本地解释方法进行基准测试的途径。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08247">PDF</a>
<h3>No. 11	带Bandit反馈的乐观策略优化</h3><h4>Yonathan Efroni, Lior Shani, Aviv Rosenberg, Shie Mannor</h4>摘要：策略优化方法是应用最广泛的一类强化学习算法。然而，到目前为止，这些方法大多是从优化的角度进行分析的，没有解决探索的问题，也没有对与环境的相互作用作出强有力的假设。本文考虑了具有未知跃迁和bandit反馈的表格式有限层位MDP设置中基于模型的RL。对于这种情况，我们提出了一个乐观信任域策略优化（TRPO）算法，我们为随机报酬建立了$tilde O（\sqrt{S^2a H^4k}）$遗憾。此外，我们还证明了$tilde O（\sqrt{S^2 A H^4}K^{2/3}）$对于对抗性奖励的后悔。有趣的是，这个结果与先前为bandit反馈情况导出的边界相匹配，但具有已知的转换。就我们所知，这两个结果是第一次得到的子线性后悔界，对于未知的转移和bandit反馈的策略优化算法。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08243">PDF</a>
<h3>No. 12	工业4.0预测维修综述</h3><h4>Christian Krupitzer (1), Tim Wagenhals (2), Marwin Züfle (1), Veronika Lesch (1), Dominik Schäfer (3), Amin Mozaffarin (4), Janick Edinger (2), Christian Becker (2), Samuel Kounev (1) ((1) University of Würzburg, Würzburg, Germany, (2) University of Mannheim, Mannheim, Germany, (3) Syntax Systems GmbH, Weinheim, Germany, (4) MOZYS Engineering GmbH, Würzburg)</h4>摘要：2016年，大众汽车的生产问题导致每周高达4亿欧元的销售大幅亏损。这个例子显示了一个工作生产设施对公司的巨大财务影响。尤其是在工业4.0和工业物联网（带智能连接机器）的数据驱动领域，传统的静态维护计划似乎过时了。本文综述了工业4.0预测维修技术的发展现状。在结构化文献调查的基础上，我们提出了工业4.0背景下预测性维修的分类，并讨论了这一领域的最新发展。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08224">PDF</a>
<h3>No. 13	SYMOG：学习对称混合高斯模以改进不动点量化</h3><h4>Lukas Enderich, Fabian Timm, Wolfram Burgard</h4>摘要：深度神经网络（DNNs）已被证明在几种机器学习基准上优于经典方法。然而，它们的计算复杂度很高，需要强大的处理单元。尤其是在嵌入式系统上部署时，模型的大小和推理时间必须大大减少。我们提出对称高斯模混合（symo），通过低比特定点量化显著降低DNNs的复杂度。SYMOG是一种新的软量化方法，它能同时解决学习任务和量化问题。在训练过程中，权值分布由单峰高斯分布变为对称的高斯混合分布，其中每个平均值属于一个特定的不动点模式。我们在公共基准数据集（MNIST、CIFAR-10、CIFAR-100）上用不同的架构（LeNet5、VGG7、VGG11、DenseNet）评估我们的方法，并与最新的量化方法进行比较。我们在CIFAR-10和CIFAR-100上分别获得了5.71%和27.65%的错误率，取得了优异的结果并优于2位最新性能。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08204">PDF</a>
<h3>No. 14	空中联合学习：无人机群联合功率分配与调度</h3><h4>Tengchan Zeng, Omid Semiari, Mohammad Mozaffari, Mingzhe Chen, Walid Saad, Mehdi Bennis</h4>摘要：无人机群体必须利用机器学习技术来完成从协调航迹规划到协同目标识别等多种任务。然而，由于无人机群和地面基站（BSs）之间缺乏连续的连接，使用集中式ML将是一项挑战，特别是在处理大量数据时。本文提出了一种新的无人机群结构来实现分布式联邦学习算法。随后的每一架无人机根据其收集的数据训练一个本地飞行模型，然后将该训练的本地模型发送给领先的无人机，后者将汇总接收的模型，生成一个全局飞行模型，并通过群内网络将其发送给跟随者。为了确定由风和机械振动引起的衰落、传输延迟和无人机天线角度偏差等无线因素如何影响FL的性能，对FL进行了严格的收敛性分析。在此基础上，提出了一种联合功率分配与调度的设计方案，以优化FL的收敛速度，同时考虑到收敛过程中的能量消耗和群控制系统的延迟要求。仿真结果验证了FL收敛性分析的有效性，表明联合设计策略与基线设计相比，可以减少收敛所需的通信轮数35%。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08196">PDF</a>
<h3>No. 15	利用后见之明在持续学习中巩固过去的知识</h3><h4>Arslan Chaudhry, Albert Gordo, Puneet K. Dokania, Philip Torr, David Lopez-Paz</h4>摘要：在持续学习中，学习者面对的是一个数据流，其分布随时间而变化。众所周知，现代神经网络在这种情况下会受到影响，因为它们很快就会忘记以前获得的知识。为了解决这种灾难性遗忘，许多连续学习方法实现了不同类型的经验重放，即对存储在称为情景记忆的小缓冲区中的过去数据进行再学习。在这项工作中，我们用一个新的目标来补充经验回放，我们称之为锚定，学习者使用双层优化来更新当前任务的知识，同时保持对过去任务的某些锚定点的预测不变。这些锚定点是通过基于梯度的优化来学习的，以最大化遗忘，这是通过微调当前训练的模型对过去任务的情节记忆来近似的。对几种有监督的连续学习学习基准的实验表明，我们的方法在准确度和遗忘度以及不同大小的情景记忆方面都提高了标准经验重放。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08165">PDF</a>
<h3>No. 16	卷积语音识别模型综合内省的梯度调整神经元激活谱</h3><h4>Andreas Krug, Sebastian Stober</h4>摘要：基于深度学习的自动语音识别（ASR）模型非常成功，但难以解释。为了更好地理解人工神经网络（ann）是如何完成其任务的，人们提出了内省方法。将这种技术从计算机视觉应用到语音识别并非一帆风顺，因为语音数据比图像数据更复杂，解释性也更低。在这项工作中，我们引入梯度调整的神经元激活轮廓（GradNAPs）来解释深部神经网络的特征和表示。梯度是神经网络对特定输入组的特征性反应，它包含了神经元对预测的相关性。我们将展示如何利用渐变来了解如何在ann中处理数据。这包括可视化特征的不同方式和梯度的聚类，以比较给定网络的任何层中不同输入组的嵌入。我们使用一个完全卷积的ASR模型来演示我们提出的技术。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08125">PDF</a>
<h3>No. 17	所有形状和大小的随机平滑</h3><h4>Greg Yang, Tony Duan, Edward Hu, Hadi Salman, Ilya Razenshteyn, Jerry Li</h4>摘要：随机平滑是最近提出的一种对抗攻击的防御方法，它对$ell_2$扰动具有最先进的可证明鲁棒性。不久之后，许多工作为其他度量设计了新的随机平滑方案，例如$\ell 1$或$\ell infty$；但是，对于每个几何体，都需要大量的工作来获得新的稳健性保证。这就引出了一个问题：我们能找到随机平滑的一般理论吗？本文提出了一种新的随机平滑方案设计与分析框架，并在实际应用中验证了其有效性。我们的理论贡献如下：（1）证明了对于一个适当的“最优”概念，任何“nice”范数的最优平滑分布都具有由该范数的*Wulff晶体*给出的水平集。（2） 我们提出了两种新的互补方法来推导任意光滑分布的可证明鲁棒半径。最后，利用Banach空间同型态理论，给出了当前随机平滑技术的基本极限。通过结合（1）和（2），我们显著提高了标准数据集上$ell_1$的最新认证精度。另一方面，利用（3），我们表明，在随机输入扰动下，如果没有比标签统计更多的信息，当输入维数$d$较大时，随机平滑无法获得针对$\ell\infty$-norm$\Omega（1/\sqrt d）$扰动的非平凡认证精度。我们在github.com/tonyduan/rs4a中提供代码。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08118">PDF</a>
<h3>No. 18	分层量化自动编码器</h3><h4>Will Williams, Sam Ringer, Tom Ash, John Hughes, David MacLeod, Jamie Dougherty</h4>摘要：尽管神经网络在有损图像压缩方面的训练取得了进展，但目前的方法不能在很低的比特率下保持感知质量和高层次特征。由于最近在矢量量化变分自编码（VQ-VAEs）中学习离散表示的成功，我们鼓励使用VQ-VAEs的层次来获得高压缩因子。我们证明了量化和层次潜在结构的结合有助于基于似然的图像压缩。这使得我们引入了一个更具概率性的VQ-VAE框架，而之前的工作是一个极限情况。我们的层次结构产生了一系列马尔可夫的潜在变量，这些变量可以重建保留语义意义特征的高质量图像。这些延迟可以进一步用于生成真实的样本。我们对CelebA和MNIST数据集的重建和样本进行定性和定量评估。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08111">PDF</a>
<h3>No. 19	随机图上的神经网络</h3><h4>Romuald A. Janik, Aleksandra Nowak</h4>文摘：我们对神经网络进行了大规模的评估，其结构对应于各种类型的随机图。除了经典的随机图族（包括随机图、无标度图和小世界图）外，我们提出了一种新的、灵活的直接生成随机有向无环图（DAG）的算法，并研究了一类由函数静息状态fMRI网络导出的图。大多数表现最好的网络确实是在这些新家庭中。我们还提出了一个将图转化为前馈神经网络所必需的DAG的一般过程。我们研究了图的各种结构和数值特性与神经网络测试精度的关系。由于经典的数值图不变量本身似乎不允许挑选出最佳网络，我们引入了新的数值特征，选择了一组准一维图，这些图是性能最好的网络中的大多数。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08104">PDF</a>
<h3>No. 20	学习线性二次调节器的对数遗憾</h3><h4>Asaf Cassel (1), Alon Cohen (2), Tomer Koren (1) ((1) School of Computer Science, Tel Aviv University, (2) Google Research, Tel Aviv)</h4>文摘：研究了过渡参数初始未知的线性二次型控制系统的学习问题。最近在这方面的研究结果已经证明了有效的学习算法，并且遗憾地随着决策步骤数的平方根的增长而增长。我们提出了新的有效算法，在两种情况下，当只有状态转移矩阵$A$未知，当只有状态作用转移矩阵$B$未知，且最优策略满足一定的非简并条件时，可能令人惊讶地实现了仅随步数对数缩放（poly）。另一方面，我们给出了一个下界，它表明当违反后一个条件时，平方根遗憾是不可避免的。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08095">PDF</a>
<h3>No. 21	解剖神经节律</h3><h4>Stefano Massaroli, Michael Poli, Jinkyoo Park, Atsushi Yamashita, Hajime Asama</h4>摘要：连续的深度学习结构最近重新出现作为神经常微分方程（Neural ods）的变体。这些模型提供的无限深度方法在理论上弥合了深度学习和动态系统之间的鸿沟；然而，破译它们的内部工作仍然是一个开放的挑战，它们的大多数应用目前仅限于作为通用黑盒模块的包含。在这项工作中，我们“开箱”并提供了一个系统理论的观点，包括状态增强策略和鲁棒性，目的是澄清几个设计选择对底层动力学的影响。我们还介绍了新的体系结构：其中，Galerkin启发的深度变化参数模型和具有数据控制向量场的神经网络节点。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08071">PDF</a>
<h3>No. 22	符号梯度下降几何</h3><h4>Lukas Balles, Fabian Pedregosa, Nicolas Le Roux</h4>文摘：基于符号的优化方法由于其在分布式优化中具有良好的通信代价和在神经网络训练中令人惊讶的良好性能，在机器学习中得到了广泛的应用。此外，它们与Adam等所谓的自适应梯度方法密切相关。最近关于signSGD的工作使用了一个非标准的“可分离平滑度”假设，而一些较老的工作研究符号梯度下降作为相对于$\ell\infty$-范数的最陡下降。在这项工作中，我们通过显示可分离光滑性和$\ell\infty$-光滑性之间的密切联系来统一这些现有的结果，并认为后者是较弱且更自然的假设。然后，我们继续研究相对于$\ell\infty$-范数的平滑常数，从而分离出影响基于符号的方法性能的目标函数的几何性质。简而言之，如果（i）Hessian在某种程度上集中在其对角线上，并且（ii）其最大特征值远大于平均特征值，则基于符号的方法优于梯度下降法。这两种特性在深层网络中都很常见。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08056">PDF</a>
<h3>No. 23	部分标签学习中真标签的渐进识别</h3><h4>Jiaqi Lv, Miao Xu, Lei Feng, Gang Niu, Xin Geng, Masashi Sugiyama</h4>摘要：部分标签学习是一个重要的弱监督学习问题，每个训练实例都有一组包含真实标签的候选标签。现有的大多数方法都将学习目标精心设计为必须以特定方式解决的约束优化，这使得它们的计算复杂性成为扩展到大数据的瓶颈。本文的目的是提出一种新的无隐式模型假设或优化算法的局部标号学习框架。更具体地说，我们提出了分类风险的一般估计，从理论上分析了分类一致性，并建立了估计误差界。然后，我们探索了一种渐进辨识方法来近似最小化所提出的风险估计器，其中模型的更新和真实标签的辨识是以无缝的方式进行的。所得算法与模型无关，与损失无关，且与随机优化相容。深入的实验证明它开创了新的艺术境界。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08053">PDF</a>
<h3>No. 24	通过在无监督域自适应中增加一个额外的类来扩大区分能力</h3><h4>Hai H. Tran, Sumyeong Ahn, Taeyoung Lee, Yung Yi</h4>文摘：本文研究了无监督域自适应问题，目的是利用源域的有标记数据和目标域的无标记数据建立目标域的预测模型。基于特征提取的思想，近年来出现了一系列的研究，这些特征不仅对两个领域都具有不变性，而且对目标领域也具有很高的识别能力。本文提出了一种增强区分能力的思想：加入一个新的人工类，并结合新类的GAN生成样本对数据进行模型训练。基于新类样本的训练模型能够通过在目标域中重新定位当前类的数据，从而更有效地提取出判别性更强的特征，从而绘制出决策边界。我们的思想是高度通用的，因此与许多现有的方法如DANN、VADA和DIRT-T兼容。我们对用于评估无监督域自适应的标准数据进行了各种实验，并证明我们的算法在许多情况下都达到了SOTA性能。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08041">PDF</a>
<h3>No. 25	通过政策转移实现有效的深度强化学习</h3><h4>Tianpei Yang, Jianye Hao, Zhaopeng Meng, Zongzhang Zhang, Weixun Wang, Yujing Hu, Yingfeng Cheng, Changjie Fan, Zhaodong Wang, Jiajie Peng</h4>摘要：迁移学习（TL）利用以往学习到的相关任务策略中的先验知识，在促进强化学习（RL）方面显示出巨大的潜力。现有的传输方法要么显式计算任务之间的相似性，要么选择适当的源策略为目标任务提供指导性的探索。然而，如何通过交替地利用来自适当源策略的知识而不显式地度量相似度来直接优化目标策略，目前还缺少。本文利用这一思想，提出了一种新的策略转移框架（PTF）来加速RL。我们的框架通过将多策略转移建模为选项学习问题，来学习何时和哪一个源策略是对目标策略最好的重用，以及何时终止它。PTF可以很容易地与现有的深RL方法相结合。实验结果表明，无论是在离散的还是连续的行为空间中，它都显著地加快了学习过程，并且在学习效率和最终性能方面都超过了最新的策略转移方法。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08037">PDF</a>
<h3>No. 26	一个固定的观点：基于模型的聚类框架</h3><h4>Jianhao Ding, Lansheng Han</h4>摘要：随着数据的膨胀，聚类分析作为无监督学习的一个分支，对其数学规律缺乏统一的认识和应用。本文从不动点的观点出发，重新阐述了基于模型的聚类方法，提出了一个统一的聚类框架。为了寻找不动点作为聚类中心，该框架迭代地构造了压缩映射，有力地揭示了算法的收敛机制和算法之间的相互联系。通过指定一个压缩映射，高斯混合模型（GMM）可以作为一个应用映射到框架。我们希望这个不动点框架能帮助我们设计未来的聚类算法。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08032">PDF</a>
<h3>No. 27	图卷积网络中通过毒害邻域的间接对抗攻击</h3><h4>Tsubasa Takahashi</h4>摘要：图卷积神经网络是一种在相邻节点上学习聚集的神经网络，在节点分类任务中取得了良好的性能。然而，最近的研究表明，这种图卷积节点分类器会被图上的对抗性扰动所欺骗。滥用图卷积，一个节点的分类结果可能会受到毒害其邻居的影响。给定一个属性图和一个节点分类器，我们如何评估这种间接对抗攻击的鲁棒性？我们能否产生强大的对抗性扰动，这种扰动不仅对一跳邻居有效，而且对离目标更远的邻居有效？在本文中，我们证明了节点分类器可以通过毒害距离目标较远的一个节点甚至两个跳或更远的节点而被高置信度欺骗。为了实现攻击，我们提出了一种新的方法，它只在远离目标的单个节点上搜索较小的扰动。在我们的实验中，我们提出的方法在两个数据集中，在距离目标两个跳的范围内，攻击成功率达到99%。我们还证明了m层图卷积神经网络有机会被我们在m跳邻居中的间接攻击所欺骗。所提出的攻击可作为未来防御尝试的基准，以开发具有对手鲁棒性的图形卷积神经网络。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08012">PDF</a>
<h3>No. 28	对随机盗贼的操作攻击：攻击与防御</h3><h4>Guanlin Liu, Lifeng lai</h4>文摘：由于随机多臂bandit模型的广泛应用，了解敌方攻击的影响，设计对攻击具有鲁棒性的bandit算法是该模型安全应用的关键。本文介绍了一种新的攻击类型，即操作攻击。在此攻击中，对手可以更改用户选择的动作信号。结果表明，在不知道武器平均回报的情况下，我们提出的攻击只需花费对数代价，就可以操纵广泛使用的bandit算法UCB（Upper Confidence Bound）。为了防御这类攻击，我们提出了一种新的算法，在给定攻击总代价的上界时，该算法对操作操作攻击具有鲁棒性。我们证明了我们的算法有一个伪后悔上界$\mathcal{O}（\max{\log T，a}）$，其中$T$是总轮数，$a$是总攻击代价的上界。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08000">PDF</a>
<h3>No. 29	具有子集选择的随机效用模型的最优项学习</h3><h4>Aadirupa Saha, Aditya Gopalan</h4>文摘：我们考虑了PAC从n$个项目池中学习最有价值的项目的问题，使用k$个项目子集的顺序、自适应选择的播放，当播放子集时，学习者接收根据一般随机效用模型（RUM）采样的相对反馈，该模型对潜在项目效用具有独立的噪声扰动。我们确定了这种RUM的一个新性质，称为最小优势，它有助于根据项目对的相对盈亏经验计数来描述项目对分离的复杂性，并且可以仅作为噪声分布的函数来限定。我们给出了一个基于项目的成对相对计数和层次消去的通用RUMs学习算法，以及一个新的PAC样本复杂度保证$O（\frac{n}{c^2\epsilon^2}\log\frac{k}{delta}）$轮来识别一个$\epsilon$-具有置信度$1-\delta$的最优项目，当RUM中的最坏情况成对优势对项目的参数间隙具有至少$c$的敏感度时。PAC样本复杂度的基本下界表明，就其对$n、k$和$c$的依赖性而言，这是接近最优的。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07994">PDF</a>
<h3>No. 30	梯度增强神经网络：GrowNet</h3><h4>Sarkhan Badirli, Xuanqing Liu, Zhengming Xing, Avradeep Bhowmik, Sathiya S. Keerthi</h4>文摘：提出了一种新的梯度增强框架，该框架采用浅层神经网络作为弱学习者。在此统一框架下考虑了一般损失函数，并给出了分类、回归和学习排序的具体实例。为了弥补经典梯度提升决策树贪心函数逼近的缺陷，引入了一个完全修正步骤。该模型在多个数据集上完成了所有这三个任务。进行了消融研究，揭示了各模型成分和模型超参数的影响。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07971">PDF</a>
<h3>No. 31	关于范畴概率的贝叶斯</h3><h4>Taejong Joo, Uijung Chung, Min-Gwan Seo</h4>文摘：神经网络在分类任务中以软极大值为基础，存在过度自信问题，缺乏不确定性表示能力。作为softmax的贝叶斯替代，我们考虑了类标签上的一个分类概率随机变量。在这个框架中，先验分布显式地对观察到的标签中固有的假定噪声进行建模，从而在多个具有挑战性的任务中提供一致的泛化性能增益。该方法继承了贝叶斯方法的优点，可以获得更好的不确定性估计和模型校正。与带交叉熵损失函数的softmax相比，我们的方法可以实现为一个即插即用损失函数，计算开销可以忽略不计。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07965">PDF</a>
<h3>No. 32	时序图的归纳表示学习</h3><h4>Da Xu, Chuanwei Ruan, Evren Korpeoglu, Sushant Kumar, Kannan Achan</h4>摘要：时间图归纳表示学习是面向现实动态网络的可销售机器学习的重要一步。时态动态图的演化本质要求处理新的节点以及捕获时态模式。节点嵌入现在是时间的函数，它应该同时表示静态节点特征和演化的拓扑结构。此外，节点和拓扑特征也可以是时态的，节点嵌入还应该捕获其模式。我们提出时间图注意（TGAT）层来有效地聚集时间拓扑邻域特征以及学习时间特征之间的相互作用。对于TGAT，我们以自关注机制为基础，在经典Bochner谐波分析定理的基础上，提出了一种新的函数时间编码技术。通过叠加TGAT层，该网络将节点嵌入识别为时间函数，并能随着图的演化归纳出新节点和观测节点的嵌入。该方法同时处理节点分类和链路预测任务，并且可以自然地扩展到包含时间边缘特征。在两个基准和一个工业数据集的时间背景下，我们对我们的方法进行了评估。我们的TGAT模型与目前最先进的基线以及之前的时间图嵌入方法相比具有优势。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07962">PDF</a>
<h3>No. 33	梯度元强化学习课程</h3><h4>Bhairav Mehta, Tristan Deleu, Sharath Chandra Raparthy, Chris J. Pal, Liam Paull</h4>摘要：基于梯度的元学习者，如模型不可知元学习（MAML）在有监督和强化学习环境中表现出了很强的少镜头学习性能。然而，特别是在元强化学习（meta-RL）的情况下，我们可以证明基于梯度的元学习者对任务分布非常敏感。在错误的课程设置下，代理人会受到元过度适应、浅适应和适应不稳定的影响。在这项工作中，我们首先强调基于梯度的元RL的有趣的失败案例，并表明任务分布可以广泛地影响算法的输出、稳定性和性能。为了解决这个问题，我们利用最近关于领域随机化的文献中的见解，提出了元主动领域随机化（meta-ADR），它学习基于梯度的meta-RL的任务课程，类似于ADR学习sim2real转移。结果表明，该方法在各种模拟的移动和导航任务上能产生更稳定的策略。我们对分布内和分布外的泛化进行了评估，发现即使在非结构化任务空间中，学习到的任务分布也大大提高了MAML的自适应性能。最后，我们激发了meta-RL中更好的基准测试的需求，该基准测试优先于单个任务的适应性能。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07956">PDF</a>
<h3>No. 34	个性化联合学习：一种元学习方法</h3><h4>Alireza Fallah, Aryan Mokhtari, Asuman Ozdaglar</h4>摘要：联邦学习的目标是设计多个代理以隐私保护的方式与一个中心节点通信的算法，以最小化它们的平均损失函数。在这种方法中，每个节点不仅共享所需的计算预算，而且可以访问更大的数据集，从而提高了生成模型的质量。然而，这种方法只为所有代理开发一个公共输出，因此不能使模型适应每个用户的数据。这是一个重要的缺失特性，特别是考虑到不同代理的底层数据分布的异构性。在本文中，我们研究了一种个性化的联邦学习变体，我们的目标是以分布式的方式找到一个共享的初始模型，该模型可以由当前用户或新用户通过对其自身的损失函数执行一步或几步梯度下降来稍微更新。这种方法保留了联邦学习体系结构的所有优点，同时为每个用户带来了更个性化的模型。我们证明这个问题可以在模型不可知元学习（MAML）框架下进行研究。受此启发，我们提出了一个著名的联邦平均算法的个性化变体，并用非凸损失函数的梯度范数来评估其性能。此外，我们还描述了用户数据的基本分布的紧密性如何影响这种性能，这些分布是根据分布距离（如总变差和1-Wasserstein度量）来测量的。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07948">PDF</a>
<h3>No. 35	具有深生成先验的源分离</h3><h4>Vivek Jayaram, John Thickstun</h4>摘要：尽管在信号源分离方面取得了实质性进展，但对于结构丰富的数据，其结果仍然包含可感知的伪影。相比之下，最近的深度生成模型可以在不同的域中生成真实的样本，这些域与数据分布的样本无法区分。本文介绍了一种基于贝叶斯方法的信源分离方法，该方法以生成模型作为信源混合物成分的先验，并利用Langevin动态系统对给定混合物的信源后验分布进行采样。这将源分离问题与生成模型分离开来，使我们能够直接使用最新的生成模型作为优先级。该方法实现了MNIST数字分离的最新性能。介绍了在较丰富数据集上评价分离质量的新方法，给出了在CIFAR-10上对分离结果的定量评价。我们还提供了关于LSUN的定性结果。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07942">PDF</a>
<h3>No. 36	用神经网络权值控制标签噪声信息提高泛化能力</h3><h4>Hrayr Harutyunyan, Kyle Reing, Greg Ver Steeg, Aram Galstyan</h4>摘要：在有噪声或错误标签的情况下，神经网络具有记忆噪声信息的不良倾向。标准的正则化技术，如辍学、体重衰减或数据增加，有时会有帮助，但不能阻止这种行为。如果将神经网络权值视为依赖于训练数据和随机性的随机变量，则可以用权值与给定输入的所有训练标签向量之间的Shannon互信息来量化记忆信息量，$I（w:\ mathbf{y}\mid\mathbf{x}）。我们证明，对于任何训练算法，这个项的低值对应于标签噪声记忆的减少和更好的泛化界。为了获得这些低值，我们提出了训练算法，该算法使用一个辅助网络，在不访问标签的情况下预测分类器最后一层的梯度。我们在MNIST、CIFAR-10和CIFAR-100的不同版本上以及在一个有噪声标签的大数据集Clothing1M上说明了我们的方法的有效性。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07933">PDF</a>
<h3>No. 37	基于变分LSTM网络的短期交通流预测</h3><h4>Mehrdad Farahani, Marzieh Farahani, Mohammad Manthouri, Okyay Kaynak</h4>摘要：交通流特性是一个地区最重要的决策和交通警务因素之一。对交通流预测状态的认识在交通管理和交通信息部门具有重要意义。本研究的目的是提出一个基于历史资料的深度学习交通流量预测模型。2019年从Caltrans绩效测量系统（PeMS）收集的6个月历史数据。所提出的预测模型是一个变分的长短期存储器编码器，与其它常规方法相比，VLSTM-E试图准确估计流量。VLSTM-E可以考虑分布和缺失值，提供更可靠的短期交通流。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07922">PDF</a>
<h3>No. 38	块交换：一种用于深度学习安全的随机方法</h3><h4>Xiao Wang, Siyue Wang, Pin-Yu Chen, Xue Lin, Peter Chin</h4>摘要：近年来对抗性攻击的研究揭示了现代深度学习模型的脆弱性。也就是说，精心设计的输入扰动可以使经过训练的高精度网络产生任意的错误预测，同时保持对人类视觉系统的不可察觉性。本文介绍了一种基于随机性的对抗攻击防御策略——块交换（BS）。BS用多个并行信道替换一个模型层块，而活动信道在运行时被随机分配，因此不可预测。实验结果表明，与随机激活剪枝（SAP）等随机防御方法相比，BS具有更分散的输入梯度分布和更好的防御效果。与其他防御相比，BS还具有以下特点：（i）BS导致较少的测试精度下降；（ii）BS独立于攻击，并且（iii）BS与其他防御兼容，可以与其他防御联合使用。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07920">PDF</a>
<h3>No. 39	信息浓缩主动学习</h3><h4>Siddhartha Jain, Ge Liu, David Gifford</h4>文摘：介绍了一种针对深度贝叶斯主动学习的批处理模式不可知主动学习方法，即信息凝聚主动学习法，该方法着重于获取尽可能多的关于未知点的信息。ICAL使用Hilbert-Schmidt独立性准则（HSIC）来度量候选批点与未标记集之间的依赖强度。我们开发了关键优化，使我们能够将我们的方法扩展到大型未标记集。我们在模型精度和负对数似然（NLL）方面与目前最先进的深度学习批处理模式AL方法相比有了显著的改进。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07916">PDF</a>
<h3>No. 40	自监督主动域随机化自动生成课程</h3><h4>Sharath Chandra Raparthy, Bhairav Mehta, Florian Golemo, Liam Paull</h4>文摘：目标定向强化学习（RL）传统上是考虑一个与环境交互的agent，给一个agent规定一个与某个目标的完成成比例的实值奖励。目标导向的RL由于易于重用或通过提出目标生成新体验，在样本效率方面有了很大的提高。在这项工作中，我们建立在自我游戏的框架上，允许一个代理与自己交互，以便在一些未知的任务上取得进展。我们使用主动领域随机化和自我游戏来创建一个新颖的、耦合的环境目标课程，在该课程中，代理通过逐步增加的困难任务和环境变化来学习。我们的方法，自我监督的主动领域随机化（SS-ADR），产生了一个不断增长的课程，鼓励代理人尝试超出其当前能力的任务，同时建立一个领域随机化课程，使最先进的结果对各种简单的转移任务。我们的研究结果显示，一个环境困难与在每个环境中设定的目标的困难共同演变的课程，在测试目标导向的任务中提供了实际的好处。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07911">PDF</a>
<h3>No. 41	原因：使用归因方法从事件序列中学习Granger因果关系</h3><h4>Wei Zhang, Thomas Kobber Panum, Somesh Jha, Prasad Chalasani, David Page</h4>文摘：研究了从异步、相互依存、多类型的事件序列中学习事件类型之间格兰杰因果关系的问题。现有的研究要么是模型的灵活性有限，要么是模型的可解释性差，因此无法揭示具有不同事件相关性的各种事件序列之间的Granger因果关系。为了解决这些缺点，我们提出了一个新的研究任务框架CAUSE（事件序列归因的因果关系）。因果关系的核心思想是先通过拟合神经点过程隐式地捕捉潜在的事件相关性，然后用公理化的归因方法从过程中提取Granger因果关系统计。在充满不同事件相关性的多个数据集中，我们证明CAUSE在一系列最新方法上正确推断类型间Granger因果关系方面取得了优异的性能。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07906">PDF</a>
<h3>No. 42	基于超图的实证政策评估</h3><h4>Daniel Vial, Vijay Subramanian</h4>文摘：设计并分析了强化学习中的经验策略评价问题的算法。我们的算法从高成本状态向后探索以找到高价值状态，而不是从所有状态向前探索。虽然有几篇论文已经从经验上证明了反向探索的实用性，但是我们进行了严格的分析，结果表明我们的算法可以将平均案例样本复杂度从$O（S\logs）$降低到$O（\logs）$。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07905">PDF</a>
<h3>No. 43	深度变换与度量学习网络：深度字典学习与神经网络的结合</h3><h4>Wen Tang, Emilie Chouzenoux, Jean-Christophe Pesquet, Hamid Krim</h4>文摘：字典学习及其相关的稀疏优化问题由于在推理任务和去噪应用方面取得了许多成功，引起了广泛的研究兴趣。虽然大多数解决方案都集中在单层字典上，但最近提出的改进的Deep DL（DDL）方法在一些问题上也有不足。在此，我们提出了一种新的DDL方法，其中每个DL层可以表示为一个线性层和一个递归神经网络（RNN）的组合。RNN灵活地解释了相关层和学习度量。我们提出的工作揭示了对神经网络和DDL的新见解，并提供了一种新的、有效的和有竞争力的方法来共同学习深度转换和推理应用的度量。通过大量的实验证明，该方法不仅可以优于现有的DDL算法，而且可以获得最新的通用CNNs。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07898">PDF</a>
<h3>No. 44	一种具有零阶自然梯度下降的高效黑盒敌手查询方法</h3><h4>Pu Zhao, Pin-Yu Chen, Siyue Wang, Xue Lin</h4>文摘：尽管现代深神经网络（DNNs）取得了巨大的成就，但目前最先进的DNNs的脆弱性和鲁棒性在许多需要高可靠性的应用领域引起了人们的安全关注。为了破坏DNN模型的学习性能，提出了各种对抗性攻击。其中，黑盒对抗攻击方法以其实用性和简单性受到了特别的关注。黑盒攻击通常倾向于较少的查询，以保持隐蔽性和低成本。然而，目前的黑盒攻击方法大多采用一阶梯度下降法，可能存在收敛速度慢、对超参数设置敏感度高等缺点。本文提出了一种零阶自然梯度下降（ZO-NGD）方法来设计对抗性攻击，该方法结合了针对黑箱攻击场景的零阶梯度估计技术和二阶自然梯度下降技术，以获得更高的查询效率。对图像分类数据集的实证评估表明，ZO-NGD与目前最先进的攻击方法相比，能够获得显著降低的模型查询复杂度。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07891">PDF</a>
<h3>No. 45	一个宽层金字塔拓扑深网络的全局收敛性</h3><h4>Quynh Nguyen, Marco Mondelli</h4>文摘：最近的一系列研究为梯度下降算法在过度参数化的情况下提供了收敛保证，在这种情况下，所有隐层的宽度都要求在训练样本数中多项式地大。然而，实际的深度网络的宽度往往只在第一层较大，然后开始向输出层减小。这就提出了一个有趣的开放性问题：在这种经验相关的背景下，类似的结果是否也成立。现有的理论观点表明，这类网络的损耗面表现良好，但这些结果通常不能为优化提供直接的算法保证。在本文中，我们通过证明一个宽层后接一个金字塔深网络拓扑足以使梯度下降找到一个具有几何速率的全局最小值来缩小这一差距。我们的证明基于Polyak-Lojasiewicz不等式的一个弱形式，它适用于全秩权矩阵流形中的深金字塔网络。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07867">PDF</a>
<h3>No. 46	数值模拟中的学习相似度量</h3><h4>Georg Kohl, Kiwon Um, Nils Thuerey</h4>文摘：提出了一种基于神经网络的方法来计算稳定的广义度量（LSiM），以比较各种数值模拟源的现场数据。我们的方法采用了暹罗网络结构，该结构是由度量的数学特性驱动的。我们利用带有偏微分方程（PDE）解算器的可控数据生成设置，从受控环境中的参考仿真创建越来越不同的输出。我们学习的度量的一个核心部分是一个专门的损失函数，它将有关单个数据样本之间相关性的知识引入到训练过程中。为了证明所提出的方法在向量空间和其他基于图像的学习度量方面优于现有的简单度量，我们在大量测试数据上评估了不同的方法。此外，我们还分析了泛化的好处以及可调训练数据难度的影响。通过对三个真实数据集的评估，证明了LSiM的鲁棒性。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07863">PDF</a>
<h3>No. 47	本地SGD比小批量SGD好吗？</h3><h4>Blake Woodworth, Kumar Kshitij Patel, Sebastian U. Stich, Zhen Dai, Brian Bullins, H. Brendan McMahan, Ohad Shamir, Nathan Srebro</h4>文摘：研究了一种自然的、常用的随机分布优化方法局部SGD（又称并行SGD和联邦平均）。它的理论基础目前缺乏，我们强调如何在现有的错误保证在凸设置主要由一个简单的基线，小批量SGD。（1） 对于二次型目标，我们证明了局部SGD严格控制小批量SGD，并且加速局部SGD对于二次型是最小极大最优的；（2）对于一般凸目标，我们提供了至少有时比小批量SGD改进的第一个保证；（3）我们证明了局部SGD确实不控制小批量SGD低于小批量SGD保证的本地SGD性能下限。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07839">PDF</a>
<h3>No. 48	多步模型不可知元学习：收敛性与改进算法</h3><h4>Kaiyi Ji, Junjie Yang, Yingbin Liang</h4>摘要：模型不可知元学习（MAML）算法作为一种流行的元学习方法，因其简单有效而得到了广泛的应用。然而，一般多步MAML的收敛性仍有待进一步研究。本文提出了一个新的理论框架，在此框架下，我们描述了多步MAML的收敛速度和计算复杂度。结果表明，虽然随机元梯度的估计偏差和方差包含指数因子$N$（内阶梯度更新次数），但在适当选择内阶步长的情况下，当复杂度仅随$N$线性增加时，MAML仍能达到收敛。然后，我们采取进一步的步骤，以开发一个更有效的无黑森MAML。我们首先证明了现有的零阶Hessian估计包含一个恒定的水平估计误差，因此MAML算法可以执行不稳定。针对这一问题，我们提出了一种新的基于梯度的高斯平滑的Hessian估计方法，并证明了该方法具有更小的估计偏差和方差，并且在温和的条件下得到了与原始MAML相同的性能保证。我们的实验验证了我们的理论，并证明了所提出的Hessian估计的有效性。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07836">PDF</a>
<h3>No. 49	核流神经网络内层的深度正则化和直接训练</h3><h4>Gene Ryan Yoo, Houman Owhadi</h4>文摘：提出了一种基于核流的人工神经网络正则化方法。在回归/克里格算法中，KFs是一种基于将随机批数据中的插值点数减半而导致的精度损失最小化的核选择方法。正在为ANN的组成结构的函数表示编写$f{（n）}{\theta{n}\circ f{（n-1）}{\theta{n-1}\circ f{（1）}\circ f{\theta{1}\big）（x）$，h^{（i）}（x）-h^{（i）}（x'）\|u 2^2）$。当与一批数据集相结合时，这些内核产生KF损失$e^2^{（i）}$（使用该批的任意一半预测另一半而产生的$L^2$回归误差），这取决于内层的参数$\theta 1、\ldots、\theta i$（和$\gamma i$）。所提出的方法只是将这些KF损失的一个子集与一个经典的输出损失相加。在不改变结构和输出分类器的情况下，我们在CNNs和WRNs上测试了所提出的方法，并报告了在不显著增加计算复杂度的情况下，减少了测试误差、减小了泛化间隙和增强了对分布移位的鲁棒性。我们怀疑，这些结果可能是由以下事实解释的：虽然传统训练只使用数据集定义的经验分布的线性函数（广义矩），并且容易陷入神经切线核区域（在过度参数化的情况下），所提出的损失函数（定义为经验分布的非线性函数）有效地训练CNN定义的底层核，而不是用该核对数据进行回归。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08335">PDF</a>
<h3>No. 50	基于强化学习的个性化产品智能选配装配</h3><h4>Caterina Neef, Dario Luipers, Jan Bollenbacher, Christian Gebel, Anja Richert</h4>摘要：个性化制造作为满足消费者日益多样化、个性化的需求和期望的一种手段，正成为一种重要的途径。虽然制造过程的实施有多种解决方案，例如添加剂制造，但随后的自动化装配仍然是一项具有挑战性的任务。作为解决这一问题的一种方法，我们旨在通过实施强化学习，教一个协作机器人成功地执行拣选和放置任务。对于在不断变化的制造环境中装配个性化产品，模拟的几何参数和动力学参数会发生变化。利用元学习的强化学习算法，首先对任务进行模拟训练。然后，它们将在真实环境中执行，其中引入了新的因素，这些因素在训练中没有模拟，以确认算法的稳健性。机器人将从触觉传感器、区域扫描摄像机和用于生成环境和物体高度图的三维摄像机获取输入数据。本文的工作包括机器学习算法和硬件组件的选择，以及实现上述生产场景的进一步研究问题。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08333">PDF</a>
<h3>No. 51	福克斯：保护个人隐私，防止未经授权的深度学习模式</h3><h4>Shawn Shan, Emily Wenger, Jiayun Zhang, Huiying Li, Haitao Zheng, Ben Y. Zhao</h4>摘要：如今，功能强大的面部识别模型层出不穷，对个人隐私构成了真正的威胁。正如Clearview.ai所展示的，任何人都可以在互联网上寻找数据，并在不知情的情况下训练我们高度精确的面部识别模型。我们需要一些工具来保护自己免受未经授权的面部识别系统及其无数潜在误用的侵害。不幸的是，相关领域的工作在实用性和有效性方面受到限制。在这篇文章中，我们提出福克斯，一个系统，允许个人接种自己的未经授权的面部识别模型。福克斯通过帮助用户在在线发布照片之前，在自己的照片中添加不可察觉的像素级变化（我们称之为“斗篷”）来实现这一点。当被第三方“追踪器”收集并用于训练面部识别模型时，这些“隐形”图像生成的功能模型会持续错误地识别用户。实验证明，无论追踪器如何训练模型，福克斯都能提供95%以上的用户识别保护。即使当干净的、未被屏蔽的图像被“泄露”到跟踪器并用于训练时，福克斯仍然可以保持80%以上的保护成功率。事实上，我们对当今最先进的面部识别服务进行了真正的实验，并取得了100%的成功。最后，我们展示了福克斯对各种试图探测或破坏斗篷的反制措施的鲁棒性。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08327">PDF</a>
<h3>No. 52	基于时态GPU脉动阵列积分的DNN加速度平衡效率与灵活性</h3><h4>Cong Guo, Yangjie Zhou, Jingwen Leng, Yuhao Zhu, Zidong Du, Quan Chen, Chao Li, Minyi Guo, Bin Yao</h4>文摘：深神经网络专用硬件加速器由于其优越的性能和效率，近年来引起了人们的研究兴趣。然而，今天的DNN加速器主要关注于加速特定的“核”，如卷积和矩阵乘法，它们是端到端DNN应用程序的关键但只是一部分。在整个应用程序中有意义的加速通常需要支持计算，这些计算虽然大量并行，但不适合DNN加速器。集成通用处理器（如CPU或GPU）会产生大量的数据移动开销，并导致DNN加速器上的资源利用率不足。我们提出了同步多模式架构（SMA），这是一种新的架构设计和执行模型，它在DNN加速器上提供通用的可编程性，以加速端到端的应用。SMA的关键是收缩执行模型和类GPU的SIMD执行模型的时间集成。SMA利用了脉动阵列加速器和GPU之间共享的公共组件，并提供了在两种模式之间就地切换的轻量级重新配置能力。SMA的性能提高高达63%，同时比采用TensorCore的基本Volta架构能耗低23%。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08326">PDF</a>
<h3>No. 53	2020年网络安全人工智能研讨会论文集</h3><h4>Dennis Ross, Arunesh Sinha, Diane Staheli, Bill Streilein</h4>摘要：本次研讨会将集中讨论人工智能在网络安全问题上的应用。AICS 2020的重点将放在网络安全问题背景下的人机合作上，并将特别探索人类操作员与人工智能技术之间的合作。研讨会将讨论人工智能的应用领域，如机器学习、博弈论、自然语言处理、知识表示、自动和辅助推理以及人机交互。此外，网络安全应用领域，特别强调人机协作的特征和部署将是重点。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08320">PDF</a>
<h3>No. 54	基于度量嵌入和最优传输的不一致分布距离</h3><h4>Mokhtar Z. Alaya, Maxime Bérar, Gilles Gasso, Alain Rakotomamonjy</h4>文摘：我们提出了一种新的方法来比较支持度不一定在同一度量空间上的分布。与Gromov-Wasserstein（GW）距离不同，我们考虑了一种将度量度量空间嵌入公共欧氏空间并计算嵌入分布上的最优传输（OT）的方法。这就产生了我们所说的子嵌入健壮Wasserstein（SERW）。在某些条件下，SERW是一个距离，它考虑了使用公共度量的（低失真）嵌入分布的OT距离。除了这一概括了最近几项OT工作的新建议外，我们的贡献还基于几个理论分析：i）我们刻画了嵌入空间来定义用于分布对齐的SERW距离；ii）我们证明了SERW模拟了几乎相同的GW距离的性质，并且我们给出了GW和SERW之间的成本关系。本文还提供了一些数值实验来说明SERW在实际匹配问题中的行为。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08314">PDF</a>
<h3>No. 55	后门DNNs的广谱靶向治疗</h3><h4>Akshaj Kumar Veldanda, Kang Liu, Benjamin Tan, Prashanth Krishnamurthy, Farshad Khorrami, Ramesh Karri, Brendan Dolan-Gavitt, Siddharth Garg</h4>文摘：提出了一种新的针对后门神经网络（BadNet s）的两级防御（NNoculation），它不同于现有防御，对后门触发器的形状、大小和位置以及BadNet的功能作了最小的假设。在预部署阶段，NNoculation使用从干净的验证集提取的输入的“广谱”随机扰动来重新训练网络，以部分减少后门的对抗性影响。在部署后阶段，NNoculation通过记录原始和部署前修补网络之间的分歧来检测和隔离后门测试输入。然后训练CycleGAN学习干净验证输入和隔离输入之间的转换；也就是说，它学习向干净验证图像添加触发器。这组经过转换的后门验证图像及其正确的标签被用于进一步重新训练BadNet，从而产生我们的最终防御。当攻击者绕过限制性假设时，NNoculation的性能优于我们所展示的最先进的神经清洁和人工大脑模拟（ABS）。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08313">PDF</a>
<h3>No. 56	多小波残差密集卷积神经网络图像去噪</h3><h4>Shuo-Fei Wang, Wen-Kai Yu, Ya-Xin Li</h4>摘要：近年来，具有大接收场（RF）的网络显示出了更高的拟合能力。在这项工作中，我们利用短期残差学习方法来改善网路对于影像去噪工作的效能与稳健性。在这里，我们选择了一个多小波卷积神经网络（MWCNN）作为骨干网络，它是一个具有大RF的最新网络之一，并在其每一层中插入剩余密集块（rdb）。我们称之为多小波残差密集卷积神经网络（MWRDCNN）。与其他基于RDB的网络相比，它可以从相邻层中提取更多的目标特征，保留较大的RF，提高计算效率。同时，这种方法也提供了在一个网络中吸收多个体系结构的优点而不发生冲突的可能性。该方法的性能已在大量实验中得到验证，并与现有技术进行了比较。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08301">PDF</a>
<h3>No. 57	MLModelScope：一个大规模的模型评估和基准测试的分布式平台</h3><h4>Abdul Dakkak, Cheng Li, Jinjun Xiong, Wen-mei Hwu</h4>摘要：机器学习（ML）和深度学习（DL）的创新正以如此之快的速度被引入，以至于研究人员很难对它们进行分析和研究。评估创新的复杂过程，以及缺乏标准和有效的方法来指定和提供ML/DL评估，是社区的一个主要“痛点”。本文提出了MLModelScope，这是一个开源的、框架/硬件无关的、可扩展的和可定制的设计，它支持可重复的、公平的和可伸缩的模型评估和基准测试。我们实现了支持所有主要框架和硬件的分布式设计，并为其配备了web、命令行和库接口。为了演示MLModelScope的功能，我们执行并行评估，并展示对模型评估管道的细微更改如何影响准确性，以及软硬件堆栈选择如何影响性能。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08295">PDF</a>
<h3>No. 58	当放射科报告生成遇到知识图时</h3><h4>Yixiao Zhang, Xiaosong Wang, Ziyue Xu, Qihang Yu, Alan Yuille, Daguang Xu</h4>文摘：近年来，为了减轻医生的工作量，放射科报告的自动生成一直是计算机辅助诊断领域的研究热点。自然图像字幕的深度学习技术已成功地应用于生成放射学报告。然而，放射学图像报告与自然图像字幕任务在两个方面有所不同：1）与自然图像字幕中每个单词的同等重要性相比，在放射学图像报告中，阳性疾病关键词提及的准确性至关重要；2）报告质量的评估应更侧重于匹配疾病关键字及其相关属性，而不是计算N-gram的发生率。基于这些考虑，我们建议在多个疾病发现上使用预先构建的图嵌入模块（用图卷积神经网络建模）来辅助报告的生成。知识图的合并允许对每个疾病发现和它们之间的关系建模进行专门的特征学习。此外，我们还提出了一个新的评估指标，以帮助放射影像报告的同一组成图。实验结果表明，与传统的图像字幕评价方法和我们提出的方法相比，在可公开访问的胸片数据集（IU-RR）上集成图形嵌入模块的方法具有更好的性能。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08277">PDF</a>
<h3>No. 59	部分Gromov-Wasserstein及其在正无标记学习中的应用</h3><h4>Laetitia Chapel, Mokhtar Z. Alaya, Gilles Gasso</h4>摘要：最优传输（OT）框架允许定义概率分布之间的相似性，并提供诸如Wasserstein和Gromov-Wasserstein差异等度量。经典OT问题寻求一个保持总质量的运输图，要求源和目标分布的质量相同。在某些应用中，例如颜色或形状匹配中，这可能限制太多，因为分布可能具有任意质量，或者只需要运输总质量的一小部分。已经设计了一些算法来计算非平衡Wasserstein度量，但是当涉及Gromov-Wasserstein问题时，还没有部分公式可用。这就排除了使用不在同一度量空间中的分布或需要对旋转或平移保持不变性的情况。本文针对部分Gromov-Wasserstein问题，提出了一种求解该问题的算法。我们在一个积极的无标签（PU）学习应用程序中展示了新的公式。据我们所知，这是本文中最优传输的第一个应用，我们首先强调基于Wasserstein的部分度量在通常的PU学习环境中证明是有效的。然后我们证明了部分Gromov-Wasserstein度量在点云来自不同领域或具有不同特征的情况下是有效的。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08276">PDF</a>
<h3>No. 60	多logue网：一种用于会话中多模态情感检测和情感分析的上下文感知RNN</h3><h4>Aman Shenoy, Ashish Sardana</h4>摘要：会话中的情感分析和情感检测是许多实际应用中的关键，不同的应用利用不同的数据来实现合理准确的预测。多模态情感检测和情感分析特别有用，因为应用程序将能够根据可用数据使用可用模式的特定子集，以生成相关预测。当前处理多模态功能的系统无法通过所有模式、对话中的当前说话者和听众以及通过适当的融合机制可用模式之间的相关性和关系来利用和捕获对话的上下文。在本文中，我们提出了一个递归神经网络架构，它试图考虑到上述所有的缺点，并跟踪对话的上下文、对话者的状态以及对话者在对话中所表达的情绪。我们提出的模型在两个基准数据集上对各种精度和回归度量进行了最新的测试。我们的模型实现是公开的，可以在github.com/amanshenoy/multilogue-net上找到<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08267">PDF</a>
<h3>No. 61	基于矩域自适应的学习界</h3><h4>Werner Zellinger, Bernhard A Moser, Susanne Saminger-Platz</h4>文摘：针对训练数据较少的目标领域，设计了一种领域自适应算法，通过对训练数据较多的源领域的模型进行自适应，最大限度地降低了判别模型的误分类风险。标准方法基于源域和目标域中经验概率分布之间的距离度量来度量适应差异。在这一背景下，我们讨论了在面向实践的一般条件下，关于潜在概率分布的学习界的推导问题。结果，我们得到了基于有限多个矩和光滑条件的域自适应学习界。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08260">PDF</a>
<h3>No. 62	用于微调的深网络基于距离的正则化</h3><h4>Henry Gouk, Timothy M. Hospedales, Massimiliano Pontil</h4>文摘：我们研究了深度神经网络微调过程中的正则化方法。首先，我们提供一个基于Rademacher复杂度的神经网络泛化界，它使用权重从初始值移动的距离。当应用于卷积网络时，这个界不直接依赖于权值的数目，并且与其他界相比是有利的。我们的界限与微调高度相关，因为提供基于转移学习的良好初始化的网络意味着学习可以较少地修改权重，从而实现更严格的泛化。受此启发，我们开发了一个简单而有效的微调算法，将假设类约束在一个以初始预训练权重为中心的小球体上，从而获得比传统转移学习更好的泛化性能。实验结果表明，我们的算法运行良好，验证了我们的理论结果。它不仅优于最先进的微调竞争对手，而且我们展示的基于惩罚的替代方案也不直接限制搜索空间的半径。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08253">PDF</a>
<h3>No. 63	研讨会报告：深入学习海洋生物声学的检测和分类</h3><h4>Fabio Frazao, Bruno Padovese, Oliver S. Kirsebom</h4>摘要：2019年11月21日至22日，约30名研究人员齐聚加拿大不列颠哥伦比亚省维多利亚市，参加由MERIDIAN组织、加拿大海洋网络主办的“海洋生物声学深度学习中的检测和分类”研讨会。来自加拿大海岸和美国的海洋生物学家、数据科学家和计算机科学家出席了研讨会，他们代表了包括大学、政府（加拿大渔业和海洋局、国家海洋和大气管理局）、工业（JASCO应用科学公司、谷歌，Axiom数据科学）和非营利组织（Orcasound，OrcaLab）。包括口头陈述、公开讨论和实践指导，研讨会项目为来自不同领域的专家提供了一个难得的机会，他们可以就深度学习及其在水声探测和分类算法发展方面的潜力进行交流。在本研讨会报告中，我们总结了演讲和讨论会的要点。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08249">PDF</a>
<h3>No. 64	洗牌型梯度法的统一收敛性分析</h3><h4>Lam M. Nguyen, Quoc Tran-Dinh, Dzung T. Phan, Phuong Ha Nguyen, Marten van Dijk</h4>文摘：针对机器学习中常用的有限和极小化问题，给出了一类洗牌型梯度法的统一收敛性分析。该算法包括各种变体，如随机重新洗牌、单洗牌和循环/增量梯度方案。我们考虑两种不同的情形：强凸和非凸问题。我们的主要贡献包括一类求解非凸和强凸问题的一般洗牌型梯度方法的新的非渐近和渐近收敛速度。虽然我们在非凸问题中的速率是新的（即在标准假设下还不知道），但是在强凸情况下的速率（直到常数）匹配最著名的结果。然而，与此方向的现有工作不同，我们仅使用平滑性和强凸性等标准假设。最后，我们通过一个非凸logistic回归和神经网络实例来实证说明学习率的影响。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08246">PDF</a>
<h3>No. 65	量子统计查询学习</h3><h4>Srinivasan Arunachalam, Alex B. Grilo, Henry Yuen</h4>文摘：我们提出了一种量子统计学习QSQ模型，它将Kearns引入的SQ学习模型推广到量子环境中。我们的模型也可以看作是量子PAC学习模型的一个限制：在这里，学习者不能直接访问量子示例，只能获得它们的测量统计估计。理论上，这个模型提供了一个简单而富有表现力的环境来探索量子例子在机器学习中的威力。从实际的角度来看，由于需要更简单的操作，QSQ模型中的学习算法更适合在近期量子器件上实现。我们证明了QSQ学习模型的一些结果。我们首先证明了奇偶函数（log n）-juntas和多项式大小的DNF公式在QSQ模型中是有效可学习的，与经典的难以证明的情形相比。这意味着量子PAC学习的许多优点甚至可以在更受限的量子SQ学习模型中实现。众所周知，用WSQDIM（C）表示的弱统计查询维数表征了经典SQ模型中C类概念学习的复杂性。我们证明了log（WSQDIM（C））是QSQ学习复杂性的一个下界，而且对于某些概念类C是紧的。此外，我们还证明了这个量为积分布下的小偏差量子通信模型提供了强下界。最后，我们引入了私有量子PAC学习的概念，其中量子PAC学习者必须是差异私有的。我们证明了QSQ模型中的可学习性意味着量子私有PAC模型中的可学习性。此外，我们还证明在私有PAC学习环境中，经典和量子样本的复杂度是相等的，直到常数因子。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08240">PDF</a>
<h3>No. 66	求解非线性扩散系数和Biot方程的物理信息神经网络</h3><h4>Teeratorn Kadeethum, Thomas M Jorgensen, Hamidreza M Nick</h4>文摘：介绍了应用物理信息神经网络解决生物医学工程、地震预报、地下能量采集等领域所必需的非线性多物理问题的潜力。具体地说，我们研究如何扩展物理信息神经网络的方法来求解非线性扩散系数和Biot方程的正问题和反问题。研究了不同训练样本大小和超参数选择下的物理信息神经网络的精度。研究了不同训练实现方式之间随机变化的影响。在相反的情况下，我们还研究了噪声测量的影响。此外，我们还讨论了选择逆模型超参数的挑战，并说明了如何将此挑战与为正向模型选择超参数联系起来。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08235">PDF</a>
<h3>No. 67	学习公平评分函数：公平定义、算法和二部排序的推广界</h3><h4>Robin Vogel, Aurélien Bellet, Stéphan Clémençon</h4>摘要：人工智能的许多应用，从信用贷款到通过累犯预测设计医疗诊断支持工具，都涉及到使用其属性的学习函数对个体进行评分。这些预测风险得分用于对一组人进行排序，和/或根据得分是否超过某个阈值（可能取决于所做决策的上下文）对他们进行个人决策。授予这种制度的授权程度将在很大程度上取决于如何回答公平问题。虽然这种关注在分类设置中得到了很多关注，但是针对学习评分函数的公平约束设计问题却没有得到太多的研究。本文针对二元标记数据的评分问题，提出了一种灵活的群体公平性方法，这是一种称为二元排序的标准学习任务。我们认为，ROC曲线的功能性质，即衡量排名绩效的金标准，导致了制定公平约束的几种可能方法。在二部排序中引入了一般的公平条件类，并建立了在这种约束下学习的评分规则的推广界。在理论公式和结果的基础上，我们设计了实用的学习算法，并通过数值实验说明了我们的方法。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08159">PDF</a>
<h3>No. 68	基于贝叶斯算术编码的可变比特率神经压缩</h3><h4>Yibo Yang, Robert Bamler, Stephan Mandt</h4>摘要：深度贝叶斯潜在变量模型为模型和数据压缩提供了新的途径。在这里，我们提出了一种新的算法来压缩后处理中的深层概率模型中的潜在表示，例如变分自编码。因此，该方法将模型设计和训练从压缩任务中分离出来。我们的算法将算术编码推广到连续域，使用自适应离散化精度，利用后验不确定性估计。我们方法的“即插即用”性质的一个结果是，可以通过一个单一的训练模型来实现各种速率失真的权衡，从而消除了为不同比特率训练多个模型的需要。我们的实验结果证明了考虑后验不确定性的重要性，并且表明，在仅使用一个机器学习模型的情况下，使用该算法的图像压缩在很大的比特率范围内优于JPEG。进一步的贝叶斯神经单词嵌入实验证明了该方法的通用性。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08158">PDF</a>
<h3>No. 69	基于互信息神经估计的隐式模型贝叶斯实验设计</h3><h4>Steven Kleinegesse, Michael U. Gutmann</h4>摘要：隐式随机模型是自然科学中普遍存在的一种模型，它的数据生成分布是不易处理的，但抽样是可能的。这些模型通常有自由参数，需要从科学实验收集的数据中推断出来。一个基本的问题是如何设计实验，使收集到的数据最有用。贝叶斯实验设计领域主张，理想情况下，我们应该选择最大化数据和参数之间相互信息（MI）的设计。然而，对于隐式模型，这种方法受到计算后验和最大化MI的高计算成本的严重阻碍，特别是当我们有多个设计变量需要优化时。本文提出了一种新的隐式模型贝叶斯实验设计方法，利用神经MI估计的最新进展来解决这些问题。我们证明，训练一个神经网络以使MI的下界最大化，可以让我们共同决定最优设计和后验。仿真研究表明，该方法将隐式模型的贝叶斯实验设计扩展到更高的设计维度。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08129">PDF</a>
<h3>No. 70	带语言偏差的Rnn变换器在汉英语码转换语音识别中的应用</h3><h4>Shuai Zhang, Jiangyan Yi, Zhengkun Tian, Jianhua Tao, Ye Bai</h4>文摘：近年来，人们利用语言身份信息来提高端到端码转换（CS）语音识别的性能。然而，以往的研究多采用附加的语言识别（LID）模型作为辅助模块，导致系统复杂。在这项工作中，我们提出了一个改进的带有语言偏差的递归神经网络转换器（RNN-T）模型来缓解这个问题。利用语言恒等式对模型进行偏误预测。这促进了该模型直接从转录中学习语言身份信息，不需要额外的LID模型。我们对一个汉英CS语料库seam进行了评价。与我们的RNN-T基线相比，该方法在两个测试集上的相对误差分别降低了16.2%和12.9%。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08126">PDF</a>
<h3>No. 71	BB U疏散：基于快速位置敏感行为的建筑物疏散</h3><h4>Subhra Mazumdar, Arindam Pal, Francesco Parisi, V.S. Subrahmanian</h4>摘要：过去关于疏散计划的工作假设疏散人员会遵守指示——然而，有充分的证据表明情况并非如此。有些人会按照指示行事，有些人则会按照自己的意愿行事。本文给出了一个基于行为的疏散问题（BBEP）的形式化定义，其中在规划疏散时考虑了人的行为模型。我们证明了一种特定形式的约束可以用来表达这种行为。我们证明，bbep可以通过一个称为BB_-IP的整数程序精确求解，而通过一个称为BB_-Evac的更快的算法则可以精确求解。我们对两种应用于建筑物的算法进行了详细的实验评估（尽管原则上算法可以应用于任何图形），并表明后者比BB_IP快一个数量级，同时在一个真实的建筑物图形和几个综合的建筑物图形上产生的结果几乎一样好生成的图表。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08114">PDF</a>
<h3>No. 72	走向低成本、稳定的区块链网络</h3><h4>Minghong Fang, Jia Liu</h4>摘要：区块链网络被认为是分布式系统的未来，近年来受到了业界和学术界越来越多的关注。然而，区块链开采过程消耗大量能源，研究表明，比特币开采消耗的能源量几乎与爱尔兰使用的电力量相同。针对区块链网络的高挖掘能耗问题，提出了一种区块链挖掘资源分配算法，以降低基于PoW（工作证明）的区块链网络的挖掘成本。我们首先对一般的区块链排队模型进行了系统的研究。在我们的排队模型中，事务随机到达队列，并以批处理的方式提供服务，其概率分布未知，对任何优先级机制都不可知。然后，利用Lyapunov优化技术，提出了一种动态挖掘资源分配算法（DMRA），该算法由一个参数$K>0$来参数化。结果表明，该算法在性能延迟上达到了$[O（1/K），O（K）]$的折衷。仿真结果也证明了DMRA在降低采矿成本方面的有效性。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08027">PDF</a>
<h3>No. 73	基于影响函数的数据中毒攻击对Top-N推荐系统的影响</h3><h4>Minghong Fang, Neil Zhenqiang Gong, Jia Liu</h4>文摘：推荐系统是web服务吸引用户的重要组成部分。流行的推荐系统使用大量的众包用户-项目交互数据（如评分）对用户偏好和项目属性进行建模；然后向用户推荐与用户偏好最匹配的顶级-N$项目。在这项工作中，我们证明攻击者可以通过向伪用户注入精心编制的用户项交互数据，向推荐系统发起数据中毒攻击，以根据攻击者的需要提出建议。具体来说，攻击者可以欺骗推荐系统，向尽可能多的普通用户推荐目标项。基于矩阵分解的推荐系统在工业上得到了广泛的应用。考虑到攻击者可以注入的假用户的数量，我们将假用户的评分作为一个优化问题来制定。然而，该优化问题是一个非凸整数规划问题，求解难度很大。为了应对这一挑战，我们开发了几种近似求解优化问题的技术。例如，我们利用影响函数来选择对推荐有影响的正常用户的子集，并基于这些有影响的用户来解决我们提出的优化问题。结果表明，我们的攻击是有效的，并优于现有的方法。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08025">PDF</a>
<h3>No. 74	非自回归对话状态跟踪</h3><h4>Hung Le, Richard Socher, Steven C.H. Hoi</h4>摘要：面向任务对话的对话状态跟踪（DST）研究已经向开放词汇或基于生成的方法发展，在这种方法中，模型可以从对话历史本身生成候选时隙值。这些方法显示了良好的性能增益，特别是在具有动态时隙值的复杂对话域中。然而，它们在两个方面存在不足：（1）它们不允许模型显式地跨域和时隙学习信号，以检测（域、时隙）对之间的潜在依赖性；（2）现有模型遵循自回归方法，当对话在多域和多圈上演化时，会产生较高的时间代价。本文提出了一种新的非自回归对话状态跟踪（NADST）框架，该框架可以考虑域和时隙之间潜在的依赖关系，以优化模型，从而更好地将对话状态预测为一个完整的集，而不是单独的时隙。特别是，我们的方法的非自回归特性不仅使得并行解码能够显著地减少DST的延迟，以便实时生成对话响应，而且还可以检测令牌级别的时隙之间以及时隙和域级别的依赖关系。我们的实验结果表明，我们的模型在MultiWOZ 2.1语料库上实现了跨领域的最新联合精度，并且随着对话历史的延长，我们的模型的延迟比以前的水平低一个数量级。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08024">PDF</a>
<h3>No. 75	基于自适应多尺度集成学习的游客季节趋势预测</h3><h4>Shaolong Suna, Dan Bi, Ju-e Guo, Shouyang Wang</h4>摘要：准确预测旅游者的季节和趋势是一项极具挑战性的任务。鉴于季节性和趋势性预测在旅游客源预测中的重要性，以往的研究工作对其重视不够。在本研究中，我们提出一种新的自适应多尺度集合（AME）学习方法，将变分模式分解（VMD）与最小二乘支援向量回归（LSSVR）相结合，来预测短期、中期及长期的季节及趋势。在我们开发的AME学习方法的公式中，首先将原始的游客到达序列分解为趋势、季节和剩余波动分量。然后利用ARIMA对趋势分量进行预测，SARIMA对12个月周期的季节性分量进行预测，LSSVR对剩余波动分量进行预测。最后，利用基于LSSVR的非线性集合方法，将三个分量的预测结果进行聚合，生成游客到达量的集合预测。此外，采用直接策略进行多步预测。通过两种精度测度和Diebold-Mariano检验，实证结果表明，本文提出的AME学习方法与本研究中使用的其他基准相比，能够获得更高的水平和方向预测精度，这表明我们的方法是一个很有前途的模型，预测游客人数具有很高的季节性和波动性。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08021">PDF</a>
<h3>No. 76	基于局部功率迭代的分布式SVD通信效率</h3><h4>Xiang Li, Shusen Wang, Kun Chen, Zhihua Zhang</h4>文摘：研究了截断奇异值分解（SVD）的分布计算。为了提高通信效率，我们开发了一个称为\texttt{LocalPower}的算法。具体地说，我们在$m$节点之间统一地划分数据集，并在多个（准确地说$p$）局部幂迭代和一个全局聚合之间交替。我们从理论上证明，在某些假设下，texttt{LocalPower}会将所需的通信次数降低$p$一个因子，以达到一定的精度。我们还展示了周期性衰减$p$的策略有助于提高\texttt{LocalPower}的性能。我们进行了实验，以证明\texttt{LocalPower}的有效性。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.08014">PDF</a>
<h3>No. 77	基于游客注意力的旅游需求预测：一种集成的深度学习方法</h3><h4>Shaolong Sun, Yanzhao Li, Shouyang Wang, Ju-e Guo</h4>摘要：大量的旅游相关数据对旅游需求预测提出了一系列挑战，包括数据不足、多重共线性、计算时间长等。为了解决这一问题，提出了一种基于Bagging的多元集成深度学习模型。采用来京游客历史数据、经济指标和游客在线行为变量对四国来京游客进行预测。四个来源国的实证结果表明，我们提出的B-SAKE模型无论在水平精度、方向精度还是统计显著性上都优于基准模型。套袋和叠层自动编码都能提高模型的预测性能。并利用多步超前预报方案对模型的预报性能进行了评价，结果一致。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07964">PDF</a>
<h3>No. 78	基于渐进生长GANs的21cm断层扫描样本生成与参数推断的统一框架</h3><h4>Florian List, Geraint F. Lewis</h4>文摘：考虑到所涉及的天体物理过程的范围和可能要探测的高维参数空间，为一系列再电离历史建立一个21厘米亮度-温度信号的数据库是一项复杂和计算成本高昂的任务。我们使用一种特定类型的神经网络，一种逐步增长的生成对抗网络（PGGAN），在提高采收率期间生成21cm亮度温度的真实层析图像，覆盖一个连续的三维参数空间，该空间模拟不同的X射线发射率、Lyman波段发射率以及硬与软之间的比率X光片。GPU训练的网络以每秒$\sim 3'$的分辨率（在笔记本电脑CPU上）生成新样本，得到的全局21cm信号、功率谱和像素分布函数与21SSD目录{Semelin2017}中的训练数据非常一致。最后，我们展示了如何利用经过训练的PGGAN通过近似贝叶斯计算从21cm断层样本中推断参数。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07940">PDF</a>
<h3>No. 79	局部卷积GAN</h3><h4>Łukasz Struski, Szymon Knop, Jacek Tabor, Wiktor Daniec, Przemysław Spurek</h4>文摘：本文构造了一个完全卷积的GAN模型：LocoGAN，它的潜在空间是由可能不同分辨率的噪声图像给出的。学习是局部的，即我们处理的不是整个噪声图像，而是固定大小的子图像。因此，LocoGAN可以生成任意尺寸的图像，例如LSUN卧室数据集。我们方法的另一个优点来自于我们使用的位置通道，它允许生成完全周期的（例如圆柱全景图像）或几乎周期的、无限长的“图像”（例如墙纸）。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07897">PDF</a>
<h3>No. 80	观测不可辨识性、广义似然与自由能</h3><h4>A.E. Allahverdyan</h4>文摘：研究了具有观测不可辨识性的混合模型的参数估计问题：完全模型（也包含隐变量）是可辨识的，而边际模型（观测）不是可辨识的。因此，边际似然的全局极大值是（无限）退化的，边际似然的预测不是唯一的。我们通过引入一个有效温度，使其与自由能相似，来说明如何推广边际似然。这种推广解决了观测的不可识别性，因为它的最大化导致的唯一结果比边缘似然的一个退化极大值的随机选择或在许多这样的极大值上的平均更好。广义似然方法继承了一般似然方法的许多特点，如它具有条件性原理，通过适当的改进期望最大化方法可以寻找其局部极大值。广义似然最大化与熵优化有关。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07884">PDF</a>
<h3>No. 81	基于深度学习特征的CBIR</h3><h4>Subhadip Maji, Smarajit Bose</h4>摘要：在基于内容的图像检索系统中，任务是从给定查询图像的大型数据库中检索相似图像。通常的步骤是从查询图像中提取一些有用的特征，并检索具有相似特征集的图像。为此，选择一个合适的相似度度量方法，对相似度较高的图像进行检索。当然，这些特征的选择对系统的成功起着非常重要的作用，需要高层次的特征来减少语义鸿沟。在本文中，我们建议使用从为一个大型图像分类问题训练的深度学习卷积网络的预先训练的网络模型中得到的特征。这种方法似乎为各种数据库产生了非常优越的结果，并且它优于许多当代的CBIR系统。我们分析了该方法的检索时间，并提出了一种基于上述特征的数据库预聚类方法，在大多数情况下，在更短的时间内得到了可比的结果。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07877">PDF</a>
<h3>No. 82	自闭症和其他任务中大型、混合位点fMRI数据集的集成深度学习</h3><h4>Matthew Leming, Juan Manuel Górriz, John Suckling</h4>摘要：用于磁共振分类的深度学习模型面临着两个反复出现的问题：它们通常受样本量的限制，并且被自身的复杂性所抽象（“黑箱问题”）。在本文中，我们训练了一个卷积神经网络（CNN），它包含有史以来最大的多源功能磁共振（fMRI）连接组数据集，由43858个数据点组成。我们将此模型应用于自闭症（ASD）与典型发育期（TD）对照的横断面比较，这些对照被证明难以用推论统计来描述。为了将这些发现具体化，我们还对性别和任务与休息进行了分类。利用类平衡建立训练集，我们在一个集成模型中训练了3$乘以300美元的修正CNN，对ASD与TD、性别和任务与休息的总体AUROC分别为0.6774、0.7680和0.9222的功能磁共振连接性矩阵进行分类。此外，我们的目标是解决这个背景下的黑箱问题，使用两种可视化方法。首先，类激活图显示了我们的模型在进行分类时关注的大脑功能连接。其次，通过分析隐藏层的最大激活，我们还能够探索该模型如何组织一个大型的混合中心数据集，发现它将隐藏层的特定区域用于处理不同的数据协变量（取决于所分析的自变量），以及其他混合不同来源数据的领域。我们的研究发现，区分ASD和TD对照的深度学习模型主要集中在颞叶和小脑连接，尤其是右尾状核和中央旁沟。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07874">PDF</a>
<h3>No. 83	统计学习技术在儿童阻塞性睡眠呼吸暂停中的应用</h3><h4>Emily T. Winn, Marilyn Vazquez, Prachi Loliencar, Kaisa Taipale, Xu Wang, Giseon Heo</h4>摘要：儿童阻塞性睡眠呼吸暂停症约影响1-5%的小学生，并可能导致其他有害的健康问题。快速的诊断和治疗对孩子的成长和发展至关重要，但症状的多样性和现有数据的复杂性使这成为一个挑战。我们通过关注调查问卷和颅面测量的廉价数据，在简化这一过程中迈出了第一步。在探索性数据分析过程中，我们应用了相关网络、拓扑数据分析中的映射算法和奇异值分解。然后，我们应用各种有监督和无监督的学习技术，从统计、机器学习和拓扑，从支持向量机到贝叶斯分类器和流形学习。最后，我们分析了每种方法的结果，并讨论了向前移动的多数据源算法的含义。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07873">PDF</a>
<h3>No. 84	基于高斯过程的安全临界系统参数在线估计</h3><h4>Mouhyemen Khan, Abhijit Chatterjee</h4>文摘：参数估计是复杂动态系统建模、跟踪和控制的关键。然而，在依赖于标称参数值的控制器下，参数不确定性会影响系统性能。通常情况下，参数是用数值回归方法作为反问题来估计的。然而，由于存在多个局部最优解、对梯度的依赖、大量的实验数据或稳定性问题，它们具有非唯一性。针对这些缺点，我们提出了一个基于高斯过程（GPs）的贝叶斯优化框架，用于在线参数估计。它在参数空间中对响应曲面使用一种有效的搜索策略来寻找具有最小函数估计的全局最优解。利用GPs在噪声数据上建立响应面相关代理模型。利用GP后验预测方差进行智能自适应采样。这平衡了勘探与开发之间的权衡，这是在有限的预算下达到全球最优的关键。我们在一个驱动的平面摆上演示了我们的技术，并在改变参数的模拟中演示了安全临界四旋翼。我们还使用内点法和序列二次规划将结果与求解器进行了比较。通过迭代地用新的优化参数重新配置控制器，我们大大改善了系统相对于标称情况和其他解算器的轨迹跟踪。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07870">PDF</a><h2>2020-02-19</h2>
<h3>No. 1	递进神经网络学习的子集抽样</h3><h4>Dat Thanh Tran, Moncef Gabbouj, Alexandros Iosifidis</h4>文摘：递进神经网络学习是一类基于训练数据逐步构造网络拓扑结构并优化网络参数的算法。虽然这种方法免除了用户设计和验证多个网络拓扑的手动任务，但它通常需要大量的计算。在本文中，我们建议通过在每个增量训练步骤中利用训练数据子集来加速这一过程。提出并评价了三种根据不同准则选择训练样本的抽样策略。我们还建议在网络进行过程中进行在线超参数选择，从而进一步减少整体训练时间。在目标、场景和人脸识别问题上的实验结果表明，该方法在训练过程中充分利用了整个训练集，在与基线方法相同的条件下，大大加快了优化过程。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07141">PDF</a>
<h3>No. 2	确定性系统中函数逼近的不可知Q学习：逼近误差和样本复杂度的严格界限</h3><h4>Simon S. Du, Jason D. Lee, Gaurav Mahajan, Ruosong Wang</h4>文摘：本文研究了确定性系统中不相关Q $ $学习的函数逼近问题，其中最佳$q $函数可由类$ \ MathCAL{f}$中的函数逼近，逼近误差$Δ\ GE 0 $。我们提出了一种新的基于递归的算法，并证明了如果$\delta=O\left（\rho/\sqrt{\dim_E}\right）$，则可以使用$O\left（\dim_E}\right）$轨迹找到最优策略，其中，$\rho$是最佳操作的最优$Q$值与次佳操作的最优$Q$值之间的差距，$\dim_E$是$\mathcal{F}$的洗脱器维度。我们的结果有两个含义：1）结合[DU等人，ICLR 2020 ]中的下界，我们的上界表明条件$\ delta \广角{\θ}左（\Roo/\qrt{{Mathm {Dim}} }）对于多项式样本复杂度的算法是必要的和充分的。2）结合[Win和Van Roy，NIPS 2013 ]中的下界，我们的上界表明样本复杂性$\广角{ \θ}左（\ Mathm {Dime} \右）$是紧的，即使在不可知的设置中。因此，我们解决了[Wen and Van Roy，NIPS 2013]中提出的不可知论$Q$-学习的开放问题。我们进一步将我们的算法推广到随机报酬设置中，得到了类似的结果。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07125">PDF</a>
<h3>No. 3	监督学习数据中缺失标注的处理</h3><h4>Alaa E. Abdel-Hakim, Wael Deabes</h4>摘要：数据标注是监督学习的一个重要阶段。然而，注释过程是详尽和耗时的，特别是对于大型数据集。日常生活活动（ADL）识别是利用非常大的原始传感器数据读数的系统的一个例子。在这种系统中，传感器读数是以24/7的方式从活动监测传感器收集的。生成的数据集太大，以至于人工注释器几乎不可能为数据集中的每个实例都赋予特定的标签。这导致采用监督学习系统的输入数据中存在注释间隙。这些差距对识别系统的性能产生了负面影响。在这项工作中，我们提出并研究了三种不同的模式来处理这些差距。在第一种范式中，通过删除所有未标记的读数来消除间隙。一个“未知”或“不做任何事”的标签被给予在第二个范例的操作中的未标记的读数。最后一个范型通过给它们中的每一个提供一个唯一的标签来识别封装的确定性标签来处理这些间隙。此外，我们还提出了一种注释间隙的语义预处理方法，通过构造这些范例的混合组合来进一步提高性能。使用ADL基准数据集（包含超过2.5美元乘以超过9个月收集的10^6美元传感器读数）评估所提出的三种范式及其混合组合的性能。评估结果强调了每种范式运作下的绩效对比，并支持特定的差距处理方法以获得更好的绩效。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07113">PDF</a>
<h3>No. 4	神经序列模型的计算与质量控制</h3><h4>Ankur Bapna, Naveen Arivazhagan, Orhan Firat</h4>翻译后摘要：大多数神经网络利用相同数量的计算为每个例子独立于固有的复杂性的输入。此外，使计算量适应示例的方法侧重于为每个示例查找固定的推理时间计算图，而忽略任何外部计算预算或变化的推理时间限制。在这项工作中，我们利用条件计算使神经序列模型（Transformer）在推理过程中更有效率和计算意识。我们首先修改Transformer架构，使每一组操作根据学习到的控制网络的输出有条件地执行。然后，我们在多任务设置中训练该模型，其中每个任务对应于特定的计算预算。这允许我们训练一个单一的模型，该模型可以控制在计算质量权衡曲线的不同点上运行，具体取决于推断时可用的计算预算。我们在两个任务上评估了我们的方法：（i）WMT英法翻译和（ii）无监督表示学习（BERT）。我们的实验表明，当允许使用条件计算转换器（CCT）的全部计算预算时，该转换器与普通变压器相比具有竞争力，而当在较小的计算预算下操作时，其性能显著优于计算等效基线。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07106">PDF</a>
<h3>No. 5	增强规范化流：弥合生成流和潜在变量模型之间的鸿沟</h3><h4>Chin-Wei Huang, Laurent Dinh, Aaron Courville</h4>文摘：在这项工作中，我们提出了一个在扩充数据空间上的新的生成流族，目的是在不显著增加抽样和估计似然下界的计算成本的情况下提高表示性。理论上，我们证明了所提出的流可以逼近哈密顿量作为一个普适映射。在经验上，我们在基于流的生成建模的标准基准上展示了最先进的性能。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07101">PDF</a>
<h3>No. 6	图反褶积生成</h3><h4>Daniel Flam-Shepherd, Tony Wu, Alan Aspuru-Guzik</h4>摘要：图形生成是一项极其重要的工作，因为图形贯穿于科学和工程的各个领域。本文研究了鄂尔多斯人一随机图模型的现代等价：图变分自编码（GVAE）。该模型假设边缘和节点是独立的，以便使用多层感知器解码器一次生成完整的图形。由于这些假设，GVAE难以匹配训练分布，并且依赖于昂贵的图匹配过程。我们通过在GVAE的编解码器中建立一个消息传递神经网络来改进这类模型。我们展示了我们关于生成小有机分子的模型<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07087">PDF</a>
<h3>No. 7	三大问题：通过回答公司关心的问题来提高数据科学投资回报率的方法</h3><h4>Daniel K. Griffin</h4>摘要：在工业应用中，企业从数据科学中获得的价值可能只有三分之一。在这篇文章中，我们提出了一种使用数据科学对“三大”问题进行分类和回答的方法（发生了什么，是什么原因造成的，我可以采取什么行动来优化我关心的问题）。数据科学的应用在当今的现代环境中似乎是无穷无尽的，每家公司都在争夺新的数据和洞察力经济的地位。然而，数据科学家似乎只专注于使用分类、回归和聚类方法来回答“发生了什么”的问题。在工业数据科学分析中，关于为什么会发生这种情况或如何采取最佳行动来改进度量的问题，通常被归入利基研究领域而被忽视。我们调查技术方法以回答这些其他重要问题，描述其中一些方法正在应用的领域，并提供如何将我们的方法和所选方法应用于实际业务用例的实际示例。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07069">PDF</a>
<h3>No. 8	用函数逼近和相关均衡学习零和同时移动马尔可夫博弈</h3><h4>Qiaomin Xie, Yudong Chen, Zhaoran Wang, Zhuoran Yang</h4>文摘：针对两人零和马尔可夫对策，提出了两人同时采取行动的可证明有效的强化学习算法。为了结合函数逼近，我们考虑了一类马尔可夫游戏，其中奖赏函数和转移核具有线性结构。同时考虑问题的脱机和联机设置。在离线环境下，我们同时控制两个参与者，目标是通过最小化最坏情况下的二元差距来有效地找到纳什均衡。在联机设置中，我们控制单个玩家与任意对手比赛，目标是最小化遗憾。对于这两种情况，我们提出了一种乐观的最小二乘最小极大值迭代算法。我们证明了我们的算法是计算有效的，并且在不需要对抽样模型进行额外假设的情况下，在对偶间隙和遗憾上可证明达到$\tilde O（\sqrt{d^3h^3t}）$上界。我们强调，我们的设置需要克服马尔可夫决策过程或基于转向的马尔可夫博弈中缺少的几个新挑战。特别地，为了在同时移动Marko博弈中实现乐观，我们构造了价值函数的上下置信界，然后通过求解一个以这些置信界为收益矩阵的一般和矩阵博弈来计算乐观策略。由于求解一般和博弈的纳什均衡是一个计算困难的问题，我们的算法求解的是一个粗相关均衡（CCE），它可以通过线性规划得到。据我们所知，这样一个基于央企的乐观主义实施方案并没有出现在文献中，它本身可能会引起人们的兴趣。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07066">PDF</a>
<h3>No. 9	再培训还是不培训？--深CNN网络的有效剪枝方法</h3><h4>Marcin Pietron, Maciej Wielgosz</h4>摘要：卷积神经网络（CNN）在图像分类、目标检测、语义分割等图像处理任务中发挥着重要作用。CNN网络通常有几百个堆叠的层和几兆字节的权重。减少复杂性和内存占用的一种可能方法是修剪。剪枝是一个去除网络中连接两个相邻层神经元的权值的过程。当DL模型具有较高的卷积层数时，寻找具有指定精度下降的近似最优解的过程会更加复杂。本文对基于再培训和非再培训的几种方法进行了描述和比较。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07051">PDF</a>
<h3>No. 10	多任务协同智能的位分配</h3><h4>Saeed Ranjbar Alvar, Ivan V. Bajić</h4>文摘：近年来的研究表明，协作智能（CI）是一种很有前途的在移动设备上部署基于人工智能（AI）的服务的框架。在CI中，在移动设备和云之间分割出一个深层神经网络。在移动设备上获得的深层特征被压缩并传输到云端以完成推理。到目前为止，文献中的方法主要集中在将单个深度特征张量从移动设备转移到云上。这种方法不适用于一些具有多分支和跳跃连接的高性能网络。本文提出了多流、多任务CI的第一位分配方法。我们首先建立了一个多个任务的联合失真模型，作为分配给不同深度特征张量的比特率的函数。然后，利用该模型求解了总速率约束下的速率失真优化问题，得到了待传输张量之间的最优速率分配。实验结果表明，与几种不同的比特分配方法相比，该方案是有效的。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07048">PDF</a>
<h3>No. 11	基于图像结构的对象变形测试</h3><h4>Adrian Wildandyawan, Yasuharu Nishi</h4>摘要：由于需要大量生成测试用例并为其提供测试oracle，测试软件往往成本高昂。这通常被称为oracle问题。为了缓解oracle问题，人们提出了一种方法：变形测试。变质测试通过改变现有的测试用例来产生新的测试用例，并利用被测试系统（SUT）的输入和输出之间的变质关系来预测所产生的测试用例的预期输出。变形测试通常用于图像处理软件，其中对图像的属性应用更改以创建带有与原始图像相同的注释的新测试用例。我们将现有的方法称为基于图像的变形测试。在本研究中，我们提出一个基于物件的变质主义测试和一个复合变质主义测试，结合不同的变质主义测试方法，以相对增加测试覆盖率。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07046">PDF</a>
<h3>No. 12	深部张量压缩的前后预测</h3><h4>Hyomin Choi, Robert A. Cohen, Ivan V. Bajic</h4>摘要：近年来人工智能的应用，如协同智能和神经网络，涉及到在不同的计算设备之间传递深层特征张量。这就需要张量压缩来优化设备之间带宽受限信道的使用。本文提出了一种针对深特征张量的预测方案，称为前后（BaF）预测，它能显著减小张量的大小，提高张量的压缩性。我们使用最先进的目标检测器进行的实验表明，所提出的方法可以显著减少压缩从模型内部深层提取的特征张量所需的比特数，而检测性能的退化可以忽略不计，并且不需要重新训练网络权值。在保证网络精度损失分别小于1%和2%的情况下，张量减小了62%和75%。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07036">PDF</a>
<h3>No. 13	为知识跟踪提供适当的查询、键和值计算</h3><h4>Youngduck Choi, Youngnam Lee, Junghyun Cho, Jineon Baek, Byungsoo Kim, Yeongmin Cha, Dongmin Shin, Chan Bae, Jaewe Heo</h4>摘要：知识追踪是计算机辅助教育领域中一个广泛研究的问题，是通过学习活动来模拟学生知识的行为。尽管带有注意机制的模型比传统的方法（如贝叶斯知识跟踪和协作过滤）有更好的性能，但它们有两个共同的局限性。首先，这些模型依赖于浅层的注意力，无法捕捉到随着时间推移练习和反应之间的复杂关系。其次，没有广泛探讨用于知识追踪的自我注意层的查询、键和值的不同组合。通常将练习和交互（练习-响应对）分别用作查询和键/值的做法缺乏经验支持。本文提出了一种新的基于变压器的知识跟踪模型SAINT：分离自关注神经知识跟踪。SAINT具有编译码结构，其中运动和响应嵌入序列分别进入编码器和解码器，允许多次堆叠注意层。据我们所知，这是第一个提出一个用于知识跟踪的编码器-解码器模型的工作，该模型将深层的自我关注层分别应用于练习和响应。对一个大规模知识跟踪数据集的实证评估表明，SAINT在知识跟踪方面取得了最新的性能，与现有的最新模型相比，AUC提高了1.8%。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07033">PDF</a>
<h3>No. 14	基于多元时间序列分类的结构健康监测全卷积网络</h3><h4>Luca Rosafalco, Andrea Manzoni, Stefano Mariani, Alberto Corigliano</h4>文摘：提出了一种新的结构健康监测方法，旨在从普适传感器系统获取的数据中自动识别损伤敏感特征。将损伤检测和定位问题描述为分类问题，并通过完全卷积网络（FCNs）进行处理。基于物理模型（扮演被监控结构的数字孪生兄弟角色）的数值模拟数据，针对不同的损伤场景，对所提出的网络体系结构进行监督训练。基于这种简化的结构模型，在FCN的训练阶段考虑了多种载荷条件，设计了FCN的结构来处理不同长度的时间序列。神经网络的训练是在监测系统开始工作之前完成的，因此能够进行实时损伤分类。以八层剪力楼为算例，在两种荷载作用下，对该方法的数值性能进行了评估，其中一种荷载作用是模拟低能地震引起的随机振动。在结构响应中加入测量噪声，以模拟实际监测系统的输出。显示了非常好的分类能力：在九种可能的备选方案中（以健康状态和任何楼层的损伤为代表），损伤在高达95%的情况下被正确分类，从而显示了所提出的方法在实际应用中的强大潜力。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07032">PDF</a>
<h3>No. 15	具有流形光滑损失的半监督图卷积网络正则化</h3><h4>Qilin Li, Wanquan Liu, Ling Li</h4>摘要：现有的图卷积网络侧重于邻域聚集方案。在应用于半监督学习时，由于网络是在少量标记数据上进行交叉熵损失训练的，常常会出现过拟合问题。本文提出了一种与图结构相关的无监督流形光滑度损失，它可以作为正则化加入到损失函数中。我们将所提出的损失与迭代扩散过程联系起来，并证明了最小化损失等价于无限层的聚合邻居预测。我们在多层感知器和现有的图形网络上进行实验，并证明添加所提出的损失可以一致地改善性能。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07031">PDF</a>
<h3>No. 16	多头注意模型中的低阶瓶颈</h3><h4>Srinadh Bhojanapalli, Chulhee Yun, Ankit Singh Rawat, Sashank J. Reddi, Sanjiv Kumar</h4>摘要：基于注意的转换结构在自然语言处理领域取得了重大进展。除了新的预训练技术外，最近的改进主要依赖于使用相对较大的令牌嵌入维度。不幸的是，这会导致在下游任务中使用的模型过大。在本文中，我们确定了一个重要因素，导致了大嵌入尺寸的要求。特别是，我们的分析强调了当前架构中头部数量和每个头部大小之间的缩放导致了注意力头部的低级别瓶颈，从而导致了这种限制。我们在实验中进一步验证了这一点。作为一种解决方案，我们建议将注意单元的头部大小设置为输入序列长度，并且与头部数量无关，从而产生具有可证明的更高表达能力的多个头部注意层。我们的经验表明，这使得我们能够训练嵌入维数相对较小且具有更好性能伸缩性的模型。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07028">PDF</a>
<h3>No. 17	基于策略修正的因果特征发现</h3><h4>Yahav Bechavod, Katrina Ligett, Zhiwei Steven Wu, Juba Ziani</h4>文摘：我们考虑了一个在线回归环境，在这个环境中，个体可以适应回归模型：到达的个体可以在整个过程中访问该模型，并战略性地投资于修改自己的特征，从而提高分配的分数。我们发现，这种策略性操作可能有助于学习者恢复因果变量，在这种情况下，代理人可以投资于改善影响性特征，也可以改善他的真实标签。我们表明，即使是学习者的简单行为（即，通过最小二乘回归，根据迄今为止观察到的数据定期更新她的模型）也能让她同时i）准确地恢复哪些特征对代理的真实标签有影响，前提是这些特征已经被大量投资，以及ii）鼓励代理商投资于这些有影响力的功能，而不是对其真实标签没有影响的功能。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07024">PDF</a>
<h3>No. 18	基于多视图信息瓶颈的鲁棒表示学习</h3><h4>Marco Federici, Anjan Dutta, Patrick Forré, Nate Kushman, Zeynep Akata</h4>文摘：信息瓶颈原理为表示学习提供了一种信息论方法，它通过训练编码器保留与预测标签相关的所有信息，同时最小化表示中的其他多余信息量。然而，原始的公式需要标记的数据来识别多余的信息。在这项工作中，我们将此功能扩展到多视图无监督设置，其中提供了同一基础实体的两个视图，但标签未知。这使我们能够将多余的信息识别为两个视图都不共享的信息。通过理论分析，定义了一个新的多视图模型，该模型可以在粗略的数据集上生成最新的结果，并为MIR Flickr数据集的有限版本添加标签。我们还利用标准的数据增强技术将理论扩展到单视图设置，在经验上显示出比一般的无监督表示学习方法更好的泛化能力。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07017">PDF</a>
<h3>No. 19	动态环境的学习群结构与解构表示</h3><h4>Robin Quessard, Thomas D. Barrett, William R. Clements</h4>摘要：发现一个动态环境的基本结构需要学习可解释和可分离的表征，这是一项具有挑战性的任务。在物理学中，对我们的宇宙及其基本动力学的可解释的表示是用对称变换群的表示来表示的。我们提出了一种受物理学启发的方法，它建立在群表示理论的基础上，学习一个环境的表示，该环境是围绕生成其演化的变换而构建的。实验上，我们学习了无监督的显式对称环境的结构，同时保证了表示的可解释性。我们表明，所学习的表示允许精确的长视界预测，并进一步证明了预测质量与潜在空间解纠缠之间的相关性。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06991">PDF</a>
<h3>No. 20	一种用于有效CTR预测的稀疏深度因子分解机</h3><h4>Wei Deng, Junwei Pan, Tian Zhou, Aaron Flores, Guang Lin</h4>摘要：点击率（CTR）预测是在线展示广告中的一项关键任务，关键是学习重要的特征交互。主流的模型是基于嵌入的神经网络，它通过融合混合组件来对低阶和高阶特征交互进行建模，从而提供端到端的训练。然而，由于深度神经网络（DNN）的存在，这些模型将预测推理速度降低了至少数百倍。考虑到在网络广告中采用嵌入式神经网络的挑战，我们首次提出对冗余参数进行剪枝，以加速推理，减少运行时的内存使用。最值得注意的是，在Criteo数据集和Avazu数据集上，我们可以在不损失预测精度的情况下，分别加速46X和27X的推理。此外，深度模型加速使得低延迟和显著性能提高的高效模型集成成为可能。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06987">PDF</a>
<h3>No. 21	深度无监督对映学习中端到端训练的收敛性</h3><h4>Zixin Wen</h4>摘要：无监督对比学习在最近的研究中得到了越来越多的关注，并被证明是一种从无标记数据中学习表示的有效方法。然而，对这一框架的理论分析却鲜为人知。本文研究了深度无监督对比学习的优化问题。我们证明了对于过参数化神经网络，通过应用端到端训练同时更新两个深度神经网络，可以找到非凸对比损失的近似平稳解。这一结果与现有的在监督设置中的过度参数化分析本质上是不同的，因为与学习特定的目标函数相反，无监督对比学习试图将未标记的数据分布编码到神经网络中，神经网络通常没有最优解。我们的分析为这些无监督预训练方法的实际成功提供了理论上的见解。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06979">PDF</a>
<h3>No. 22	深层神经网络的组成结构研究</h3><h4>Francesco Craighero, Fabrizio Angaroni, Alex Graudenzi, Fabio Stella, Marco Antoniotti</h4>文摘：目前对深部神经网络的理解只能部分地解释输入结构、网络参数和优化算法如何共同作用于实现在许多实际应用中通常观察到的强泛化能力。为了提高对深层神经网络的理解和解释能力，提出了一种基于分段线性激活函数组合结构的深层神经网络理论框架。通过定义表示通过网络层的激活模式的组成的直接无环图，可以针对预测标签和用于执行预测的特定（线性）变换来表征输入数据的实例。MNIST数据集的初步测试表明，我们的方法可以将输入实例与它们在神经网络的内部表示中的相似性分组，提供输入复杂性的直观度量。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06967">PDF</a>
<h3>No. 23	具有调整平均秩的链路预测或实体对齐方法的可解释性和公平性比较</h3><h4>Max Berrendorf, Evgeniy Faerman, Laurent Vermue, Volker Tresp</h4>文摘：在这项工作中，我们仔细研究了两类从知识图中丰富信息的方法：链接预测和实体对齐。在当前的实验环境中，多个不同的分数被用来评估模型性能的不同方面。我们分析了这些评价方法的信息价值，并指出了一些不足之处。特别是，我们表明，所有现有的分数难以用于比较不同数据集的结果。此外，当比较同一数据集的不同列车/测试分段时，也可能出现此问题。我们发现，这会导致在解释结果时出现各种各样的问题，这可能支持误导性的结论。因此，我们提出了一种不同的评估方法，并通过实证证明这有助于对模型绩效进行公平、可比和可解释的评估。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06914">PDF</a>
<h3>No. 24	t-viSNE：t-SNE投影的交互评价与解释</h3><h4>Angelos Chatzimparmpas, Rafael Messias Martins, Andreas Kerren</h4>文摘：基于t-分布随机邻域嵌入（t-SNE）的多维数据可视化方法已被证明是一种流行的方法，在许多领域都有成功的应用。尽管t-SNE预测有用，但它可能很难解释，甚至误导人，这损害了结果的可信度。了解t-SNE本身的细节及其输出中特定模式背后的原因可能是一项艰巨的任务，特别是对于非维度归约专家来说。在这项工作中，我们提出了t-viSNE，一个用于t-SNE投影可视化探索的交互式工具，它使分析人员能够检查其准确性和含义的不同方面，例如超参数的影响、距离和邻域保护、特定邻域的密度和成本，以及维度和视觉模式之间的相互关系。我们提出了一个连贯的，可访问的，并且很好地集成了不同视图的集合，用于t-SNE投影的可视化。通过实际数据集的假设使用场景，验证了t-viSNE的适用性和可用性。最后，我们给出了一个用户研究的结果，其中评估了工具的有效性。通过揭示运行t-SNE后通常会丢失的信息，我们希望支持分析师使用t-SNE，并使其结果更易于理解。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06910">PDF</a>
<h3>No. 25	$π$VAE:用变分自编码器编码随机过程先验</h3><h4>Swapnil Mishra, Seth Flaxman, Samir Bhatt</h4>摘要：随机过程为复杂数据建模提供了一种数学上优雅的方法。理论上，它们在函数类上提供灵活的先验，可以对广泛的有趣假设进行编码。然而，在实践中，通过优化或边缘化进行有效的推理是困难的，大数据和高维输入空间进一步加剧了这一问题。我们提出了一种新的变分自动编码器（VAE），称为先验编码变分自动编码器（VAE）。$\pi$VAE是有限可交换且Kolmogorov一致的，因而是一个连续的随机过程。我们使用$\pi$VAE来学习函数类的低维嵌入。我们证明我们的框架可以准确地学习表示函数类，如高斯过程，还可以学习函数的性质，以便进行统计推断（如对数高斯过程的积分）。对于流行的任务，如空间插值，$\pi$VAE在精度和计算效率方面都达到了最先进的性能。也许最有用的是，我们证明了所学习的低维独立分布的潜在空间表示提供了一种优雅和可伸缩的方法，可以在概率编程语言（如Stan）中对随机过程执行贝叶斯推理。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06873">PDF</a>
<h3>No. 26	深度神经网络的可扩展性定量验证</h3><h4>Teodora Baluta, Zheng Leong Chua, Kuldeep S. Meel, Prateek Saxena</h4>文摘：验证深度神经网络（DNNs）的安全性越来越重要。本文介绍了一种新的DNN定量验证框架，该框架可以在用户指定的置信度下，确定给定DNN输入空间上定义的给定逻辑属性{\psi}是否保持在用户指定的阈值{\theta}以下。我们提出了新的算法，可扩展到大型现实世界模型，并证明是健全的。我们的方法只需要黑盒访问模型。进一步证明了确定性DNNs和非确定性DNNs的性质。我们在一个叫做PROVERO的工具中实现了我们的方法。我们将PROVERO应用于证明对抗稳健性的问题。在这种情况下，PROVERO为给定DNN和测试输入提供了一种与攻击无关的健壮性度量。首先，我们发现这个度量与目前最显著的两种白盒攻击策略所报告的扰动界具有很强的统计相关性。其次，我们证明了PROVERO可以在最新的定性验证工具（ERAN）不能产生结论性结果的情况下，以高度的置信度对稳健性进行定量验证。因此，定量验证容易扩展到大dnn。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06864">PDF</a>
<h3>No. 27	隶属度推理攻击的数据和模型依赖性</h3><h4>Shakila Mahjabin Tonni, Farhad Farokhi, Dinusha Vatsalan, Dali Kaafar</h4>摘要：机器学习（ML）技术被大多数数据驱动的组织用来提取洞察力。机器学习即服务（MLaaS）正在成为现实，在MLaaS中，模型被训练成潜在的敏感用户数据，然后被外部方查询。然而，最近的研究表明，这些系统易受成员推断攻击（MIA）的攻击，在MIA中，可以推断目标的数据是否属于训练数据。虽然MIMA成功的关键因素还没有完全了解，现有的防御机制只考虑模型特有的性质。我们研究了数据和ML模型属性对ML技术对MIA的脆弱性的影响。我们的分析表明MIA的成功与使用中的数据的属性（如数据大小和类之间的平衡）以及模型属性（包括预测的公平性和记录与模型参数之间的相互信息）之间有着密切的关系。然后，我们提出了一种新的方法来保护ML模型不受MIA的攻击，该方法利用了模型的公平性和记录与模型参数之间的互信息作为正则化，使得攻击精度降低了25%，同时得到了一个更公平、性能更好的ML模型。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06856">PDF</a>
<h3>No. 28	间歇强化学习中基于动作持久性的控制频率自适应</h3><h4>Alberto Maria Metelli, Flavio Mazzolini, Lorenzo Bisi, Luca Sabbioni, Marcello Restelli</h4>摘要：系统控制频率的选择对强化学习算法学习高性能策略的能力有着相关的影响。在本文中，我们引入了动作持续性的概念，即在固定的决策步骤数下重复一个动作，从而改变控制频率。我们首先分析了行为持久性对最优策略性能的影响，然后提出了一种新的算法，持久拟合Q迭代（PFQI），它扩展了FQI，目的是在给定的持久性下学习最优值函数。在对PFQI进行了理论研究和启发式方法识别最优持久性之后，我们提出了一个在基准域上的实验活动，展示了行动持久性的优点，并证明了我们的持久性选择方法的有效性。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06836">PDF</a>
<h3>No. 29	班级非均衡半监督学习</h3><h4>Minsung Hyun, Jisoo Jeong, Nojun Kwak</h4>摘要：半监督学习在克服标注困难和充分利用未标注数据方面取得了巨大的成功。然而，SSL有一个有限的假设，即不同类中的样本数是平衡的，并且许多SSL算法对于类分布不平衡的数据集表现出较低的性能。本文介绍了一个类不平衡半监督学习（CISSL）的任务，即利用类不平衡数据进行半监督学习。在这个过程中，我们考虑了有标签集和无标签集的类不平衡。首先，我们分析现有的SSL方法在不平衡的环境中，并检查类不平衡如何影响SSL方法。然后，我们提出了抑制一致性损失（SCL），一种对类不平衡鲁棒的正则化方法。在CISSL环境下，我们的方法比传统方法显示出更好的性能。特别是，类不平衡越严重，标记数据的大小越小，我们的方法的性能就越好。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06815">PDF</a>
<h3>No. 30	眼跟踪数据处理中的强化学习</h3><h4>Wolfgang Fuhl</h4>文摘：提出了一种基于强化学习的眼动跟踪数据处理方法。它基于两个相反的代理，其中一个代理试图正确分类数据，另一个代理在数据中寻找模式，这些模式被操纵以隐藏特定信息。我们证明我们的方法是成功地适用于保护一个主题的隐私。此外，我们的方法可以评估眼睛跟踪数据的时间和空间信息对于特定分类目标的重要性。一般来说，这种方法也可用于刺激操作，使其对注视引导感兴趣。为此，本文提供了理论依据，这也是为什么我们还整合了一节如何应用这种方法进行凝视引导。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06806">PDF</a>
<h3>No. 31	基于图序列神经模型重写规则的数据流图等价性</h3><h4>Steve Kommrusch, Théo Barollet, Louis-Noël Pouchet</h4>文摘：本文的研究目标是可证明地计算以数据流图表示的两个程序之间的等价性。为此，我们将两个程序之间的等价问题形式化为找到一组语义保持重写规则，从而在重写之后，两个程序在结构上是相同的，因此是微不足道的等价。然后，我们开发了第一个用于程序等价的图到序列神经网络系统，通过精心设计的自动示例生成算法训练生成这样的重写序列。我们利用丰富的多类型线性代数表达式语言，利用100 +图重写公理的任意组合，对系统进行了广泛的评价。我们的系统通过推理输出一个正确的重写序列，用于测试的10000个程序对中的96%，使用30个术语的程序。而且在所有情况下，产生的序列的有效性以及由此可证明的程序等价性断言是可计算的，在可忽略的时间内。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06799">PDF</a>
<h3>No. 32	CAT：定制对抗训练，提高健壮性</h3><h4>Minhao Cheng, Qi Lei, Pin-Yu Chen, Inderjit Dhillon, Cho-Jui Hsieh</h4>摘要：对抗训练已成为提高神经网络鲁棒性的最有效方法之一。然而，无论是在干净的数据上还是在扰动的数据上，它通常都会受到不好的泛化。本文提出了一种新的算法，称为自定义对抗训练（CAT），它自适应地为对抗训练中的每个训练样本定制扰动水平和相应的标签。通过大量实验证明，该算法比以往的对抗性训练方法具有更好的干净性和鲁棒性。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06789">PDF</a>
<h3>No. 33	剩余持续学习</h3><h4>Janghyeon Lee, Donggyu Joo, Hyeong Gwon Hong, Junmo Kim</h4>文摘：提出了一种新的连续学习方法：剩余连续学习（ResCL）。该方法可以避免多任务序列学习中的灾难性遗忘现象，除了原始网络外，不需要任何源任务信息。ResCL通过线性组合原始网络和微调网络的每一层来重新参数化网络参数；因此，网络的大小根本没有增加。为了将该方法应用于一般的卷积神经网络，还考虑了批量归一化层的影响。通过利用剩余学习（如重新参数化）和特殊的权重衰减，有效地控制了源性能和目标性能之间的权衡。所提出的方法在不同的持续学习情境中表现出最先进的性能。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06774">PDF</a>
<h3>No. 34	可微盗贼探测</h3><h4>Craig Boutilier, Chih-Wei Hsu, Branislav Kveton, Martin Mladenov, Csaba Szepesvari, Manzil Zaheer</h4>翻译后摘要：我们学习ButdID政策，最大限度地获得平均回报的匪徒实例从一个未知的分布$ \ MathCAL{P}$，从一个样本$ \ MathCAL{P}$。我们的方法是元学习的一个实例，它的吸引力在于可以不受限制地利用$\mathcal{P}$的属性。我们以可微的方式参数化我们的策略，并通过策略梯度来优化它们——这是一种易于实现且令人愉快的通用方法。接下来的挑战是设计有效的梯度估计和良好的策略类。为了使政策梯度实用化，我们引入了新的方差减少技术。我们实验了各种强盗策略类，包括神经网络和一种新的软消除策略。后者有遗憾的保证，是我们优化的自然起点。我们的实验突出了我们方法的多功能性。我们还观察到，神经网络策略可以学习隐式偏见，这些偏见只在训练期间通过样本bandit实例来表达。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06772">PDF</a>
<h3>No. 35	无悔学习中的最后迭代收敛：凸凹景观的约束最小最大优化</h3><h4>Qi Lei, Sai Ganesh Nagarajan, Ioannis Panageas, Xiao Wang</h4>文摘：在最近的一系列文献中，我们已经证明了在凸凹零和对策中梯度下降/上升和镜像下降的变量具有最后迭代收敛性。具体来说，{DISZ17，LiangS18}显示了所谓的“乐观梯度下降/上升”的最后一次迭代收敛，适用于{textit{unconstrained}min-max优化。此外，在{Metal}一文中，作者指出，对于凸凹问题（约束和非约束问题），具有额外梯度步长的镜像下降显示出最后一次迭代收敛，尽管他们的算法不遵循在线学习框架；它使用额外的信息而不是历史来计算下一次迭代。在这项工作中，我们证明了遵循无遗憾在线学习框架的“乐观乘性权值更新（OMWU）”在局部凸凹博弈中表现出最后一次迭代收敛，推广了{DP19}的结果，其中OMWU的最后一次迭代收敛仅在{textit{bilinar case}中表现出来。实验结果表明，该方法收敛速度快。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06768">PDF</a>
<h3>No. 36	基于w-LPPD-SVM集成的嵌入式稀疏自编码器</h3><h4>Yongming Li, Yan Lei, Pin Wang, Yuchuan Liu</h4>文摘：深度学习是一种具有强非线性特征变换的特征学习方法，在人工智能的许多领域中越来越重要。深度自动编码器是深度学习方法的代表方法之一，能够有效地提取数据集的抽象信息。但是，在深度特征变换过程中没有考虑深度特征与原始特征之间的互补性。此外，它还存在小样本问题。为了解决这些问题，本文提出了一种新的深度自动编码器-混合特征嵌入式叠置稀疏自动编码器（HESSAE）。在训练过程中，HFESAE能够通过嵌入原始特征来过滤弱隐层输出，从而学习鉴别深层特征。针对小样本问题限制了抽象信息的类表示能力的问题，设计了一种将HFESAE学习到的抽象信息与原始特征相结合，获得混合特征进行特征约简的特征融合策略。该策略是基于L1正则化的混合特征选择策略，其次是支持向量机（SVM）集成模型，在每个基分类器上设计并使用加权局部判别保持投影（w_-LPPD）。最后，利用几个具有代表性的公共数据集验证了算法的有效性。实验结果表明，所提出的特征学习方法与现有和最先进的特征学习算法（包括一些有代表性的深度自编码方法）相比，具有更好的性能。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06761">PDF</a>
<h3>No. 37	知识图完成的实体上下文和关系路径</h3><h4>Hongwei Wang, Hongyu Ren, Jure Leskovec</h4>摘要：知识图补全是为了预测知识图中实体间的缺失关系。虽然提出了许多不同的方法，但缺乏一个统一的框架，这将导致最先进的结果。在这里，我们开发PathCon，知识图完成方法，利用四个新的见解优于现有的方法。PathCon通过以下方法预测一对实体之间的关系：（1）通过捕获与实体相邻的关系类型并通过一种新的基于边缘的消息传递方案建模来考虑每个实体的关系上下文；（2）考虑捕获两个实体之间所有路径的关系路径；（3）自适应地集成通过可学习注意机制的关系语境和关系路径。重要的是，（4）与传统的基于节点的表示不同，PathCon只使用关系类型表示上下文和路径，这使得它适用于归纳设置。在知识图基准测试和我们新提出的数据集上的实验结果表明，PathCon在很大程度上优于最新的知识图完成方法。最后，PathCon能够通过识别为给定的预测关系提供重要上下文和路径的关系来提供可解释的解释。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06757">PDF</a>
<h3>No. 38	统一图卷积神经网络与标记传播</h3><h4>Hongwei Wang, Jure Leskovec</h4>摘要：标签传播（LPA）和图卷积神经网络（GCN）都是图上的消息传递算法。两者都解决了节点分类的任务，但LPA将节点标签信息传播到图的边缘，而GCN则传播和转换节点特征信息。然而，虽然在概念上相似，但LPA和GCN之间的理论关系尚未得到研究。这里我们从两个方面研究LPA和GCN之间的关系：（1）特征/标签平滑，我们分析一个节点的特征/标签是如何分布到其邻居的；（2）特征/标签对一个节点的初始特征/标签对另一个节点的最终特征/标签的影响程度。在理论分析的基础上，提出了一种将GCN和LPA相结合的端到端节点分类模型。在我们的统一模型中，边缘权值是可学习的，LPA作为正则化来帮助GCN学习适当的边缘权值，从而提高分类性能。我们的模型也可以被看作是学习基于节点标签的注意力权重，它比现有的基于特征的注意力模型更面向任务。在实际图形上的大量实验中，我们的模型在节点分类精度方面显示出优于最新的基于GCN的方法。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06755">PDF</a>
<h3>No. 39	解构元学习：理解少量射击任务的特征表示</h3><h4>Micah Goldblum, Steven Reich, Liam Fowl, Renkun Ni, Valeriia Cherepanova, Tom Goldstein</h4>摘要：元学习算法产生的特征抽取器在少量镜头分类上达到了最新的性能。虽然文献中有大量的元学习方法，但是对于为什么得到的特征抽取器表现得如此出色却知之甚少。我们对元学习的基本机制以及元学习模型和经典模型的区别有了更好的理解。在这样做的过程中，我们为元学习模型为什么表现得更好提出了几个假设。除了可视化之外，我们还设计了一些受我们的假设启发的正则化器，这些正则化器可以提高很少镜头分类的性能。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06753">PDF</a>
<h3>No. 40	因果约束下个体公平分类器的学习</h3><h4>Yoichi Chikahara, Shinsaku Sakaue, Akinori Fujino</h4>摘要：机器学习越来越多地应用于为个人做出决策的各种应用中。对于这样的应用，我们需要在实现良好的预测准确性和对敏感特征（例如种族或性别）做出公平决策之间取得平衡，这在复杂的现实场景中是很难做到的。现有的方法测量不公平性在这样的场景{它不公平的因果效应}，并将其均值约束为零。不幸的是，使用这些方法，决定不一定对所有个人都公平，因为即使平均不公平影响为零，不公平影响也可能对某些个人有利，对其他人不利，这对他们是歧视性的。为了学习一个对所有个体都公平的分类器，我们将不公平定义为个体不公平的it概率（PIU），并提出了一个约束PIU上界的优化问题。我们从理论上解释了为什么我们的方法能够实现个人公平。实验结果表明，该方法在保证预测精度的前提下，学习了一个独立的公平分类器。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06746">PDF</a>
<h3>No. 41	跨流形聚类的多平面投影</h3><h4>Lan Bai, Yuan-Hai Shao, Wei-Jie Chen, Zhen Wang, Nai-Yang Deng</h4>摘要：交叉流形聚类是一个很难解决的问题，传统的聚类方法由于存在交叉流形结构而失败。针对交叉流形聚类问题，提出了一种多平面投影聚类算法。在我们的MFPC中，将给定的样本投影到多个子空间以发现隐式流形的全局结构。因此，交叉流形簇区别于各种投影。进一步，我们的MFPC通过核技巧扩展到非线性流形聚类，以处理更复杂的交叉流形聚类。采用递归算法求解了MFPC中的一系列非凸矩阵优化问题。综合测试表明，我们的MFPC在交叉流形结构上工作良好。此外，在基准数据集上的实验结果表明，与一些最新的聚类方法相比，我们的MFPC具有优异的性能。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06739">PDF</a>
<h3>No. 42	基于多智能体强化学习的驾驶员重新定位奖励设计</h3><h4>Zhenyu Shou, Xuan Di</h4>摘要：据报道，大部分乘客的请求都是无效的，部分原因是空乘司机在乘客寻找过程中的巡航行为。本文旨在利用平均场多智能体强化学习（MARL）方法对多驾驶员重新定位任务进行建模。注意到在给定的报酬机制下，直接将MARL应用于多驱动系统很可能会由于驱动者的自私性而产生次优均衡，因此本研究提出了一个报酬设计方案，用以达到更期望的均衡。为了有效地解决以上层为奖赏设计，下层为多智能体系统（MAS）的双层优化问题，采用贝叶斯优化算法加快学习速度。然后，我们使用一个合成数据集来测试所提出的模型。结果表明，与无奖励设计相比，使用简单的平台服务收费，订单响应率和总服务收费的加权平均值可提高4%。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06723">PDF</a>
<h3>No. 43	在没有训练或测试数据的情况下预测最先进的神经网络的质量趋势</h3><h4>Charles H. Martin, Tongsu (Serena)Peng, Michael W. Mahoney</h4>文摘：在许多应用中，人们使用由他人训练的深度神经网络（DNN）模型。对于这种预先训练的模型，通常无法获得训练/测试数据。此外，人们对模型的许多细节并不了解，例如训练数据的细节、损失函数、超参数值等。给定一个或多个预先训练的模型，人们能对模型的预期性能或质量说些什么吗？在这里，我们提出并评估了预训练DNN模型的经验质量度量。使用开源的WeightWatcher工具，我们分析了数百个公开可用的预训练模型，包括CV和NLP中的旧模型和当前的最新模型。从最近发展起来的重尾自正则化理论出发，我们研究了基于范数的容量控制度量以及新的基于幂律（PL）的度量（包括拟合PL指数和加权α度量）。基于规范的度量与几乎所有CV体系结构系列中训练有素模型的测试精度报告有很好的相关性。另一方面，基于规范的度量不能区分“好的和坏的”模型——这可以说是需要质量度量的关键。事实上，他们可能会给出虚假的结果。基于损益的指标做得更好——在数量上更好地区分一系列“好的更好的最好”模型，在质量上更好地区分“好的和坏的”模型。基于PL的度量也可以用来描述模型的精细尺度特性，我们引入了分层相关流作为新的质量评估。我们展示了训练不好（和/或微调不好）的模型可能同时表现出尺度塌陷和异常大的PL指数，特别是对于最近的NLP模型。我们的技术可用于识别预先训练的DNN何时存在仅通过检查训练/测试精度无法检测到的问题。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06716">PDF</a>
<h3>No. 44	批集成：一种有效集成和终身学习的替代方法</h3><h4>Yeming Wen, Dustin Tran, Jimmy Ba</h4>文摘：多个神经网络单独训练并对其预测进行平均的集合在提高单个神经网络的精度和预测不确定性方面取得了广泛的成功。然而，一个集成的训练和测试成本都随着网络数量的增加而线性增加，这很快就变得难以维持。在本文中，我们提出了BatchEnsemble，这是一种计算和存储成本显著低于典型集成的集成方法。BatchEnsemble通过将每个权重矩阵定义为所有集成成员共享权重和每个成员一个秩一矩阵的Hadamard乘积来实现这一点。与集成不同，batch ensemble不仅可以跨设备并行化，其中一个设备训练一个成员，而且可以在一个设备内并行化，其中多个集成成员在给定的小批量中同时更新。通过CIFAR-10、CIFAR-100、WMT14 EN-DE/EN-FR转换和分发外任务，BatchEnsemble作为典型的集成产生了竞争性的准确性和不确定性；在测试时的加速是3倍，在大小为4的集成中的内存减少是3倍。我们还将BatchEnsemble应用于终身学习，在Split-CIFAR-100上，BatchEnsemble可以获得与渐进式神经网络相当的性能，同时具有更低的计算和内存成本。我们进一步证明，在包含100个顺序学习任务的分割图像网络上，BatchEnsemble可以很容易地扩展到终身学习。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06715">PDF</a>
<h3>No. 45	无模型深层强化学习中简单对象表示的研究</h3><h4>Guy Davidson, Brenden M. Lake</h4>文摘：我们探讨了使用简单的对象表示来增强最新的无模型深度增强算法的好处。根据Lake等人提出的冻伤挑战。（2017），我们将对象表征确定为当前强化学习代理缺乏的关键认知能力。我们发现，为彩虹模型（Hessel等人，2018年）提供简单、功能工程化的对象表示大大提高了它在Atari 2600的冻伤游戏中的性能。然后，我们分析不同类型对象的表示的相对贡献，确定这些表示最具影响力的环境状态，并检查这些表示如何有助于将其归纳为新的情况。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06703">PDF</a>
<h3>No. 46	行为预测</h3><h4>Juan C. Perdomo, Tijana Zrnic, Celestine Mendler-Dünner, Moritz Hardt</h4>摘要：当预测支持决策时，他们可能会影响他们想要预测的结果。我们把这种预测称为行为预测；预测影响目标。绩效是决策中一个被广泛研究的现象，但在监督学习中却一直被忽视。当忽略时，表现力表现为不希望的分布变化，通常通过再训练来解决。我们将统计学、博弈论和因果关系的概念结合起来，开发了一个绩效预测的风险最小化框架。概念新颖性是一种平衡概念，我们称之为行为稳定性。行为稳定性意味着预测不是针对过去的结果进行校准，而是针对未来的结果进行校准，这些结果是通过对预测的作用而显现出来的。我们的主要结果是再训练收敛到几乎最小损失的性能稳定点的充分必要条件。总体而言，绩效预测严格地包含了战略分类。因此，我们也给出了第一个充分的条件，使再培训能够克服战略反馈效应。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06673">PDF</a>
<h3>No. 47	过度参数化对抗训练：克服维度诅咒的分析</h3><h4>Yi Zhang, Orestis Plevrakis, Simon S. Du, Xingguo Li, Zhao Song, Sanjeev Arora</h4>摘要：对抗性训练是一种常用的神经网络抗对抗性扰动的方法。在实践中，对抗性训练导致低强度训练损失。然而，对于为什么在自然条件下会发生这种情况，仍然缺少一个严格的解释。最近，针对{em超参数化}网络，不同的研究小组提出了一种标准（非对抗性）监督训练的收敛理论。目前尚不清楚如何将这些结果推广到对抗性训练中，因为这是最小-最大目标。最近，Gao等人朝着这个方向迈出了第一步。使用来自在线学习的工具，但它们要求网络的宽度在输入维度$d$中为{指数}，并且具有非自然的激活函数。我们的工作证明了在自然假设和ReLU激活下，对于多项式宽度而不是指数宽度，收敛到低鲁棒训练损失。我们的证明的关键元素表明，Relu网络接近初始化可以近似的阶跃函数，这可能是独立的利益。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06668">PDF</a>
<h3>No. 48	TempLe：样本有效多任务RL转换学习模板</h3><h4>Yanchao Sun, Xiangyu Yin, Furong Huang</h4>摘要：知识在不同环境中的传递对于有效地在线学习多个任务具有重要意义。大多数现有的方法直接使用先前学习的模型或先前学习的最优策略来学习新任务。然而，当底层模型或最优策略在不同任务之间存在显著差异时，这些方法可能效率低下。本文提出了模板学习（Template Learning，简称TempLe）方法，这是第一种用于多任务强化学习的PAC-MDP方法，适用于状态/动作空间变化的任务。TempLe生成转换动力学模板，即跨任务的转换动力学的抽象，以便通过提取任务之间的相似性来获得样本效率，即使它们的底层模型或最优策略具有有限的共性。我们提出了两个算法分别为“在线”和“有限模型”设置。我们证明了我们所提出的PANK算法比单任务学习者或最先进的多任务方法实现的样本复杂度要低得多。我们通过系统设计的实验表明，我们的TempLe方法在不同的环境和条件下都比目前最先进的多任务方法（PAC-MDP或not）有更好的性能。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06659">PDF</a>
<h3>No. 49	变压器的稳健性验证</h3><h4>Zhouxing Shi, Huan Zhang, Kai-Wei Chang, Minlie Huang, Cho-Jui Hsieh</h4>文摘：以形式化验证神经网络预测行为为目的的鲁棒性验证已成为理解模型行为、获取安全保证的重要工具。然而，以往的方法通常只能处理结构相对简单的神经网络。本文研究变压器的鲁棒性验证问题。变压器具有复杂的自关注层，这对验证提出了许多挑战，包括交叉非线性和交叉位置相关性，这在以前的工作中还没有讨论过。我们解决了这些挑战，并开发了第一个变压器稳健性验证算法。该方法计算出的鲁棒性界比单纯区间界传播法计算出的鲁棒性界要严格得多。这些界限也有助于解释变形金刚，因为它们一贯反映了不同的词在情感分析中的重要性。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06622">PDF</a>
<h3>No. 50	基于GANs的汽车软件在环测试控制时序生成</h3><h4>Dhasarathy Parthasarathy, Karl Bäckström, Jens Henriksson, Sólrún Einarsdóttir</h4>文摘：汽车机电系统的测试部分采用软件在环方法，系统地覆盖被测系统的输入仍然是一个主要的挑战。在目前的实践中，有两种主要的输入刺激技术。一种方法是设计输入序列，这样可以简化测试过程的控制和反馈，但不能使系统暴露在真实的场景中。另一种方法是重放从野外作业中记录的序列，这种方法考虑到了实际情况，但需要收集一个标记良好的数据集，具有足够的容量，以供广泛使用，成本高昂。本文应用生成性对抗网络（GAN）的无监督学习框架，学习一个未标记的车内信号数据集，并将其用于合成输入刺激的生成。此外，还演示了一种基于度量的线性插值算法，该算法保证生成的刺激与指定的引用遵循可定制的相似关系。这两种技术的结合使得能够有控制地生成大量有意义和现实的输入模式，提高虚拟测试覆盖率，减少对昂贵的现场测试的需求。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06611">PDF</a>
<h3>No. 51	REST：基于RL空间变换的黑箱模型性能改进</h3><h4>Jae Myung Kim, Hyungjin Kim, Chanwoo Park, Jungwoo Lee</h4>文摘：近年来，深神经网络（DNN）已成为一个高度活跃的研究领域，并在各种计算机视觉任务上取得了显著的成绩。然而，已知dnn经常对分布外样本做出过度自信但不正确的预测，这可能是实际部署的一个主要障碍，因为与各种实际样本相比，训练数据集总是有限的。因此，在实际构造DNN模型时，必须保证对训练时间和测试时间之间的分布变化具有鲁棒性。此外，在许多情况下，深度学习模型被部署为黑箱，并且已经针对训练数据集优化了性能，因此改变黑箱本身可能导致性能下降。本文研究了在给定黑盒图像分类器的特定条件下对几何变换的鲁棒性。我们提出一个额外的学习者，将扭曲的输入数据转换成黑箱模型认为是分布的样本。我们的工作旨在通过在任何黑盒前面添加一个REST模块，并且只训练REST模块，而不以端到端的方式重新训练原始黑盒模型，即我们尝试将真实世界的数据转换为最适合黑盒模型性能的训练分布，从而提高鲁棒性。我们使用从黑箱模型中获得的置信分数来确定转换后的输入是否来自于in分布。实验表明，该方法在推广几何变换和样本效率方面具有优势。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06610">PDF</a>
<h3>No. 52	推荐系统的广义嵌入机</h3><h4>Enneng Yang, Xin Xin, Li Shen, Guibing Guo</h4>摘要：因子分解机（FM）是一种有效的基于特征的推荐模型，它利用内积来捕获二阶特征交互。然而，调频的一个主要缺点是不能捕获复杂的高阶交互信号。一个常见的解决方案是改变交互作用函数，例如在FM的顶部叠加深度神经网络。在这项工作中，我们提出了另一种在嵌入层模拟高阶交互信号的方法，即广义嵌入机（GEM）。GEM中的嵌入不仅对特征本身的信息进行编码，还对其他相关特征的信息进行编码。在这种情况下，嵌入成为高阶的。然后，我们可以将GEM与FM甚至其高级变体结合起来执行功能交互。更具体地说，本文利用图卷积网络（GCN）生成高阶嵌入。我们将GEM与几个基于FM的模型集成，并在两个真实数据集上进行了广泛的实验。结果表明，GEM的性能明显优于相应的基线。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06561">PDF</a>
<h3>No. 53	公平主成分分析与滤波器设计</h3><h4>Gad Zalcberg, Ami Wiesel</h4>文摘：考虑公平主成分分析（FPCA）问题，寻找一个公平地跨越多个目标向量的低维子空间。FPCA被定义为给定集合内最差投影目标范数的非凹最大化。该问题出现在信号处理中的滤波器设计，以及在将公平性纳入降维方案时。FPCA的最新方法是通过半定松弛，并涉及多项式但计算代价昂贵的优化。为了允许可伸缩性，我们建议使用朴素的次梯度下降来处理FPCA。在目标正交的情况下，我们分析了底层优化的景观。我们证明了景观是良性的，并且所有的局部极小值都是全局最优的。有趣的是，在这个简单的例子中，SDR方法会导致次优解。最后，讨论了正交FPCA与规范化紧框架设计的等价性。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06557">PDF</a>
<h3>No. 54	在嘈杂的标签面前学会不学习</h3><h4>Liu Ziyin, Blair Chen, Ru Wang, Paul Pu Liang, Ruslan Salakhutdinov, Louis-Philippe Morency, Masahito Ueda</h4>摘要：在存在标签噪声的情况下进行学习是一项具有挑战性的重要任务：设计在存在错误标签数据集的情况下具有鲁棒性的模型至关重要。在本文中，我们发现一类新的损失函数称为赌徒损失函数，它对各种腐败程度的标签噪声具有很强的鲁棒性。研究表明，利用这种损失函数进行训练，可以使模型避免对带有噪声标签的数据点进行学习，从而得到一种简单有效的方法，提高了模型的鲁棒性和泛化能力。此外，我们提出了两个实际扩展的方法：1）一个分析的早期停止标准，在噪声标签的记忆之前近似停止训练，以及2）用于设置不需要知道噪声损坏率的超参数的启发式算法。我们证明了我们的方法的有效性，通过与现有基线相比，在三个图像和文本分类任务中获得强的结果。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06541">PDF</a>
<h3>No. 55	双星：通过耦合双星激活减少双星激活网络中的梯度失配</h3><h4>Hyungjun Kim, Kyungsu Kim, Jinseok Kim, Jae-Joon Kim</h4>摘要：二进制神经网络（BNN）由于其计算成本的降低和内存的节省而受到人们的关注。然而，bnn的性能下降主要是由于二值化激活引起的梯度失配。以前的工作试图解决梯度失配问题，通过减少在前向激活函数和其在向后传递中使用的可微近似之间的差异，这是一种间接测量。在这项工作中，我们使用平滑损失函数的梯度来更好地估计量化神经网络中的梯度失配。使用梯度失配估计器的分析表明，使用更高的激活精度比修改激活函数的可微近似更有效。在此基础上，我们提出了一种新的二元激活网络训练方案，称为二元激活网络，在训练过程中，两个二元激活耦合成一个三元激活网络。实验结果表明，在相同的参数和计算代价下，binarydou在各种基准上都优于最新的BNNs。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06517">PDF</a>
<h3>No. 56	噪声相似标记数据的多类分类</h3><h4>Songhua Wu, Xiaobo Xia, Tongliang Liu, Bo Han, Mingming Gong, Nannan Wang, Haifeng Liu, Gang Niu</h4>摘要：相似性标签表示两个实例是否属于同一个类，而类标签表示实例的类。在没有类标签的情况下，通过元分类学习，可以从相似性标记的成对数据中学习多类分类器。然而，由于相似性标签的信息量比类标签少，因此它更容易产生噪声。深层神经网络可以很容易地记住有噪声的数据，导致分类的过度拟合。本文提出了一种仅从带噪声的相似标记数据中学习的方法。具体来说，为了对噪声进行建模，我们使用噪声转移矩阵来桥接干净数据和噪声数据之间的类后验概率。我们进一步从噪声数据中估计出转换矩阵，并建立了一个新的学习系统来学习一个分类器，该分类器可以为实例分配无噪声类标签。此外，我们从理论上证明了我们所提出的方法对于学习分类器是如何推广的。实验结果表明，该方法在基准模拟和真实噪声标签数据集上优于目前最先进的方法。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06508">PDF</a>
<h3>No. 57	约束深度强化学习策略空间的一阶优化</h3><h4>Yiming Zhang, Quan Vuong, Keith W. Ross</h4>摘要：在强化学习中，主体试图通过与环境的交互来学习高绩效的行为，这种行为通常以奖励函数的形式被量化。然而，行为的某些方面，例如那些被认为不安全且应避免的方面，最好通过约束来捕捉。我们提出了一种新的方法，称为策略空间中的一阶约束优化（Foops），它最大化代理的整体报酬，同时确保代理满足一组成本约束。FOCOPS首先利用当前策略生成的数据，通过求解非参数策略空间中的约束优化问题，找到最优更新策略。FOCOPS然后将更新策略投影回参数策略空间。我们的方法为整个培训过程中的约束满足提供了保证，并且是一级的，因此实现起来非常简单。我们提供的经验证据表明，与现有的方法相比，我们的算法在一组受限机器人机车任务上取得了更好的性能。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06506">PDF</a>
<h3>No. 58	神经网络逼近能力的进一步研究</h3><h4>Kai Fong Ernest Chong</h4>翻译后摘要：通用逼近定理，在其最一般的版本之一，说，如果我们只考虑连续激活函数$ \ sigma $，那么一个标准的前向神经网络与一个隐藏层能够近似任何连续的多元函数$f$到任何给定的近似阈值$\VaRePiSLon $，如果且仅如果$\sigma$是非多项式。本文给出了该定理的直接代数证明。此外，我们将明确量化近似所需的隐藏单位的数量。具体来说，如果$X\substeq\mathbb{R}^n$是紧凑的，那么一个包含$n$input units、$m$output units的神经网络，以及一个包含$\binom{n+d}{d}$hidden units的单隐层（独立于$m$和$\varepsilon$），可以一致地逼近任何多项式函数f:x\到\ Mththb{{r} m $，其总度数最多为$$$，用于其$M $坐标函数中的每一个。在$F$是任何连续函数的一般情况下，我们表明存在$N\\\MathCAL{O}（\VaRePiSLION ^ {N}）$（独立于$M $），使得$N$隐藏单元就足够接近$F$。我们还表明，这种均匀逼近性质（UAP）仍然保持在看似强加的条件下的权重。我们强调了几个结果：（i）对于任何$\delta>0$，如果我们将最后一层中的所有非偏移权重$w$限制为满足$| w |<\delta$，则UAP仍然有效。（ii）存在一些$lambda＞0美元（仅取决于$F$和$\σ$），使得如果我们在第一层中限制所有非偏置权重$W$以满足$W*>λ$，则UAP仍然持有。（iii）如果第一层中的非偏倚权重是{fixed}，并且是从适当的范围中随机选择的，则UAP的概率为$1$。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06505">PDF</a>
<h3>No. 59	具有最优传输的可微Top-k算子</h3><h4>Yujia Xie, Hanjun Dai, Minshuo Chen, Bo Dai, Tuo Zhao, Hongyuan Zha, Wei Wei, Tomas Pfister</h4>摘要：top-k操作是一种重要的模型构件，广泛应用于信息检索、机器学习和数据挖掘等领域。但是，如果top-k操作是以算法的方式实现的，例如使用bubble算法，则生成的模型不能使用流行的梯度下降算法进行端到端的训练。这是因为这些实现通常涉及交换索引，其梯度无法计算。此外，从输入分数到该元素是否属于top-k集的指标向量的对应映射本质上是不连续的。为了解决这个问题，我们提出了平滑近似，即软（可伸缩的基于最优传输的可微的）top-k算子。具体地，我们的软top-k算子逼近top-k操作的输出作为熵最优运输（EOT）问题的解。然后，基于EOT问题的最优性条件，可以有效地逼近软算子的梯度。将该算子应用于k近邻和波束搜索算法中，取得了较好的性能。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06504">PDF</a>
<h3>No. 60	带噪声标签的鲁棒学习自适应损失</h3><h4>Jun Shu, Qian Zhao, Keyu Chen, Zongben Xu, Deyu Meng</h4>摘要：鲁棒损失最小化是处理含噪标签鲁棒学习问题的重要策略。然而，目前的鲁棒损失函数不可避免地涉及到要通过交叉验证手动或启发式地调整的超参数，这使得它们很难在实际中得到普遍应用。此外，由于丢失带来的非凸性以及复杂的网络结构，使得它容易陷入陷入泛化能力较差的意外解决方案中。针对上述问题，我们提出了一种在鲁棒损失函数中自适应学习超参数的元学习方法。具体地说，该方法通过鲁棒损失超参数和网络参数的相互改进，可以同时对两者进行精细学习和协调，得到具有良好泛化能力的解。本文尝试将四种SOTA鲁棒损失函数集成到算法中，综合实验证明，与传统的超参数整定方法相比，该方法在精度和泛化性能上都具有普遍的有效性，即使是精心调整的超参数。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06482">PDF</a>
<h3>No. 61	相关对抗性模仿学习</h3><h4>Ari Azarafrooz</h4>文摘：将博弈论中的相关均衡思想应用到生成性对抗性模仿学习中，提出了一种新的模仿学习算法。该模拟学习算法与传统的单分类器单agent学习算法相比，具有多个分类器和多个agent的队列。相关均衡的实现是由于一种中介神经结构，它增加了鉴别器和代理队列所看到的观察结果。在训练的每一步中，中介网络都使用鉴别器和代理的奖励来计算反馈，从而相应地增加下一步的观察。通过游戏中的交互作用，将训练动态引导到更合适的区域。由此产生的模仿学习提供了三个重要的好处。首先，它使学习模型对新环境的适应性和可移植性变得简单明了。其次，它适合于模拟一个混合状态的动作轨迹。第三，避免了生成对抗型结构中鉴别器所面临的非凸优化问题。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06476">PDF</a>
<h3>No. 62	模拟学习和目标条件强化学习的普适值密度估计</h3><h4>Yannick Schroecker, Charles Isbell</h4>摘要：本研究考虑两种不同的情境：模仿学习和目标条件强化学习。在这两种情况下，有效的解决方案都要求代理可靠地达到指定的状态（目标）或状态集（演示）。本文将概率长期动力学与期望值函数联系起来，介绍了一种利用密度估计的最新进展来有效学习达到给定状态的方法。作为我们的第一个贡献，我们将此方法用于目标条件强化学习，并证明其在随机域中既有效又不受后见偏差的影响。作为我们的第二个贡献，我们将该方法扩展到模仿学习，并证明它在标准基准任务上实现了最先进的示范样本效率。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06473">PDF</a>
<h3>No. 63	支持向量机的核心集</h3><h4>Murad Tukan, Cenk Baykal, Dan Feldman, Daniela Rus</h4>文摘：针对大数据流应用中大规模支持向量机（SVM）训练问题，提出了一种有效的核心集构造算法。核心集是原始数据点的一个小的、有代表性的子集，因此在核心集上训练的模型与在原始数据集上训练的模型具有可证明的竞争性。由于核集的大小通常比原始核集小得多，因此我们的预处理-然后训练方案在训练支持向量机模型时有可能导致显著的加速。我们证明了支持向量机问题获得小数据摘要所需的核心集大小的上下界。作为推论，我们证明我们的算法可用于扩展任何现成的支持向量机解算器对流式、分布式和动态数据设置的适用性。我们评估了我们的算法在真实世界和合成数据集上的性能。实验结果验证了该算法良好的理论性能，证明了该算法在加速支持向量机训练方面的实用性。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06469">PDF</a>
<h3>No. 64	匹配平均的联合学习</h3><h4>Hongyi Wang, Mikhail Yurochkin, Yuekai Sun, Dimitris Papailiopoulos, Yasaman Khazaeni</h4>摘要：联邦学习允许边缘设备协作学习共享模型，同时将训练数据保存在设备上，将模型训练能力与将数据存储在云中的需求分离。针对卷积神经网络（CNNs）和LSTMs等现代神经网络结构的联合学习问题，提出了联邦匹配平均（FedMA）算法。FedMA通过匹配和平均具有相似特征提取特征的隐藏元素（即卷积层的通道；LSTM的隐藏状态；完全连接层的神经元）以层方式构建共享全局模型。我们的实验表明，FedMA不仅在基于真实世界数据集的深层CNN和LSTM体系结构上优于流行的最新联邦学习算法，而且还降低了总体通信负担。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06440">PDF</a>
<h3>No. 65	MRRC：基于R-CNN特征分布合成（FDC）的图像字幕多角色表示交叉解释</h3><h4>Chiranjib Sur</h4>摘要：通过机器进行图像字幕需要结构化的学习和解释的基础，而改进则需要以有意义的方式对多种上下文进行理解和处理。这项研究将为上下文组合提供一个新的概念，并将影响许多处理视觉特征的应用，将其作为对象、活动和事件描述的等价物。该体系结构由三部分组成：特征分布合成（FDC）层注意、多角色表示交叉（MRRC）注意层和语言解码器。FDC层注意有助于从RCNN特征中生成加权注意，MRRC注意层作为中间表示处理，有助于生成下一个单词注意，而语言解码器有助于估计句子中下一个可能单词的可能性。我们证明了FDC、MRRC、区域目标特征注意和强化学习对有效学习产生更好的图像字幕的有效性。模型的性能提高了35.3%，为基于逻辑、更好的可解释性和上下文的表示生成创造了新的标准和理论。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06436">PDF</a>
<h3>No. 66	量子强盗</h3><h4>Balthazar Casalé, Giuseppe Di Molfetta, Hachem Kadri, Liva Ralaivola</h4>摘要：我们考虑量子版的bandit问题，称为{em-best arm identification}（BAI）。我们首先提出了BAI问题的量子模型，假设学习主体和环境都是量子的，然后提出了一种基于量子振幅放大的算法来求解BAI问题。我们形式化地分析了算法在所有问题实例上的行为，特别地，我们证明了它能够比在经典情况下已知的更快地获得最优解。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06395">PDF</a>
<h3>No. 67	多任务多准则超参数优化</h3><h4>Kirill Akhmetzyanov, Alexander Yuzhakov</h4>文摘：提出了一种在多个任务和多个准则中寻找最优超参数的新方法。多任务多准则方法（MTMC）提供了多个Pareto最优解，其中一个解具有给定的准则显著性系数。本文首先给出了最优超参数选择问题的数学表达式。然后，介绍了MTMC方法解决这一问题的步骤。利用卷积神经网络对图像分类问题进行了评价。本文给出了各种准则显著性系数的最优超参数。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06372">PDF</a>
<h3>No. 68	分散数据的神经结构搜索</h3><h4>Mengwei Xu, Yuxin Zhao, Kaigui Bian, Gang Huang, Qiaozhu Mei, Xuanzhe Liu</h4>摘要：为了保护用户隐私，同时实现移动智能，人们提出了在分散数据上训练深层神经网络的技术。然而，对分散数据的训练使得神经结构的设计变得相当困难。在为异构移动平台设计和部署不同的神经体系结构时，这种困难进一步扩大。在这项工作中，我们提出了一个自动神经架构搜索到分散训练，作为一个新的DNN训练范例称为联邦神经架构搜索，即联邦NAS。为了解决客户端计算和通信资源有限的主要挑战，我们提出了一个高效联邦NAS的高度优化框架FedNAS。FedNAS充分利用了体系结构搜索过程中模型候选重新训练不足的关键机会，并结合了三个关键优化：部分客户端上的并行候选训练、性能较差的候选提前丢弃和动态轮数。FedNAS在大规模数据集和典型CNN体系结构上进行了测试，它达到了与最先进的NAS算法相当的模型精度，该算法使用集中数据训练模型，并且与联邦NAS的直接设计相比，它还将客户机成本降低了两个数量级。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06352">PDF</a>
<h3>No. 69	抱紧我！判别特征对深网络边界的影响</h3><h4>Guillermo Ortiz-Jimenez, Apostolos Modas, Seyed-Mohsen Moosavi-Dezfooli, Pascal Frossard</h4>摘要：对神经网络的可解释性及其性质的重要认识在于其决策边界的形成。在这项工作中，我们借用了对抗稳健性领域的工具，提出了一个新的框架，可以将数据集的特征与数据样本沿特定方向到决策边界的距离联系起来。我们证明了深度学习的归纳偏差倾向于产生沿数据集非判别方向不变的分类函数。更令人惊讶的是，我们进一步证明，对数据样本的小扰动进行训练足以完全改变决策边界。这实际上是所谓的对抗训练用来产生强大分类器的特点。我们的总体框架可以用来揭示特定数据集特征对深度模型宏观特性的影响，并更好地理解深度学习的成功和局限性。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06349">PDF</a>
<h3>No. 70	基于流形的图像分类器测试生成</h3><h4>Taejoon Byun, Abhishek Vijayakumar, Sanjai Rayadurgam, Darren Cofer</h4>文摘：在关键应用中，用于图像分类任务的神经网络必须用足够的真实数据进行测试，以确保其正确性。为了有效地测试一个图像分类神经网络，必须获得足够的真实测试数据，以激发人们的信心，即隐式需求和学习模型之间的差异会暴露出来。这就提出了两个挑战：第一，必须仔细选择足够的数据点子集，以激发信心；第二，必须有意义地将隐含的要求外推到超出显式训练集中的数据点。本文提出了一个新的框架来应对这些挑战。我们的方法是基于这样一个前提：在一个大的输入数据空间中的模式可以在一个较小的流形空间中有效地捕获，从这个流形空间中可以采样和生成相似但新颖的测试用例——输入和标签。利用条件变分自动编码器（CVAE）的一个变种来捕获具有生成函数的流形，并在该流形空间上应用搜索技术来有效地查找故障揭示输入。实验表明，即使对于训练有素的模型，这种方法也能有效地生成成千上万个真实的、揭示错误的测试用例。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06337">PDF</a>
<h3>No. 71	双曲正火流的潜变量模型</h3><h4>Avishek Joey Bose, Ariella Smofsky, Renjie Liao, Prakash Panangaden, William L. Hamilton</h4>文摘：近似后验分布的选择在随机变分推理（VI）中起着核心作用。一个有效的解决方案是使用正规化流{Eclipse空间上定义的{{} }来构造灵活的后验分布。然而，现有的归一化流的一个关键限制是它们被限制到欧几里得空间，并且不具备用于建模具有底层层次结构的数据的能力。为了解决这一基本限制，我们提出了规范化流到双曲空间的第一个推广。我们首先使用定义在切线束上的耦合变换将规范化流提升到双曲空间，称为切线耦合（$\mathcal{TC}$）。我们进一步介绍了包裹双曲面耦合（$\mathcal{W}\mathbb{H}C$），这是一种完全可逆且可学习的变换，它显式地利用了双曲空间的几何结构，允许在高效采样的同时表示后验。我们证明了我们的新规范化流对双曲VAEs和欧氏规范化流的有效性。我们的方法提高了密度估计的性能，并重建了真实世界的图形数据，显示出层次结构。最后，我们证明了我们的方法可以使用双曲型潜在变量在分层数据上对生成模型进行幂化。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06336">PDF</a>
<h3>No. 72	果冻豆世界：永无止境学习的试验台</h3><h4>Emmanouil Antonios Platanios, Abulhair Saparov, Tom Mitchell</h4>摘要：近年来，机器学习取得了越来越大的成功。然而，目前的机器学习系统是高度专业化的，针对特定的问题或领域进行训练，通常是在一个狭窄的数据集上。另一方面，人类的学习具有高度的普遍性和适应性。永无止境的学习是一种机器学习范式，旨在弥合这一鸿沟，目的是鼓励研究人员设计机器学习系统，使其能够在更复杂的环境中学习执行更广泛的相互关联的任务。到目前为止，还没有环境或试验台来帮助开发和评估永无止境的学习系统。为此，我们提出了果冻豆世界试验台。果冻豆世界允许在二维网格世界中进行实验，这些网格世界中充满了项目，代理可以在其中导航。这个测试平台提供了足够复杂的环境，在这些环境中，更一般的智能算法应该比当前最先进的强化学习方法执行得更好。它通过产生非平稳环境和促进多任务、多智能体、多模式和课程学习环境的实验来实现。我们希望这一新的免费软件将促进新的研究和兴趣，在开发和评估永无止境的学习系统和更广泛的通用智能系统。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06306">PDF</a>
<h3>No. 73	马尔可夫报酬过程中折现值的循环估计</h3><h4>Falcon Z. Dai, Matthew R. Walter</h4>文摘：在强化学习折扣设置中常用和研究的策略迭代算法的工作中心，策略评估步骤利用马尔可夫决策过程中遵循马尔可夫策略所诱导的马尔可夫奖赏过程的样本来估计状态值。我们提出一个简单而有效的估计器，称为{emph{loop估计器}，它利用Markov奖赏过程的再生结构，而不必显式地估计一个完整的模型。我们的方法的空间复杂度为O（1）$，当估计一个正正循环状态的值$$不同于TD（带O（S）$）或基于模型的方法（用O（S^ 2）$）。此外，再生结构使我们能够显示，而不依赖于生成模型方法，估计器在一个样本路径上具有$\广角{O}（\qRt{{TuuSs/t}）的实例依赖收敛速率，超过$$$在一个样本路径上，其中$\ Tuuis$是状态$s$的最大预期命中时间。在初步的数值实验中，环路估计器的性能优于TD（k）等无模型方法，并且与基于模型的估计器具有竞争性。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06299">PDF</a>
<h3>No. 74	至少让我了解一下你真正喜欢什么：在学习偏好时与吵闹的人类打交道</h3><h4>Sriram Gopalakrishnan, Utkarsh Soni</h4>摘要：学习人的偏好可以提高人与人的互动质量。可用于学习偏好的查询数量可能有限，特别是在与人交互时，因此必须进行主动学习。主动学习的一种方法是使用不确定性抽样来确定查询的信息性。本文提出了一种改进的不确定性抽样方法，利用期望输出值来加速偏好的学习。我们将我们的方法与不确定抽样基线进行比较，并进行消融研究以检验我们方法的每个组成部分的有效性。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06288">PDF</a>
<h3>No. 75	马尔可夫抽样下Adam型强化学习算法的非渐近收敛性</h3><h4>Huaqing Xiong, Tengyu Xu, Yingbin Liang, Wei Zhang</h4>文摘：尽管Adam在强化学习（RL）中有着广泛的应用，但Adam型RL算法的理论收敛性尚未建立。本文首次对包含AMSGrad更新（理论分析中Adam的标准替代）的策略梯度（PG）和时间差分（TD）学习两种基本RL算法（PG-AMSGrad和TD-AMSGrad）进行了收敛性分析。此外，我们的分析集中在两种算法的马尔可夫抽样上。我们表明，在一般非线性函数逼近下，具有常数步长的PG AMSGRAGE收敛到一个固定点的邻域，其速率为$\ MathCAL{O}（1／T）$（其中$ T$表示迭代次数），并且随着步长的减小，以$\ MathCAL{O}（\log 2 ^ /\SqRT {t}）的速率收敛到平稳点。此外，在线性函数逼近下，具有常数步长的TD-AMSGRAD收敛到以$\ MathCAL{O}（1／t）$的速率的全局最优的邻域，并且随着步长的减小，以$\ MathCAL{O}（\ log t/\qRt{t}）的速率收敛到全局最优值。我们的研究为分析马尔可夫抽样下的Adam型RL算法提供了新的技术。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06286">PDF</a>
<h3>No. 76	算法追索：从反事实解释到干预</h3><h4>Amir-Hossein Karimi, Bernhard Schölkopf, Isabel Valera</h4>摘要：随着机器学习越来越多地被用于辅助决策（如审前保释和贷款批准），解释系统是如何做出决定的，并提出实现有利决策的措施变得非常重要。反事实的解释——“为了达到理想的结果，世界将如何（不得不）变得不同”——旨在满足这些标准。现有的工作主要集中于设计算法，以获得广泛的设置的反事实解释。然而，“解释作为帮助数据主体行为而不仅仅是理解的手段”的主要目标之一却被忽视了。通俗地说，反事实的解释告诉一个人他们需要去哪里，而不是如何去那里。在这项工作中，我们依靠因果推理来警告不要使用反事实的解释作为一套建议的追索行动。相反，我们提出了一个范式的转变，从通过最近的反事实解释求助到通过最小的干预求助，将焦点从解释转移到建议。最后，我们为读者提供了一个广泛的讨论，即如何在结构干预之外实现实际的求助。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06278">PDF</a>
<h3>No. 77	两人零和对策的平均场分析</h3><h4>Carles Domingo-Enrich, Samy Jelassi, Arthur Mensch, Grant Rotskoff, Joan Bruna</h4>文摘：在两人零和连续博弈中寻找纳什均衡是机器学习中的一个核心问题，例如用于训练GANs模型和鲁棒模型。纯纳什平衡的存在需要强的条件，这在实践中通常不满足。混合纳什均衡存在更大的一般性，可以发现使用镜像下降。然而，这种方法并没有扩展到高维度。为了解决这一限制，我们将混合策略参数化为粒子的混合，粒子的位置和权重使用梯度下降-上升更新。我们将此动力学作为一个相互作用的梯度流，在具有Wasserstein-Fisher-Rao度量的测度空间上进行研究。我们建立全局收敛到近似平衡的相关Langevin梯度上升动态。我们证明了一个将粒子动力学与平均场动力学联系起来的大数定律。我们的方法在高维中识别混合平衡，并且对于训练混合甘氨酸是有效的。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06277">PDF</a>
<h3>No. 78	为什么深度残差网络比深度前馈网络更具普遍性？--神经切线核透视图</h3><h4>Kaixuan Huang, Yuqing Wang, Molei Tao, Tuo Zhao</h4>文摘：深度残差网络（ResNets）比深度前馈网络（FFNets）具有更好的泛化性能。然而，这种现象背后的理论在很大程度上仍是未知的。本文从“神经切核”的角度研究了深度学习中的这一基本问题。具体地说，我们首先证明在适当的条件下，当宽度趋于无穷大时，训练深度resnet可以看作是用某种核函数学习再生核函数。然后，我们比较了深度resnet和深度ffnet的核，发现当深度趋于无穷大时，由ffnet核所诱导的函数类是渐近不可学习的。与此相反，ResNets核所诱导的函数类并没有表现出这种简并性。我们的发现部分证明了深度重网在泛化能力上优于深度ffnet。数值结果支持我们的索赔。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06262">PDF</a>
<h3>No. 79	运动皮层刺激与肌肉反应的映射：一种深部神经网络建模方法</h3><h4>Md Navid Akbar, Mathew Yarossi, Marc Martinez-Gost, Marc A. Sommer, Moritz Dannhauer, Sumientra Rampersad, Dana Brooks, Eugene Tunik, Deniz Erdoğmuş</h4>文摘：深部神经网络（DNN）能够可靠地模拟相应脑刺激引起的肌肉反应，有可能为许多基础科学和应用案例增加协调运动控制的知识。这些案例包括了解由于中风造成的神经损伤而导致的异常运动模式，以及基于刺激的神经康复干预措施，如成对联合刺激。在这项工作中，我们探索了潜在的DNN模型，并推荐了最小平方误差的模型来优化M2M网络的性能，M2M网络是一个将运动皮层的经颅磁刺激映射到相应肌肉反应的网络，使用：有限元模拟，经验神经反应曲线，卷积自动编码器，一个单独的深度网络映射器，和多肌肉激活的记录。我们讨论了不同建模方法和架构背后的基本原理，并对比了它们的结果。此外，为了获得复杂性和性能分析之间的权衡的比较洞察力，我们探索不同的技术，包括扩展的两个经典的信息标准M2M网。最后，我们发现，当输入端使用神经反应曲线时，类似于将运动皮层刺激映射为与肌肉直接和协同连接的组合的模型表现最佳。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06250">PDF</a>
<h3>No. 80	积极主动的重症监护室转移的稳健政策</h3><h4>Julien Grand-Clement, Carri W. Chan, Vineet Goyal, Gabriel Escobar</h4>摘要：非计划转入重症监护病房（ICU）的病人，其死亡率比直接转入ICU的病人高。机器学习预测病人病情恶化的最新进展已经引入了将病人从病房转移到ICU的可能性。在这项工作中，我们研究了在优化以改善整体患者护理时，如何找到在统计估计中由于数据限制而导致不确定性的{emph{robust}患者转移策略的问题。我们提出一个马尔可夫决策过程模型来捕捉病人健康的演变，其中状态代表病人严重程度的度量。在相当一般的假设下，我们证明了最优转移策略有一个阈值结构，即它将超过一定严重程度的所有患者转移到ICU（取决于可用容量）。由于模型参数通常是根据实际数据的统计估计来确定的，因此它们在本质上会受到错误说明和估计误差的影响。我们通过推导一个稳健的策略来解释这个参数的不确定性，该策略在模型参数的所有可能值中优化最坏情况下的回报。我们证明在相当一般的假设下，稳健策略也有一个阈值结构。此外，与不考虑参数不确定性的最优名义策略相比，它在转移患者方面更具攻击性。我们使用21家KNPC医院的住院数据进行了计算实验，并提供了各种医院指标（死亡率、住院时间、平均ICU入住率）对参数微小变化的敏感性的经验证据。我们的工作提供了有用的见解，对参数不确定性的影响，推导出简单的政策，主动重症监护室转移，有很强的经验表现和理论保障。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06247">PDF</a>
<h3>No. 81	状态变量、Bandit问题与POMDPs</h3><h4>Warren B Powell</h4>摘要：状态变量是序列决策问题中最微妙的维度。在主动学习问题（bandit问题）中尤其如此，在这种情况下，决策会影响我们观察和学习的内容。我们描述了建模{it any}顺序决策问题的规范框架，并给出了允许我们声明的状态变量的定义：任何正确建模的顺序决策问题都是马尔可夫的。然后，我们提出了部分可观测马尔可夫决策问题（POMDPs）的一个新的两代理视角，它允许我们宣称：任何实际决策问题的模型（可能）都是非马尔可夫的。我们使用观察和治疗人群中流感的背景来说明这些观点，并在此背景下提供所有四类政策的示例。最后，我们将说明如何将这种思想扩展到多代理问题。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06238">PDF</a>
<h3>No. 82	基于多层感知器和鲸鱼优化算法混合模型的风速预测</h3><h4>Saeed Samadianfard, Sajjad Hashemi, Katayoun Kargar, Mojtaba Izadyar, Ali Mostafaeipour, Amir Mosavi, Narjes Nabipour, Shahaboddin Shamshirband</h4>摘要：风电作为一种可再生能源，具有众多的经济、环境和社会效益。为了提高和控制可再生风力发电，必须利用高精度的风速预测模型。由于忽略了数据预处理的要求和意义，忽略了单一预测模型的不足，许多传统模型在风速预测方面的性能较差。在目前的研究中，为了预测伊朗北部目标站的风速，将多层感知器模型（MLP）与鲸鱼优化算法（WOA）相结合，在有限的数据集上建立了新的方法（MLP-WOA）（2004-2014）。然后，在10个目标站中的每个站使用MLP-WOA模型，其中9个站用于训练，第10个站用于测试（即：Astara、Bandar-E-Anzali、Rasht、Manjil、Jirandeh、Talesh、Kiyashahr、Lahijan、Masuleh和Deylaman），以提高后续混合模型的准确性。比较了混合模型与无WOA优化的MLP模型在各目标站风速预测中的性能。为了确定确切的结果，使用了大量的统计性能。对于所有十个目标站，MLP-WOA模型比独立的MLP模型有精确的结果。该混合模型的RMSE、SI和RE参数较低，NSE、WI和KGE参数较高，性能良好。结果表明，WOA优化算法可以提高MLP模型的预测精度，可用于准确的风速预测。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06226">PDF</a>
<h3>No. 83	自我关注的窃电检测</h3><h4>Paulo Finardi, Israel Campiotti, Gustavo Plensack, Rafael Derradi de Souza, Rodrigo Nogueira, Gustavo Pinheiro, Roberto Lotufo</h4>文摘：针对国家电网公司提供的一个日用电量数据集，提出了一种新的基于不平衡现实数据集的窃电检测自关注机制模型。我们的主要贡献是引入了一种多头自注意机制，该机制与扩展卷积连接，并由核大小为$1$的卷积统一。此外，我们引入一个二进制输入通道（二进制掩码）来识别缺失值的位置，使网络能够学习如何处理这些值。我们的模型实现了0.926美元的AUC，比以前的基线工作提高了17%以上。该代码可以在GitHub上的这个https URL上找到<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06219">PDF</a>
<h3>No. 84	基于多智能体深度强化学习的无线网络资源管理</h3><h4>Navid Naderializadeh, Jaroslaw Sydir, Meryem Simsek, Hosein Nikopour</h4>文摘：提出了一种基于多智能体深度强化学习（RL）的无线网络分布式资源管理机制。我们为网络中的每个发射机配备了一个深度RL代理，该代理接收来自其关联用户的部分延迟观测，同时还与相邻的代理交换观测，并决定在每个调度间隔使用哪个用户和哪些发射功率。我们提出的框架使代理能够同时以分布式的方式做出决策，而不需要知道其他代理的并发决策。此外，我们对代理的观察和行动空间的设计是可伸缩的，因为在特定数量的发射器和接收器的场景中训练的代理可以容易地应用于具有不同数量的发射器和/或接收器的场景。仿真结果表明，与分散基线相比，本文提出的方法在平均用户速率和5^{th}$percentile用户速率之间的折衷方面具有优越性，同时性能接近，甚至在某些情况下优于集中式信息论调度算法。我们还表明，我们的训练有素的代理是健壮的，并在遇到培训和测试部署不匹配时保持其性能增益。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06215">PDF</a>
<h3>No. 85	基于互信息有效近似的快速公平回归</h3><h4>Daniel Steinberg, Alistair Reid, Simon O'Callaghan, Finnian Lattimore, Lachlan McCalman, Tiberio Caetano</h4>摘要：迄今为止，在算法公平性方面的大部分工作都集中在离散的结果上，比如决定是否给某人贷款。在这些分类设置中，可以通过比较不同亚群之间的结果率来直接衡量群体公平性标准，如独立性、分离性和充分性。然而，许多重要的问题都需要预测实际价值的结果，如风险分数或保险费。在这样的回归设置中，测量组公平性标准在计算上是有挑战性的，因为它需要估计条件概率密度函数之间的信息论分歧。本文介绍了从它们的（条件）互信息定义的回归模型的独立性、分离性和充分性组公平标准的快速近似，并使用这种近似作为正则化来在正则化风险最小化框架内执行公平性。在真实数据集上的实验表明，尽管我们的算法具有优越的计算效率，但仍然显示出最先进的精度/公平性折衷。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06200">PDF</a>
<h3>No. 86	精密浇口：动态双精度激活提高神经网络效率</h3><h4>Yichi Zhang, Ritchie Zhao, Weizhe Hua, Nayun Xu, G. Edward Suh, Zhiru Zhang</h4>文摘：提出了一种适用于深部神经网络的端到端可训练动态双精度量化技术——精密选通（PG）。PG以较低的精度计算大多数特征，而以较高的精度计算只有一小部分重要特征以保持精度。该方法适用于多种DNN体系结构，大大降低了DNN执行的计算成本，几乎没有精度损失。我们的实验表明，PG在CNNs上取得了很好的效果，包括静态压缩的移动友好网络，如ShuffleNet。与目前最先进的基于预测的量化方案相比，PG在ImageNet上的计算量减少了2.4美元，达到了相同或更高的精度。PG还适用于RNNs。与8位均匀量化相比，PG在PNN树银行数据集上对每一个字的困惑获得了1.2%的改善，2.7的计算成本降低了LSTM。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07136">PDF</a>
<h3>No. 87	基于图注意网络的单细胞疾病状态预测</h3><h4>Neal G. Ravindra, Arijit Sehanobish, Jenna L. Pappalardo, David A. Hafler, David van Dijk</h4>文摘：单细胞RNA序列分析（scRNA-seq）为生物学的发现带来了革命性的进展，它提供了组织中细胞异质性的无偏图像。虽然scRNA-seq被广泛用于提供对健康和疾病的洞察，但它并没有被用于疾病预测或诊断。图形注意网络通过从原始特征和图形结构中学习，已被证明在广泛的任务中具有多用途。在这里，我们提出了一个图表注意模型，用于预测多发性硬化（MS）患者的大数据集上的单细胞数据的疾病状态。MS是一种中枢神经系统疾病，很难诊断。我们利用从血液和脑脊液（CSF）中获得的单细胞数据为一组7名MS患者和6名健康成人（HA）训练我们的模型，得到66667个单个细胞。我们在预测MS方面达到了$\mathbf{92}$\%的准确率，优于其他最新的方法，如图卷积网络、随机森林和多层感知器。此外，我们使用学习的图形注意模型来洞察对预测非常重要的特征（细胞类型和基因）。图形注意模型还允许我们为细胞推断一个新的特征空间，强调这两个条件之间的差异。最后，我们使用注意权重来学习一个新的低维嵌入，我们用PHATE和UMAP进行可视化。据我们所知，这是第一次尝试使用图形注意和深度学习，从单细胞数据预测疾病状态。我们设想将这种方法应用于其他疾病的单细胞数据。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07128">PDF</a>
<h3>No. 88	XCAT解剖模型的4D心磁共振图像合成</h3><h4>Samaneh Abbasi-Sureshjani, Sina Amirrajab, Cristian Lorenz, Juergen Weese, Josien Pluim, Marcel Breeuwer</h4>文摘：提出了一种混合可控图像生成方法，用于合成具有解剖学意义的3D+t标记心脏磁共振（CMR）图像。我们的混合方法以机械性4D扩展心脏躯干（XCAT）心脏模型为解剖基础，通过数据驱动的生成性对抗网络（GAN）合成CMR图像。我们采用最新的空间自适应去规范化（SPADE）技术进行条件图像合成，以保留基本真实解剖的语义空间信息。使用XCAT心脏的参数化运动模型，我们在短轴视图的18个位置为一个心动周期产生心脏的25个时间帧的标签。随后，从这些标签生成真实图像，具有从真实CMR图像数据中学习到的模态特定特征。我们证明使用样式编码器网络可以从另一个心脏图像完成样式转换。由于XCAT在创建新心脏模型中的灵活性，这种方法可以导致现实的虚拟群体来解决医学图像分析研究社区所面临的不同挑战，例如昂贵的数据收集。本文提出的方法具有很好的应用潜力，可以合成具有注释和自适应样式的4D可控CMR图像，应用于医学图像分析中的各种有监督的多站点、多供应商应用。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07089">PDF</a>
<h3>No. 89	基于深度学习视觉分类的物理硬标签查询攻击</h3><h4>Ryan Feng, Jiefeng Chen, Nelson Manohar, Earlence Fernandes, Somesh Jha, Atul Prakash</h4>文摘：提出了一种在黑盒硬标签设置中的物理对抗示例算法生存选择算法，攻击者只能访问模型预测类标签。假设这种对模型的有限访问与之前的工作假设的白盒设置相比，对于专有网络物理和云系统等设置更为相关。利用物理攻击的特性，提出了一种基于物理变换扰动生存性的攻击方法。通过简单地查询硬标签预测模型，我们优化扰动以在许多不同的物理条件下生存，并表明即使在硬标签威胁模型中，对抗性示例仍然是网络物理系统（cps）的安全风险。我们证明了Survival OPT是一种高效且健壮的查询方法：使用少于200K的查询，我们成功地通过设置在98.5%的视频帧中攻击了一个被误分类为限速30km/hr的停车标志。生存OPT也优于现有的硬标签和物理方法的基线组合，这需要超过10倍的查询来获得不太健壮的结果。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07088">PDF</a>
<h3>No. 90	PCSGAN：用于热图像和近红外图像到可见光图像转换的感知循环合成生成对抗网络</h3><h4>Kancharagunta Kishan Babu, Shiv Ram Dubey</h4>摘要：在现实生活中，由于光照条件的影响，在可见光光谱中很难捕捉到图像。然而，在这种情况下，可以使用近红外（NIR）和热（THM）摄像机拍摄图像。近红外和THM图像包含有限的细节。因此，需要将图像从THM/NIR转换为VIS，以便更好地理解。然而，由于存在较大的领域差异和缺乏丰富的数据集，这是一项非平凡的任务。目前，生成性对抗网络（generativedepartarialnetwork，GAN）能够将图像从一个域转换到另一个域。现有的基于GAN的训练方法大多采用对抗性和像素损失（如L1或L2）相结合的方法作为训练目标函数。在THM/NIR-VIS变换的情况下，用这种目标函数变换后的图像质量仍然达不到要求。因此，需要更好的目标函数来提高变换图像的质量、细节和真实感。为了解决这一问题，提出了一种新的THM/NIR-VIS图像转换模型：感知循环合成生成对抗网络（PCSGAN）。PCSGAN使用感知（即基于特征的）损失、像素损失和对抗性损失的组合。采用定量和定性方法对PCSGAN模型在WHU-IIP人脸和RGB-NIR场景数据集上的性能进行了评价。所提出的PCSGAN在SSIM、MSE、PSNR和LPIPS评价指标方面优于现有的图像转换模型，包括Pix2pix、DualGAN、CycleGAN、PS2GAN和PAN。代码可在以下位置获得：url{this https url}。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07082">PDF</a>
<h3>No. 91	具有局部和全局约束的可伸缩二元独立模型</h3><h4>Florian Adriaens, Alexandru Mara, Jefrey Lijffijt, Tijl De Bie</h4>文摘：指数随机图（ERGs）领域的一个重要挑战是在大型网络上拟合非平凡ERGs。通过利用矩阵块近似技术，我们提出了一个近似框架，这样的非平凡的ERG，导致二元独立性（即，边缘无关）模型，同时能够有意义地建模本地信息（度）以及全局信息（聚类系数，分类等），如果需要的话。这使得我们能够有效地生成具有与观测网络相似特性的随机网络，可扩展到由数百万个节点组成的稀疏图。实证分析表明，该方法在准确度方面具有较强的竞争力。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07076">PDF</a>
<h3>No. 92	基于时频卷积神经网络的双线性池声场景分类</h3><h4>Xing Yong Kek, Cheng Siong Chin, Ye Li</h4>文摘：目前处理声场景分类（ASC）任务的方法可以分为两步：将音频波形预处理成对数mel谱图，然后将其作为卷积神经网络（CNN）的输入表示。这种范式转换发生在DCASE2016之后，该框架模型在（ESC-50）数据集上实现了ASC任务的最新结果，精度达到64.5%，比基线模型提高了20.5%，DCASE2016数据集的精度达到90.0%（开发）和86.2%（评估），这构成了与基线系统相比分别提高了6.4%和9%。本文探讨了利用和声与打击声源分离（HPSS）将音频分为和声与打击声，在音乐信息检索（MIR）领域得到了广泛的应用。在ASC任务中，虽然已经用HPSS作为CNN模型的输入表示做了一些工作，但本文进一步研究了利用分离的谐波分量和敲击分量，通过两个CNN来理解谐波和敲击音的自然形式的可能性，一个专门提取时偏域的深层特征，另一个专门提取频偏域的深层特征。从这两个cnn中提取的深层特征将使用双线性池进行组合。因此，提出了一种双流时频CNN结构的声场景分类方法。该模型正在DCASE 2019子任务1a数据集上进行评估，在开发数据集Kaggle Leadership Private and Public board上的平均得分为65%。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07065">PDF</a>
<h3>No. 93	生物随机游动：在疾病基因排序中整合异质数据</h3><h4>Michele Gentili, Leonardo Martini, Manuela Petti, Lorenzo Farina, Luca Becchetti</h4>摘要：本文提出了一个在基于网络传播的基因优先算法中利用生物信息的统一框架。乳腺癌数据的初步结果显示，与最先进的基线相比，基因的优先级有了显著的提高，例如未通过基于交互作用的算法确定为潜在候选基因，但似乎与乳腺癌有关/或可能与乳腺癌有关的基因的优先级，根据最近文献的功能分析。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07064">PDF</a>
<h3>No. 94	基于神经网络处理器结构的批处理加速优化调度体系结构</h3><h4>Phani Kumar Nyshadham, Mohit Sinha, Biswajit Mishra, H S Vijay</h4>摘要：在神经网络拓扑中，算法是在成批的数据张量上运行的。数据批通常被调度到并行执行的计算核心上。对于运行在成批数据上的算法，通过适当利用硬件资源，需要一个最优的成批调度体系结构，从而大大减少训练和推理时间。在本文中，我们建议通过一个调度架构来加速神经网络的批处理算法，以实现最佳的计算功率利用率。所提出的优化调度体系结构可以构建在硬件中，也可以单独在软件中实现，这可以用来加速批处理算法。结果表明，与以往的算法相比，该结构加快了批处理算法的速度。所提出的思想适用于任何用于神经网络的HPC架构。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07062">PDF</a>
<h3>No. 95	通过学习产生定理来学习证明定理</h3><h4>Mingzhe Wang, Jia Deng</h4>文摘：我们认为自动定理证明是人工智能的关键任务。深度学习对于训练定理证明者是有希望的，但是对于有监督的学习来说，人类书写的定理和证明是有限的。为了解决这一局限性，我们提出学习一个自动综合定理和证明的神经生成器，以训练定理证明器。在实际任务上的实验表明，该方法的综合数据改进了定理证明器，提高了元数学中定理自动证明的技术水平。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07019">PDF</a>
<h3>No. 96	用于音乐源分离的元学习提取器</h3><h4>David Samuel, Aditya Ganeshan, Jason Naradowsky</h4>文摘：提出了一种基于分层元学习的音乐源分离模型（meta-TasNet），该模型使用生成器模型来预测单个提取器模型的权重。这样可以实现有效的参数共享，同时还允许特定于仪器的参数化。Meta-TasNet被证明比独立训练或多任务环境下训练的模型更有效，并且实现了与最新方法相当的性能。与后者相比，我们的提取器包含的参数更少，运行时性能更快。我们讨论了重要的架构考虑因素，并探讨了这种方法的成本和好处。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07016">PDF</a>
<h3>No. 97	生成模型提出的分子可合成性</h3><h4>Wenhao Gao, Connor W. Coley</h4>摘要：功能分子的发现是一个昂贵而耗时的过程，小分子治疗性发现的成本不断上升就是一个例证。在新的深度学习方法的推动下，新的分子生成和优化技术是早期药物发现的一类越来越受关注的技术。这些技术可以建议新的分子结构，旨在最大化多目标函数，例如，适合于针对特定目标的治疗，而不依赖于化学空间的强力探索。然而，这些方法的实用性由于对可综合性的无知而受到阻碍。为了突出这个问题的严重性，我们使用一个数据驱动的计算机辅助合成规划程序来量化由最先进的生成模型提出的分子不容易合成的频率。我们的分析表明，尽管这些模型在流行的定量基准上表现良好，但仍有一些任务产生了不现实的分子结构。合成复杂性启发式可以成功地将生成偏向合成可处理的化学空间，虽然这样做必然减损了主要目标。分析表明，为了提高这些模型在实际发现工作流中的实用性，需要开发新的算法。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07007">PDF</a>
<h3>No. 98	约束自洽极小化的Newton-Frank-Wolfe方法</h3><h4>Deyi Liu, Volkan Cevher, Quoc Tran-Dinh</h4>文摘：利用约束集上的线性极小化oracles（LMO）证明了如何可标度地求解一类约束自洽极小化问题。证明了在L-光滑情形下，我们方法的LMO调用次数与Frank Wolfe方法的LMO调用次数几乎相同。具体来说，我们的Newton-Frank-Wolfe方法使用$\mathcal{O}（\epsilon^{-\nu}）$LMO，其中$\epsilon$是所需的精度，而$\nu:=1+O（1）$。此外，我们还演示了我们的算法如何利用基于LMO的方案的改进变体（包括远离步数）来获得线性收敛速度。我们还为具有竞争比率的投资组合设计、D-最优实验设计以及牛顿-弗兰克-沃尔夫（Newton-Frank-Wolfe）优于最新水平的弹性网络logistic回归提供了数值证据。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07003">PDF</a>
<h3>No. 99	二进制网络的学习结构</h3><h4>Kunal Pratap Singh, Dahyun Kim, Jonghyun Choi</h4>摘要：大多数二进制网络的骨干结构都是著名的浮点结构，如ResNet家族。针对浮点网络的体系结构不适合二进制网络的问题，我们提出了二进制网络体系结构（BNAS）的搜索方法。具体来说，在基于单元的搜索方法的基础上，我们定义了一组新的层类型，设计了一个新的单元模板，重新发现了零层的实用性，并提出使用零层来学习性能良好的二进制网络。此外，我们建议多样化的早期搜索，以学习性能更好的二进制架构。我们的搜索二进制网络在CIFAR10和ImageNet数据集上的性能优于最新的二进制网络。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06963">PDF</a>
<h3>No. 100	引文推荐：方法和数据集</h3><h4>Michael Färber, Adam Jatowt</h4>摘要：引文推荐是指对给定文本进行引文推荐的任务。由于近年来发表的科学著作一方面超载，另一方面在撰写科学文本时需要引用最合适的出版物，引文推荐已成为一个重要的研究课题。近年来，提出了几种方法和评价数据集。然而，据我们所知，没有对引文推荐进行明确的文献调查。本文对引文自动推荐的研究进行了深入的介绍。然后，我们对引文推荐的方法和数据集进行了概述，并使用不同的维度确定了差异和共性。最后，我们对评估方法进行了说明，并概述了评估中的一般挑战以及如何应对这些挑战。我们仅限于科学出版物的引文推荐，因为这类文献在这方面的研究最多。然而，本次调查中的许多观察和讨论也适用于其他类型的文本，如新闻文章和百科全书文章。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06961">PDF</a>
<h3>No. 101	政策梯度的自适应经验选择</h3><h4>Saad Mohamad, Giovanni Montana</h4>摘要：策略梯度强化学习（RL）算法在连续性控制等挑战性学习任务中取得了令人瞩目的成绩，但仍存在较高的样本复杂度。经验重演是提高样本效率的常用方法，但使用过去轨迹的梯度估计器通常具有高方差。现有的采样策略，如均匀采样或优先体验重放的经验重放没有明确尝试控制梯度估计的方差。本文提出了一种在线学习算法，即自适应经验选择（AES），以自适应地学习一个经验抽样分布，该分布能显式地最小化这种方差。使用后悔最小化方法，AES迭代更新经验抽样分布，以匹配假设具有最优方差的竞争对手分布的性能。针对样本非平稳性，提出了一种动态（即时变）竞争分布，并给出了一种闭式解。我们证明了AES是一个低后悔算法，具有合理的样本复杂度。在经验上，AES已经被用于深度确定的策略梯度和软参与者批评算法，并在OpenAI体育馆库中的8个连续控制任务上进行了测试。我们的结果显示，与目前可用的策略梯度经验抽样策略相比，AES显著提高了性能。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06946">PDF</a>
<h3>No. 102	放大神秘</h3><h4>Terence Broad, Frederic Fol Leymarie, Mick Grierson</h4>摘要：深度神经网络在制造逼真的深度假象方面已经变得非常出色，人们的图像（对未经训练的人来说）与真实的图像无法区分。这些是由学习区分真假图像的算法生成的，并经过优化以生成系统认为真实的样本。本文，以及由此产生的一系列艺术作品被挫败，探索了逆转这一过程，而不是优化系统，以产生它认为是假的图像的审美结果。最大化数据的不可能性，进而放大这些机器幻觉的不可思议性质。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06890">PDF</a>
<h3>No. 103	基于可解释神经网络回归的大型生物测量学</h3><h4>Taro Langner, Håkan Ahlström, Joel Kullberg</h4>摘要：英国生物银行的这项研究成功地为32000多名志愿者进行了颈部到膝盖的身体核磁共振成像。每次扫描都链接到大量的元数据，提供了对成像解剖学和相关健康状态的全面调查。尽管有研究的潜力，但这大量的数据对现有的评估方法提出了挑战，这些方法通常依赖于人工输入。迄今为止，心血管和代谢危险因素的参考值范围是不完整的。在这项工作中，神经网络被训练用于回归，以自动推断从颈部到膝盖的身体MRI的各种生物学指标。该方法无需人工干预或地面真相分割训练。研究领域涉及64个变量，这些变量来自人体测量、双能X射线吸收测量（DXA）、基于图谱的分割和专用肝脏扫描。标准化框架与ResNet50进行了7倍交叉验证，与目标值（中值R^2>0.97）非常吻合。对聚合显著性地图的解释表明，该网络正确地针对特定的身体区域和四肢，并学会了模拟不同的模式。在几个身体成分指标上，预测的质量在已建立的金标准技术之间观察到的变异范围内。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06862">PDF</a>
<h3>No. 104	抽象视觉推理的层次规则归纳网络</h3><h4>Sheng Hu, Yuqing Ma, Xianglong Liu, Yanlu Wei, Shihao Bai</h4>摘要：抽象推理是指对信息进行分析，在无形的层面上发现规律，以创新的方式解决问题的能力。Raven的渐进矩阵（RPM）测试通常用于检查抽象推理的能力。在测试中，要求受试者根据矩阵中的基本规则，从答案集中确定正确的选择，以填充RPM右下角缺少的面板（例如，3$\times$3矩阵）。近年来，利用卷积神经网络（CNNs）的优势，在解决转速测试问题上取得了可喜的进展。不幸的是，仅仅依赖于矩阵级的关系抽取，他们无法识别RPM中行/列内部或跨行/列的复杂属性模式。为了解决这一问题，本文提出了一种层次化的规则归纳网络（HriNet），它通过暗示人类的归纳策略。HriNet从不同层次提取多粒度规则嵌入，并通过门控嵌入融合模块进行集成。我们进一步引入了一种基于嵌入的规则相似度度量，使得HriNet不仅可以利用元组损失进行训练，而且可以根据相似度得分推断出最佳答案。为了全面评估HriNet，我们首先修复了最近RAVEN数据集中包含的缺陷，并生成了一个新的称为Balanced RAVEN的数据集。然后在大规模数据集PGM和我们的平衡RAVEN上进行了大量的实验，结果表明HriNet在很大程度上优于最新的模型。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06838">PDF</a>
<h3>No. 105	歌手识别中伴奏的混淆</h3><h4>Tsung-Han Hsieh, Kai-Hsiang Cheng, Zhe-Cheng Fan, Yu-Ching Yang, Yi-Hsuan Yang</h4>摘要：歌手识别是一项重要的工作，有着广泛的应用。然而，由于许多问题，这项任务仍然具有挑战性。一个主要的问题是，在音乐制作中，背景器乐与人声混用的混淆因素。歌手识别模型可以学习从歌曲的器乐部分提取非声乐相关特征，如果歌手只在特定的音乐环境（例如，流派）中演唱。因此，当歌手在看不见的环境中演唱时，这个模型就不能很好地概括。在本文中，我们试图解决这个问题。具体来说，我们使用开源的unmix工具，一个在源代码分离方面具有最先进性能的开源工具，来分离音乐的声乐和器乐曲目。然后，我们研究了两种方法来训练歌手识别模型：仅从分离的人声中学习，或从一组增加的数据中“洗牌和混音”不同歌曲的分离的人声轨迹和器乐轨迹，以人为地使歌手在不同的上下文中演唱。我们还结合了从声乐旋律轮廓学习到的旋律特征，以获得更好的表现。在一个名为artist20的基准数据集上的评估结果表明，这种数据增强方法大大提高了歌手识别的准确性。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06817">PDF</a>
<h3>No. 106	论说教与对抗性例子中深层学习表征的相似性</h3><h4>Pamela K. Douglas, Farzad Vasheghani Farahani</h4>文摘：深度神经网络（DNNs）的日益广泛应用促使了一项平行的努力：设计从成功的错误分类中获利的对手。然而，并非所有的对抗性例子都是出于恶意目的而精心设计的。例如，现实世界中的系统通常包含跨仪器的物理、时间和采样可变性。在野外对抗性的例子可能无意中证明对准确的预测模型有害。相反，自然发生的图像特征协方差可以用于教学目的。在这里，我们研究了深度学习表征在神经影像学分类中的稳定性，这种分类是在不同的教学和对抗条件下进行的。结果表明，在输入空间中，对抗性例子的出现频率不同，表现出的相似性和表现也不同。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06816">PDF</a>
<h3>No. 107	利用离线分析模拟ML系统的性能</h3><h4>Hongming Huang, Peng Cheng, Hong Xu, Yongqiang Xiong</h4>文摘：我们认为基于离线评测的仿真是一种有希望的方法，可以更好地理解和改进复杂的ML系统。我们的方法使用操作级分析和基于数据流的模拟，以确保为所有框架和ML模型提供一个统一和自动化的解决方案，并且通过考虑实际系统中的各种并行化策略也很精确。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06790">PDF</a>
<h3>No. 108	如何在业余时间拥有NAS</h3><h4>Sanghyun Hong, Michael Davinroy, Yiğitcan Kaya, Dana Dachman-Soled, Tudor Dumitraş</h4>摘要：新的数据处理管道和新的网络结构日益推动着深度学习的成功。因此，业界将性能最好的架构视为知识产权，并投入大量计算资源通过神经架构搜索（NAS）来发现此类架构。这为对手窃取这些新架构提供了激励；当在云中使用时，为了提供机器学习服务，对手也有机会通过利用一系列硬件侧通道来重建架构。然而，在不知道计算图（例如，层、分支或跳过连接）、结构参数（例如，卷积层中的滤波器数量）或特定预处理步骤（例如，嵌入）的情况下重建新的架构和管道是一项挑战。本文设计了一种新的深度学习系统的关键部件重构算法，该算法利用了缓存侧信道攻击Flush+Reload带来的少量信息泄漏。我们使用Flush+Reload来推断计算的轨迹和每次计算的时间。然后，我们的算法从跟踪中生成候选计算图，并通过参数估计过程消除不兼容的候选。我们在PyTorch和Tensorflow中实现了我们的算法。实验证明，我们可以重建MalConv（一种用于恶意软件检测的新型数据预处理管道）和ProxylessNAS-CPU（一种用于优化在CPU上运行的ImageNet分类的新型网络体系结构），而无需知道体系结构族。在这两种情况下，我们都会得到0%的误差。这些结果表明，硬件侧信道是一种实用的针对MLaaS的攻击载体，应进一步研究其对深度学习系统安全性的影响。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06776">PDF</a>
<h3>No. 109	正则化信息最大化的卷积神经网络超像素分割</h3><h4>Teppei Suzuki</h4>文摘：提出了一种在推理时间内优化随机初始化卷积神经网络（CNN）的无监督超像素分割方法。我们的方法通过CNN从没有任何标签的单一图像中生成超像素，通过最小化在推理时间内提出的超像素分割目标函数。与现有的许多方法相比，我们的方法有三个优点：（i）利用美国有线电视新闻网之前的图像进行超像素分割，（ii）根据给定的图像自适应地改变超像素的数量，以及（iii）通过向目标函数添加辅助成本来控制超像素的性质。我们在BSDS500和SBD数据集上定量和定性地验证了该方法的优势。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06765">PDF</a>
<h3>No. 110	（个人）公平性$k$-集群</h3><h4>Sepideh Mahabadi, Ali Vakilian</h4>文摘：从个体公平的角度出发，提出了一种基于局部搜索的$k$-中值（$k$-均值）聚类算法。更准确地说，对于$x$点集$P$的大小$n$，设$r（x）$为最小半径，使得以$x$为中心的半径$r（x）$球从$P$至少有$n/k$点。直观地说，如果从$P$中选择一组$k$随机点作为中心，则$x在P$中的每个点都希望有一个半径为$r（x）$的中心。单独的公平集群为P$中的每个点$x提供了这样的保证。这种公平的概念被引入[Jung等人，2019 ]，在这里他们展示了如何获得一个近似可行的$K$-聚类相对于这个公平条件。在这项工作中，我们展示了如何获得近似最优的这种公平的$ $ $聚类。我们的解决方案的$K$-中位数（$k$ -均值）是在一个最佳的公平$k $聚类的成本的常数因子内，并且我们的解决方案近似满足公平性条件（也在一个常数因子内）。此外，我们用实证评估来补充我们的理论界限。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06742">PDF</a>
<h3>No. 111	基于CNN的超声弹性成像自动帧选择</h3><h4>Abdelrahman Zayed, Guy Cloutier, Hassan Rivaz</h4>摘要：超声弹性成像是通过监测组织对外力或外力的响应来估计组织的力学性能。不同的组织类型根据其力学性质得到不同程度的变形，其中较硬的组织变形较小。在给定两个射频（RF）帧的变形前后，通过比较RF帧估计位移和应变图像。应变图像的质量取决于变形过程中发生的运动类型。平面内的轴向运动导致高质量的应变图像，而面外运动导致低质量应变图像。本文介绍了一种利用卷积神经网络（CNN）在5.4ms内确定一对RF帧在弹性成像中适用性的新方法，该方法还可用于自动选择最佳RF帧对，得到高质量的应变图像。美国有线电视新闻网在3818对射频帧上进行了训练，而在986对新的看不见的帧上进行了测试，达到了91%以上的准确率。从体模和活体数据中收集射频帧。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06734">PDF</a>
<h3>No. 112	随机正规化流</h3><h4>Hao Wu, Jonas Köhler, Frank Noé</h4>文摘：规范化流是一种流行的生成学习方法，它训练一个可逆函数，将简单的先验分布转化为复杂的目标分布。在这里，我们通过引入随机规范化流（SNF）-一个确定性可逆函数的任意序列和随机过程，如Markov链Monte Carlo（MCMC）或Langevin动力学，推广了该框架。这种组合可以是强大的，因为向流中添加随机性有助于克服所选确定性可逆函数的表达限制，而可训练流转换可以提高纯MCMC的采样效率。我们的方法的关键是，我们可以匹配一个边缘目标密度，而不必边缘化出所穿越路径的随机性。借鉴非平衡统计力学的思想，提出了一种只使用条件路径概率的训练方法。我们可以将SNF转化为Boltzmann生成器，通过对这些路径的重要性采样，对给定的目标密度进行渐近无偏采样。我们在几个基准上说明了SNFs的表示能力、采样效率和渐近正确性。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06707">PDF</a>
<h3>No. 113	高斯平滑语义特征（GSSF）——基于MSCOCO框架的印度语（孟加拉语）视觉字幕语言研究</h3><h4>Chiranjib Sur</h4>翻译后摘要：在这项工作中，我们引入了高斯平滑语义特征（GSSF）为更好的语义选择印度区域语言为基础的图像字幕，并介绍了一个过程中，我们使用现有的翻译和英语人群来源的句子进行培训。我们已经表明，这种体系结构是一种很有前途的替代资源，那里的资源紧张。我们的主要贡献是为孟加拉语（世界上第五种广泛使用的语言）开发具有完全不同语法和语言属性的深度学习架构。我们已经证明，这些方法对于复杂的应用程序（如从图像上下文生成语言）非常有效，并且可以通过引入约束、更广泛的特征和独特的特征空间使表示多样化。我们还证明，在传统的LSTM和特征分解网络中使用平滑语义张量可以获得绝对的精度和多样性。通过更好的学习架构，我们成功地建立了一个自动化的算法和评估程序，可以帮助评估合格的应用程序，而无需专业知识和人工干预。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06701">PDF</a>
<h3>No. 114	伪局部极小值的结构</h3><h4>Wei Qian, Yuqian Zhang, Yudong Chen</h4>摘要：k$-聚类是无监督学习中的一个基本问题。这个问题涉及到如何将数据点划分成$k$个集群，从而最小化集群内的变化。尽管它的重要性和广泛的适用性，理论上对$k$-意味着问题的理解并不完全令人满意。具有理论性能保证的现有算法通常依赖于复杂的（有时是人工的）算法技术和对数据的限制性假设。主要的挑战在于问题的非凸性；特别是，除了全局最优之外，还存在附加的局部解。此外，最简单和最流行的$k$-均值算法，即Lloyd算法，在理论和实践中通常会收敛到这种虚假的局部解。在本文中，我们从一个新的角度来探讨$k$-均值问题，通过研究这些伪局部解在具有$k$基本真值簇的概率生成模型下的结构。只要K＝3美元，伪造局部极小可证明存在，即使对于良好分离和平衡的集群。一个这样的局部最小值将两个中心放在一个真正的簇上，而第三个中心放在其他两个真正簇的中间。对于一般的$k$，一个本地最小值将多个中心放在一个真正的集群上，一个中心放在多个真正集群的中间。或许令人惊讶的是，我们证明了这是分离条件下唯一一类伪局部极小。我们的结果适用于混合高斯分布或有界分布的$k$-均值公式。我们的理论结果证实了现有的经验观察，并提供了一些改进的算法$ k$均值聚类的理由。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06694">PDF</a>
<h3>No. 115	面向自我网络分析的全局和局部特征学习</h3><h4>Fatemeh Salehi Rizi, Michael Granitzer, Konstantin Ziegler</h4>摘要：在自我网络中，个体（自我）在不同的群体（社交圈）中组织其朋友（改变）。在学习了自我的表征及其在低维、实向量空间中的变化之后，可以有效地分析这个社会网络。然后，这些表示很容易通过统计模型用于诸如社交圈检测和预测等任务。通过深度学习进行语言建模的最新进展激发了学习网络表示的新方法。这些方法可以捕捉网络的全局结构。在本文中，我们发展这些技术，也编码邻域的局部结构。因此，我们的本地表示捕获隐藏在大型网络的全局表示中的网络特性。我们证明，社交圈预测的任务得益于我们的技术产生的全局和局部特征的结合。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06685">PDF</a>
<h3>No. 116	预测活动出席率探索社会影响</h3><h4>Fatemeh Salehi Rizi, Michael Granitzer</h4>摘要：预测人们对现实世界事件的参与程度，为人类行为分析和事件相关广告提供了有价值的见解，受到了广泛的关注。如今，社交网络（如Twitter）广泛反映了人们与朋友讨论兴趣的大型热门事件。活动参与者通常会鼓励朋友加入到网络传播社会影响的活动中。在这篇文章中，我们建议建立朋友对出席活动的社会影响模型。除了社会群体结构之外，我们还考虑非地理标记的帖子来推断用户的出席率。为了充分利用网络拓扑信息，我们采用了node2vec、HARP和Poincar`e等最新的图形嵌入技术，描述了特征空间的设计方法，并将其反馈给神经网络。表演评估使用两个大型音乐节数据集进行，即VFestival和Creamfields。实验结果表明，我们的分类器优于最新的基线，对VFestival数据集的准确率达到89%。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06665">PDF</a>
<h3>No. 117	SBERT-WK：一种基于BERT模型的句子嵌入方法</h3><h4>Bin Wang, C.-C. Jay Kuo</h4>摘要：句子嵌入是自然语言处理（NLP）中的一个重要研究课题，它能将知识传递给下游任务。同时，一个被称为BERT的上下文化的单词表示在许多NLP任务中实现了最新的性能。然而，从基于BERT的词模型中生成高质量的句子表示是一个开放的问题。以往的研究表明，不同层次的BERT捕捉不同的语言属性。这使得我们可以跨层融合信息，以找到更好的句子表示。在这项工作中，我们研究了深层语境化模型的词表示的分层模式。然后，通过对单词表示所跨越的空间进行几何分析，对基于BERT的单词模型进行剖分，提出了一种新的句子嵌入方法。它被称为SBERT-WK方法。SBERT-WK无需进一步培训。我们评估了SBERT-WK的语义文本相似度和下游监督任务。此外，本文还提出了10个句子级的探究任务，用于详细的语言分析。实验表明，SBERT-WK达到了最先进的性能。我们的代码是公开的。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06652">PDF</a>
<h3>No. 118	最近邻规则的核心集</h3><h4>Alejandro Flores Velazco, David M. Mount</h4>文摘：最近邻凝聚问题是从一组标记点P中找到一个子集R，使得对于R中的每一个点P，P的最近邻R都具有与P相同的标记，这是由于分类应用的缘故，其中，最近邻规则将点集中最近邻的标签指定给未标记的查询点。在这种情况下，压缩的目的是减少对新点进行分类所需的集合的大小。然而，寻找这样的最小基数子集是NP困难的，而且大多数研究都集中在没有性能保证的实用启发式算法上。此外，总是使用精确的最近邻居，忽略了在最近的邻居被近似计算时的分类精度的影响。在本文中，我们提出这些缺点，提出新的近似敏感准则的最近邻凝聚问题，以及实用算法与可证明的性能保证。我们描述了足够的条件，保证正确分类未标记点使用近似最近邻查询这些子集，引入了概念集分类最近的邻居规则。此外，我们证明了具有这些特征的子集是NP难的，其基数近似于最小基数子集。此外，我们提出了新的算法来计算这样的子集，具有严格的近似因子在一般度量，以及改进因子倍度量和LpP度量与P>＝2。最后，我们展示了一种替代的实现方案，减少了最坏情况下的时间复杂度之一，这些算法，成为第一个真正的二次近似算法的最近邻凝聚问题。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06650">PDF</a>
<h3>No. 119	编解码框架下的语音转换</h3><h4>Jayneel Parekh, Preeti Rao, Yi-Hsuan Yang</h4>文摘：本文的目标是将一组口语台词转换成歌唱台词。与以往基于信号处理的方法不同，我们采用基于学习的方法来解决这个问题。这使我们能够自动地对转换的各个方面进行建模，从而克服对特定输入的依赖，例如高质量的歌唱模板或音素乐谱同步信息。具体来说，我们为我们的任务提出了一个编码器-解码器框架。给定语音的时频表示和目标旋律轮廓，我们学习编码，使我们能够综合歌唱，在遵守目标旋律的同时保留说话人的语言内容和音色。我们还提出了一个基于多任务学习的目标，以提高歌词的可懂度。我们对我们的框架进行了定量和定性分析。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06595">PDF</a>
<h3>No. 120	管道干预</h3><h4>Eshwar Ram Arunachaleswaran, Sampath Kannan, Aaron Roth, Juba Ziani</h4>文摘：介绍了由分层有向无环图和一组控制连续层间转换的随机矩阵定义的{管道干预}问题。这个图表是一个程式化的模型，用来描述来自不同人群的人们如何获得机会，最终获得某种回报。在我们的模型中，个体按照固定的概率分布出生在一个初始位置（即图的第一层中的某个节点），然后根据转移矩阵在图中随机前进，直到到达图的最后一层中的某个节点；最后一层中的每个节点都有一个与之关联的\emph{reward}。管道干预问题要求在预算约束下，如何通过图对控制人们随机转换的转换矩阵进行代价最大的更改。我们考虑两个目标：社会福利最大化，和公平动机最大值目标，寻求最大值的人口（起始节点）的EMPH{{}}期望值。我们考虑的最大值目标的两个变种，结果是不同的，这取决于我们是否需要确定性解决方案或允许随机化。对于每一个目标，我们给出了一个有效的近似算法（添加剂FPTAS）的恒定宽度网络。在我们的设置中，我们也严格地描述了“公平价格”：最高可实现的社会福利与最高社会福利之间的比率与最大值最优解的一致性。最后，我们表明，对于多项式宽度的网络，即使近似最大值目标到任何常数因子是NP-hard，即使对于具有恒定深度的网络。这说明在我们的实证结果中，对宽度的限制是必要的。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06592">PDF</a>
<h3>No. 121	将自然语言解析为一阶逻辑的神经模型探讨</h3><h4>Hrituraj Singh, Milan Aggrawal, Balaji Krishnamurthy</h4>摘要：语义分析是从自然语言文本中获取机器可解释表示的任务。我们考虑了一个这样的形式化表示-一阶逻辑（FOL），并探讨了神经模型在英语句子的FOL分析中的能力。我们将FOL分析建模为一个序列到序列的映射任务，在给定一个自然语言句子的情况下，它被编码成一个中间表示，使用LSTM，然后是一个解码器，解码器在相应的FOL公式中依次生成谓词。我们通过引入一种变量对齐机制来改进标准的编码器-解码器模型，使其能够在预测的FOL中跨谓词对齐变量。进一步证明了在每个解码器步骤中预测FOL实体Unary、二进制、变量和范围实体的类别的有效性，作为提高生成的FOL的一致性的辅助任务。我们进行严格的评估和广泛的消融。我们还将发布我们的代码以及大规模的FOL数据集和模型，以帮助进一步研究NLP中基于逻辑的解析和推理。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06544">PDF</a>
<h3>No. 122	随机二阶优化的分布平均法</h3><h4>Burak Bartan, Mert Pilanci</h4>文摘：我们考虑了分布优化问题，其中Hessian的形成在计算上具有挑战性，而通信是一个重要的瓶颈。我们发展了随机二阶优化的无偏参数平均方法，采用海森抽样和草图。现有的工作不考虑估计的偏倚，这限制了它们在大规模并行计算中的应用。我们提供了正则化参数和步长的闭式公式，这些公式可证明最小化了牛顿方向草图的偏差。本文还扩展了二阶平均法的框架，提出了一种适用于具有不同工作资源的异构计算系统的无偏分布式优化框架。此外，我们通过在无服务器计算平台上进行的大规模实验，证明了我们的理论发现的含义。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06540">PDF</a>
<h3>No. 123	隐私保护回归的分布式绘制方法</h3><h4>Burak Bartan, Mert Pilanci</h4>文摘：本文研究了大规模回归问题的分布式绘制方法。在异步分布式系统中，我们利用多个随机草图来减少问题的维数，同时保护隐私和提高散乱者的弹性。我们推导出新的近似保证经典草图方法，并分析参数的平均分布草图的准确性。在分布式环境下，我们考虑了随机矩阵，包括高斯、随机Hadamard、均匀采样和杠杆分数采样。此外，为了提高计算效率，我们提出了一种结合抽样和快速随机投影的混合方法。在无服务器计算平台上，通过大规模的实验验证了分布式草图的性能。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06538">PDF</a>
<h3>No. 124	黑箱分类器的主动贝叶斯评估</h3><h4>Disi Ji, Robert L. Logan IV, Padhraic Smyth, Mark Steyvers</h4>摘要：机器学习的最新进展导致黑盒分类器在各种应用中的应用越来越多。在许多这样的情况下，需要评估这些预先训练的模型的性能，例如确保足够的预测精度，或者类概率得到很好的校准。此外，由于标记的数据可能稀少或收集成本高，因此希望以有效的方式进行此类评估。本文介绍了一种满足这些要求的贝叶斯模型评估方法。我们开发了一些推理策略来量化常见评估指标的不确定性（准确性、误分类成本、预期校准误差），并提出了一个使用此不确定性进行主动评估的框架，以指导标记实例的有效选择。我们在评估现代神经分类器（如ResNet和BERT）在几种标准图像和文本分类数据集上的性能的实验中说明了我们的方法的优点。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06532">PDF</a>
<h3>No. 125	学习为输入句子生成多种风格的转换输出</h3><h4>Kevin Lin, Ming-Yu Liu, Ming-Ting Sun, Jan Kautz</h4>摘要：文本风格转换是指以不同的风格对给定文本进行重新措辞的任务。虽然已经提出了各种方法来提高技术水平，但它们通常假设传输输出遵循delta分布，因此它们的模型无法为给定的输入文本生成不同的样式传输结果。为了解决这个问题，我们提出了一个一对多的文本风格转换框架。与以往学习将输入句子转换为输出句子的一对一映射的工作不同，我们的方法学习一对多映射，可以将输入句子转换为多个不同的输出句子，同时保留输入内容。这是通过使用潜在分解方案的对抗性训练来实现的。具体来说，我们将输入语句的潜在表示分解为捕获语言风格变化的样式代码和编码语言风格无关内容的内容代码。然后，我们将内容代码与样式代码相结合，以生成样式传输输出。通过将相同的内容代码与不同的样式代码组合，我们生成不同的样式传输输出。大量的实验结果与使用不同性能度量集的多个公共数据集上的几种文本样式传输方法进行了比较，验证了所提方法的有效性。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06525">PDF</a>
<h3>No. 126	基于序数观测的张量去噪与补全</h3><h4>Chanwoo Lee, Miaoyan Wang</h4>摘要：高阶张量在神经影像学、推荐系统、社会网络分析、心理研究等应用中经常出现。我们考虑了不完全序值观测的低秩张量估计问题。研究了两个相关问题，一个是张量去噪问题，另一个是张量完备问题。我们提出了一个多线性累积链路模型，发展了一个秩约束M估计，并得到了理论上的精度保证。我们的均方误差界比以前的结果有更快的收敛速度，并且我们证明了在一类低秩模型下，所提出的估计是极大极小最优的。此外，所开发的过程是一种有效的完成方法，它保证了仅使用$\tilde{\mathcal{O}（K d）$噪声量化观测值的顺序-$K$$（d，ldots，d）$维低秩张量的一致恢复。我们证明了我们的方法在聚类和协作过滤任务上比以前的方法有更好的表现。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06524">PDF</a>
<h3>No. 127	基于因果估计的凸公平约束模型</h3><h4>Hikaru Ogura, Akiko Takeda</h4>摘要：近年来，关于机器学习公平性的研究越来越多。在这里，平均差（MD）或人口均等是最受欢迎的公平衡量标准之一。然而，MD不仅量化了歧视，而且量化了解释性偏差，解释性偏差是由解释性特征证明的结果差异。在本文中，我们设计了一个新的模型，称为公平模型，它在保留解释偏差的同时消除了歧视。这些模型是基于使用倾向得分分析的因果效应估计。证明了带平方损失的公平性理论上优于一个朴素的MD约束模型。我们提供了一个求解回归和二元分类任务中的公平性的有效算法。在我们的实验中，在这两个任务的合成和真实世界的数据，FIECESE优于现有的模型，认为在特定情况下的解释偏倚。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06501">PDF</a>
<h3>No. 128	盲对抗网络扰动</h3><h4>Milad Nasr, Alireza Bahramali, Amir Houmansadr</h4>文摘：深度神经网络（DNNs）由于其在很大程度上优于传统的（如统计）技术，因此被广泛应用于各种流量分析问题，如网站指纹识别和流量关联等。然而，深部神经网络很容易受到对抗性例子的攻击：由于小的对抗性扰动，模型错误地标记了对抗性输入到模型中。在本文中，我们首次证明对手可以通过在网络流量模式上应用对手扰动来击败基于DNN的流量分析技术。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06495">PDF</a>
<h3>No. 129	概率密度泛函的凸优化</h3><h4>Tomohiro Nishiyama</h4>文摘：在信息论中，一些优化问题导致了概率密度严格凸泛函上的凸优化问题。在这篇文章中，我们研究了这些问题，并给出了极小化因子的条件和极小值的唯一性，如果存在极小值的话。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06488">PDF</a>
<h3>No. 130	学习分组：一个自底向上的三维零件发现框架</h3><h4>Tiange Luo, Kaichun Mo, Zhiao Huang, Jiarui Xu, Siyu Hu, Liwei Wang, Hao Su</h4>摘要：我们解决了在不可见类别中发现物体的三维零件的问题。能够学习零件的几何先验知识，并将其转移到不可见的类别之前，对数据驱动的形状分割方法提出了根本性的挑战。作为一个上下文盗贼问题，我们提出了一个基于学习的聚集聚类框架，该框架学习一个分组策略，以自下而上的方式逐步将小部分提议分组为大的提议。我们方法的核心是限制用于提取零件级特征的局部上下文，这鼓励了对不可见类别的泛化。在大规模细粒度三维零件数据集PartNet上，我们证明了该方法可以在不看到任何标注样本的情况下，将从3个训练类别中学习到的零件知识转移到21个不可见的测试类别中。对四个形状分割基线的定量比较表明，我们的方法达到了最先进的性能。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06478">PDF</a>
<h3>No. 131	深度学习中的域内不确定性估计与集结陷阱</h3><h4>Arsenii Ashukha, Alexander Lyzhov, Dmitry Molchanov, Dmitry Vetrov</h4>文摘：不确定度估计与不确定度集成方法密切相关。不确定度估计是综合性能评估的主要基准之一。同时，深度学习集成在不确定性估计方面提供了最新的结果。在这项工作中，我们主要关注图像分类领域内的不确定性。我们探索其量化的标准，并指出现有度量的陷阱。为了避免这些陷阱，我们对不同的加密技术进行了广泛的研究。为了在本研究中提供更深入的见解，我们引入了深度系综等价分数（DEE），并证明许多复杂的系综技术在测试性能方面等同于仅由少数几个独立训练的网络组成的系综。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06470">PDF</a>
<h3>No. 132	高分辨率网：卫星图像多帧超分辨率的递归融合</h3><h4>Michel Deudon, Alfredo Kalaitzis, Israel Goytom, Md Rifat Arefin, Zhichao Lin, Kris Sankaran, Vincent Michalski, Samira E. Kahou, Julien Cornebise, Yoshua Bengio</h4>摘要：生成性深度学习已经引发了一股新的超分辨率（SR）算法浪潮，这种算法增强了单个图像，尽管具有虚构的细节，但其美学效果令人印象深刻。多帧超分辨率（MFSR）通过对多个低分辨率视图进行调节，为解决不适定问题提供了一种更为可靠的方法。这对于卫星监测人类对地球的影响——从毁林到侵犯人权——非常重要，而这些都依赖于可靠的图像。为此，我们提出了HighRes-net，这是MFSR的第一种深度学习方法，它以端到端的方式学习其子任务：（i）共注册，（ii）融合，（iii）上采样，和（iv）丢失时的注册。低分辨率视图的联合注册是通过参考帧通道隐式学习的，没有显式的注册机制。我们学习了一个全局融合算子，它递归地应用于任意数量的低分辨率对。通过学习通过ShiftNet将SR输出与一个基本事实对齐，我们引入了一个注册损失。研究表明，通过学习多视图的深度表示，可以对低分辨率信号进行超分辨率处理，提高对地观测数据的分辨率。我们的方法最近在欧洲航天局的实际卫星图像多功能遥感竞赛中名列前茅。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06460">PDF</a>
<h3>No. 133	相似选择的单调基数估计：一种深度学习方法</h3><h4>Yaoshu Wang, Chuan Xiao, Jianbin Qin, Xin Cao, Yifang Sun, Wei Wang, Makoto Onizuka</h4>摘要：由于深度学习技术在捕捉底层数据分布方面的突出能力，近年来被广泛应用于一系列传统的数据库问题中。本文探讨了利用深度学习进行相似性选择基数估计的可能性。准确、高效地解决这一问题对于许多数据管理应用，特别是查询优化是至关重要的。此外，在某些应用中，估计的基数应该是一致的和可解释的。因此，首选单调估计w.r.t.查询阈值。提出了一种适用于任意数据类型和距离函数的通用方法。该方法由特征提取模型和回归模型组成。特征提取模型将原始数据和阈值转换为Hamming空间，利用基于深度学习的回归模型，利用基数w.r.t.的增量特性，使阈值具有精度和单调性。我们开发了适合我们的模型的训练策略以及快速估计的技术。我们还讨论了如何处理更新。我们通过实验证明了该方法的准确性和效率，并说明了它如何提高查询优化器的性能。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06442">PDF</a>
<h3>No. 134	潜在变量的后验比估计</h3><h4>Yulong Zhang, Mingxuan Yi, Song Liu, Mladen Kolar</h4>摘要：密度比估计由于能够比较两个数据集的潜在分布而受到机器学习界的关注。然而，在某些应用中，我们希望比较只能从观测中推断出的{潜在}随机变量的分布。本文研究了一个潜在变量的两个后验概率密度函数之比的估计问题。特别是，我们假设后验比率函数可以很好地近似由参数模型，然后使用观测数据集和合成先验样本估计。证明了当先验样本数趋于无穷大时，估计量的相合性和估计参数的渐近正态性。最后，我们用数值实验验证了我们的理论，并通过一些实际应用证明了该方法的有效性。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06410">PDF</a>
<h3>No. 135	混合引文：一种上下文感知引文推荐的混合模型</h3><h4>Michael Färber, Ashwath Sampath</h4>摘要：引文推荐系统旨在为一篇完整的论文或一小部分被称为引文上下文的文本推荐引文。引文推荐过程被称为局部引文推荐，是本文研究的重点。本文首先研究了基于嵌入、主题建模和信息检索技术的引文推荐方法。根据我们的知识，我们首次将性能最好的算法组合成半遗传混合推荐系统，用于引文推荐。我们基于多个数据集对单一方法和混合方法进行了离线评估，如微软学术图（MAG）和结合arXiv和ACL的MAG。我们进一步进行用户研究，以评估我们的在线方法。我们的评估结果表明，包含嵌入和基于信息检索的组件的混合模型比其单独的组件和进一步的算法有很大的优势。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06406">PDF</a>
<h3>No. 136	基于CNN的云IaaS行为恶意软件检测技术分析</h3><h4>Andrew McDole, Mahmoud Abdelsalam, Maanak Gupta, Sudip Mittal</h4>摘要：云基础设施即服务（IaaS）由于暴露于外部对手而容易受到恶意软件的攻击，使其成为恶意参与者获利颇丰的攻击载体。感染恶意软件的数据中心可能会导致数据丢失和/或对其用户的服务造成重大中断。本文分析比较了各种卷积神经网络（CNNs）在云IaaS恶意软件在线检测中的应用。该检测基于行为数据，使用进程级性能指标（包括cpu使用率、内存使用率、磁盘使用率等）执行。我们使用最先进的DenseNets和ResNets有效地检测在线云系统中的恶意软件。CNN的设计目的是从运行在真实云环境中的实时恶意软件收集的数据中提取特征。实验是在OpenStack（一个云IaaS软件）测试台上进行的，这个测试台被设计用来复制一个典型的3层web架构。对本研究中使用的不同CNN模型的不同度量进行了比较分析。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06383">PDF</a>
<h3>No. 137	眼底图像病变自动分割与病理性近视分类</h3><h4>Cefas Rodrigues Freire, Julio Cesar da Costa Moura, Daniele Montenegro da Silva Barros, Ricardo Alexsandro de Medeiros Valentim</h4>文摘：本文提出了病理性近视（PM）的诊断算法，并对视网膜结构和病变如视神经盘（OD）、中央凹、萎缩、脱离等进行了检测。所有这些任务都是在PM患者的眼底成像中完成的，它们是参与病理性近视挑战（PALM）的必要条件。这项挑战是在意大利威尼斯举行的IEEE生物医学成像国际研讨会的卫星活动，为期半天。我们的方法在每项任务中应用不同的深度学习技术。所有任务都采用迁移学习，以异常为基线模型。同时，将YOLO结构的一些关键思想应用到光盘分割算法流水线中。我们根据AUC-ROC、F1分数、平均骰子分数和平均欧几里德距离的挑战规则来评估模型的性能。对于初始活动，我们的方法显示了令人满意的结果。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06382">PDF</a>
<h3>No. 138	基于物联网的大城市交通数据挖掘系统</h3><h4>Daniel. Firouzimagham, Mohammad. Sabouri, Fatemeh. Adhami</h4>摘要：目前，在包括伊朗在内的发展中国家，由于人口的增长，汽车的数量在不断增加。最近，这导致浪费时间陷入交通堵塞，每天上下班的时间增加，事故增加。因此，有必要由交警来控制交通拥堵，有效地拓宽道路，选择减少市民交通的最佳途径。因此，掌握每条车道上的瞬时交通量是很重要的。今天，许多交通组织服务，如交警和城市交通控制系统，使用交通摄像机、感应传感器、卫星图像、雷达传感器、超声波技术和射频识别（RFID）进行城市交通诊断。但该方法存在着受大气条件影响大流量时效率不高、无法检测出平行交通等问题。本文提出的基于物联网的交通拥堵检测方法，包含一个智能系统，通过计算该区域的空气污染量来检测交通拥堵。经实验验证，结果令人满意。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06374">PDF</a>
<h3>No. 139	UniViLM：多模态理解和生成的统一视频和语言预训练模型</h3><h4>Huaishao Luo, Lei Ji, Botian Shi, Haoyang Huang, Nan Duan, Tianrui Li, Xilin Chen, Ming Zhou</h4>文摘：提出了统一的视频和语言预训练模型UniViLM，用于多模态理解和生成。针对近年来基于BERT的NLP和图像语言预训练技术的成功应用，VideoBERT和CBT提出了一种基于叙事教学视频的视频和语言预训练BERT模型。与他们只进行理解任务预训练的工作不同，我们提出了一个统一的视频语言理解和生成任务预训练模型。我们的模型由4个部分组成，包括两个单模式编码器、一个交叉编码器和一个带变压器主干的解码器。我们首先对我们的模型进行预训练，以学习大型教学视频数据集上视频和语言的通用表示。然后，我们对模型进行了两个多模式任务的微调，包括理解任务（基于文本的视频检索）和生成任务（多模式视频字幕）。大量的实验表明，该方法可以提高理解任务和生成任务的性能，达到了最新的效果。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06353">PDF</a>
<h3>No. 140	基于条件循环一致对抗网络的多对多语音转换</h3><h4>Shindong Lee, BongGu Ko, Keonnyeong Lee, In-Chul Yoo, Dongsuk Yook</h4>摘要：语音转换是指在不改变话语语言内容的情况下，改变话语的说话人特征。许多关于语音转换的工作都需要并行训练数据，而这些数据的获取成本很高。近年来，循环一致对抗网络（cycle-consistent particial network，CycleGAN）已被应用于语音转换领域，显示了其最新的性能。然而，基于CycleGAN的语音转换只能用于一对扬声器，即两个扬声器之间的一对一语音转换。在本文中，我们通过调节扬声器上的网络来扩展CycleGAN。结果表明，该方法可以在一个生成性对抗网络（GAN）上实现多个说话人之间的多对多语音转换。与为每对扬声器建立多个循环相比，该方法在不影响转换语音质量的前提下，显著降低了计算和空间开销。基于VCC2018语料库的实验结果验证了该方法的有效性。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06328">PDF</a>
<h3>No. 141	基于小能量掩蔽的端到端语音识别改进神经网络训练</h3><h4>Chanwoo Kim, Kwangyoun Kim, Sathish Reddy Indurthi</h4>文摘：本文提出了一种小能量掩蔽（SEM）算法，它屏蔽了输入值低于某一阈值的情况。更具体地说，如果滤波器组能量小于某个能量阈值，则屏蔽时频滤波器组。采用均匀分布的方法，随机产生该能量阈值与每个话语的峰值滤波器组能量之比（分贝）。通过此掩蔽过程，将缩放未掩蔽的特征元素，以便特征值的总和保持不变。这个非常简单的算法在标准LibriSpeech测试clean和测试其他集上的字错误率（WER）分别比基线端到端语音识别系统提高了11.2%和13.5%。此外，与输入-退出算法相比，SEM算法在同一LibriSpeech test clean和test-other集上分别提高了7.7%和11.6%。采用改进的变压器LM浅熔技术，在LibriSpeech试验清洁集上获得了2.62%的功率，在LibriSpeech试验其他集上获得了7.87%的功率。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06312">PDF</a>
<h3>No. 142	军团：最佳的首次混合测试</h3><h4>Dongge Liu, Gidon Ernst, Toby Murray, Benjamin I. P. Rubinstein</h4>摘要：军团是一种灰盒混合工具，旨在平衡模糊和符号执行的互补性，以达到两者的最佳效果。提出了蒙特卡罗树搜索（MCTS）的一种新方法，即在不确定性条件下，在最优优先搜索策略的指导下，将程序探索定义为顺序决策。它依赖于近似路径保持模糊化，一种新的约束随机测试实例，它快速生成许多可能针对感兴趣的程序部分的不同输入。在2020年的测试中，该原型在22个类别中有9个类别的最佳分数的90%以内完成。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06311">PDF</a>
<h3>No. 143	基于反对称SoftMax近似的极值分类</h3><h4>Robert Bamler, Stephan Mandt</h4>摘要：在大量的类上训练分类器，即所谓的“极端分类”，已经成为技术、科学和电子商务应用中的一个重要课题。传统的softmax回归会导致与类数成正比的梯度成本$C$，这通常是非常昂贵的。一种流行的可扩展的SUMTTMAX近似依赖于均匀的负采样，其由于信噪比较差而收敛缓慢。本文提出了一种简单的训练方法，通过从模拟数据分布的对抗模型中提取负样本来显著增强梯度信号。我们的贡献是三方面的：（i）一种对抗性采样机制，它以成本仅为对数（单位：加元）生成负样本，从而仍然导致廉价的梯度更新；（ii）一个数学证明，这种对抗性采样可以最小化梯度方差，而非均匀采样造成的任何偏差都可以消除；（iii）在大规模数据集上的实验结果表明，相对于几个竞争基线，训练时间减少了一个数量级。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06298">PDF</a>
<h3>No. 144	基于面分裂的超图高阶共现张量</h3><h4>Bryan Bischof</h4>文摘：计算成对共生矩阵的一个常用技巧是关联矩阵及其转置的乘积。我们提出了一种模拟高阶元组共现的方法，使用面分裂积，或者称为转置Khatri-Rao积。这些高阶共现编码了令牌与其他令牌的共同性，从而概括了共同研究的信息。我们通过一个流行的NLP模型和相似的超图模型来演示这个张量的使用。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06285">PDF</a>
<h3>No. 145	基于功能近红外光谱的深度学习精确应力评估</h3><h4>Mahya Mirbagheri, Ata Jodeiri, Naser Hakimi, Vahid Zakeri, Seyed Kamaledin Setarehdan</h4>摘要：压力是威胁人类健康的主要因素之一。为了通过分析大脑和心脏相关信号来评估或缓解压力，已经进行了大量的研究。本研究利用10名健康志愿者脑功能近红外光谱（fNIRS）所产生的信号，通过深度学习系统对蒙特利尔成像应激任务所诱发的应激进行评估。本文提出的深度学习系统主要由两部分组成：一是利用一维卷积神经网络建立信息特征映射。然后，用一组深全连接层预测应力存在概率。实验结果表明，训练后的fNIRS模型进行应力分类的准确率达到88.52-+0.77%。所提出的深度学习系统在FNIRS测量上的训练导致比在FNIRS研究中提出的现有方法中更高的应力分类精度，其中已经使用了相同的实验过程。该方法具有较好的稳定性和较低的预测偏差。此外，该方法计算量小，为实时应力评估提供了可能。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06282">PDF</a>
<h3>No. 146	Twin BERT：将知识提取到双结构BERT模型以实现高效检索</h3><h4>Wenhao Lu, Jian Jiao, Ruofei Zhang</h4>文摘：BERT等预训练语言模型在各种NLP任务中取得了巨大的成功，但其优越的性能对计算资源提出了更高的要求，阻碍了其在低延迟IR系统中的应用。本文提出了一种有效的twin BERT检索模型，该模型采用双结构的类BERT编码来分别表示查询和文档，并通过交叉层来组合嵌入，产生相似度得分。与BERT不同，TwinBERT将两个输入语句连接在一起并进行编码，在编码过程中对它们进行解耦，独立生成查询和文档所需的嵌入，这使得文档嵌入可以离线预计算并缓存在内存中。因此，留给运行时的计算仅来自查询编码和查询文档交叉。这种改变可以节省大量的计算时间和资源，从而显著提高服务效率。此外，本文还提出了一些精心设计的网络层和训练策略，进一步降低了计算量，同时保持了BERT模型的良好性能。最后，我们开发了两个版本的TwinBERT，分别用于检索和相关任务，它们都达到了与BERT基模型接近或相当的性能。该模型遵循师生框架进行训练，并使用一个主要搜索引擎的数据进行评估。实验结果表明，在cpu上，推理时间明显缩短，并首先控制在20ms左右，同时保留了微调BERT基模型的性能增益。将这些模型集成到生产系统中也证明了相关性度量的显著改进，对延迟的影响可以忽略不计。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06275">PDF</a>
<h3>No. 147	用于人脸识别的深卷积神经网络编码中的单单元状态：稀疏性的重新定义</h3><h4>Connor J. Parde, Y. Ivette Colón, Matthew Q. Hill, Carlos D. Castillo, Prithviraj Dhar, Alice J. O'Toole</h4>文摘：用于人脸识别的深卷积神经网络（DCNNs）在保留被试（如性别）和图像（如视点）信息的同时，发展了对可变图像的泛化表示。在人脸识别网络的“神经单元”和集成层上研究了身份、性别和视点编码。在单元层次上，通过删除单元在顶层创建可变大小的随机采样子空间来测量识别、性别分类和视点估计。3531个身份的识别仍然很高（ROC下面积约1），随着维度的下降，从512个单位减少到16个（0.95）、4个（0.80个）和2个（0.72个）单元。在每一个顶层单元上都有统计上分离的个体身份。跨单位反应的相关性最小，表明单位编码非冗余的身份线索。这种“分布式”代码只需要一个稀疏的、随机的单元样本就可以准确地识别人脸。随着维度的降低，性别分类逐渐下降，观点估计急剧下降。个体单位对性别和观点的预测能力很弱，但合奏被证明是有效的预测因素。因此，分布式和稀疏代码共存于网络单元中，以表示不同的面部属性。在集成层次上，人脸表示的主成分分析表明，身份、性别和视点信息被分解成高维子空间，按解释方差排序。身份、性别和观点信息对所有个体的反应都有贡献，削弱了面部特征的神经调节类比。从DCNNs和类似的高级视觉编码中对类神经编码的解释，不能从单个单位的反应中推断出来。相反，“意义”是由高维空间中的方向编码的。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06274">PDF</a>
<h3>No. 148	TPLVM：学生$t$-过程潜在变量模型的投资组合构建</h3><h4>Yusuke Uchiyama, Kei Nakagawa</h4>摘要：资产优化配置是现代金融理论中的一个重要课题。为了实现投资者规避风险的最优资产配置，人们提出了多种组合构建方法。近年来，机器学习在金融领域的应用迅速发展。本文提出用低维潜在变量描述金融时间序列非高斯波动的Student$t$-过程潜在变量模型（TPLVM）。随后，我们将TPLVM应用于最小方差组合，作为现有非线性因素模型的替代。为了检验所提出的投资组合的性能，我们构建了基于TPLVM或高斯过程潜在变量模型的全球股市指数的最小方差投资组合。通过比较这些投资组合，我们证实了所提出的投资组合优于现有的高斯过程隐变量模型。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06243">PDF</a>
<h3>No. 149	社会WaGDAT：基于Wasserstein图双注意网络的交互感知轨迹预测</h3><h4>Jiachen Li, Hengbo Ma, Zhihao Zhang, Masayoshi Tomizuka</h4>文摘：智能移动系统（如自主车辆和社会机器人）在高度交互性和拥挤的场景中导航时，对环境的有效理解和对周围动态障碍物的准确轨迹预测是实现安全、高质量规划的必要条件。由于场景演化中频繁交互和不确定性的存在，期望预测系统能够在不同实体上进行关系推理，并为每个代理提供未来轨迹的分布。本文提出了一个通用的多智能体轨迹预测生成神经系统（Social WaGDAT），该系统通过将关联归纳偏差与动态图表示相结合，同时利用轨迹和场景上下文信息，向显式交互建模迈进了一步。我们还采用了一个有效的运动约束层应用于车辆轨迹预测，不仅保证了物理上的可行性，而且提高了模型的性能。该系统在三个公共基准数据集上进行评估，用于轨迹预测，其中代理包括行人、骑自行车者和道路车辆。实验结果表明，该模型在预测精度方面优于各种基线方法。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06241">PDF</a>
<h3>No. 150	增强的局部敏感哈希：用于源分离的区分二进制代码</h3><h4>Sunwoo Kim, Haici Yang, Minje Kim</h4>摘要：随着深度学习技术的进步，语音增强任务得到了显著的改善，但是计算复杂度的增加也带来了代价。在本研究中，我们提出一种自适应的boosting方法来学习局部敏感的杂凑码，以有效地表示音频频谱。我们将学习的散列码用于单通道语音去噪任务，以替代复杂的机器学习模型，特别是解决资源受限的环境。我们的自适应boosting算法学习简单的logistic回归作为弱学习者。经过训练，他们的二值分类结果将每个测试噪声语音谱转换成一个位串。简单的位运算计算Hamming距离，在训练有噪语音谱的字典中找到K-最近匹配帧，其相关的理想二值掩码被平均以估计该测试混合的去噪掩码。我们提出的学习算法与AdaBoost的不同之处在于，训练投影的目的是最小化散列码的自相似矩阵与原始谱的自相似矩阵之间的距离，而不是降低误分类率。我们评估我们的歧视性哈希码的TIMIT语料库与各种噪声类型，并表现出比较深刻的学习方法在降噪性能和复杂性方面的性能。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06239">PDF</a>
<h3>No. 151	波斯语社交媒体中情感分析的卷积神经网络</h3><h4>Morteza Rohanian, Mostafa Salehi, Ali Darzi, Vahid Ranjbar</h4>摘要：随着社会化媒体参与度的不断提高，由此产生的数据可以作为分析和理解我们周围不同现象的丰富资源。情绪分析系统利用这些数据来发现社交媒体用户对给定文档中某些实体的态度。本文提出了一种基于前向人工神经网络卷积神经网络（CNN）的波斯语文本情感分析方法，该方法通过不同的滤波器对输入数据进行一层卷积，将句子分为两类和五类（考虑其强度）。我们使用曲线下面积度量对三个不同的波斯社交媒体文本数据集进行了评估。最后的结果显示了使用CNN在开发波斯文本情感分类特别是短文本的传统机器学习方法方面的优势。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06233">PDF</a>
<h3>No. 152	甘斯的Top-K培训：通过减少批评来改进发电机</h3><h4>Samarth Sinha, Anirudh Goyal, Colin Raffel, Augustus Odena</h4>文摘：我们对生成性对抗网络（GAN）训练算法进行了一个简单的（一行代码）修改，在不增加计算成本的情况下显著地提高了训练结果：当更新生成器参数时，我们简单地从批元素中剔除梯度贡献，该批元素被批评者评为“最少”现实主义。通过对许多不同GAN变体的实验，我们表明这种top-k更新过程是一种普遍适用的改进。为了理解改进的本质，我们对一个简单的高斯混合数据集进行了广泛的分析，并发现了一些有趣的现象。其中之一是，当使用得分最差的批处理元素计算梯度更新时，实际上可以将样本推离其最近的模式更远。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06224">PDF</a>
<h3>No. 153	集成切片采样</h3><h4>Minas Karamanis, Florian Beutler</h4>文摘：切片抽样是一种功能强大的马尔可夫链蒙特卡罗算法，它以最小的手动调整适应目标分布的特点。但是，切片采样的性能对用户指定的初始长度比例超参数非常敏感。此外，切片取样通常难以处理低比例或强相关分布。本文介绍了一种新的集成切片采样算法，该算法通过自适应地调整长度尺度来避开这些困难。此外，集成切片采样的性能不受线性相关的影响。这些算法构造简单，无需人工调整，并且可以在并行计算环境中轻松实现。实验结果表明，与传统的MCMC方法相比，集成切片采样在高相关目标分布（如1阶自回归过程和相关漏斗分布）上可以提高效率一个数量级以上。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06212">PDF</a>
<h3>No. 154	注意事项2vec：神经注意用户表示</h3><h4>Oren Barkan, Avi Caciularu, Ori Katz, Noam Koenigstein</h4>文摘：推荐系统的因子分解方法倾向于将用户表示为单个潜在向量。但是，用户行为和兴趣可能会在向用户提供的建议的上下文中发生变化。例如，在电影推荐的情况下，以前的用户数据通常比最近的数据信息量少。然而，在一部流行的续集电影面前，某部早期电影可能会突然变得更加相关。这只是一个例子，展示了在潜在的新建议出现时，各种可能动态改变用户兴趣的情况。在这项工作中，我们提出了注意项2vec（a I2V）-一个新的注意项2vec（I2V）的版本。AI2V采用上下文-目标-注意机制，以学习和捕捉用户历史行为（上下文）相对于潜在推荐项（目标）的不同特征。注意上下文目标机制使得最终的神经注意用户表示成为可能。我们在几个数据集上证明了AI2V的有效性，在这些数据集上，AI2V的性能优于其他基线。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06205">PDF</a>
<h3>No. 155	参数模态回归的隐函数学习方法</h3><h4>Yangchen Pan, Ehsan Imani, Martha White, Amir-massoud Farahmand</h4>文摘：对于多值函数，如给定输入的目标上的条件分布是多模态的，标准回归方法并不总是可取的，因为它们提供了条件均值。模态回归的目的是寻找条件模态，但仅限于非参数方法。这样的方法很难缩放，不能受益于参数函数逼近，如神经网络，它可以学习复杂的输入和目标之间的关系。在这项工作中，我们提出了一个参数化的模态回归算法，利用隐函数定理来发展一个学习输入和目标联合参数化函数的目标。我们在几个综合问题上的经验证明，我们的方法（i）可以学习多值函数并产生条件模式，（ii）可以很好地扩展到高维输入，（iii）对于某些单峰问题更有效，特别是对于高频数据，输入和目标之间的联合函数可以更好地捕捉它们之间的复杂关系。然后我们证明我们的方法在实际的模态回归问题中是实用的。我们的结论是，我们的方法对目标上具有不对称分布的两个回归数据集提供了小的改进。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06195">PDF</a>
<h3>No. 156	分段凸函数估计与模型选择</h3><h4>Kurt S. Riedel</h4>文摘：在给定噪声数据的情况下，当未知函数先验地由少数凸或凹区域组成时，考虑函数估计。当区域先验已知时，该估计在对偶空间中降为有限维凸优化。当区域的数目未知时，模型选择问题是确定凸性变化点的数目。我们使用基于期望的假拐点数目的导频估计器。<br><a href = "http://xxx.itp.ac.cn/pdf/1803.03903">PDF</a><h2>2020-02-18</h2>
<h3>No. 1	再培训还是不培训？--深CNN网络的有效剪枝方法</h3><h4>Marcin Pietron, Maciej Wielgosz</h4>摘要：卷积神经网络（CNN）在图像分类、目标检测、语义分割等图像处理任务中发挥着重要作用。CNN网络通常有几百个堆叠的层和几兆字节的权重。减少复杂性和内存占用的一种可能方法是修剪。剪枝是一个去除网络中连接两个相邻层神经元的权值的过程。当DL模型具有较高的卷积层数时，寻找具有指定精度下降的近似最优解的过程会更加复杂。本文对基于再培训和非再培训的几种方法进行了描述和比较。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07051">PDF</a>
<h3>No. 2	多任务协同智能的位分配</h3><h4>Saeed Ranjbar Alvar, Ivan V. Bajić</h4>文摘：近年来的研究表明，协作智能（CI）是一种很有前途的在移动设备上部署基于人工智能（AI）的服务的框架。在CI中，在移动设备和云之间分割出一个深层神经网络。在移动设备上获得的深层特征被压缩并传输到云端以完成推理。到目前为止，文献中的方法主要集中在将单个深度特征张量从移动设备转移到云上。这种方法不适用于一些具有多分支和跳跃连接的高性能网络。本文提出了多流、多任务CI的第一位分配方法。我们首先建立了一个多个任务的联合失真模型，作为分配给不同深度特征张量的比特率的函数。然后，利用该模型求解了总速率约束下的速率失真优化问题，得到了待传输张量之间的最优速率分配。实验结果表明，与几种不同的比特分配方法相比，该方案是有效的。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07048">PDF</a>
<h3>No. 3	基于图像结构的对象变形测试</h3><h4>Adrian Wildandyawan, Yasuharu Nishi</h4>摘要：由于需要大量生成测试用例并为其提供测试oracle，测试软件往往成本高昂。这通常被称为oracle问题。为了缓解oracle问题，人们提出了一种方法：变形测试。变质测试通过改变现有的测试用例来产生新的测试用例，并利用被测试系统（SUT）的输入和输出之间的变质关系来预测所产生的测试用例的预期输出。变形测试通常用于图像处理软件，其中对图像的属性应用更改以创建带有与原始图像相同的注释的新测试用例。我们将现有的方法称为基于图像的变形测试。在本研究中，我们提出一个基于物件的变质主义测试和一个复合变质主义测试，结合不同的变质主义测试方法，以相对增加测试覆盖率。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07046">PDF</a>
<h3>No. 4	深部张量压缩的前后预测</h3><h4>Hyomin Choi, Robert A. Cohen, Ivan V. Bajic</h4>摘要：近年来人工智能的应用，如协同智能和神经网络，涉及到在不同的计算设备之间传递深层特征张量。这就需要张量压缩来优化设备之间带宽受限信道的使用。本文提出了一种针对深特征张量的预测方案，称为前后（BaF）预测，它能显著减小张量的大小，提高张量的压缩性。我们使用最先进的目标检测器进行的实验表明，所提出的方法可以显著减少压缩从模型内部深层提取的特征张量所需的比特数，而检测性能的退化可以忽略不计，并且不需要重新训练网络权值。在保证网络精度损失分别小于1%和2%的情况下，张量减小了62%和75%。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07036">PDF</a>
<h3>No. 5	为知识跟踪提供适当的查询、键和值计算</h3><h4>Youngduck Choi, Youngnam Lee, Junghyun Cho, Jineon Baek, Byungsoo Kim, Yeongmin Cha, Dongmin Shin, Chan Bae, Jaewe Heo</h4>摘要：知识追踪是计算机辅助教育领域中一个广泛研究的问题，是通过学习活动来模拟学生知识的行为。尽管带有注意机制的模型比传统的方法（如贝叶斯知识跟踪和协作过滤）有更好的性能，但它们有两个共同的局限性。首先，这些模型依赖于浅层的注意力，无法捕捉到随着时间推移练习和反应之间的复杂关系。其次，没有广泛探讨用于知识追踪的自我注意层的查询、键和值的不同组合。通常将练习和交互（练习-响应对）分别用作查询和键/值的做法缺乏经验支持。本文提出了一种新的基于变压器的知识跟踪模型SAINT：分离自关注神经知识跟踪。SAINT具有编译码结构，其中运动和响应嵌入序列分别进入编码器和解码器，允许多次堆叠注意层。据我们所知，这是第一个提出一个用于知识跟踪的编码器-解码器模型的工作，该模型将深层的自我关注层分别应用于练习和响应。对一个大规模知识跟踪数据集的实证评估表明，SAINT在知识跟踪方面取得了最新的性能，与现有的最新模型相比，AUC提高了1.8%。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07033">PDF</a>
<h3>No. 6	基于多元时间序列分类的结构健康监测全卷积网络</h3><h4>Luca Rosafalco, Andrea Manzoni, Stefano Mariani, Alberto Corigliano</h4>文摘：提出了一种新的结构健康监测方法，旨在从普适传感器系统获取的数据中自动识别损伤敏感特征。将损伤检测和定位问题描述为分类问题，并通过完全卷积网络（FCNs）进行处理。基于物理模型（扮演被监控结构的数字孪生兄弟角色）的数值模拟数据，针对不同的损伤场景，对所提出的网络体系结构进行监督训练。基于这种简化的结构模型，在FCN的训练阶段考虑了多种载荷条件，设计了FCN的结构来处理不同长度的时间序列。神经网络的训练是在监测系统开始工作之前完成的，因此能够进行实时损伤分类。以八层剪力楼为算例，在两种荷载作用下，对该方法的数值性能进行了评估，其中一种荷载作用是模拟低能地震引起的随机振动。在结构响应中加入测量噪声，以模拟实际监测系统的输出。显示了非常好的分类能力：在九种可能的备选方案中（以健康状态和任何楼层的损伤为代表），损伤在高达95%的情况下被正确分类，从而显示了所提出的方法在实际应用中的强大潜力。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07032">PDF</a>
<h3>No. 7	眼跟踪数据处理中的强化学习</h3><h4>Wolfgang Fuhl</h4>文摘：提出了一种基于强化学习的眼动跟踪数据处理方法。它基于两个相反的代理，其中一个代理试图正确分类数据，另一个代理在数据中寻找模式，这些模式被操纵以隐藏特定信息。我们证明我们的方法是成功地适用于保护一个主题的隐私。此外，我们的方法可以评估眼睛跟踪数据的时间和空间信息对于特定分类目标的重要性。一般来说，这种方法也可用于刺激操作，使其对注视引导感兴趣。为此，本文提供了理论依据，这也是为什么我们还整合了一节如何应用这种方法进行凝视引导。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06806">PDF</a>
<h3>No. 8	基于w-LPPD-SVM集成的嵌入式稀疏自编码器</h3><h4>Yongming Li, Yan Lei, Pin Wang, Yuchuan Liu</h4>文摘：深度学习是一种具有强非线性特征变换的特征学习方法，在人工智能的许多领域中越来越重要。深度自动编码器是深度学习方法的代表方法之一，能够有效地提取数据集的抽象信息。但是，在深度特征变换过程中没有考虑深度特征与原始特征之间的互补性。此外，它还存在小样本问题。为了解决这些问题，本文提出了一种新的深度自动编码器-混合特征嵌入式叠置稀疏自动编码器（HESSAE）。在训练过程中，HFESAE能够通过嵌入原始特征来过滤弱隐层输出，从而学习鉴别深层特征。针对小样本问题限制了抽象信息的类表示能力的问题，设计了一种将HFESAE学习到的抽象信息与原始特征相结合，获得混合特征进行特征约简的特征融合策略。该策略是基于L1正则化的混合特征选择策略，其次是支持向量机（SVM）集成模型，在每个基分类器上设计并使用加权局部判别保持投影（w_-LPPD）。最后，利用几个具有代表性的公共数据集验证了算法的有效性。实验结果表明，所提出的特征学习方法与现有和最先进的特征学习算法（包括一些有代表性的深度自编码方法）相比，具有更好的性能。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06761">PDF</a>
<h3>No. 9	分散数据的神经结构搜索</h3><h4>Mengwei Xu, Yuxin Zhao, Kaigui Bian, Gang Huang, Qiaozhu Mei, Xuanzhe Liu</h4>摘要：为了保护用户隐私，同时实现移动智能，人们提出了在分散数据上训练深层神经网络的技术。然而，对分散数据的训练使得神经结构的设计变得相当困难。在为异构移动平台设计和部署不同的神经体系结构时，这种困难进一步扩大。在这项工作中，我们提出了一个自动神经架构搜索到分散训练，作为一个新的DNN训练范例称为联邦神经架构搜索，即联邦NAS。为了解决客户端计算和通信资源有限的主要挑战，我们提出了一个高效联邦NAS的高度优化框架FedNAS。FedNAS充分利用了体系结构搜索过程中模型候选重新训练不足的关键机会，并结合了三个关键优化：部分客户端上的并行候选训练、性能较差的候选提前丢弃和动态轮数。FedNAS在大规模数据集和典型CNN体系结构上进行了测试，它达到了与最先进的NAS算法相当的模型精度，该算法使用集中数据训练模型，并且与联邦NAS的直接设计相比，它还将客户机成本降低了两个数量级。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06352">PDF</a>
<h3>No. 10	运动皮层刺激与肌肉反应的映射：一种深部神经网络建模方法</h3><h4>Md Navid Akbar, Mathew Yarossi, Marc Martinez-Gost, Marc A. Sommer, Moritz Dannhauer, Sumientra Rampersad, Dana Brooks, Eugene Tunik, Deniz Erdoğmuş</h4>文摘：深部神经网络（DNN）能够可靠地模拟相应脑刺激引起的肌肉反应，有可能为许多基础科学和应用案例增加协调运动控制的知识。这些案例包括了解由于中风造成的神经损伤而导致的异常运动模式，以及基于刺激的神经康复干预措施，如成对联合刺激。在这项工作中，我们探索了潜在的DNN模型，并推荐了最小平方误差的模型来优化M2M网络的性能，M2M网络是一个将运动皮层的经颅磁刺激映射到相应肌肉反应的网络，使用：有限元模拟，经验神经反应曲线，卷积自动编码器，一个单独的深度网络映射器，和多肌肉激活的记录。我们讨论了不同建模方法和架构背后的基本原理，并对比了它们的结果。此外，为了获得复杂性和性能分析之间的权衡的比较洞察力，我们探索不同的技术，包括扩展的两个经典的信息标准M2M网。最后，我们发现，当输入端使用神经反应曲线时，类似于将运动皮层刺激映射为与肌肉直接和协同连接的组合的模型表现最佳。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06250">PDF</a>
<h3>No. 11	精密浇口：动态双精度激活提高神经网络效率</h3><h4>Yichi Zhang, Ritchie Zhao, Weizhe Hua, Nayun Xu, G. Edward Suh, Zhiru Zhang</h4>文摘：提出了一种适用于深部神经网络的端到端可训练动态双精度量化技术——精密选通（PG）。PG以较低的精度计算大多数特征，而以较高的精度计算只有一小部分重要特征以保持精度。该方法适用于多种DNN体系结构，大大降低了DNN执行的计算成本，几乎没有精度损失。我们的实验表明，PG在CNNs上取得了很好的效果，包括静态压缩的移动友好网络，如ShuffleNet。与目前最先进的基于预测的量化方案相比，PG在ImageNet上的计算量减少了2.4美元，达到了相同或更高的精度。PG还适用于RNNs。与8位均匀量化相比，PG在PNN树银行数据集上对每一个字的困惑获得了1.2%的改善，2.7的计算成本降低了LSTM。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07136">PDF</a>
<h3>No. 12	基于深度学习视觉分类的物理硬标签查询攻击</h3><h4>Ryan Feng, Jiefeng Chen, Nelson Manohar, Earlence Fernandes, Somesh Jha, Atul Prakash</h4>文摘：提出了一种在黑盒硬标签设置中的物理对抗示例算法生存选择算法，攻击者只能访问模型预测类标签。假设这种对模型的有限访问与之前的工作假设的白盒设置相比，对于专有网络物理和云系统等设置更为相关。利用物理攻击的特性，提出了一种基于物理变换扰动生存性的攻击方法。通过简单地查询硬标签预测模型，我们优化扰动以在许多不同的物理条件下生存，并表明即使在硬标签威胁模型中，对抗性示例仍然是网络物理系统（cps）的安全风险。我们证明了Survival OPT是一种高效且健壮的查询方法：使用少于200K的查询，我们成功地通过设置在98.5%的视频帧中攻击了一个被误分类为限速30km/hr的停车标志。生存OPT也优于现有的硬标签和物理方法的基线组合，这需要超过10倍的查询来获得不太健壮的结果。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07088">PDF</a>
<h3>No. 13	PCSGAN：用于热图像和近红外图像到可见光图像转换的感知循环合成生成对抗网络</h3><h4>Kancharagunta Kishan Babu, Shiv Ram Dubey</h4>摘要：在现实生活中，由于光照条件的影响，在可见光光谱中很难捕捉到图像。然而，在这种情况下，可以使用近红外（NIR）和热（THM）摄像机拍摄图像。近红外和THM图像包含有限的细节。因此，需要将图像从THM/NIR转换为VIS，以便更好地理解。然而，由于存在较大的领域差异和缺乏丰富的数据集，这是一项非平凡的任务。目前，生成性对抗网络（generativedepartarialnetwork，GAN）能够将图像从一个域转换到另一个域。现有的基于GAN的训练方法大多采用对抗性和像素损失（如L1或L2）相结合的方法作为训练目标函数。在THM/NIR-VIS变换的情况下，用这种目标函数变换后的图像质量仍然达不到要求。因此，需要更好的目标函数来提高变换图像的质量、细节和真实感。为了解决这一问题，提出了一种新的THM/NIR-VIS图像转换模型：感知循环合成生成对抗网络（PCSGAN）。PCSGAN使用感知（即基于特征的）损失、像素损失和对抗性损失的组合。采用定量和定性方法对PCSGAN模型在WHU-IIP人脸和RGB-NIR场景数据集上的性能进行了评价。所提出的PCSGAN在SSIM、MSE、PSNR和LPIPS评价指标方面优于现有的图像转换模型，包括Pix2pix、DualGAN、CycleGAN、PS2GAN和PAN。代码可在以下位置获得：url{this https url}。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07082">PDF</a>
<h3>No. 14	基于神经网络处理器结构的批处理加速优化调度体系结构</h3><h4>Phani Kumar Nyshadham, Mohit Sinha, Biswajit Mishra, H S Vijay</h4>摘要：在神经网络拓扑中，算法是在成批的数据张量上运行的。数据批通常被调度到并行执行的计算核心上。对于运行在成批数据上的算法，通过适当利用硬件资源，需要一个最优的成批调度体系结构，从而大大减少训练和推理时间。在本文中，我们建议通过一个调度架构来加速神经网络的批处理算法，以实现最佳的计算功率利用率。所提出的优化调度体系结构可以构建在硬件中，也可以单独在软件中实现，这可以用来加速批处理算法。结果表明，与以往的算法相比，该结构加快了批处理算法的速度。所提出的思想适用于任何用于神经网络的HPC架构。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07062">PDF</a>
<h3>No. 15	用于音乐源分离的元学习提取器</h3><h4>David Samuel, Aditya Ganeshan, Jason Naradowsky</h4>文摘：提出了一种基于分层元学习的音乐源分离模型（meta-TasNet），该模型使用生成器模型来预测单个提取器模型的权重。这样可以实现有效的参数共享，同时还允许特定于仪器的参数化。Meta-TasNet被证明比独立训练或多任务环境下训练的模型更有效，并且实现了与最新方法相当的性能。与后者相比，我们的提取器包含的参数更少，运行时性能更快。我们讨论了重要的架构考虑因素，并探讨了这种方法的成本和好处。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.07016">PDF</a>
<h3>No. 16	二进制网络的学习结构</h3><h4>Kunal Pratap Singh, Dahyun Kim, Jonghyun Choi</h4>摘要：大多数二进制网络的骨干结构都是著名的浮点结构，如ResNet家族。针对浮点网络的体系结构不适合二进制网络的问题，我们提出了二进制网络体系结构（BNAS）的搜索方法。具体来说，在基于单元的搜索方法的基础上，我们定义了一组新的层类型，设计了一个新的单元模板，重新发现了零层的实用性，并提出使用零层来学习性能良好的二进制网络。此外，我们建议多样化的早期搜索，以学习性能更好的二进制架构。我们的搜索二进制网络在CIFAR10和ImageNet数据集上的性能优于最新的二进制网络。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06963">PDF</a>
<h3>No. 17	引文推荐：方法和数据集</h3><h4>Michael Färber, Adam Jatowt</h4>摘要：引文推荐是指对给定文本进行引文推荐的任务。由于近年来发表的科学著作一方面超载，另一方面在撰写科学文本时需要引用最合适的出版物，引文推荐已成为一个重要的研究课题。近年来，提出了几种方法和评价数据集。然而，据我们所知，没有对引文推荐进行明确的文献调查。本文对引文自动推荐的研究进行了深入的介绍。然后，我们对引文推荐的方法和数据集进行了概述，并使用不同的维度确定了差异和共性。最后，我们对评估方法进行了说明，并概述了评估中的一般挑战以及如何应对这些挑战。我们仅限于科学出版物的引文推荐，因为这类文献在这方面的研究最多。然而，本次调查中的许多观察和讨论也适用于其他类型的文本，如新闻文章和百科全书文章。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06961">PDF</a>
<h3>No. 18	放大神秘</h3><h4>Terence Broad, Frederic Fol Leymarie, Mick Grierson</h4>摘要：深度神经网络在制造逼真的深度假象方面已经变得非常出色，人们的图像（对未经训练的人来说）与真实的图像无法区分。这些是由学习区分真假图像的算法生成的，并经过优化以生成系统认为真实的样本。本文，以及由此产生的一系列艺术作品被挫败，探索了逆转这一过程，而不是优化系统，以产生它认为是假的图像的审美结果。最大化数据的不可能性，进而放大这些机器幻觉的不可思议性质。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06890">PDF</a>
<h3>No. 19	基于可解释神经网络回归的大型生物测量学</h3><h4>Taro Langner, Håkan Ahlström, Joel Kullberg</h4>摘要：英国生物银行的这项研究成功地为32000多名志愿者进行了颈部到膝盖的身体核磁共振成像。每次扫描都链接到大量的元数据，提供了对成像解剖学和相关健康状态的全面调查。尽管有研究的潜力，但这大量的数据对现有的评估方法提出了挑战，这些方法通常依赖于人工输入。迄今为止，心血管和代谢危险因素的参考值范围还不完整。在这项工作中，神经网络被训练用于回归，以自动推断从颈部到膝盖的身体MRI的各种生物学指标。该方法无需人工干预或地面真相分割训练。研究领域涉及64个变量，这些变量来自人体测量、双能X射线吸收测量（DXA）、基于图谱的分割和专用肝脏扫描。标准化框架与ResNet50进行了7倍交叉验证，与目标值（中值R^2>0.97）非常吻合。对聚合显著性地图的解释表明，该网络正确地针对特定的身体区域和四肢，并学会了模拟不同的模式。在几个身体成分指标上，预测的质量在已建立的金标准技术之间观察到的变异范围内。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06862">PDF</a>
<h3>No. 20	抽象视觉推理的层次规则归纳网络</h3><h4>Sheng Hu, Yuqing Ma, Xianglong Liu, Yanlu Wei, Shihao Bai</h4>摘要：抽象推理是指对信息进行分析，在无形的层面上发现规律，以创新的方式解决问题的能力。Raven的渐进矩阵（RPM）测试通常用于检查抽象推理的能力。在测试中，要求受试者根据矩阵中的基本规则，从答案集中确定正确的选择，以填充RPM右下角缺少的面板（例如，3$\times$3矩阵）。近年来，利用卷积神经网络（CNNs）的优势，在解决转速测试问题上取得了可喜的进展。不幸的是，仅仅依赖于矩阵级的关系抽取，他们无法识别RPM中行/列内部或跨行/列的复杂属性模式。为了解决这一问题，本文提出了一种层次化的规则归纳网络（HriNet），它通过暗示人类的归纳策略。HriNet从不同层次提取多粒度规则嵌入，并通过门控嵌入融合模块进行集成。我们进一步引入了一种基于嵌入的规则相似度度量，使得HriNet不仅可以利用元组损失进行训练，而且可以根据相似度得分推断出最佳答案。为了全面评估HriNet，我们首先修复了最近RAVEN数据集中包含的缺陷，并生成了一个新的称为Balanced RAVEN的数据集。然后在大规模数据集PGM和我们的平衡RAVEN上进行了大量的实验，结果表明HriNet在很大程度上优于最新的模型。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06838">PDF</a>
<h3>No. 21	歌手识别中伴奏的混淆</h3><h4>Tsung-Han Hsieh, Kai-Hsiang Cheng, Zhe-Cheng Fan, Yu-Ching Yang, Yi-Hsuan Yang</h4>摘要：歌手识别是一项重要的工作，有着广泛的应用。然而，由于许多问题，这项任务仍然具有挑战性。一个主要的问题是，在音乐制作中，背景器乐与人声混用的混淆因素。歌手识别模型可以学习从歌曲的器乐部分提取非声乐相关特征，如果歌手只在特定的音乐环境（例如，流派）中演唱。因此，当歌手在看不见的环境中演唱时，这个模型就不能很好地概括。在本文中，我们试图解决这个问题。具体来说，我们使用开源的unmix工具，一个在源代码分离方面具有最先进性能的开源工具，来分离音乐的声乐和器乐曲目。然后，我们研究了两种方法来训练歌手识别模型：仅从分离的人声中学习，或从一组增加的数据中“洗牌和混音”不同歌曲的分离的人声轨迹和器乐轨迹，以人为地使歌手在不同的上下文中演唱。我们还结合了从声乐旋律轮廓学习到的旋律特征，以获得更好的表现。在一个名为artist20的基准数据集上的评估结果表明，这种数据增强方法大大提高了歌手识别的准确性。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06817">PDF</a>
<h3>No. 22	利用离线分析模拟ML系统的性能</h3><h4>Hongming Huang, Peng Cheng, Hong Xu, Yongqiang Xiong</h4>文摘：我们认为基于离线评测的仿真是一种有希望的方法，可以更好地理解和改进复杂的ML系统。我们的方法使用操作级分析和基于数据流的模拟，以确保为所有框架和ML模型提供一个统一和自动化的解决方案，并且通过考虑实际系统中的各种并行化策略也很精确。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06790">PDF</a>
<h3>No. 23	如何在业余时间拥有NAS</h3><h4>Sanghyun Hong, Michael Davinroy, Yiğitcan Kaya, Dana Dachman-Soled, Tudor Dumitraş</h4>摘要：新的数据处理管道和新的网络结构日益推动着深度学习的成功。因此，业界将性能最好的架构视为知识产权，并投入大量计算资源通过神经架构搜索（NAS）来发现此类架构。这为对手窃取这些新架构提供了激励；当在云中使用时，为了提供机器学习服务，对手也有机会通过利用一系列硬件侧通道来重建架构。然而，在不知道计算图（例如，层、分支或跳过连接）、结构参数（例如，卷积层中的滤波器数量）或特定预处理步骤（例如，嵌入）的情况下重建新的架构和管道是一项挑战。本文设计了一种新的深度学习系统的关键部件重构算法，该算法利用了缓存侧信道攻击Flush+Reload带来的少量信息泄漏。我们使用Flush+Reload来推断计算的轨迹和每次计算的时间。然后，我们的算法从跟踪中生成候选计算图，并通过参数估计过程消除不兼容的候选。我们在PyTorch和Tensorflow中实现了我们的算法。实验证明，我们可以重建MalConv（一种用于恶意软件检测的新型数据预处理管道）和ProxylessNAS-CPU（一种用于优化在CPU上运行的ImageNet分类的新型网络体系结构），而无需知道体系结构族。在这两种情况下，我们都会得到0%的误差。这些结果表明，硬件侧信道是一种实用的针对MLaaS的攻击载体，应进一步研究其对深度学习系统安全性的影响。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06776">PDF</a>
<h3>No. 24	正则化信息最大化的卷积神经网络超像素分割</h3><h4>Teppei Suzuki</h4>文摘：提出了一种在推理时间内优化随机初始化卷积神经网络（CNN）的无监督超像素分割方法。我们的方法通过CNN从没有任何标签的单一图像中生成超像素，通过最小化在推理时间内提出的超像素分割目标函数。与现有的许多方法相比，我们的方法有三个优点：（i）利用美国有线电视新闻网之前的图像进行超像素分割，（ii）根据给定的图像自适应地改变超像素的数量，以及（iii）通过向目标函数添加辅助成本来控制超像素的性质。我们在BSDS500和SBD数据集上定量和定性地验证了该方法的优势。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06765">PDF</a>
<h3>No. 25	高斯平滑语义特征（GSSF）——基于MSCOCO框架的印度语（孟加拉语）视觉字幕语言研究</h3><h4>Chiranjib Sur</h4>翻译后摘要：在这项工作中，我们引入了高斯平滑语义特征（GSSF）为更好的语义选择印度区域语言为基础的图像字幕，并介绍了一个过程中，我们使用现有的翻译和英语人群来源的句子进行培训。我们已经表明，这种体系结构是一种很有前途的替代资源，那里的资源紧张。我们的主要贡献是为孟加拉语（世界上第五种广泛使用的语言）开发具有完全不同语法和语言属性的深度学习架构。我们已经证明，这些方法对于复杂的应用程序（如从图像上下文生成语言）非常有效，并且可以通过引入约束、更广泛的特征和独特的特征空间使表示多样化。我们还证明，在传统的LSTM和特征分解网络中使用平滑语义张量可以获得绝对的精度和多样性。通过更好的学习架构，我们成功地建立了一个自动化的算法和评估程序，可以帮助评估合格的应用程序，而无需专业知识和人工干预。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06701">PDF</a>
<h3>No. 26	SBERT-WK：一种基于BERT模型的句子嵌入方法</h3><h4>Bin Wang, C.-C. Jay Kuo</h4>摘要：句子嵌入是自然语言处理（NLP）中的一个重要研究课题，它能将知识传递给下游任务。同时，一个被称为BERT的上下文化的单词表示在许多NLP任务中实现了最新的性能。然而，从基于BERT的词模型中生成高质量的句子表示是一个开放的问题。以往的研究表明，不同层次的BERT捕捉不同的语言属性。这使得我们可以跨层融合信息，以找到更好的句子表示。在这项工作中，我们研究了深层语境化模型的词表示的分层模式。然后，通过对单词表示所跨越的空间进行几何分析，对基于BERT的单词模型进行剖分，提出了一种新的句子嵌入方法。它被称为SBERT-WK方法。SBERT-WK无需进一步培训。我们评估了SBERT-WK的语义文本相似度和下游监督任务。此外，本文还提出了10个句子级的探究任务，用于详细的语言分析。实验表明，SBERT-WK达到了最先进的性能。我们的代码是公开的。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06652">PDF</a>
<h3>No. 27	最近邻规则的核心集</h3><h4>Alejandro Flores Velazco, David M. Mount</h4>文摘：最近邻凝聚问题是从一组标记点P中找到一个子集R，使得对于R中的每一个点P，P的最近邻R都具有与P相同的标记，这是由于分类应用的缘故，其中，最近邻规则将点集中最近邻的标签指定给未标记的查询点。在这种情况下，压缩的目的是减少对新点进行分类所需的集合的大小。然而，寻找这样的最小基数子集是NP困难的，而且大多数研究都集中在没有性能保证的实用启发式算法上。此外，总是使用精确的最近邻居，忽略了在最近的邻居被近似计算时的分类精度的影响。在本文中，我们提出这些缺点，提出新的近似敏感准则的最近邻凝聚问题，以及实用算法与可证明的性能保证。我们描述了足够的条件，保证正确分类未标记点使用近似最近邻查询这些子集，引入了概念集分类最近的邻居规则。此外，我们证明了具有这些特征的子集是NP难的，其基数近似于最小基数子集。此外，我们提出了新的算法来计算这样的子集，具有严格的近似因子在一般度量，以及改进因子倍度量和LpP度量与P>＝2。最后，我们展示了一种替代的实现方案，减少了最坏情况下的时间复杂度之一，这些算法，成为第一个真正的二次近似算法的最近邻凝聚问题。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06650">PDF</a>
<h3>No. 28	编解码框架下的语音转换</h3><h4>Jayneel Parekh, Preeti Rao, Yi-Hsuan Yang</h4>文摘：本文的目标是将一组口语台词转换成歌唱台词。与以往基于信号处理的方法不同，我们采用基于学习的方法来解决这个问题。这使我们能够自动地对转换的各个方面进行建模，从而克服对特定输入的依赖，例如高质量的歌唱模板或音素乐谱同步信息。具体来说，我们为我们的任务提出了一个编码器-解码器框架。给定语音的时频表示和目标旋律轮廓，我们学习编码，使我们能够综合歌唱，在遵守目标旋律的同时保留说话人的语言内容和音色。我们还提出了一个基于多任务学习的目标，以提高歌词的可懂度。我们对我们的框架进行了定量和定性分析。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06595">PDF</a>
<h3>No. 29	管道干预</h3><h4>Eshwar Ram Arunachaleswaran, Sampath Kannan, Aaron Roth, Juba Ziani</h4>文摘：介绍了由分层有向无环图和一组控制连续层间转换的随机矩阵定义的{管道干预}问题。这个图表是一个程式化的模型，用来描述来自不同人群的人们如何获得机会，最终获得某种回报。在我们的模型中，个体按照固定的概率分布出生在一个初始位置（即图的第一层中的某个节点），然后根据转移矩阵在图中随机前进，直到到达图的最后一层中的某个节点；最后一层中的每个节点都有一个与之关联的\emph{reward}。管道干预问题要求在预算约束下，如何通过图对控制人们随机转换的转换矩阵进行代价最大的更改。我们考虑两个目标：社会福利最大化，和公平动机最大值目标，寻求最大值的人口（起始节点）的EMPH{{}}期望值。我们考虑的最大值目标的两个变种，结果是不同的，这取决于我们是否需要确定性解决方案或允许随机化。对于每一个目标，我们给出了一个有效的近似算法（添加剂FPTAS）的恒定宽度网络。在我们的设置中，我们也严格地描述了“公平价格”：最高可实现的社会福利与最高社会福利之间的比率与最大值最优解的一致性。最后，我们表明，对于多项式宽度的网络，即使近似最大值目标到任何常数因子是NP-hard，即使对于具有恒定深度的网络。这说明在我们的实证结果中，对宽度的限制是必要的。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06592">PDF</a>
<h3>No. 30	将自然语言解析为一阶逻辑的神经模型探讨</h3><h4>Hrituraj Singh, Milan Aggrawal, Balaji Krishnamurthy</h4>摘要：语义分析是从自然语言文本中获取机器可解释表示的任务。我们考虑了一个这样的形式化表示-一阶逻辑（FOL），并探讨了神经模型在英语句子的FOL分析中的能力。我们将FOL分析建模为一个序列到序列的映射任务，在给定一个自然语言句子的情况下，它被编码成一个中间表示，使用LSTM，然后是一个解码器，解码器在相应的FOL公式中依次生成谓词。我们通过引入一种变量对齐机制来改进标准的编码器-解码器模型，使其能够在预测的FOL中跨谓词对齐变量。进一步证明了在每个解码器步骤中预测FOL实体Unary、二进制、变量和范围实体的类别的有效性，作为提高生成的FOL的一致性的辅助任务。我们进行严格的评估和广泛的消融。我们还将发布我们的代码以及大规模的FOL数据集和模型，以帮助进一步研究NLP中基于逻辑的解析和推理。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06544">PDF</a>
<h3>No. 31	隐私保护回归的分布式绘制方法</h3><h4>Burak Bartan, Mert Pilanci</h4>文摘：本文研究了大规模回归问题的分布式绘制方法。在异步分布式系统中，我们利用多个随机草图来减少问题的维数，同时保护隐私和提高散乱者的弹性。我们推导出新的近似保证经典草图方法，并分析参数的平均分布草图的准确性。在分布式环境下，我们考虑了随机矩阵，包括高斯、随机Hadamard、均匀采样和杠杆分数采样。此外，为了提高计算效率，我们提出了一种结合抽样和快速随机投影的混合方法。在无服务器计算平台上，通过大规模的实验验证了分布式草图的性能。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06538">PDF</a>
<h3>No. 32	学习为输入句子生成多种风格的转换输出</h3><h4>Kevin Lin, Ming-Yu Liu, Ming-Ting Sun, Jan Kautz</h4>摘要：文本风格转换是指以不同的风格对给定文本进行重新措辞的任务。虽然已经提出了各种方法来提高技术水平，但它们通常假设传输输出遵循delta分布，因此它们的模型无法为给定的输入文本生成不同的样式传输结果。为了解决这个问题，我们提出了一个一对多的文本风格转换框架。与以往学习将输入句子转换为输出句子的一对一映射的工作不同，我们的方法学习一对多映射，可以将输入句子转换为多个不同的输出句子，同时保留输入内容。这是通过使用潜在分解方案的对抗性训练来实现的。具体来说，我们将输入语句的潜在表示分解为捕获语言风格变化的样式代码和编码语言风格无关内容的内容代码。然后，我们将内容代码与样式代码相结合，以生成样式传输输出。通过将相同的内容代码与不同的样式代码组合，我们生成不同的样式传输输出。大量的实验结果与使用不同性能度量集的多个公共数据集上的几种文本样式传输方法进行了比较，验证了所提方法的有效性。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06525">PDF</a>
<h3>No. 33	盲对抗网络扰动</h3><h4>Milad Nasr, Alireza Bahramali, Amir Houmansadr</h4>文摘：深度神经网络（DNNs）由于其在很大程度上优于传统的（如统计）技术，因此被广泛应用于各种流量分析问题，如网站指纹识别和流量关联等。然而，深部神经网络很容易受到对抗性例子的攻击：由于小的对抗性扰动，模型错误地标记了对抗性输入到模型中。在本文中，我们首次证明对手可以通过在网络流量模式上应用对手扰动来击败基于DNN的流量分析技术。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06495">PDF</a>
<h3>No. 34	学习分组：一个自底向上的三维零件发现框架</h3><h4>Tiange Luo, Kaichun Mo, Zhiao Huang, Jiarui Xu, Siyu Hu, Liwei Wang, Hao Su</h4>摘要：我们解决了在不可见类别中发现物体的三维零件的问题。能够学习零件的几何先验知识，并将其转移到不可见的类别之前，对数据驱动的形状分割方法提出了根本性的挑战。作为一个上下文盗贼问题，我们提出了一个基于学习的聚集聚类框架，该框架学习一个分组策略，以自下而上的方式逐步将小部分提议分组为大的提议。我们方法的核心是限制用于提取零件级特征的局部上下文，这鼓励了对不可见类别的泛化。在大规模细粒度三维零件数据集PartNet上，我们证明了该方法可以在不看到任何标注样本的情况下，将从3个训练类别中学习到的零件知识转移到21个不可见的测试类别中。对四个形状分割基线的定量比较表明，我们的方法达到了最先进的性能。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06478">PDF</a>
<h3>No. 35	相似选择的单调基数估计：一种深度学习方法</h3><h4>Yaoshu Wang, Chuan Xiao, Jianbin Qin, Xin Cao, Yifang Sun, Wei Wang, Makoto Onizuka</h4>摘要：由于深度学习技术在捕捉底层数据分布方面的突出能力，近年来被广泛应用于一系列传统的数据库问题中。本文探讨了利用深度学习进行相似性选择基数估计的可能性。准确、高效地解决这一问题对于许多数据管理应用，特别是查询优化是至关重要的。此外，在某些应用中，估计的基数应该是一致的和可解释的。因此，首选单调估计w.r.t.查询阈值。提出了一种适用于任意数据类型和距离函数的通用方法。该方法由特征提取模型和回归模型组成。特征提取模型将原始数据和阈值转换为Hamming空间，利用基于深度学习的回归模型，利用基数w.r.t.的增量特性，使阈值具有精度和单调性。我们开发了适合我们的模型的训练策略以及快速估计的技术。我们还讨论了如何处理更新。我们通过实验证明了该方法的准确性和效率，并说明了它如何提高查询优化器的性能。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06442">PDF</a>
<h3>No. 36	混合引文：一种上下文感知引文推荐的混合模型</h3><h4>Michael Färber, Ashwath Sampath</h4>摘要：引文推荐系统旨在推荐一篇完整的论文或一小部分被称为引文上下文的文本的引文。引文推荐过程被称为局部引文推荐，是本文研究的重点。本文首先研究了基于嵌入、主题建模和信息检索技术的引文推荐方法。根据我们的知识，我们首次将性能最好的算法组合成半遗传混合推荐系统，用于引文推荐。我们基于多个数据集对单一方法和混合方法进行了离线评估，如微软学术图（MAG）和结合arXiv和ACL的MAG。我们进一步进行用户研究，以评估我们的在线方法。我们的评估结果表明，包含嵌入和基于信息检索的组件的混合模型比其单独的组件和进一步的算法有很大的优势。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06406">PDF</a>
<h3>No. 37	基于物联网的大城市交通数据挖掘系统</h3><h4>Daniel. Firouzimagham, Mohammad. Sabouri, Fatemeh. Adhami</h4>摘要：目前，在包括伊朗在内的发展中国家，由于人口的增长，汽车的数量在不断增加。最近，这导致浪费时间陷入交通堵塞，每天上下班的时间增加，事故增加。因此，有必要由交警来控制交通拥堵，有效地拓宽道路，选择减少市民交通的最佳途径。因此，掌握每条车道上的瞬时交通量是很重要的。今天，许多交通组织服务，如交警和城市交通控制系统，使用交通摄像机、感应传感器、卫星图像、雷达传感器、超声波技术和射频识别（RFID）进行城市交通诊断。但该方法存在着受大气条件影响大流量时效率不高、无法检测出平行交通等问题。本文提出的基于物联网的交通拥堵检测方法，包含一个智能系统，通过计算该区域的空气污染量来检测交通拥堵。经实验验证，结果令人满意。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06374">PDF</a>
<h3>No. 38	UniViLM：多模态理解和生成的统一视频和语言预训练模型</h3><h4>Huaishao Luo, Lei Ji, Botian Shi, Haoyang Huang, Nan Duan, Tianrui Li, Xilin Chen, Ming Zhou</h4>文摘：提出了统一的视频和语言预训练模型UniViLM，用于多模态理解和生成。针对近年来基于BERT的NLP和图像语言预训练技术的成功应用，VideoBERT和CBT提出了一种基于叙事教学视频的视频和语言预训练BERT模型。与他们只进行理解任务预训练的工作不同，我们提出了一个统一的视频语言理解和生成任务预训练模型。我们的模型由4个部分组成，包括两个单模式编码器、一个交叉编码器和一个带变压器主干的解码器。我们首先对我们的模型进行预训练，以学习大型教学视频数据集上视频和语言的通用表示。然后，我们对模型进行了两个多模式任务的微调，包括理解任务（基于文本的视频检索）和生成任务（多模式视频字幕）。大量的实验表明，该方法可以提高理解任务和生成任务的性能，达到了最新的效果。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06353">PDF</a>
<h3>No. 39	基于条件循环一致对抗网络的多对多语音转换</h3><h4>Shindong Lee, BongGu Ko, Keonnyeong Lee, In-Chul Yoo, Dongsuk Yook</h4>摘要：语音转换是指在不改变话语语言内容的情况下，改变话语的说话人特征。许多关于语音转换的工作都需要并行训练数据，而这些数据的获取成本很高。近年来，循环一致对抗网络（cycle-consistent particial network，CycleGAN）已被应用于语音转换领域，显示了其最新的性能。然而，基于CycleGAN的语音转换只能用于一对扬声器，即两个扬声器之间的一对一语音转换。在本文中，我们通过调节扬声器上的网络来扩展CycleGAN。结果表明，该方法可以在一个生成性对抗网络（GAN）上实现多个说话人之间的多对多语音转换。与为每对扬声器建立多个循环相比，该方法在不影响转换语音质量的前提下，显著降低了计算和空间开销。基于VCC2018语料库的实验结果验证了该方法的有效性。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06328">PDF</a>
<h3>No. 40	基于小能量掩蔽的端到端语音识别改进神经网络训练</h3><h4>Chanwoo Kim, Kwangyoun Kim, Sathish Reddy Indurthi</h4>文摘：本文提出了一种小能量掩蔽（SEM）算法，它屏蔽了输入值低于某一阈值的情况。更具体地说，如果滤波器组能量小于某个能量阈值，则屏蔽时频滤波器组。采用均匀分布的方法，随机产生该能量阈值与每个话语的峰值滤波器组能量之比（分贝）。通过此掩蔽过程，将缩放未掩蔽的特征元素，以便特征值的总和保持不变。这个非常简单的算法在标准LibriSpeech测试clean和测试其他集上的字错误率（WER）分别比基线端到端语音识别系统提高了11.2%和13.5%。此外，与输入-退出算法相比，SEM算法在同一LibriSpeech test clean和test-other集上分别提高了7.7%和11.6%。采用改进的变压器LM浅熔技术，在LibriSpeech试验清洁集上获得了2.62%的功率，在LibriSpeech试验其他集上获得了7.87%的功率。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06312">PDF</a>
<h3>No. 41	军团：最佳的首次混合测试</h3><h4>Dongge Liu, Gidon Ernst, Toby Murray, Benjamin I. P. Rubinstein</h4>摘要：军团是一种灰盒混合工具，旨在平衡模糊和符号执行的互补性，以达到两者的最佳效果。提出了蒙特卡罗树搜索（MCTS）的一种新方法，即在不确定性条件下，在最优优先搜索策略的指导下，将程序探索定义为顺序决策。它依赖于近似路径保持模糊化，一种新的约束随机测试实例，它快速生成许多可能针对感兴趣的程序部分的不同输入。在2020年的测试中，该原型在22个类别中有9个类别的最佳分数的90%以内完成。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06311">PDF</a>
<h3>No. 42	基于功能近红外光谱的深度学习精确应力评估</h3><h4>Mahya Mirbagheri, Ata Jodeiri, Naser Hakimi, Vahid Zakeri, Seyed Kamaledin Setarehdan</h4>摘要：压力是威胁人类健康的主要因素之一。为了通过分析大脑和心脏相关信号来评估或缓解压力，已经进行了大量的研究。本研究利用10名健康志愿者脑功能近红外光谱（fNIRS）所产生的信号，通过深度学习系统对蒙特利尔成像应激任务所诱发的应激进行评估。本文提出的深度学习系统主要由两部分组成：一是利用一维卷积神经网络建立信息特征映射。然后，用一组深全连接层预测应力存在概率。实验结果表明，训练后的fNIRS模型进行应力分类的准确率达到88.52-+0.77%。所提出的深度学习系统在FNIRS测量上的训练导致比在FNIRS研究中提出的现有方法中更高的应力分类精度，其中已经使用了相同的实验过程。该方法具有较好的稳定性和较低的预测偏差。此外，该方法计算量小，为实时应力评估提供了可能。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06282">PDF</a>
<h3>No. 43	Twin BERT：将知识提取到双结构BERT模型以实现高效检索</h3><h4>Wenhao Lu, Jian Jiao, Ruofei Zhang</h4>文摘：BERT等预训练语言模型在各种NLP任务中取得了巨大的成功，但其优越的性能对计算资源提出了更高的要求，阻碍了其在低延迟IR系统中的应用。本文提出了一种有效的twin BERT检索模型，该模型采用双结构的类BERT编码来分别表示查询和文档，并通过交叉层来组合嵌入，产生相似度得分。与BERT不同，TwinBERT将两个输入语句连接在一起并进行编码，在编码过程中对它们进行解耦，独立生成查询和文档所需的嵌入，这使得文档嵌入可以离线预计算并缓存在内存中。因此，留给运行时的计算仅来自查询编码和查询文档交叉。这种改变可以节省大量的计算时间和资源，从而显著提高服务效率。此外，本文还提出了一些精心设计的网络层和训练策略，进一步降低了计算量，同时保持了BERT模型的良好性能。最后，我们开发了两个版本的TwinBERT，分别用于检索和相关任务，它们都达到了与BERT基模型接近或相当的性能。该模型遵循师生框架进行训练，并使用一个主要搜索引擎的数据进行评估。实验结果表明，在cpu上，推理时间明显缩短，并首先控制在20ms左右，同时保留了微调BERT基模型的性能增益。将这些模型集成到生产系统中也证明了相关性度量的显著改进，对延迟的影响可以忽略不计。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06275">PDF</a>
<h3>No. 44	用于人脸识别的深卷积神经网络编码中的单单元状态：稀疏性的重新定义</h3><h4>Connor J. Parde, Y. Ivette Colón, Matthew Q. Hill, Carlos D. Castillo, Prithviraj Dhar, Alice J. O'Toole</h4>文摘：用于人脸识别的深卷积神经网络（DCNNs）在保留被试（如性别）和图像（如视点）信息的同时，发展了对可变图像的泛化表示。在人脸识别网络的“神经单元”和集成层上研究了身份、性别和视点编码。在单元层次上，通过删除单元在顶层创建可变大小的随机采样子空间来测量识别、性别分类和视点估计。3531个身份的识别仍然很高（ROC下面积约1），随着维度的下降，从512个单位减少到16个（0.95）、4个（0.80个）和2个（0.72个）单元。在每一个顶层单元上都有统计上分离的个体身份。跨单位反应的相关性最小，表明单位编码非冗余的身份线索。这种“分布式”代码只需要一个稀疏的、随机的单元样本就可以准确地识别人脸。随着维度的降低，性别分类逐渐下降，观点估计急剧下降。个体单位对性别和观点的预测能力很弱，但合奏被证明是有效的预测因素。因此，分布式和稀疏代码共存于网络单元中，以表示不同的面部属性。在集成层次上，人脸表示的主成分分析表明，身份、性别和视点信息被分解成高维子空间，按解释方差排序。身份、性别和观点信息对所有个体的反应都有贡献，削弱了面部特征的神经调节类比。从DCNNs和类似的高级视觉编码中对类神经编码的解释，不能从单个单位的反应中推断出来。相反，“意义”是由高维空间中的方向编码的。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06274">PDF</a>
<h3>No. 45	社会WaGDAT：基于Wasserstein图双注意网络的交互感知轨迹预测</h3><h4>Jiachen Li, Hengbo Ma, Zhihao Zhang, Masayoshi Tomizuka</h4>文摘：智能移动系统（如自主车辆和社会机器人）在高度交互性和拥挤的场景中导航时，对环境的有效理解和对周围动态障碍物的准确轨迹预测是实现安全、高质量规划的必要条件。由于场景演化中频繁交互和不确定性的存在，期望预测系统能够在不同实体上进行关系推理，并为每个代理提供未来轨迹的分布。本文提出了一个通用的多智能体轨迹预测生成神经系统（Social WaGDAT），该系统通过将关联归纳偏差与动态图表示相结合，同时利用轨迹和场景上下文信息，向显式交互建模迈进了一步。我们还采用了一个有效的运动约束层应用于车辆轨迹预测，不仅保证了物理上的可行性，而且提高了模型的性能。该系统在三个公共基准数据集上进行评估，用于轨迹预测，其中代理包括行人、骑自行车者和道路车辆。实验结果表明，该模型在预测精度方面优于各种基线方法。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06241">PDF</a>
<h3>No. 46	增强的局部敏感哈希：用于源分离的区分二进制代码</h3><h4>Sunwoo Kim, Haici Yang, Minje Kim</h4>摘要：随着深度学习技术的进步，语音增强任务得到了显著的改善，但是计算复杂度的增加也带来了代价。在本研究中，我们提出一种自适应的boosting方法来学习局部敏感的杂凑码，以有效地表示音频频谱。我们将学习的散列码用于单通道语音去噪任务，以替代复杂的机器学习模型，特别是解决资源受限的环境。我们的自适应boosting算法学习简单的logistic回归作为弱学习者。经过训练，他们的二值分类结果将每个测试噪声语音谱转换成一个位串。简单的位运算计算Hamming距离，在训练有噪语音谱的字典中找到K-最近匹配帧，其相关的理想二值掩码被平均以估计该测试混合的去噪掩码。我们提出的学习算法与AdaBoost的不同之处在于，训练投影的目的是最小化散列码的自相似矩阵与原始谱的自相似矩阵之间的距离，而不是降低误分类率。我们评估我们的歧视性哈希码的TIMIT语料库与各种噪声类型，并表现出比较深刻的学习方法在降噪性能和复杂性方面的性能。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06239">PDF</a>
<h3>No. 47	波斯语社交媒体中情感分析的卷积神经网络</h3><h4>Morteza Rohanian, Mostafa Salehi, Ali Darzi, Vahid Ranjbar</h4>摘要：随着社会化媒体参与度的不断提高，由此产生的数据可以作为分析和理解我们周围不同现象的丰富资源。情绪分析系统利用这些数据来发现社交媒体用户对给定文档中某些实体的态度。本文提出了一种基于前向人工神经网络卷积神经网络（CNN）的波斯语文本情感分析方法，该方法通过不同的滤波器对输入数据进行一层卷积，将句子分为两类和五类（考虑其强度）。我们使用曲线下面积度量对三个不同的波斯社交媒体文本数据集进行了评估。最后的结果显示了使用CNN在开发波斯文本情感分类特别是短文本的传统机器学习方法方面的优势。<br><a href = "http://xxx.itp.ac.cn/pdf/2002.06233">PDF</a>
<h3>No. 48	分段凸函数估计与模型选择</h3><h4>Kurt S. Riedel</h4>文摘：在给定噪声数据的情况下，当未知函数先验地由少数凸或凹区域组成时，考虑函数估计。当区域先验已知时，该估计在对偶空间中降为有限维凸优化。当区域的数目未知时，模型选择问题是确定凸性变化点的数目。我们使用基于期望的假拐点数目的导频估计器。<br><a href = "http://xxx.itp.ac.cn/pdf/1803.03903">PDF</a>
</body></html>